{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "from math import log10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hmm tagger 2\n",
    "\n",
    "following https://github.com/RahulGuptaIIITA/HMM-POS-Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMMLearn:\n",
    "    \n",
    "    def __init__(self, model_path = \"hmmmodel.txt\"):\n",
    "        \n",
    "        self.model_path = model_path\n",
    "        # variables to keep the word/tags and tag/tag\n",
    "        self.tag_tag_dict = dict()\n",
    "        self.word_tag_dict= dict()\n",
    "\n",
    "        # variables to keep the counts\n",
    "        self.unique_tags_count_dict = dict()\n",
    "        \n",
    "        # variables to keep the probabilities\n",
    "        self.emission_probabilities = dict()\n",
    "        self.transition_probabilities = dict()\n",
    "        \n",
    "        return\n",
    "\n",
    "    def calculate_probabilities(self):\n",
    "        \n",
    "        # emission probability\n",
    "        for key, value in self.word_tag_dict.items():\n",
    "            var_array = key.split(\"/\")\n",
    "            tag = var_array[-1]\n",
    "            self.emission_probabilities[key] = value / float(self.unique_tags_count_dict[tag])\n",
    "        \n",
    "        # transition probability\n",
    "        for key, value in self.tag_tag_dict.items():\n",
    "            prev_tag = key.split(\"/\")[0]\n",
    "            exclude_tag = prev_tag + \"/<~s>\"\n",
    "            exclude_prob = self.tag_tag_dict[exclude_tag] if exclude_tag in self.tag_tag_dict else 0\n",
    "            self.transition_probabilities[key] = (1+value) / float(len(self.unique_tags_count_dict) + self.unique_tags_count_dict[prev_tag] - exclude_prob)\n",
    "            \n",
    "        return\n",
    "\n",
    "    def save_model(self):\n",
    "        file_object = open(self.model_path, \"w\")\n",
    "    \n",
    "        for string, prob in self.emission_probabilities.items():\n",
    "            file_object.write(\"em \" + string + \" \" + str(prob))\n",
    "            file_object.write(\"\\n\")\n",
    "    \n",
    "        for string, prob in self.transition_probabilities.items():\n",
    "            file_object.write(\"tr \" + string + \" \" + str(prob))\n",
    "            file_object.write(\"\\n\")\n",
    "    \n",
    "        for tag, count in self.unique_tags_count_dict.items():\n",
    "            exclude_count = 0\n",
    "            if tag + \"/<~s>\" in self.tag_tag_dict:\n",
    "                exclude_count = self.tag_tag_dict[tag + \"/<~s>\"]\n",
    "            file_object.write(\"tg \" + tag + \" \" + str(count - exclude_count))\n",
    "            file_object.write(\"\\n\")\n",
    "            \n",
    "        file_object.close()\n",
    "    \n",
    "        return\n",
    "    \n",
    "    def parse_sentence(self, sentence):\n",
    "        \n",
    "        previous = \"<s>\"\n",
    "        previous = previous.strip()\n",
    "        if previous not in self.unique_tags_count_dict:\n",
    "            self.unique_tags_count_dict[previous] = 0\n",
    "        self.unique_tags_count_dict[previous] += 1\n",
    "        \n",
    "        word_tags = sentence.split(\" \")\n",
    "        \n",
    "        for i, word_tag in enumerate(word_tags):\n",
    "            word_tag = word_tag.strip()\n",
    "            var_array = word_tag.split(\"/\")\n",
    "            tag = var_array[-1]\n",
    "            tag = tag.strip()\n",
    "            \n",
    "            if tag not in self.unique_tags_count_dict:\n",
    "                self.unique_tags_count_dict[tag] = 0\n",
    "            self.unique_tags_count_dict[tag] += 1\n",
    "            \n",
    "            if word_tag not in self.word_tag_dict:\n",
    "                self.word_tag_dict[word_tag] = 0\n",
    "            self.word_tag_dict[word_tag] += 1\n",
    "            \n",
    "            if previous + \"/\" + tag not in self.tag_tag_dict:\n",
    "                self.tag_tag_dict[previous + \"/\" + tag] = 0\n",
    "            self.tag_tag_dict[previous + \"/\" + tag] += 1\n",
    "            \n",
    "            previous = tag\n",
    "        \n",
    "        if previous + \"/<~s>\" not in self.tag_tag_dict:\n",
    "            self.tag_tag_dict[previous + \"/<~s>\"] = 0\n",
    "        self.tag_tag_dict[previous + \"/<~s>\"] += 1\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def run(self, infile):\n",
    "        try:\n",
    "            with open(infile) as file:\n",
    "                sentences = file.readlines()\n",
    "                for sentence in sentences:\n",
    "                    self.parse_sentence(sentence)\n",
    "            \n",
    "            self.calculate_probabilities()\n",
    "            self.save_model()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "            \n",
    "        return\n",
    "\n",
    "model_path = './github/HMM-POS-Tagger/hmmmodel.txt'\n",
    "training_file = './github/HMM-POS-Tagger/data/en_train_tagged.txt'\n",
    "hmm_learn_object = HMMLearn(model_path)\n",
    "hmm_learn_object.run(training_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time it took 7.179669380187988s\n"
     ]
    }
   ],
   "source": [
    "class HMMDecode:\n",
    "    \n",
    "    def __init__(self, model_path = \"hmmmodel.txt\"):\n",
    "        \n",
    "        self.model_path = model_path\n",
    "        # variables to keep possible tags and words\n",
    "        self.possible_tags = set()\n",
    "        self.possible_words = set()\n",
    "        \n",
    "        # variable to keep possible tags count\n",
    "        self.possible_tags_count = dict()\n",
    "        \n",
    "        # variables to keep the probabilities\n",
    "        self.emission_probabilities = dict()\n",
    "        self.transition_probabilities = dict()\n",
    "\n",
    "        with open(self.model_path) as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                var_array = line.split(\" \")\n",
    "                if var_array[0] == \"em\":\n",
    "                    self.emission_probabilities[var_array[1]] = float(var_array[2].strip())\n",
    "                    word_tag = var_array[1]\n",
    "                    word = word_tag.rsplit(\"/\")[0]\n",
    "                    self.possible_words.add(word)\n",
    "        \n",
    "                elif var_array[0] == \"tr\":\n",
    "                    self.transition_probabilities[var_array[1]] = float(var_array[2].strip())\n",
    "        \n",
    "                elif var_array[0] == \"tg\":\n",
    "                    self.possible_tags.add(var_array[1].strip())\n",
    "                    self.possible_tags_count[var_array[1]] = int(var_array[2].strip())\n",
    "        return\n",
    "        \n",
    "    def smooth_probabilities(self, word, prev_tag, cur_tag):\n",
    "        \n",
    "        if (prev_tag + \"/\" + cur_tag) not in self.transition_probabilities:\n",
    "            tr_prob = 1 / float(len(self.possible_tags) + self.possible_tags_count[prev_tag])\n",
    "        else:\n",
    "            tr_prob = self.transition_probabilities[prev_tag + \"/\" + cur_tag]\n",
    "        \n",
    "        if word not in self.possible_words:\n",
    "            em_prob = 1\n",
    "        elif (word + \"/\" + cur_tag) not in self.emission_probabilities:\n",
    "            em_prob = 0\n",
    "        else:\n",
    "            em_prob = self.emission_probabilities[word + \"/\" + cur_tag]\n",
    "            \n",
    "        return em_prob, tr_prob\n",
    "    \n",
    "    def viterbi_algorithm(self, sentence):\n",
    "        best_edge = dict()\n",
    "        best_score = dict()\n",
    "        words = sentence.split(\" \")\n",
    "        words = [word.strip() for word in words]\n",
    "       \n",
    "        for tag in self.possible_tags:\n",
    "            em_prob, tr_prob = self.smooth_probabilities(words[0], \"<s>\", tag)\n",
    "            best_score[(words[0], tag, 0)] = em_prob * tr_prob\n",
    "            best_edge[(words[0], tag, 0)] = \"<s>\"\n",
    "\n",
    "        for i in range(1, len(words)):\n",
    "            for cur_tag in self.possible_tags:\n",
    "                temp_score = 0\n",
    "                if (words[i] in self.possible_words) and ((words[i] + \"/\" + cur_tag) not in self.emission_probabilities):\n",
    "                    best_score[(words[i], cur_tag, i)] = temp_score\n",
    "                else:\n",
    "                    for prev_tag in self.possible_tags:\n",
    "                        em_prob, tr_prob = self.smooth_probabilities(words[i], prev_tag, cur_tag)\n",
    "                        score = best_score[(words[i-1], prev_tag, i-1)] * em_prob * tr_prob\n",
    "                        best_score[(words[i], cur_tag, i)] = temp_score\n",
    "                        \n",
    "                        if score > temp_score:\n",
    "                            temp_score = score\n",
    "                            best_score[(words[i], cur_tag, i)] = score\n",
    "                            best_edge[(words[i], cur_tag, i)] = prev_tag\n",
    "        score = 0\n",
    "        best_tag = None\n",
    "        tagged_sentence = []\n",
    "        nth_word = words[-1]\n",
    "        words_length = len(words) - 1\n",
    "        for tag in self.possible_tags:\n",
    "            if best_score[(nth_word, tag, words_length)] > score:\n",
    "                score = best_score[(nth_word, tag, words_length)]\n",
    "                best_tag = tag\n",
    "        tagged_sentence.append((nth_word, best_tag))\n",
    "        \n",
    "        for i in range(len(words) - 2, -1, -1):\n",
    "            tagged_sentence.append((words[i], best_edge[(words[i+1], best_tag, i+1)]))\n",
    "            best_tag = best_edge[(words[i+1], best_tag, i+1)]\n",
    "            \n",
    "        return tagged_sentence\n",
    "    \n",
    "    def tag_sentence(self, sentence, file_object):\n",
    "        tagged_sentence = self.viterbi_algorithm(sentence)\n",
    "        tagged_sentence = tagged_sentence[::-1]\n",
    "        \n",
    "        lnth = len(tagged_sentence)\n",
    "        for i, word_tag in enumerate(tagged_sentence):\n",
    "            word = word_tag[0]\n",
    "            tag = word_tag[1]\n",
    "            file_object.write(word + \"/\" + tag)\n",
    "            if i != lnth - 1:\n",
    "                file_object.write(\" \")\n",
    "        \n",
    "        file_object.write(\"\\n\")\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def run(self, infile, outfile):\n",
    "        try:\n",
    "            file_object = open(outfile, \"w\")\n",
    "            with open(infile) as file:\n",
    "                sentences = file.readlines()\n",
    "                for i, sentence in enumerate(sentences):\n",
    "                    self.tag_sentence(sentence, file_object)\n",
    "            \n",
    "            file_object.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "    \n",
    "        return\n",
    "    def predict(self, sentence):\n",
    "        tagged_sentence = self.viterbi_algorithm(sentence)\n",
    "        tagged_sentence = tagged_sentence[::-1]\n",
    "        return tagged_sentence\n",
    "    \n",
    "output_file = './github/HMM-POS-Tagger/en_dev_predict.txt'\n",
    "testing_file = './github/HMM-POS-Tagger/data/en_dev_raw.txt'\n",
    "\n",
    "hmm_decode_object = HMMDecode(model_path)\n",
    "\n",
    "start_time = time.time()\n",
    "hmm_decode_object.run(testing_file, output_file)\n",
    "print (\"total time it took {}s\".format(time.time() - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('He', 'PRP'), ('is', 'VBZ'), ('great.', 'RB')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_decode_object.predict('He is great.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_ground_truth = './github/HMM-POS-Tagger/data/en_dev_tagged.txt'\n",
    "testing_ground_truth_seq = ''\n",
    "with open(testing_ground_truth) as f:\n",
    "    for line in f.readlines():\n",
    "        testing_ground_truth_seq = testing_ground_truth_seq + ' ' + line.rstrip('\\n')\n",
    "testing_ground_truth_seq = testing_ground_truth_seq.lstrip(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_predict_file = './github/HMM-POS-Tagger/en_dev_predict.txt'\n",
    "testing_predict_seq = ''\n",
    "with open(testing_predict_file) as f:\n",
    "    for line in f.readlines():\n",
    "        testing_predict_seq = testing_predict_seq + ' ' + line.rstrip('\\n')\n",
    "testing_predict_seq = testing_predict_seq.lstrip(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_ground_truth_list = testing_ground_truth_seq.split(' ')\n",
    "testing_predict_list = testing_predict_seq.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.81215205980595\n"
     ]
    }
   ],
   "source": [
    "correct_idx = [i for i, j in zip(testing_ground_truth_list, testing_predict_list) if i == j] \n",
    " \n",
    "accuracy = len(correct_idx)/len(testing_ground_truth_list)\n",
    "print('Accuracy:',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1704539"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_file = './github/HMM-POS-Tagger/data/en_train_tagged.txt'\n",
    "training_seq = ''\n",
    "with open(training_file) as f:\n",
    "    for line in f.readlines():\n",
    "        training_seq = training_seq + ' ' + line.rstrip('\\n')\n",
    "training_seq = training_seq.lstrip(' ')\n",
    "len(training_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25148"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testing_ground_truth_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
