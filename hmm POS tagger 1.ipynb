{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pprint, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hmm tagger 1\n",
    "Following https://www.mygreatlearning.com/blog/pos-tagging/\n",
    "\n",
    "Takes 1h30m to get accuracy on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to /home/joey/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package brown to /home/joey/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /home/joey/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('treebank')\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NN', 13166),\n",
       " ('IN', 9857),\n",
       " ('NNP', 9410),\n",
       " ('DT', 8165),\n",
       " ('-NONE-', 6592),\n",
       " ('NNS', 6047),\n",
       " ('JJ', 5834),\n",
       " (',', 4886),\n",
       " ('.', 3874),\n",
       " ('CD', 3546),\n",
       " ('VBD', 3043),\n",
       " ('RB', 2822),\n",
       " ('VB', 2554),\n",
       " ('CC', 2265),\n",
       " ('TO', 2179),\n",
       " ('VBN', 2134),\n",
       " ('VBZ', 2125),\n",
       " ('PRP', 1716),\n",
       " ('VBG', 1460),\n",
       " ('VBP', 1321),\n",
       " ('MD', 927),\n",
       " ('POS', 824),\n",
       " ('PRP$', 766),\n",
       " ('$', 724),\n",
       " ('``', 712),\n",
       " (\"''\", 694),\n",
       " (':', 563),\n",
       " ('WDT', 445),\n",
       " ('JJR', 381),\n",
       " ('NNPS', 244),\n",
       " ('WP', 241),\n",
       " ('RP', 216),\n",
       " ('JJS', 182),\n",
       " ('WRB', 178),\n",
       " ('RBR', 136),\n",
       " ('-RRB-', 126),\n",
       " ('-LRB-', 120),\n",
       " ('EX', 88),\n",
       " ('RBS', 35),\n",
       " ('PDT', 27),\n",
       " ('#', 16),\n",
       " ('WP$', 14),\n",
       " ('LS', 13),\n",
       " ('FW', 4),\n",
       " ('UH', 3),\n",
       " ('SYM', 1)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treebank = list(nltk.corpus.treebank.tagged_words())\n",
    "tag_fd = nltk.FreqDist(tag for (word, tag) in treebank)\n",
    "tag_fd.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "treebank = list(nltk.corpus.treebank.tagged_sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Pierre', 'NNP')\n",
      "('Vinken', 'NNP')\n",
      "(',', ',')\n",
      "('61', 'CD')\n",
      "('years', 'NNS')\n",
      "('old', 'JJ')\n",
      "(',', ',')\n",
      "('will', 'MD')\n",
      "('join', 'VB')\n",
      "('the', 'DT')\n",
      "('board', 'NN')\n",
      "('as', 'IN')\n",
      "('a', 'DT')\n",
      "('nonexecutive', 'JJ')\n",
      "('director', 'NN')\n",
      "('Nov.', 'NNP')\n",
      "('29', 'CD')\n",
      "('.', '.')\n",
      "('Mr.', 'NNP')\n",
      "('Vinken', 'NNP')\n",
      "('is', 'VBZ')\n",
      "('chairman', 'NN')\n",
      "('of', 'IN')\n",
      "('Elsevier', 'NNP')\n",
      "('N.V.', 'NNP')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('Dutch', 'NNP')\n",
      "('publishing', 'VBG')\n",
      "('group', 'NN')\n",
      "('.', '.')\n"
     ]
    }
   ],
   "source": [
    "for sent in treebank[:2]:\n",
    "    for tuple in sent:\n",
    "        print(tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set,test_set =train_test_split(treebank,train_size=0.80,test_size=0.20,random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80310\n",
      "20366\n"
     ]
    }
   ],
   "source": [
    "train_tagged_words = [ tup for sent in train_set for tup in sent ]\n",
    "test_tagged_words = [ tup for sent in test_set for tup in sent ]\n",
    "test_words = [tup[0] for sent in test_set for tup in sent]\n",
    "test_tags = [tup[1] for sent in test_set for tup in sent]\n",
    "\n",
    "print(len(train_tagged_words))\n",
    "print(len(test_tagged_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "{'``', ':', 'JJR', ',', 'NNS', '-RRB-', 'JJS', 'UH', 'RBR', 'JJ', 'LS', 'RBS', 'PRP', 'WDT', '$', 'PRP$', '#', 'RB', \"''\", 'CD', 'MD', 'VBN', 'WP', 'VBP', 'VBG', 'CC', 'VB', '.', 'NN', 'DT', 'TO', '-LRB-', 'RP', 'VBZ', 'FW', 'IN', 'POS', 'WRB', 'WP$', 'VBD', 'NNPS', 'EX', 'NNP', 'PDT', '-NONE-'}\n"
     ]
    }
   ],
   "source": [
    "tags = {tag for word,tag in train_tagged_words}\n",
    "print(len(tags))\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {word for word,tag in train_tagged_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_given_tag(word, tag, train_bag = train_tagged_words):\n",
    "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
    "    count_tag = len(tag_list)#total number of times the passed tag occurred in train_bag\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "    #now calculate the total number of times the passed word occurred as the passed tag.\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "     \n",
    "    return (count_w_given_tag, count_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t2_given_t1(t2, t1, train_bag = train_tagged_words):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0000000e+00 0.0000000e+00 1.7543860e-03 ... 6.8421051e-02\n",
      "  0.0000000e+00 3.3333335e-02]\n",
      " [5.1224943e-02 0.0000000e+00 4.4543431e-03 ... 1.7371938e-01\n",
      "  0.0000000e+00 3.3407573e-02]\n",
      " [0.0000000e+00 6.4724921e-03 0.0000000e+00 ... 9.7087380e-03\n",
      "  0.0000000e+00 1.9417476e-02]\n",
      " ...\n",
      " [5.4083287e-04 8.1124930e-03 1.3520822e-04 ... 3.7817740e-01\n",
      "  0.0000000e+00 5.6787455e-03]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [2.3125843e-03 6.7450376e-03 1.7344382e-03 ... 3.9313935e-02\n",
      "  0.0000000e+00 7.5929850e-02]]\n"
     ]
    }
   ],
   "source": [
    "tags_matrix = np.zeros((len(tags), len(tags)), dtype='float32')\n",
    "for i, t1 in enumerate(list(tags)):\n",
    "    for j, t2 in enumerate(list(tags)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]\n",
    "\n",
    "print(tags_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tags = pd.DataFrame(tags_matrix, columns = list(tags), index=list(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "     \n",
    "    for key, word in enumerate(tqdm(words)):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = df_tags.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = df_tags.loc[state[-1], tag]\n",
    "                 \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "             \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef9769f64ec847b1b54a977bfe190eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20366.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Viterbi Algorithm Accuracy:  0.0\n"
     ]
    }
   ],
   "source": [
    "tagged_seq = Viterbi(test_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viterbi Algorithm Accuracy:  87.62643621722479\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "correct_idx = [i for i, j in zip(tagged_seq, test_tagged_words) if i == j] \n",
    " \n",
    "accuracy = len(correct_idx)/len(tagged_seq)\n",
    "print('Viterbi Algorithm Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06592"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6592/100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
