{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.optim.adam import Adam\n",
    "from flair.data import Corpus\n",
    "from flair.datasets import CSVClassificationCorpus\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings,  TransformerWordEmbeddings, TransformerDocumentEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 01:57:39,711 Reading data from dataset/Spooky Author Identification/split\n",
      "2020-10-22 01:57:39,712 Train: dataset/Spooky Author Identification/split/train.csv\n",
      "2020-10-22 01:57:39,712 Dev: dataset/Spooky Author Identification/split/dev.csv\n",
      "2020-10-22 01:57:39,713 Test: dataset/Spooky Author Identification/split/test.csv\n",
      "2020-10-22 01:57:39,767 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15668/15668 [00:02<00:00, 5498.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 01:57:42,736 [b'EAP', b'MWS', b'HPL']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# this is the folder in which train, test and dev files reside\n",
    "data_folder = './dataset/Spooky Author Identification/split/'\n",
    "\n",
    "# column format indicating which columns hold the text and label(s)\n",
    "column_name_map = {2: \"text\", 3: \"label\"}\n",
    "\n",
    "# load corpus containing training, test and dev data and if CSV has a header, you can skip it\n",
    "corpus: Corpus = CSVClassificationCorpus(data_folder,\n",
    "                                         column_name_map,\n",
    "                                         skip_header=True,\n",
    "                                         delimiter=',',    # tab-separated files\n",
    ") \n",
    "label_dict = corpus.make_label_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"TRAIN\": {\n",
      "        \"dataset\": \"TRAIN\",\n",
      "        \"total_number_of_documents\": 11762,\n",
      "        \"number_of_documents_per_class\": {\n",
      "            \"EAP\": 4780,\n",
      "            \"MWS\": 3642,\n",
      "            \"HPL\": 3340\n",
      "        },\n",
      "        \"number_of_tokens_per_tag\": {},\n",
      "        \"number_of_tokens\": {\n",
      "            \"total\": 354144,\n",
      "            \"min\": 4,\n",
      "            \"max\": 446,\n",
      "            \"avg\": 30.109165107974835\n",
      "        }\n",
      "    },\n",
      "    \"TEST\": {\n",
      "        \"dataset\": \"TEST\",\n",
      "        \"total_number_of_documents\": 3906,\n",
      "        \"number_of_documents_per_class\": {\n",
      "            \"EAP\": 1554,\n",
      "            \"HPL\": 1142,\n",
      "            \"MWS\": 1210\n",
      "        },\n",
      "        \"number_of_tokens_per_tag\": {},\n",
      "        \"number_of_tokens\": {\n",
      "            \"total\": 120056,\n",
      "            \"min\": 4,\n",
      "            \"max\": 875,\n",
      "            \"avg\": 30.736303123399896\n",
      "        }\n",
      "    },\n",
      "    \"DEV\": {\n",
      "        \"dataset\": \"DEV\",\n",
      "        \"total_number_of_documents\": 3911,\n",
      "        \"number_of_documents_per_class\": {\n",
      "            \"HPL\": 1153,\n",
      "            \"EAP\": 1566,\n",
      "            \"MWS\": 1192\n",
      "        },\n",
      "        \"number_of_tokens_per_tag\": {},\n",
      "        \"number_of_tokens\": {\n",
      "            \"total\": 120046,\n",
      "            \"min\": 4,\n",
      "            \"max\": 597,\n",
      "            \"avg\": 30.69445154691895\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(corpus.obtain_statistics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-21 23:29:36,541 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:29:36,541 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (rnn): GRU(100, 256, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=256, out_features=3, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2020-10-21 23:29:36,542 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:29:36,542 Corpus: \"Corpus: 11762 train + 3911 dev + 3906 test sentences\"\n",
      "2020-10-21 23:29:36,543 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:29:36,543 Parameters:\n",
      "2020-10-21 23:29:36,543  - learning_rate: \"0.1\"\n",
      "2020-10-21 23:29:36,544  - mini_batch_size: \"32\"\n",
      "2020-10-21 23:29:36,544  - patience: \"5\"\n",
      "2020-10-21 23:29:36,544  - anneal_factor: \"0.5\"\n",
      "2020-10-21 23:29:36,545  - max_epochs: \"150\"\n",
      "2020-10-21 23:29:36,545  - shuffle: \"True\"\n",
      "2020-10-21 23:29:36,545  - train_with_dev: \"False\"\n",
      "2020-10-21 23:29:36,546  - batch_growth_annealing: \"False\"\n",
      "2020-10-21 23:29:36,546 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:29:36,546 Model training base path: \"classifiers/spooky_authorship_classifier\"\n",
      "2020-10-21 23:29:36,547 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:29:36,547 Device: cuda:0\n",
      "2020-10-21 23:29:36,547 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:29:36,548 Embeddings storage mode: cpu\n",
      "2020-10-21 23:29:36,550 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:29:38,701 epoch 1 - iter 36/368 - loss 1.13630687 - samples/sec: 619.29 - lr: 0.100000\n",
      "2020-10-21 23:29:40,577 epoch 1 - iter 72/368 - loss 1.11591681 - samples/sec: 639.87 - lr: 0.100000\n",
      "2020-10-21 23:29:42,384 epoch 1 - iter 108/368 - loss 1.10432425 - samples/sec: 663.84 - lr: 0.100000\n",
      "2020-10-21 23:29:45,815 epoch 1 - iter 144/368 - loss 1.09855903 - samples/sec: 727.39 - lr: 0.100000\n",
      "2020-10-21 23:29:47,398 epoch 1 - iter 180/368 - loss 1.09184504 - samples/sec: 760.25 - lr: 0.100000\n",
      "2020-10-21 23:29:49,032 epoch 1 - iter 216/368 - loss 1.08405807 - samples/sec: 738.01 - lr: 0.100000\n",
      "2020-10-21 23:29:51,058 epoch 1 - iter 252/368 - loss 1.07898585 - samples/sec: 587.94 - lr: 0.100000\n",
      "2020-10-21 23:29:52,974 epoch 1 - iter 288/368 - loss 1.07606168 - samples/sec: 622.68 - lr: 0.100000\n",
      "2020-10-21 23:29:54,938 epoch 1 - iter 324/368 - loss 1.07242860 - samples/sec: 608.67 - lr: 0.100000\n",
      "2020-10-21 23:29:56,911 epoch 1 - iter 360/368 - loss 1.06902977 - samples/sec: 605.79 - lr: 0.100000\n",
      "2020-10-21 23:29:57,370 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:29:57,371 EPOCH 1 done: loss 1.0694 - lr 0.1000000\n",
      "2020-10-21 23:30:05,644 DEV : loss 0.9999428391456604 - score 0.5098\n",
      "2020-10-21 23:30:07,564 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-21 23:30:09,164 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:30:11,260 epoch 2 - iter 36/368 - loss 1.03801403 - samples/sec: 636.74 - lr: 0.100000\n",
      "2020-10-21 23:30:13,056 epoch 2 - iter 72/368 - loss 1.03530278 - samples/sec: 666.85 - lr: 0.100000\n",
      "2020-10-21 23:30:14,785 epoch 2 - iter 108/368 - loss 1.02453946 - samples/sec: 695.28 - lr: 0.100000\n",
      "2020-10-21 23:30:18,579 epoch 2 - iter 144/368 - loss 1.02866353 - samples/sec: 729.76 - lr: 0.100000\n",
      "2020-10-21 23:30:20,204 epoch 2 - iter 180/368 - loss 1.02734939 - samples/sec: 737.51 - lr: 0.100000\n",
      "2020-10-21 23:30:21,819 epoch 2 - iter 216/368 - loss 1.02552482 - samples/sec: 746.07 - lr: 0.100000\n",
      "2020-10-21 23:30:23,505 epoch 2 - iter 252/368 - loss 1.02238747 - samples/sec: 711.91 - lr: 0.100000\n",
      "2020-10-21 23:30:25,217 epoch 2 - iter 288/368 - loss 1.02174925 - samples/sec: 698.56 - lr: 0.100000\n",
      "2020-10-21 23:30:26,868 epoch 2 - iter 324/368 - loss 1.01963048 - samples/sec: 726.97 - lr: 0.100000\n",
      "2020-10-21 23:30:28,606 epoch 2 - iter 360/368 - loss 1.01840139 - samples/sec: 689.41 - lr: 0.100000\n",
      "2020-10-21 23:30:29,045 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:30:29,045 EPOCH 2 done: loss 1.0190 - lr 0.1000000\n",
      "2020-10-21 23:30:37,250 DEV : loss 1.0232622623443604 - score 0.4845\n",
      "2020-10-21 23:30:39,176 BAD EPOCHS (no improvement): 1\n",
      "2020-10-21 23:30:39,177 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:30:41,277 epoch 3 - iter 36/368 - loss 0.99472011 - samples/sec: 650.16 - lr: 0.100000\n",
      "2020-10-21 23:30:43,031 epoch 3 - iter 72/368 - loss 0.98876608 - samples/sec: 685.74 - lr: 0.100000\n",
      "2020-10-21 23:30:44,748 epoch 3 - iter 108/368 - loss 0.98541932 - samples/sec: 701.32 - lr: 0.100000\n",
      "2020-10-21 23:30:46,505 epoch 3 - iter 144/368 - loss 0.98650721 - samples/sec: 688.25 - lr: 0.100000\n",
      "2020-10-21 23:30:50,180 epoch 3 - iter 180/368 - loss 0.98497248 - samples/sec: 800.25 - lr: 0.100000\n",
      "2020-10-21 23:30:51,650 epoch 3 - iter 216/368 - loss 0.98517073 - samples/sec: 821.69 - lr: 0.100000\n",
      "2020-10-21 23:30:53,269 epoch 3 - iter 252/368 - loss 0.98066132 - samples/sec: 742.90 - lr: 0.100000\n",
      "2020-10-21 23:30:54,874 epoch 3 - iter 288/368 - loss 0.97943068 - samples/sec: 747.61 - lr: 0.100000\n",
      "2020-10-21 23:30:56,562 epoch 3 - iter 324/368 - loss 0.98191494 - samples/sec: 711.85 - lr: 0.100000\n",
      "2020-10-21 23:30:58,164 epoch 3 - iter 360/368 - loss 0.98005984 - samples/sec: 750.29 - lr: 0.100000\n",
      "2020-10-21 23:30:58,603 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:30:58,605 EPOCH 3 done: loss 0.9793 - lr 0.1000000\n",
      "2020-10-21 23:31:06,930 DEV : loss 0.9181423187255859 - score 0.5687\n",
      "2020-10-21 23:31:08,834 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-21 23:31:10,439 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:31:12,614 epoch 4 - iter 36/368 - loss 0.96599467 - samples/sec: 618.47 - lr: 0.100000\n",
      "2020-10-21 23:31:14,326 epoch 4 - iter 72/368 - loss 0.95274332 - samples/sec: 708.75 - lr: 0.100000\n",
      "2020-10-21 23:31:15,955 epoch 4 - iter 108/368 - loss 0.95858310 - samples/sec: 731.68 - lr: 0.100000\n",
      "2020-10-21 23:31:17,688 epoch 4 - iter 144/368 - loss 0.95542895 - samples/sec: 691.08 - lr: 0.100000\n",
      "2020-10-21 23:31:19,300 epoch 4 - iter 180/368 - loss 0.95274808 - samples/sec: 744.21 - lr: 0.100000\n",
      "2020-10-21 23:31:23,086 epoch 4 - iter 216/368 - loss 0.95270854 - samples/sec: 746.71 - lr: 0.100000\n",
      "2020-10-21 23:31:24,798 epoch 4 - iter 252/368 - loss 0.95346100 - samples/sec: 699.68 - lr: 0.100000\n",
      "2020-10-21 23:31:26,377 epoch 4 - iter 288/368 - loss 0.95045817 - samples/sec: 759.46 - lr: 0.100000\n",
      "2020-10-21 23:31:28,015 epoch 4 - iter 324/368 - loss 0.95041977 - samples/sec: 733.67 - lr: 0.100000\n",
      "2020-10-21 23:31:29,599 epoch 4 - iter 360/368 - loss 0.95233603 - samples/sec: 758.05 - lr: 0.100000\n",
      "2020-10-21 23:31:30,042 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:31:30,043 EPOCH 4 done: loss 0.9529 - lr 0.1000000\n",
      "2020-10-21 23:31:38,264 DEV : loss 1.2456282377243042 - score 0.3728\n",
      "2020-10-21 23:31:40,163 BAD EPOCHS (no improvement): 1\n",
      "2020-10-21 23:31:40,163 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:31:42,257 epoch 5 - iter 36/368 - loss 0.94126955 - samples/sec: 643.35 - lr: 0.100000\n",
      "2020-10-21 23:31:43,990 epoch 5 - iter 72/368 - loss 0.94372598 - samples/sec: 694.45 - lr: 0.100000\n",
      "2020-10-21 23:31:45,651 epoch 5 - iter 108/368 - loss 0.93407188 - samples/sec: 728.34 - lr: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-21 23:31:47,286 epoch 5 - iter 144/368 - loss 0.93159901 - samples/sec: 738.12 - lr: 0.100000\n",
      "2020-10-21 23:31:48,814 epoch 5 - iter 180/368 - loss 0.93545088 - samples/sec: 787.14 - lr: 0.100000\n",
      "2020-10-21 23:31:52,467 epoch 5 - iter 216/368 - loss 0.93576069 - samples/sec: 786.86 - lr: 0.100000\n",
      "2020-10-21 23:31:53,979 epoch 5 - iter 252/368 - loss 0.93436251 - samples/sec: 794.39 - lr: 0.100000\n",
      "2020-10-21 23:31:55,521 epoch 5 - iter 288/368 - loss 0.93376560 - samples/sec: 777.09 - lr: 0.100000\n",
      "2020-10-21 23:31:57,153 epoch 5 - iter 324/368 - loss 0.93307721 - samples/sec: 734.47 - lr: 0.100000\n",
      "2020-10-21 23:31:58,769 epoch 5 - iter 360/368 - loss 0.92926995 - samples/sec: 742.29 - lr: 0.100000\n",
      "2020-10-21 23:31:59,223 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:31:59,224 EPOCH 5 done: loss 0.9314 - lr 0.1000000\n",
      "2020-10-21 23:32:07,426 DEV : loss 0.8543479442596436 - score 0.6339\n",
      "2020-10-21 23:32:09,326 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-21 23:32:10,918 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:32:12,948 epoch 6 - iter 36/368 - loss 0.92929713 - samples/sec: 653.27 - lr: 0.100000\n",
      "2020-10-21 23:32:14,527 epoch 6 - iter 72/368 - loss 0.92235041 - samples/sec: 761.34 - lr: 0.100000\n",
      "2020-10-21 23:32:16,052 epoch 6 - iter 108/368 - loss 0.91212790 - samples/sec: 788.77 - lr: 0.100000\n",
      "2020-10-21 23:32:17,624 epoch 6 - iter 144/368 - loss 0.91682655 - samples/sec: 766.44 - lr: 0.100000\n",
      "2020-10-21 23:32:19,212 epoch 6 - iter 180/368 - loss 0.91796125 - samples/sec: 756.74 - lr: 0.100000\n",
      "2020-10-21 23:32:22,956 epoch 6 - iter 216/368 - loss 0.91582064 - samples/sec: 755.13 - lr: 0.100000\n",
      "2020-10-21 23:32:24,538 epoch 6 - iter 252/368 - loss 0.91682128 - samples/sec: 759.39 - lr: 0.100000\n",
      "2020-10-21 23:32:26,200 epoch 6 - iter 288/368 - loss 0.91456030 - samples/sec: 720.10 - lr: 0.100000\n",
      "2020-10-21 23:32:27,756 epoch 6 - iter 324/368 - loss 0.91447166 - samples/sec: 773.27 - lr: 0.100000\n",
      "2020-10-21 23:32:29,335 epoch 6 - iter 360/368 - loss 0.91292723 - samples/sec: 759.26 - lr: 0.100000\n",
      "2020-10-21 23:32:29,808 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:32:29,809 EPOCH 6 done: loss 0.9118 - lr 0.1000000\n",
      "2020-10-21 23:32:38,029 DEV : loss 0.8451018333435059 - score 0.6249\n",
      "2020-10-21 23:32:39,936 BAD EPOCHS (no improvement): 1\n",
      "2020-10-21 23:32:39,937 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:32:41,937 epoch 7 - iter 36/368 - loss 0.87045198 - samples/sec: 656.99 - lr: 0.100000\n",
      "2020-10-21 23:32:43,600 epoch 7 - iter 72/368 - loss 0.88867513 - samples/sec: 727.92 - lr: 0.100000\n",
      "2020-10-21 23:32:45,263 epoch 7 - iter 108/368 - loss 0.89374957 - samples/sec: 726.90 - lr: 0.100000\n",
      "2020-10-21 23:32:46,881 epoch 7 - iter 144/368 - loss 0.88592055 - samples/sec: 742.78 - lr: 0.100000\n",
      "2020-10-21 23:32:48,410 epoch 7 - iter 180/368 - loss 0.88734628 - samples/sec: 790.11 - lr: 0.100000\n",
      "2020-10-21 23:32:52,137 epoch 7 - iter 216/368 - loss 0.89178861 - samples/sec: 758.06 - lr: 0.100000\n",
      "2020-10-21 23:32:53,772 epoch 7 - iter 252/368 - loss 0.89544092 - samples/sec: 735.01 - lr: 0.100000\n",
      "2020-10-21 23:32:55,447 epoch 7 - iter 288/368 - loss 0.89549996 - samples/sec: 721.30 - lr: 0.100000\n",
      "2020-10-21 23:32:57,097 epoch 7 - iter 324/368 - loss 0.89835484 - samples/sec: 728.27 - lr: 0.100000\n",
      "2020-10-21 23:32:58,803 epoch 7 - iter 360/368 - loss 0.89929466 - samples/sec: 706.67 - lr: 0.100000\n",
      "2020-10-21 23:32:59,220 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:32:59,221 EPOCH 7 done: loss 0.8991 - lr 0.1000000\n",
      "2020-10-21 23:33:07,488 DEV : loss 0.8209620118141174 - score 0.6349\n",
      "2020-10-21 23:33:09,386 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-21 23:33:11,023 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:33:13,014 epoch 8 - iter 36/368 - loss 0.87162180 - samples/sec: 666.22 - lr: 0.100000\n",
      "2020-10-21 23:33:14,711 epoch 8 - iter 72/368 - loss 0.87530578 - samples/sec: 709.15 - lr: 0.100000\n",
      "2020-10-21 23:33:16,346 epoch 8 - iter 108/368 - loss 0.87536185 - samples/sec: 738.09 - lr: 0.100000\n",
      "2020-10-21 23:33:17,827 epoch 8 - iter 144/368 - loss 0.88846158 - samples/sec: 815.26 - lr: 0.100000\n",
      "2020-10-21 23:33:19,507 epoch 8 - iter 180/368 - loss 0.88099079 - samples/sec: 715.55 - lr: 0.100000\n",
      "2020-10-21 23:33:21,200 epoch 8 - iter 216/368 - loss 0.88381860 - samples/sec: 707.05 - lr: 0.100000\n",
      "2020-10-21 23:33:24,928 epoch 8 - iter 252/368 - loss 0.88487961 - samples/sec: 751.89 - lr: 0.100000\n",
      "2020-10-21 23:33:26,483 epoch 8 - iter 288/368 - loss 0.88446887 - samples/sec: 772.88 - lr: 0.100000\n",
      "2020-10-21 23:33:28,110 epoch 8 - iter 324/368 - loss 0.88411804 - samples/sec: 739.48 - lr: 0.100000\n",
      "2020-10-21 23:33:29,745 epoch 8 - iter 360/368 - loss 0.88332906 - samples/sec: 737.96 - lr: 0.100000\n",
      "2020-10-21 23:33:30,205 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:33:30,206 EPOCH 8 done: loss 0.8819 - lr 0.1000000\n",
      "2020-10-21 23:33:38,521 DEV : loss 0.8540104627609253 - score 0.6305\n",
      "2020-10-21 23:33:40,404 BAD EPOCHS (no improvement): 1\n",
      "2020-10-21 23:33:40,405 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:33:42,479 epoch 9 - iter 36/368 - loss 0.83488378 - samples/sec: 656.32 - lr: 0.100000\n",
      "2020-10-21 23:33:44,090 epoch 9 - iter 72/368 - loss 0.85176373 - samples/sec: 746.43 - lr: 0.100000\n",
      "2020-10-21 23:33:45,756 epoch 9 - iter 108/368 - loss 0.85123037 - samples/sec: 723.03 - lr: 0.100000\n",
      "2020-10-21 23:33:47,375 epoch 9 - iter 144/368 - loss 0.85073858 - samples/sec: 741.98 - lr: 0.100000\n",
      "2020-10-21 23:33:49,003 epoch 9 - iter 180/368 - loss 0.85704963 - samples/sec: 738.83 - lr: 0.100000\n",
      "2020-10-21 23:33:50,624 epoch 9 - iter 216/368 - loss 0.85786047 - samples/sec: 738.44 - lr: 0.100000\n",
      "2020-10-21 23:33:54,352 epoch 9 - iter 252/368 - loss 0.85926994 - samples/sec: 757.52 - lr: 0.100000\n",
      "2020-10-21 23:33:55,987 epoch 9 - iter 288/368 - loss 0.86522506 - samples/sec: 733.23 - lr: 0.100000\n",
      "2020-10-21 23:33:57,641 epoch 9 - iter 324/368 - loss 0.86487892 - samples/sec: 725.26 - lr: 0.100000\n",
      "2020-10-21 23:33:59,128 epoch 9 - iter 360/368 - loss 0.86470686 - samples/sec: 812.42 - lr: 0.100000\n",
      "2020-10-21 23:33:59,559 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:33:59,560 EPOCH 9 done: loss 0.8645 - lr 0.1000000\n",
      "2020-10-21 23:34:07,903 DEV : loss 0.7853684425354004 - score 0.6707\n",
      "2020-10-21 23:34:09,788 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-21 23:34:11,384 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:34:13,363 epoch 10 - iter 36/368 - loss 0.84889092 - samples/sec: 677.40 - lr: 0.100000\n",
      "2020-10-21 23:34:14,998 epoch 10 - iter 72/368 - loss 0.81970751 - samples/sec: 736.90 - lr: 0.100000\n",
      "2020-10-21 23:34:16,606 epoch 10 - iter 108/368 - loss 0.82643313 - samples/sec: 747.76 - lr: 0.100000\n",
      "2020-10-21 23:34:18,247 epoch 10 - iter 144/368 - loss 0.83400981 - samples/sec: 734.24 - lr: 0.100000\n",
      "2020-10-21 23:34:19,843 epoch 10 - iter 180/368 - loss 0.84251489 - samples/sec: 756.92 - lr: 0.100000\n",
      "2020-10-21 23:34:21,464 epoch 10 - iter 216/368 - loss 0.84301661 - samples/sec: 746.97 - lr: 0.100000\n",
      "2020-10-21 23:34:23,152 epoch 10 - iter 252/368 - loss 0.83967302 - samples/sec: 713.77 - lr: 0.100000\n",
      "2020-10-21 23:34:26,905 epoch 10 - iter 288/368 - loss 0.84126651 - samples/sec: 745.11 - lr: 0.100000\n",
      "2020-10-21 23:34:28,478 epoch 10 - iter 324/368 - loss 0.84462870 - samples/sec: 765.90 - lr: 0.100000\n",
      "2020-10-21 23:34:29,990 epoch 10 - iter 360/368 - loss 0.84524782 - samples/sec: 797.60 - lr: 0.100000\n",
      "2020-10-21 23:34:30,425 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:34:30,426 EPOCH 10 done: loss 0.8460 - lr 0.1000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-21 23:34:36,552 DEV : loss 0.8141556978225708 - score 0.6446\n",
      "2020-10-21 23:34:38,455 BAD EPOCHS (no improvement): 1\n",
      "2020-10-21 23:34:38,456 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:34:40,530 epoch 11 - iter 36/368 - loss 0.85544606 - samples/sec: 638.11 - lr: 0.100000\n",
      "2020-10-21 23:34:44,429 epoch 11 - iter 72/368 - loss 0.84553569 - samples/sec: 705.24 - lr: 0.100000\n",
      "2020-10-21 23:34:46,108 epoch 11 - iter 108/368 - loss 0.83701550 - samples/sec: 714.98 - lr: 0.100000\n",
      "2020-10-21 23:34:47,778 epoch 11 - iter 144/368 - loss 0.82869205 - samples/sec: 718.05 - lr: 0.100000\n",
      "2020-10-21 23:34:49,350 epoch 11 - iter 180/368 - loss 0.82934599 - samples/sec: 762.89 - lr: 0.100000\n",
      "2020-10-21 23:34:50,991 epoch 11 - iter 216/368 - loss 0.82982853 - samples/sec: 734.55 - lr: 0.100000\n",
      "2020-10-21 23:34:52,578 epoch 11 - iter 252/368 - loss 0.82439812 - samples/sec: 757.42 - lr: 0.100000\n",
      "2020-10-21 23:34:54,232 epoch 11 - iter 288/368 - loss 0.82741108 - samples/sec: 729.47 - lr: 0.100000\n",
      "2020-10-21 23:34:55,877 epoch 11 - iter 324/368 - loss 0.82590574 - samples/sec: 730.88 - lr: 0.100000\n",
      "2020-10-21 23:34:59,810 epoch 11 - iter 360/368 - loss 0.82795905 - samples/sec: 299.70 - lr: 0.100000\n",
      "2020-10-21 23:35:00,270 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:35:00,271 EPOCH 11 done: loss 0.8284 - lr 0.1000000\n",
      "2020-10-21 23:35:06,659 DEV : loss 0.7375808358192444 - score 0.686\n",
      "2020-10-21 23:35:08,565 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-21 23:35:10,178 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:35:12,277 epoch 12 - iter 36/368 - loss 0.83066874 - samples/sec: 642.73 - lr: 0.100000\n",
      "2020-10-21 23:35:13,882 epoch 12 - iter 72/368 - loss 0.82314292 - samples/sec: 747.37 - lr: 0.100000\n",
      "2020-10-21 23:35:17,652 epoch 12 - iter 108/368 - loss 0.83162633 - samples/sec: 749.79 - lr: 0.100000\n",
      "2020-10-21 23:35:19,265 epoch 12 - iter 144/368 - loss 0.82385136 - samples/sec: 742.54 - lr: 0.100000\n",
      "2020-10-21 23:35:20,726 epoch 12 - iter 180/368 - loss 0.82515666 - samples/sec: 821.47 - lr: 0.100000\n",
      "2020-10-21 23:35:22,324 epoch 12 - iter 216/368 - loss 0.82058894 - samples/sec: 750.41 - lr: 0.100000\n",
      "2020-10-21 23:35:23,975 epoch 12 - iter 252/368 - loss 0.82414798 - samples/sec: 727.66 - lr: 0.100000\n",
      "2020-10-21 23:35:25,688 epoch 12 - iter 288/368 - loss 0.82155354 - samples/sec: 700.96 - lr: 0.100000\n",
      "2020-10-21 23:35:27,303 epoch 12 - iter 324/368 - loss 0.82175956 - samples/sec: 746.13 - lr: 0.100000\n",
      "2020-10-21 23:35:31,221 epoch 12 - iter 360/368 - loss 0.82237856 - samples/sec: 701.88 - lr: 0.100000\n",
      "2020-10-21 23:35:31,676 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:35:31,677 EPOCH 12 done: loss 0.8233 - lr 0.1000000\n",
      "2020-10-21 23:35:38,524 DEV : loss 0.730599582195282 - score 0.6911\n",
      "2020-10-21 23:35:40,537 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-21 23:35:42,174 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:35:44,321 epoch 13 - iter 36/368 - loss 0.84016366 - samples/sec: 622.29 - lr: 0.100000\n",
      "2020-10-21 23:35:46,107 epoch 13 - iter 72/368 - loss 0.82472763 - samples/sec: 670.39 - lr: 0.100000\n",
      "2020-10-21 23:35:49,885 epoch 13 - iter 108/368 - loss 0.82161741 - samples/sec: 759.27 - lr: 0.100000\n",
      "2020-10-21 23:35:51,516 epoch 13 - iter 144/368 - loss 0.80948651 - samples/sec: 736.96 - lr: 0.100000\n",
      "2020-10-21 23:35:53,100 epoch 13 - iter 180/368 - loss 0.80917179 - samples/sec: 760.08 - lr: 0.100000\n",
      "2020-10-21 23:35:54,641 epoch 13 - iter 216/368 - loss 0.81057391 - samples/sec: 779.94 - lr: 0.100000\n",
      "2020-10-21 23:35:56,289 epoch 13 - iter 252/368 - loss 0.81249898 - samples/sec: 733.93 - lr: 0.100000\n",
      "2020-10-21 23:35:57,938 epoch 13 - iter 288/368 - loss 0.81399958 - samples/sec: 731.10 - lr: 0.100000\n",
      "2020-10-21 23:35:59,537 epoch 13 - iter 324/368 - loss 0.81524485 - samples/sec: 749.23 - lr: 0.100000\n",
      "2020-10-21 23:36:03,123 epoch 13 - iter 360/368 - loss 0.81229251 - samples/sec: 772.63 - lr: 0.100000\n",
      "2020-10-21 23:36:03,527 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:36:03,528 EPOCH 13 done: loss 0.8123 - lr 0.1000000\n",
      "2020-10-21 23:36:09,815 DEV : loss 0.9572136402130127 - score 0.6137\n",
      "2020-10-21 23:36:11,731 BAD EPOCHS (no improvement): 1\n",
      "2020-10-21 23:36:11,731 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:36:13,971 epoch 14 - iter 36/368 - loss 0.79264029 - samples/sec: 593.01 - lr: 0.100000\n",
      "2020-10-21 23:36:15,752 epoch 14 - iter 72/368 - loss 0.78891920 - samples/sec: 673.74 - lr: 0.100000\n",
      "2020-10-21 23:36:19,785 epoch 14 - iter 108/368 - loss 0.78341797 - samples/sec: 714.17 - lr: 0.100000\n",
      "2020-10-21 23:36:21,439 epoch 14 - iter 144/368 - loss 0.78697415 - samples/sec: 722.37 - lr: 0.100000\n",
      "2020-10-21 23:36:23,047 epoch 14 - iter 180/368 - loss 0.78772828 - samples/sec: 743.56 - lr: 0.100000\n",
      "2020-10-21 23:36:24,568 epoch 14 - iter 216/368 - loss 0.79496403 - samples/sec: 787.84 - lr: 0.100000\n",
      "2020-10-21 23:36:26,117 epoch 14 - iter 252/368 - loss 0.79554822 - samples/sec: 778.34 - lr: 0.100000\n",
      "2020-10-21 23:36:27,692 epoch 14 - iter 288/368 - loss 0.79379921 - samples/sec: 761.70 - lr: 0.100000\n",
      "2020-10-21 23:36:29,279 epoch 14 - iter 324/368 - loss 0.79726757 - samples/sec: 756.49 - lr: 0.100000\n",
      "2020-10-21 23:36:30,819 epoch 14 - iter 360/368 - loss 0.79585386 - samples/sec: 778.49 - lr: 0.100000\n",
      "2020-10-21 23:36:33,284 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:36:33,285 EPOCH 14 done: loss 0.7955 - lr 0.1000000\n",
      "2020-10-21 23:36:39,558 DEV : loss 0.9923636317253113 - score 0.5566\n",
      "2020-10-21 23:36:41,473 BAD EPOCHS (no improvement): 2\n",
      "2020-10-21 23:36:41,473 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:36:43,518 epoch 15 - iter 36/368 - loss 0.79994871 - samples/sec: 642.69 - lr: 0.100000\n",
      "2020-10-21 23:36:45,213 epoch 15 - iter 72/368 - loss 0.79664440 - samples/sec: 710.59 - lr: 0.100000\n",
      "2020-10-21 23:36:46,864 epoch 15 - iter 108/368 - loss 0.79361244 - samples/sec: 726.68 - lr: 0.100000\n",
      "2020-10-21 23:36:50,697 epoch 15 - iter 144/368 - loss 0.78556635 - samples/sec: 722.02 - lr: 0.100000\n",
      "2020-10-21 23:36:52,317 epoch 15 - iter 180/368 - loss 0.78051591 - samples/sec: 739.09 - lr: 0.100000\n",
      "2020-10-21 23:36:53,907 epoch 15 - iter 216/368 - loss 0.78141247 - samples/sec: 753.66 - lr: 0.100000\n",
      "2020-10-21 23:36:55,419 epoch 15 - iter 252/368 - loss 0.78577023 - samples/sec: 794.63 - lr: 0.100000\n",
      "2020-10-21 23:36:56,873 epoch 15 - iter 288/368 - loss 0.78538425 - samples/sec: 828.66 - lr: 0.100000\n",
      "2020-10-21 23:36:58,547 epoch 15 - iter 324/368 - loss 0.78590755 - samples/sec: 715.18 - lr: 0.100000\n",
      "2020-10-21 23:37:02,331 epoch 15 - iter 360/368 - loss 0.78469090 - samples/sec: 684.92 - lr: 0.100000\n",
      "2020-10-21 23:37:02,769 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:37:02,769 EPOCH 15 done: loss 0.7842 - lr 0.1000000\n",
      "2020-10-21 23:37:08,995 DEV : loss 0.7425697445869446 - score 0.6916\n",
      "2020-10-21 23:37:10,895 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-21 23:37:12,519 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:37:14,606 epoch 16 - iter 36/368 - loss 0.75838898 - samples/sec: 648.22 - lr: 0.100000\n",
      "2020-10-21 23:37:16,224 epoch 16 - iter 72/368 - loss 0.76416724 - samples/sec: 741.03 - lr: 0.100000\n",
      "2020-10-21 23:37:20,064 epoch 16 - iter 108/368 - loss 0.76887030 - samples/sec: 724.48 - lr: 0.100000\n",
      "2020-10-21 23:37:21,664 epoch 16 - iter 144/368 - loss 0.77264586 - samples/sec: 752.36 - lr: 0.100000\n",
      "2020-10-21 23:37:23,230 epoch 16 - iter 180/368 - loss 0.78035519 - samples/sec: 769.70 - lr: 0.100000\n",
      "2020-10-21 23:37:24,874 epoch 16 - iter 216/368 - loss 0.77883476 - samples/sec: 733.51 - lr: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-21 23:37:26,390 epoch 16 - iter 252/368 - loss 0.78221223 - samples/sec: 792.90 - lr: 0.100000\n",
      "2020-10-21 23:37:27,960 epoch 16 - iter 288/368 - loss 0.78330726 - samples/sec: 765.72 - lr: 0.100000\n",
      "2020-10-21 23:37:29,714 epoch 16 - iter 324/368 - loss 0.78588932 - samples/sec: 684.91 - lr: 0.100000\n",
      "2020-10-21 23:37:31,391 epoch 16 - iter 360/368 - loss 0.78471214 - samples/sec: 713.99 - lr: 0.100000\n",
      "2020-10-21 23:37:31,778 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:37:31,778 EPOCH 16 done: loss 0.7848 - lr 0.1000000\n",
      "2020-10-21 23:37:40,544 DEV : loss 0.6886066794395447 - score 0.7111\n",
      "2020-10-21 23:37:42,504 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-21 23:37:44,207 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:37:46,457 epoch 17 - iter 36/368 - loss 0.77470153 - samples/sec: 597.24 - lr: 0.100000\n",
      "2020-10-21 23:37:48,294 epoch 17 - iter 72/368 - loss 0.75844791 - samples/sec: 654.11 - lr: 0.100000\n",
      "2020-10-21 23:37:49,960 epoch 17 - iter 108/368 - loss 0.76498829 - samples/sec: 723.40 - lr: 0.100000\n",
      "2020-10-21 23:37:53,748 epoch 17 - iter 144/368 - loss 0.76791368 - samples/sec: 746.95 - lr: 0.100000\n",
      "2020-10-21 23:37:55,322 epoch 17 - iter 180/368 - loss 0.76697596 - samples/sec: 761.92 - lr: 0.100000\n",
      "2020-10-21 23:37:56,925 epoch 17 - iter 216/368 - loss 0.77011980 - samples/sec: 746.06 - lr: 0.100000\n",
      "2020-10-21 23:37:58,505 epoch 17 - iter 252/368 - loss 0.77397403 - samples/sec: 758.49 - lr: 0.100000\n",
      "2020-10-21 23:38:00,031 epoch 17 - iter 288/368 - loss 0.77173210 - samples/sec: 788.79 - lr: 0.100000\n",
      "2020-10-21 23:38:01,636 epoch 17 - iter 324/368 - loss 0.77327037 - samples/sec: 749.12 - lr: 0.100000\n",
      "2020-10-21 23:38:03,224 epoch 17 - iter 360/368 - loss 0.77325228 - samples/sec: 759.29 - lr: 0.100000\n",
      "2020-10-21 23:38:03,669 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:38:03,670 EPOCH 17 done: loss 0.7711 - lr 0.1000000\n",
      "2020-10-21 23:38:12,719 DEV : loss 0.8168845772743225 - score 0.6796\n",
      "2020-10-21 23:38:14,654 BAD EPOCHS (no improvement): 1\n",
      "2020-10-21 23:38:14,655 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:38:17,000 epoch 18 - iter 36/368 - loss 0.75609908 - samples/sec: 567.32 - lr: 0.100000\n",
      "2020-10-21 23:38:18,977 epoch 18 - iter 72/368 - loss 0.76517300 - samples/sec: 609.36 - lr: 0.100000\n",
      "2020-10-21 23:38:20,672 epoch 18 - iter 108/368 - loss 0.77142786 - samples/sec: 711.62 - lr: 0.100000\n",
      "2020-10-21 23:38:22,321 epoch 18 - iter 144/368 - loss 0.76682316 - samples/sec: 729.06 - lr: 0.100000\n",
      "2020-10-21 23:38:26,279 epoch 18 - iter 180/368 - loss 0.76708558 - samples/sec: 675.48 - lr: 0.100000\n",
      "2020-10-21 23:38:27,906 epoch 18 - iter 216/368 - loss 0.76580670 - samples/sec: 735.70 - lr: 0.100000\n",
      "2020-10-21 23:38:29,513 epoch 18 - iter 252/368 - loss 0.76667484 - samples/sec: 749.05 - lr: 0.100000\n",
      "2020-10-21 23:38:31,107 epoch 18 - iter 288/368 - loss 0.76433382 - samples/sec: 753.39 - lr: 0.100000\n",
      "2020-10-21 23:38:32,741 epoch 18 - iter 324/368 - loss 0.76385181 - samples/sec: 734.98 - lr: 0.100000\n",
      "2020-10-21 23:38:34,492 epoch 18 - iter 360/368 - loss 0.76230387 - samples/sec: 689.45 - lr: 0.100000\n",
      "2020-10-21 23:38:34,939 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:38:34,940 EPOCH 18 done: loss 0.7626 - lr 0.1000000\n",
      "2020-10-21 23:38:43,631 DEV : loss 0.6903313994407654 - score 0.7095\n",
      "2020-10-21 23:38:45,529 BAD EPOCHS (no improvement): 2\n",
      "2020-10-21 23:38:45,529 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:38:47,572 epoch 19 - iter 36/368 - loss 0.76006106 - samples/sec: 660.44 - lr: 0.100000\n",
      "2020-10-21 23:38:49,222 epoch 19 - iter 72/368 - loss 0.73641358 - samples/sec: 732.14 - lr: 0.100000\n",
      "2020-10-21 23:38:50,986 epoch 19 - iter 108/368 - loss 0.74096431 - samples/sec: 682.37 - lr: 0.100000\n",
      "2020-10-21 23:38:52,653 epoch 19 - iter 144/368 - loss 0.74599621 - samples/sec: 724.92 - lr: 0.100000\n",
      "2020-10-21 23:38:56,678 epoch 19 - iter 180/368 - loss 0.75268760 - samples/sec: 738.55 - lr: 0.100000\n",
      "2020-10-21 23:38:58,296 epoch 19 - iter 216/368 - loss 0.74931940 - samples/sec: 740.70 - lr: 0.100000\n",
      "2020-10-21 23:39:00,045 epoch 19 - iter 252/368 - loss 0.74902334 - samples/sec: 684.71 - lr: 0.100000\n",
      "2020-10-21 23:39:01,635 epoch 19 - iter 288/368 - loss 0.74669971 - samples/sec: 754.69 - lr: 0.100000\n",
      "2020-10-21 23:39:03,333 epoch 19 - iter 324/368 - loss 0.74903464 - samples/sec: 704.23 - lr: 0.100000\n",
      "2020-10-21 23:39:05,075 epoch 19 - iter 360/368 - loss 0.75233118 - samples/sec: 688.41 - lr: 0.100000\n",
      "2020-10-21 23:39:05,559 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:39:05,559 EPOCH 19 done: loss 0.7528 - lr 0.1000000\n",
      "2020-10-21 23:39:14,142 DEV : loss 0.6710543632507324 - score 0.7236\n",
      "2020-10-21 23:39:16,047 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-21 23:39:17,662 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:39:19,960 epoch 20 - iter 36/368 - loss 0.77423289 - samples/sec: 577.47 - lr: 0.100000\n",
      "2020-10-21 23:39:21,620 epoch 20 - iter 72/368 - loss 0.74598892 - samples/sec: 726.08 - lr: 0.100000\n",
      "2020-10-21 23:39:23,289 epoch 20 - iter 108/368 - loss 0.75518983 - samples/sec: 721.04 - lr: 0.100000\n",
      "2020-10-21 23:39:25,025 epoch 20 - iter 144/368 - loss 0.75901768 - samples/sec: 694.17 - lr: 0.100000\n",
      "2020-10-21 23:39:26,599 epoch 20 - iter 180/368 - loss 0.75427871 - samples/sec: 766.90 - lr: 0.100000\n",
      "2020-10-21 23:39:30,436 epoch 20 - iter 216/368 - loss 0.75047659 - samples/sec: 711.54 - lr: 0.100000\n",
      "2020-10-21 23:39:32,115 epoch 20 - iter 252/368 - loss 0.74636626 - samples/sec: 711.57 - lr: 0.100000\n",
      "2020-10-21 23:39:33,766 epoch 20 - iter 288/368 - loss 0.74779734 - samples/sec: 728.12 - lr: 0.100000\n",
      "2020-10-21 23:39:35,367 epoch 20 - iter 324/368 - loss 0.74815261 - samples/sec: 752.99 - lr: 0.100000\n",
      "2020-10-21 23:39:37,019 epoch 20 - iter 360/368 - loss 0.74915165 - samples/sec: 724.74 - lr: 0.100000\n",
      "2020-10-21 23:39:37,445 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:39:37,446 EPOCH 20 done: loss 0.7499 - lr 0.1000000\n",
      "2020-10-21 23:39:45,956 DEV : loss 0.7346181273460388 - score 0.6898\n",
      "2020-10-21 23:39:47,872 BAD EPOCHS (no improvement): 1\n",
      "2020-10-21 23:39:47,872 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:39:50,020 epoch 21 - iter 36/368 - loss 0.73804030 - samples/sec: 627.43 - lr: 0.100000\n",
      "2020-10-21 23:39:51,685 epoch 21 - iter 72/368 - loss 0.74120742 - samples/sec: 721.95 - lr: 0.100000\n",
      "2020-10-21 23:39:53,445 epoch 21 - iter 108/368 - loss 0.74437700 - samples/sec: 682.54 - lr: 0.100000\n",
      "2020-10-21 23:39:55,112 epoch 21 - iter 144/368 - loss 0.73543172 - samples/sec: 724.52 - lr: 0.100000\n",
      "2020-10-21 23:39:56,883 epoch 21 - iter 180/368 - loss 0.74805484 - samples/sec: 680.72 - lr: 0.100000\n",
      "2020-10-21 23:40:00,692 epoch 21 - iter 216/368 - loss 0.74940123 - samples/sec: 736.13 - lr: 0.100000\n",
      "2020-10-21 23:40:02,343 epoch 21 - iter 252/368 - loss 0.74649125 - samples/sec: 726.67 - lr: 0.100000\n",
      "2020-10-21 23:40:03,909 epoch 21 - iter 288/368 - loss 0.74522099 - samples/sec: 765.03 - lr: 0.100000\n",
      "2020-10-21 23:40:05,602 epoch 21 - iter 324/368 - loss 0.74657493 - samples/sec: 709.87 - lr: 0.100000\n",
      "2020-10-21 23:40:07,276 epoch 21 - iter 360/368 - loss 0.74552922 - samples/sec: 717.69 - lr: 0.100000\n",
      "2020-10-21 23:40:07,752 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:40:07,753 EPOCH 21 done: loss 0.7463 - lr 0.1000000\n",
      "2020-10-21 23:40:16,674 DEV : loss 0.7354001402854919 - score 0.674\n",
      "2020-10-21 23:40:18,745 BAD EPOCHS (no improvement): 2\n",
      "2020-10-21 23:40:18,745 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-21 23:40:20,836 epoch 22 - iter 36/368 - loss 0.69647878 - samples/sec: 645.69 - lr: 0.100000\n",
      "2020-10-21 23:40:22,510 epoch 22 - iter 72/368 - loss 0.72251955 - samples/sec: 721.13 - lr: 0.100000\n",
      "2020-10-21 23:40:24,171 epoch 22 - iter 108/368 - loss 0.73687818 - samples/sec: 727.06 - lr: 0.100000\n",
      "2020-10-21 23:40:25,857 epoch 22 - iter 144/368 - loss 0.73680936 - samples/sec: 717.18 - lr: 0.100000\n",
      "2020-10-21 23:40:27,567 epoch 22 - iter 180/368 - loss 0.73450513 - samples/sec: 702.94 - lr: 0.100000\n",
      "2020-10-21 23:40:29,268 epoch 22 - iter 216/368 - loss 0.73652112 - samples/sec: 708.23 - lr: 0.100000\n",
      "2020-10-21 23:40:33,613 epoch 22 - iter 252/368 - loss 0.73656856 - samples/sec: 635.70 - lr: 0.100000\n",
      "2020-10-21 23:40:35,341 epoch 22 - iter 288/368 - loss 0.73935149 - samples/sec: 694.91 - lr: 0.100000\n",
      "2020-10-21 23:40:37,051 epoch 22 - iter 324/368 - loss 0.73551780 - samples/sec: 701.49 - lr: 0.100000\n",
      "2020-10-21 23:40:38,779 epoch 22 - iter 360/368 - loss 0.73459725 - samples/sec: 692.84 - lr: 0.100000\n",
      "2020-10-21 23:40:39,221 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:40:39,222 EPOCH 22 done: loss 0.7342 - lr 0.1000000\n",
      "2020-10-21 23:40:48,278 DEV : loss 0.6590310335159302 - score 0.7185\n",
      "2020-10-21 23:40:50,207 BAD EPOCHS (no improvement): 3\n",
      "2020-10-21 23:40:50,208 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:40:52,290 epoch 23 - iter 36/368 - loss 0.69162327 - samples/sec: 645.65 - lr: 0.100000\n",
      "2020-10-21 23:40:54,021 epoch 23 - iter 72/368 - loss 0.70899149 - samples/sec: 696.57 - lr: 0.100000\n",
      "2020-10-21 23:40:55,787 epoch 23 - iter 108/368 - loss 0.72904338 - samples/sec: 682.48 - lr: 0.100000\n",
      "2020-10-21 23:40:57,592 epoch 23 - iter 144/368 - loss 0.72561346 - samples/sec: 666.81 - lr: 0.100000\n",
      "2020-10-21 23:40:59,276 epoch 23 - iter 180/368 - loss 0.73023396 - samples/sec: 718.71 - lr: 0.100000\n",
      "2020-10-21 23:41:00,953 epoch 23 - iter 216/368 - loss 0.73694691 - samples/sec: 721.92 - lr: 0.100000\n",
      "2020-10-21 23:41:04,890 epoch 23 - iter 252/368 - loss 0.73071145 - samples/sec: 298.25 - lr: 0.100000\n",
      "2020-10-21 23:41:06,635 epoch 23 - iter 288/368 - loss 0.72884866 - samples/sec: 690.45 - lr: 0.100000\n",
      "2020-10-21 23:41:08,302 epoch 23 - iter 324/368 - loss 0.72822554 - samples/sec: 720.87 - lr: 0.100000\n",
      "2020-10-21 23:41:09,999 epoch 23 - iter 360/368 - loss 0.72966864 - samples/sec: 709.21 - lr: 0.100000\n",
      "2020-10-21 23:41:10,463 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:41:10,464 EPOCH 23 done: loss 0.7286 - lr 0.1000000\n",
      "2020-10-21 23:41:16,988 DEV : loss 0.714730978012085 - score 0.7095\n",
      "2020-10-21 23:41:18,960 BAD EPOCHS (no improvement): 4\n",
      "2020-10-21 23:41:18,961 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:41:23,277 epoch 24 - iter 36/368 - loss 0.68520669 - samples/sec: 663.43 - lr: 0.100000\n",
      "2020-10-21 23:41:25,033 epoch 24 - iter 72/368 - loss 0.70585240 - samples/sec: 682.96 - lr: 0.100000\n",
      "2020-10-21 23:41:26,624 epoch 24 - iter 108/368 - loss 0.71897475 - samples/sec: 755.94 - lr: 0.100000\n",
      "2020-10-21 23:41:28,179 epoch 24 - iter 144/368 - loss 0.71877637 - samples/sec: 774.55 - lr: 0.100000\n",
      "2020-10-21 23:41:29,793 epoch 24 - iter 180/368 - loss 0.72078176 - samples/sec: 745.72 - lr: 0.100000\n",
      "2020-10-21 23:41:31,567 epoch 24 - iter 216/368 - loss 0.72455422 - samples/sec: 675.11 - lr: 0.100000\n",
      "2020-10-21 23:41:33,265 epoch 24 - iter 252/368 - loss 0.72217526 - samples/sec: 709.36 - lr: 0.100000\n",
      "2020-10-21 23:41:37,123 epoch 24 - iter 288/368 - loss 0.72628537 - samples/sec: 731.26 - lr: 0.100000\n",
      "2020-10-21 23:41:38,916 epoch 24 - iter 324/368 - loss 0.72300643 - samples/sec: 669.98 - lr: 0.100000\n",
      "2020-10-21 23:41:40,699 epoch 24 - iter 360/368 - loss 0.72088943 - samples/sec: 674.25 - lr: 0.100000\n",
      "2020-10-21 23:41:41,177 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:41:41,177 EPOCH 24 done: loss 0.7217 - lr 0.1000000\n",
      "2020-10-21 23:41:47,805 DEV : loss 0.6431719064712524 - score 0.732\n",
      "2020-10-21 23:41:49,796 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-21 23:41:51,451 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:41:55,836 epoch 25 - iter 36/368 - loss 0.71487302 - samples/sec: 640.62 - lr: 0.100000\n",
      "2020-10-21 23:41:57,406 epoch 25 - iter 72/368 - loss 0.70321395 - samples/sec: 770.61 - lr: 0.100000\n",
      "2020-10-21 23:41:59,037 epoch 25 - iter 108/368 - loss 0.71264836 - samples/sec: 742.48 - lr: 0.100000\n",
      "2020-10-21 23:42:00,669 epoch 25 - iter 144/368 - loss 0.71357923 - samples/sec: 739.74 - lr: 0.100000\n",
      "2020-10-21 23:42:02,304 epoch 25 - iter 180/368 - loss 0.71108643 - samples/sec: 738.36 - lr: 0.100000\n",
      "2020-10-21 23:42:03,883 epoch 25 - iter 216/368 - loss 0.71508630 - samples/sec: 765.45 - lr: 0.100000\n",
      "2020-10-21 23:42:05,562 epoch 25 - iter 252/368 - loss 0.71511328 - samples/sec: 716.35 - lr: 0.100000\n",
      "2020-10-21 23:42:07,087 epoch 25 - iter 288/368 - loss 0.71366535 - samples/sec: 791.38 - lr: 0.100000\n",
      "2020-10-21 23:42:10,943 epoch 25 - iter 324/368 - loss 0.71440838 - samples/sec: 692.78 - lr: 0.100000\n",
      "2020-10-21 23:42:12,561 epoch 25 - iter 360/368 - loss 0.71555360 - samples/sec: 743.48 - lr: 0.100000\n",
      "2020-10-21 23:42:13,036 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:42:13,037 EPOCH 25 done: loss 0.7146 - lr 0.1000000\n",
      "2020-10-21 23:42:19,449 DEV : loss 0.7292117476463318 - score 0.7037\n",
      "2020-10-21 23:42:21,436 BAD EPOCHS (no improvement): 1\n",
      "2020-10-21 23:42:21,437 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:42:23,632 epoch 26 - iter 36/368 - loss 0.68158326 - samples/sec: 619.62 - lr: 0.100000\n",
      "2020-10-21 23:42:25,355 epoch 26 - iter 72/368 - loss 0.70945218 - samples/sec: 701.36 - lr: 0.100000\n",
      "2020-10-21 23:42:29,168 epoch 26 - iter 108/368 - loss 0.70372937 - samples/sec: 789.48 - lr: 0.100000\n",
      "2020-10-21 23:42:30,834 epoch 26 - iter 144/368 - loss 0.70384315 - samples/sec: 722.98 - lr: 0.100000\n",
      "2020-10-21 23:42:32,520 epoch 26 - iter 180/368 - loss 0.69913284 - samples/sec: 713.47 - lr: 0.100000\n",
      "2020-10-21 23:42:34,152 epoch 26 - iter 216/368 - loss 0.69999092 - samples/sec: 739.81 - lr: 0.100000\n",
      "2020-10-21 23:42:35,604 epoch 26 - iter 252/368 - loss 0.70094069 - samples/sec: 831.25 - lr: 0.100000\n",
      "2020-10-21 23:42:37,182 epoch 26 - iter 288/368 - loss 0.70472280 - samples/sec: 763.46 - lr: 0.100000\n",
      "2020-10-21 23:42:38,874 epoch 26 - iter 324/368 - loss 0.70481598 - samples/sec: 714.66 - lr: 0.100000\n",
      "2020-10-21 23:42:42,577 epoch 26 - iter 360/368 - loss 0.70761916 - samples/sec: 750.60 - lr: 0.100000\n",
      "2020-10-21 23:42:42,989 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:42:42,990 EPOCH 26 done: loss 0.7062 - lr 0.1000000\n",
      "2020-10-21 23:42:49,466 DEV : loss 0.7858922481536865 - score 0.6988\n",
      "2020-10-21 23:42:51,411 BAD EPOCHS (no improvement): 2\n",
      "2020-10-21 23:42:51,412 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:42:53,591 epoch 27 - iter 36/368 - loss 0.67233131 - samples/sec: 605.66 - lr: 0.100000\n",
      "2020-10-21 23:42:55,288 epoch 27 - iter 72/368 - loss 0.69590324 - samples/sec: 710.85 - lr: 0.100000\n",
      "2020-10-21 23:42:59,236 epoch 27 - iter 108/368 - loss 0.68361510 - samples/sec: 713.65 - lr: 0.100000\n",
      "2020-10-21 23:43:00,940 epoch 27 - iter 144/368 - loss 0.68896014 - samples/sec: 703.61 - lr: 0.100000\n",
      "2020-10-21 23:43:02,467 epoch 27 - iter 180/368 - loss 0.69001468 - samples/sec: 790.35 - lr: 0.100000\n",
      "2020-10-21 23:43:04,220 epoch 27 - iter 216/368 - loss 0.69755624 - samples/sec: 682.50 - lr: 0.100000\n",
      "2020-10-21 23:43:05,792 epoch 27 - iter 252/368 - loss 0.69331936 - samples/sec: 766.65 - lr: 0.100000\n",
      "2020-10-21 23:43:07,435 epoch 27 - iter 288/368 - loss 0.69790220 - samples/sec: 729.50 - lr: 0.100000\n",
      "2020-10-21 23:43:09,133 epoch 27 - iter 324/368 - loss 0.69600281 - samples/sec: 706.67 - lr: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-21 23:43:13,025 epoch 27 - iter 360/368 - loss 0.69734888 - samples/sec: 679.13 - lr: 0.100000\n",
      "2020-10-21 23:43:13,506 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:43:13,506 EPOCH 27 done: loss 0.6982 - lr 0.1000000\n",
      "2020-10-21 23:43:19,963 DEV : loss 0.7510592937469482 - score 0.6883\n",
      "2020-10-21 23:43:21,909 BAD EPOCHS (no improvement): 3\n",
      "2020-10-21 23:43:21,910 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:43:24,122 epoch 28 - iter 36/368 - loss 0.70842419 - samples/sec: 596.64 - lr: 0.100000\n",
      "2020-10-21 23:43:26,043 epoch 28 - iter 72/368 - loss 0.68488073 - samples/sec: 628.91 - lr: 0.100000\n",
      "2020-10-21 23:43:30,136 epoch 28 - iter 108/368 - loss 0.69510447 - samples/sec: 671.31 - lr: 0.100000\n",
      "2020-10-21 23:43:31,722 epoch 28 - iter 144/368 - loss 0.69131341 - samples/sec: 759.46 - lr: 0.100000\n",
      "2020-10-21 23:43:33,369 epoch 28 - iter 180/368 - loss 0.69680939 - samples/sec: 732.67 - lr: 0.100000\n",
      "2020-10-21 23:43:35,019 epoch 28 - iter 216/368 - loss 0.69558501 - samples/sec: 730.81 - lr: 0.100000\n",
      "2020-10-21 23:43:36,597 epoch 28 - iter 252/368 - loss 0.70103713 - samples/sec: 762.68 - lr: 0.100000\n",
      "2020-10-21 23:43:38,252 epoch 28 - iter 288/368 - loss 0.69983253 - samples/sec: 729.16 - lr: 0.100000\n",
      "2020-10-21 23:43:39,896 epoch 28 - iter 324/368 - loss 0.70268691 - samples/sec: 730.45 - lr: 0.100000\n",
      "2020-10-21 23:43:41,574 epoch 28 - iter 360/368 - loss 0.69916544 - samples/sec: 717.83 - lr: 0.100000\n",
      "2020-10-21 23:43:44,125 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:43:44,125 EPOCH 28 done: loss 0.6997 - lr 0.1000000\n",
      "2020-10-21 23:43:50,426 DEV : loss 0.7850872278213501 - score 0.6975\n",
      "2020-10-21 23:43:52,339 BAD EPOCHS (no improvement): 4\n",
      "2020-10-21 23:43:52,340 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:43:54,431 epoch 29 - iter 36/368 - loss 0.68872037 - samples/sec: 654.45 - lr: 0.100000\n",
      "2020-10-21 23:43:56,100 epoch 29 - iter 72/368 - loss 0.68864952 - samples/sec: 728.66 - lr: 0.100000\n",
      "2020-10-21 23:43:57,722 epoch 29 - iter 108/368 - loss 0.68747575 - samples/sec: 746.62 - lr: 0.100000\n",
      "2020-10-21 23:44:01,647 epoch 29 - iter 144/368 - loss 0.68907162 - samples/sec: 694.59 - lr: 0.100000\n",
      "2020-10-21 23:44:03,208 epoch 29 - iter 180/368 - loss 0.68854795 - samples/sec: 772.84 - lr: 0.100000\n",
      "2020-10-21 23:44:04,803 epoch 29 - iter 216/368 - loss 0.68925222 - samples/sec: 757.31 - lr: 0.100000\n",
      "2020-10-21 23:44:06,481 epoch 29 - iter 252/368 - loss 0.69387522 - samples/sec: 720.58 - lr: 0.100000\n",
      "2020-10-21 23:44:08,193 epoch 29 - iter 288/368 - loss 0.69084498 - samples/sec: 701.47 - lr: 0.100000\n",
      "2020-10-21 23:44:09,775 epoch 29 - iter 324/368 - loss 0.69304543 - samples/sec: 760.93 - lr: 0.100000\n",
      "2020-10-21 23:44:11,370 epoch 29 - iter 360/368 - loss 0.69465633 - samples/sec: 752.90 - lr: 0.100000\n",
      "2020-10-21 23:44:11,834 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:44:11,835 EPOCH 29 done: loss 0.6939 - lr 0.1000000\n",
      "2020-10-21 23:44:20,433 DEV : loss 0.5956150889396667 - score 0.7504\n",
      "2020-10-21 23:44:22,363 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-21 23:44:24,007 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:44:26,197 epoch 30 - iter 36/368 - loss 0.68155713 - samples/sec: 618.35 - lr: 0.100000\n",
      "2020-10-21 23:44:27,967 epoch 30 - iter 72/368 - loss 0.66845638 - samples/sec: 683.66 - lr: 0.100000\n",
      "2020-10-21 23:44:29,854 epoch 30 - iter 108/368 - loss 0.66146911 - samples/sec: 638.44 - lr: 0.100000\n",
      "2020-10-21 23:44:31,518 epoch 30 - iter 144/368 - loss 0.67035036 - samples/sec: 723.49 - lr: 0.100000\n",
      "2020-10-21 23:44:35,505 epoch 30 - iter 180/368 - loss 0.67693457 - samples/sec: 678.94 - lr: 0.100000\n",
      "2020-10-21 23:44:37,158 epoch 30 - iter 216/368 - loss 0.68050950 - samples/sec: 725.99 - lr: 0.100000\n",
      "2020-10-21 23:44:38,810 epoch 30 - iter 252/368 - loss 0.68184853 - samples/sec: 726.48 - lr: 0.100000\n",
      "2020-10-21 23:44:40,505 epoch 30 - iter 288/368 - loss 0.68164782 - samples/sec: 708.19 - lr: 0.100000\n",
      "2020-10-21 23:44:42,243 epoch 30 - iter 324/368 - loss 0.68180011 - samples/sec: 690.76 - lr: 0.100000\n",
      "2020-10-21 23:44:43,904 epoch 30 - iter 360/368 - loss 0.68128153 - samples/sec: 723.76 - lr: 0.100000\n",
      "2020-10-21 23:44:44,339 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:44:44,339 EPOCH 30 done: loss 0.6810 - lr 0.1000000\n",
      "2020-10-21 23:44:52,961 DEV : loss 0.6293452382087708 - score 0.7443\n",
      "2020-10-21 23:44:54,917 BAD EPOCHS (no improvement): 1\n",
      "2020-10-21 23:44:54,917 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:44:57,131 epoch 31 - iter 36/368 - loss 0.67629590 - samples/sec: 598.26 - lr: 0.100000\n",
      "2020-10-21 23:44:59,010 epoch 31 - iter 72/368 - loss 0.65748924 - samples/sec: 640.82 - lr: 0.100000\n",
      "2020-10-21 23:45:00,636 epoch 31 - iter 108/368 - loss 0.66253950 - samples/sec: 743.21 - lr: 0.100000\n",
      "2020-10-21 23:45:02,249 epoch 31 - iter 144/368 - loss 0.66204375 - samples/sec: 744.09 - lr: 0.100000\n",
      "2020-10-21 23:45:06,080 epoch 31 - iter 180/368 - loss 0.67138532 - samples/sec: 723.11 - lr: 0.100000\n",
      "2020-10-21 23:45:07,650 epoch 31 - iter 216/368 - loss 0.67797194 - samples/sec: 764.24 - lr: 0.100000\n",
      "2020-10-21 23:45:09,328 epoch 31 - iter 252/368 - loss 0.67740144 - samples/sec: 713.50 - lr: 0.100000\n",
      "2020-10-21 23:45:10,938 epoch 31 - iter 288/368 - loss 0.67936589 - samples/sec: 744.84 - lr: 0.100000\n",
      "2020-10-21 23:45:12,532 epoch 31 - iter 324/368 - loss 0.67697863 - samples/sec: 753.66 - lr: 0.100000\n",
      "2020-10-21 23:45:14,126 epoch 31 - iter 360/368 - loss 0.67528103 - samples/sec: 755.05 - lr: 0.100000\n",
      "2020-10-21 23:45:14,595 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:45:14,595 EPOCH 31 done: loss 0.6758 - lr 0.1000000\n",
      "2020-10-21 23:45:22,989 DEV : loss 0.6436154246330261 - score 0.7274\n",
      "2020-10-21 23:45:24,952 BAD EPOCHS (no improvement): 2\n",
      "2020-10-21 23:45:24,953 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:45:27,098 epoch 32 - iter 36/368 - loss 0.66160322 - samples/sec: 617.21 - lr: 0.100000\n",
      "2020-10-21 23:45:28,906 epoch 32 - iter 72/368 - loss 0.66004131 - samples/sec: 665.01 - lr: 0.100000\n",
      "2020-10-21 23:45:30,654 epoch 32 - iter 108/368 - loss 0.66917837 - samples/sec: 688.31 - lr: 0.100000\n",
      "2020-10-21 23:45:32,378 epoch 32 - iter 144/368 - loss 0.67230427 - samples/sec: 698.94 - lr: 0.100000\n",
      "2020-10-21 23:45:34,093 epoch 32 - iter 180/368 - loss 0.67373356 - samples/sec: 698.84 - lr: 0.100000\n",
      "2020-10-21 23:45:37,993 epoch 32 - iter 216/368 - loss 0.67616368 - samples/sec: 694.57 - lr: 0.100000\n",
      "2020-10-21 23:45:39,663 epoch 32 - iter 252/368 - loss 0.67259177 - samples/sec: 719.34 - lr: 0.100000\n",
      "2020-10-21 23:45:41,358 epoch 32 - iter 288/368 - loss 0.67476105 - samples/sec: 707.55 - lr: 0.100000\n",
      "2020-10-21 23:45:42,999 epoch 32 - iter 324/368 - loss 0.67209826 - samples/sec: 730.90 - lr: 0.100000\n",
      "2020-10-21 23:45:44,634 epoch 32 - iter 360/368 - loss 0.67212040 - samples/sec: 732.28 - lr: 0.100000\n",
      "2020-10-21 23:45:45,095 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:45:45,096 EPOCH 32 done: loss 0.6734 - lr 0.1000000\n",
      "2020-10-21 23:45:53,657 DEV : loss 0.6124259829521179 - score 0.7558\n",
      "2020-10-21 23:45:55,593 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-21 23:45:57,273 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:45:59,459 epoch 33 - iter 36/368 - loss 0.67976651 - samples/sec: 615.33 - lr: 0.100000\n",
      "2020-10-21 23:46:01,160 epoch 33 - iter 72/368 - loss 0.66659728 - samples/sec: 708.20 - lr: 0.100000\n",
      "2020-10-21 23:46:02,902 epoch 33 - iter 108/368 - loss 0.66351012 - samples/sec: 691.43 - lr: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-21 23:46:04,589 epoch 33 - iter 144/368 - loss 0.67661164 - samples/sec: 712.76 - lr: 0.100000\n",
      "2020-10-21 23:46:08,459 epoch 33 - iter 180/368 - loss 0.67139573 - samples/sec: 719.95 - lr: 0.100000\n",
      "2020-10-21 23:46:10,121 epoch 33 - iter 216/368 - loss 0.66805120 - samples/sec: 720.73 - lr: 0.100000\n",
      "2020-10-21 23:46:11,827 epoch 33 - iter 252/368 - loss 0.66920253 - samples/sec: 704.58 - lr: 0.100000\n",
      "2020-10-21 23:46:13,490 epoch 33 - iter 288/368 - loss 0.66717444 - samples/sec: 723.08 - lr: 0.100000\n",
      "2020-10-21 23:46:15,164 epoch 33 - iter 324/368 - loss 0.67058101 - samples/sec: 718.22 - lr: 0.100000\n",
      "2020-10-21 23:46:16,841 epoch 33 - iter 360/368 - loss 0.67135442 - samples/sec: 714.58 - lr: 0.100000\n",
      "2020-10-21 23:46:17,291 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:46:17,291 EPOCH 33 done: loss 0.6714 - lr 0.1000000\n",
      "2020-10-21 23:46:25,687 DEV : loss 0.592469334602356 - score 0.754\n",
      "2020-10-21 23:46:27,607 BAD EPOCHS (no improvement): 1\n",
      "2020-10-21 23:46:27,608 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:46:29,837 epoch 34 - iter 36/368 - loss 0.66817052 - samples/sec: 602.20 - lr: 0.100000\n",
      "2020-10-21 23:46:31,539 epoch 34 - iter 72/368 - loss 0.64404351 - samples/sec: 705.83 - lr: 0.100000\n",
      "2020-10-21 23:46:33,281 epoch 34 - iter 108/368 - loss 0.66114452 - samples/sec: 691.09 - lr: 0.100000\n",
      "2020-10-21 23:46:34,891 epoch 34 - iter 144/368 - loss 0.66355720 - samples/sec: 748.72 - lr: 0.100000\n",
      "2020-10-21 23:46:36,444 epoch 34 - iter 180/368 - loss 0.65933465 - samples/sec: 776.18 - lr: 0.100000\n",
      "2020-10-21 23:46:40,261 epoch 34 - iter 216/368 - loss 0.66127794 - samples/sec: 745.40 - lr: 0.100000\n",
      "2020-10-21 23:46:41,913 epoch 34 - iter 252/368 - loss 0.66307320 - samples/sec: 726.08 - lr: 0.100000\n",
      "2020-10-21 23:46:43,547 epoch 34 - iter 288/368 - loss 0.66328755 - samples/sec: 734.12 - lr: 0.100000\n",
      "2020-10-21 23:46:45,259 epoch 34 - iter 324/368 - loss 0.66032064 - samples/sec: 701.33 - lr: 0.100000\n",
      "2020-10-21 23:46:46,939 epoch 34 - iter 360/368 - loss 0.66374288 - samples/sec: 713.59 - lr: 0.100000\n",
      "2020-10-21 23:46:47,360 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:46:47,360 EPOCH 34 done: loss 0.6623 - lr 0.1000000\n",
      "2020-10-21 23:46:55,792 DEV : loss 0.8097596764564514 - score 0.6824\n",
      "2020-10-21 23:46:57,725 BAD EPOCHS (no improvement): 2\n",
      "2020-10-21 23:46:57,726 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:46:59,871 epoch 35 - iter 36/368 - loss 0.67434985 - samples/sec: 628.38 - lr: 0.100000\n",
      "2020-10-21 23:47:01,523 epoch 35 - iter 72/368 - loss 0.66149980 - samples/sec: 729.34 - lr: 0.100000\n",
      "2020-10-21 23:47:03,232 epoch 35 - iter 108/368 - loss 0.65344155 - samples/sec: 705.03 - lr: 0.100000\n",
      "2020-10-21 23:47:04,804 epoch 35 - iter 144/368 - loss 0.65078169 - samples/sec: 772.61 - lr: 0.100000\n",
      "2020-10-21 23:47:06,449 epoch 35 - iter 180/368 - loss 0.64958754 - samples/sec: 736.22 - lr: 0.100000\n",
      "2020-10-21 23:47:10,251 epoch 35 - iter 216/368 - loss 0.65056809 - samples/sec: 756.57 - lr: 0.100000\n",
      "2020-10-21 23:47:11,872 epoch 35 - iter 252/368 - loss 0.64357207 - samples/sec: 745.33 - lr: 0.100000\n",
      "2020-10-21 23:47:13,446 epoch 35 - iter 288/368 - loss 0.64469881 - samples/sec: 766.62 - lr: 0.100000\n",
      "2020-10-21 23:47:14,978 epoch 35 - iter 324/368 - loss 0.64187103 - samples/sec: 785.98 - lr: 0.100000\n",
      "2020-10-21 23:47:16,619 epoch 35 - iter 360/368 - loss 0.64528033 - samples/sec: 730.80 - lr: 0.100000\n",
      "2020-10-21 23:47:17,064 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:47:17,065 EPOCH 35 done: loss 0.6474 - lr 0.1000000\n",
      "2020-10-21 23:47:25,397 DEV : loss 0.7293943166732788 - score 0.7072\n",
      "2020-10-21 23:47:27,331 BAD EPOCHS (no improvement): 3\n",
      "2020-10-21 23:47:27,332 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:47:29,405 epoch 36 - iter 36/368 - loss 0.66262520 - samples/sec: 659.61 - lr: 0.100000\n",
      "2020-10-21 23:47:31,131 epoch 36 - iter 72/368 - loss 0.65871712 - samples/sec: 695.31 - lr: 0.100000\n",
      "2020-10-21 23:47:32,689 epoch 36 - iter 108/368 - loss 0.65557796 - samples/sec: 775.41 - lr: 0.100000\n",
      "2020-10-21 23:47:34,221 epoch 36 - iter 144/368 - loss 0.64814361 - samples/sec: 789.29 - lr: 0.100000\n",
      "2020-10-21 23:47:35,937 epoch 36 - iter 180/368 - loss 0.64398716 - samples/sec: 701.41 - lr: 0.100000\n",
      "2020-10-21 23:47:37,660 epoch 36 - iter 216/368 - loss 0.65507346 - samples/sec: 699.09 - lr: 0.100000\n",
      "2020-10-21 23:47:41,411 epoch 36 - iter 252/368 - loss 0.65991638 - samples/sec: 312.50 - lr: 0.100000\n",
      "2020-10-21 23:47:42,985 epoch 36 - iter 288/368 - loss 0.65752092 - samples/sec: 766.49 - lr: 0.100000\n",
      "2020-10-21 23:47:44,606 epoch 36 - iter 324/368 - loss 0.65831759 - samples/sec: 743.95 - lr: 0.100000\n",
      "2020-10-21 23:47:46,232 epoch 36 - iter 360/368 - loss 0.65115589 - samples/sec: 740.66 - lr: 0.100000\n",
      "2020-10-21 23:47:46,680 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:47:46,681 EPOCH 36 done: loss 0.6525 - lr 0.1000000\n",
      "2020-10-21 23:47:54,961 DEV : loss 0.6759738922119141 - score 0.7369\n",
      "2020-10-21 23:47:56,884 BAD EPOCHS (no improvement): 4\n",
      "2020-10-21 23:47:56,885 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:47:58,888 epoch 37 - iter 36/368 - loss 0.62071450 - samples/sec: 674.24 - lr: 0.100000\n",
      "2020-10-21 23:48:00,505 epoch 37 - iter 72/368 - loss 0.62647901 - samples/sec: 747.12 - lr: 0.100000\n",
      "2020-10-21 23:48:02,117 epoch 37 - iter 108/368 - loss 0.62609905 - samples/sec: 750.00 - lr: 0.100000\n",
      "2020-10-21 23:48:03,768 epoch 37 - iter 144/368 - loss 0.63919652 - samples/sec: 730.17 - lr: 0.100000\n",
      "2020-10-21 23:48:05,489 epoch 37 - iter 180/368 - loss 0.64470605 - samples/sec: 699.49 - lr: 0.100000\n",
      "2020-10-21 23:48:07,013 epoch 37 - iter 216/368 - loss 0.64077188 - samples/sec: 794.33 - lr: 0.100000\n",
      "2020-10-21 23:48:08,628 epoch 37 - iter 252/368 - loss 0.64246605 - samples/sec: 746.43 - lr: 0.100000\n",
      "2020-10-21 23:48:12,470 epoch 37 - iter 288/368 - loss 0.64223506 - samples/sec: 711.83 - lr: 0.100000\n",
      "2020-10-21 23:48:14,084 epoch 37 - iter 324/368 - loss 0.64047180 - samples/sec: 741.90 - lr: 0.100000\n",
      "2020-10-21 23:48:15,641 epoch 37 - iter 360/368 - loss 0.63897350 - samples/sec: 770.98 - lr: 0.100000\n",
      "2020-10-21 23:48:16,040 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:48:16,040 EPOCH 37 done: loss 0.6381 - lr 0.1000000\n",
      "2020-10-21 23:48:22,191 DEV : loss 0.8755925297737122 - score 0.6939\n",
      "2020-10-21 23:48:24,135 BAD EPOCHS (no improvement): 5\n",
      "2020-10-21 23:48:24,135 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:48:28,342 epoch 38 - iter 36/368 - loss 0.65726851 - samples/sec: 712.55 - lr: 0.100000\n",
      "2020-10-21 23:48:29,986 epoch 38 - iter 72/368 - loss 0.64074349 - samples/sec: 728.03 - lr: 0.100000\n",
      "2020-10-21 23:48:31,577 epoch 38 - iter 108/368 - loss 0.64176397 - samples/sec: 755.67 - lr: 0.100000\n",
      "2020-10-21 23:48:41,622 epoch 38 - iter 144/368 - loss 0.63353976 - samples/sec: 705.22 - lr: 0.100000\n",
      "2020-10-21 23:48:44,949 epoch 38 - iter 180/368 - loss 0.62873454 - samples/sec: 766.39 - lr: 0.100000\n",
      "2020-10-21 23:48:46,504 epoch 38 - iter 216/368 - loss 0.62919296 - samples/sec: 777.77 - lr: 0.100000\n",
      "2020-10-21 23:48:48,095 epoch 38 - iter 252/368 - loss 0.63457521 - samples/sec: 753.90 - lr: 0.100000\n",
      "2020-10-21 23:48:51,764 epoch 38 - iter 288/368 - loss 0.63532682 - samples/sec: 321.00 - lr: 0.100000\n",
      "2020-10-21 23:48:53,410 epoch 38 - iter 324/368 - loss 0.63685445 - samples/sec: 730.08 - lr: 0.100000\n",
      "2020-10-21 23:48:55,089 epoch 38 - iter 360/368 - loss 0.63470982 - samples/sec: 717.14 - lr: 0.100000\n",
      "2020-10-21 23:48:55,660 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:48:55,660 EPOCH 38 done: loss 0.6345 - lr 0.1000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-21 23:49:01,867 DEV : loss 0.6200039982795715 - score 0.7481\n",
      "Epoch    38: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2020-10-21 23:49:03,771 BAD EPOCHS (no improvement): 6\n",
      "2020-10-21 23:49:03,772 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:49:08,130 epoch 39 - iter 36/368 - loss 0.60912606 - samples/sec: 701.93 - lr: 0.050000\n",
      "2020-10-21 23:49:09,686 epoch 39 - iter 72/368 - loss 0.62134207 - samples/sec: 768.91 - lr: 0.050000\n",
      "2020-10-21 23:49:11,229 epoch 39 - iter 108/368 - loss 0.61379554 - samples/sec: 776.37 - lr: 0.050000\n",
      "2020-10-21 23:49:12,898 epoch 39 - iter 144/368 - loss 0.61025615 - samples/sec: 718.06 - lr: 0.050000\n",
      "2020-10-21 23:49:14,460 epoch 39 - iter 180/368 - loss 0.60833614 - samples/sec: 768.07 - lr: 0.050000\n",
      "2020-10-21 23:49:18,045 epoch 39 - iter 216/368 - loss 0.60684191 - samples/sec: 761.02 - lr: 0.050000\n",
      "2020-10-21 23:49:21,582 epoch 39 - iter 252/368 - loss 0.59948962 - samples/sec: 772.59 - lr: 0.050000\n",
      "2020-10-21 23:49:29,896 epoch 39 - iter 288/368 - loss 0.59566957 - samples/sec: 729.84 - lr: 0.050000\n",
      "2020-10-21 23:49:31,473 epoch 39 - iter 324/368 - loss 0.59783464 - samples/sec: 763.90 - lr: 0.050000\n",
      "2020-10-21 23:49:33,151 epoch 39 - iter 360/368 - loss 0.59749567 - samples/sec: 714.81 - lr: 0.050000\n",
      "2020-10-21 23:49:33,682 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:49:33,682 EPOCH 39 done: loss 0.5988 - lr 0.0500000\n",
      "2020-10-21 23:49:39,858 DEV : loss 0.5956435203552246 - score 0.763\n",
      "2020-10-21 23:49:41,777 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-21 23:49:43,443 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:49:47,765 epoch 40 - iter 36/368 - loss 0.57157102 - samples/sec: 663.78 - lr: 0.050000\n",
      "2020-10-21 23:49:49,387 epoch 40 - iter 72/368 - loss 0.57151198 - samples/sec: 736.89 - lr: 0.050000\n",
      "2020-10-21 23:49:51,000 epoch 40 - iter 108/368 - loss 0.57075932 - samples/sec: 745.06 - lr: 0.050000\n",
      "2020-10-21 23:49:52,559 epoch 40 - iter 144/368 - loss 0.58252442 - samples/sec: 773.47 - lr: 0.050000\n",
      "2020-10-21 23:49:54,126 epoch 40 - iter 180/368 - loss 0.58471184 - samples/sec: 768.37 - lr: 0.050000\n",
      "2020-10-21 23:49:55,749 epoch 40 - iter 216/368 - loss 0.58753448 - samples/sec: 744.01 - lr: 0.050000\n",
      "2020-10-21 23:49:57,355 epoch 40 - iter 252/368 - loss 0.58605466 - samples/sec: 750.44 - lr: 0.050000\n",
      "2020-10-21 23:50:00,974 epoch 40 - iter 288/368 - loss 0.58593732 - samples/sec: 747.79 - lr: 0.050000\n",
      "2020-10-21 23:50:02,629 epoch 40 - iter 324/368 - loss 0.58447167 - samples/sec: 726.85 - lr: 0.050000\n",
      "2020-10-21 23:50:04,187 epoch 40 - iter 360/368 - loss 0.58607429 - samples/sec: 773.26 - lr: 0.050000\n",
      "2020-10-21 23:50:04,595 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:50:04,596 EPOCH 40 done: loss 0.5866 - lr 0.0500000\n",
      "2020-10-21 23:50:10,804 DEV : loss 0.6526654958724976 - score 0.7466\n",
      "2020-10-21 23:50:12,733 BAD EPOCHS (no improvement): 1\n",
      "2020-10-21 23:50:12,734 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:50:14,812 epoch 41 - iter 36/368 - loss 0.57375806 - samples/sec: 662.14 - lr: 0.050000\n",
      "2020-10-21 23:50:18,592 epoch 41 - iter 72/368 - loss 0.58466539 - samples/sec: 773.40 - lr: 0.050000\n",
      "2020-10-21 23:50:20,240 epoch 41 - iter 108/368 - loss 0.58486803 - samples/sec: 730.56 - lr: 0.050000\n",
      "2020-10-21 23:50:21,880 epoch 41 - iter 144/368 - loss 0.59079143 - samples/sec: 733.55 - lr: 0.050000\n",
      "2020-10-21 23:50:23,459 epoch 41 - iter 180/368 - loss 0.59132275 - samples/sec: 764.86 - lr: 0.050000\n",
      "2020-10-21 23:50:24,971 epoch 41 - iter 216/368 - loss 0.58247847 - samples/sec: 802.32 - lr: 0.050000\n",
      "2020-10-21 23:50:26,660 epoch 41 - iter 252/368 - loss 0.58521464 - samples/sec: 712.62 - lr: 0.050000\n",
      "2020-10-21 23:50:28,365 epoch 41 - iter 288/368 - loss 0.58799621 - samples/sec: 706.25 - lr: 0.050000\n",
      "2020-10-21 23:50:31,998 epoch 41 - iter 324/368 - loss 0.59059075 - samples/sec: 324.46 - lr: 0.050000\n",
      "2020-10-21 23:50:33,636 epoch 41 - iter 360/368 - loss 0.59009724 - samples/sec: 732.47 - lr: 0.050000\n",
      "2020-10-21 23:50:34,074 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:50:34,075 EPOCH 41 done: loss 0.5877 - lr 0.0500000\n",
      "2020-10-21 23:50:40,428 DEV : loss 0.6356345415115356 - score 0.7515\n",
      "2020-10-21 23:50:42,355 BAD EPOCHS (no improvement): 2\n",
      "2020-10-21 23:50:42,356 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:50:44,448 epoch 42 - iter 36/368 - loss 0.53612641 - samples/sec: 649.23 - lr: 0.050000\n",
      "2020-10-21 23:50:46,165 epoch 42 - iter 72/368 - loss 0.56691081 - samples/sec: 699.78 - lr: 0.050000\n",
      "2020-10-21 23:50:50,036 epoch 42 - iter 108/368 - loss 0.57275207 - samples/sec: 710.43 - lr: 0.050000\n",
      "2020-10-21 23:50:51,620 epoch 42 - iter 144/368 - loss 0.57265510 - samples/sec: 759.99 - lr: 0.050000\n",
      "2020-10-21 23:50:53,263 epoch 42 - iter 180/368 - loss 0.57544302 - samples/sec: 729.40 - lr: 0.050000\n",
      "2020-10-21 23:50:54,864 epoch 42 - iter 216/368 - loss 0.57933780 - samples/sec: 748.92 - lr: 0.050000\n",
      "2020-10-21 23:50:56,476 epoch 42 - iter 252/368 - loss 0.57523134 - samples/sec: 747.28 - lr: 0.050000\n",
      "2020-10-21 23:50:58,072 epoch 42 - iter 288/368 - loss 0.57701947 - samples/sec: 754.45 - lr: 0.050000\n",
      "2020-10-21 23:50:59,669 epoch 42 - iter 324/368 - loss 0.57412512 - samples/sec: 752.29 - lr: 0.050000\n",
      "2020-10-21 23:51:03,375 epoch 42 - iter 360/368 - loss 0.57505615 - samples/sec: 722.31 - lr: 0.050000\n",
      "2020-10-21 23:51:03,814 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:51:03,815 EPOCH 42 done: loss 0.5738 - lr 0.0500000\n",
      "2020-10-21 23:51:10,180 DEV : loss 0.6122890710830688 - score 0.7579\n",
      "2020-10-21 23:51:12,104 BAD EPOCHS (no improvement): 3\n",
      "2020-10-21 23:51:12,105 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:51:14,251 epoch 43 - iter 36/368 - loss 0.56566969 - samples/sec: 632.30 - lr: 0.050000\n",
      "2020-10-21 23:51:15,953 epoch 43 - iter 72/368 - loss 0.57911073 - samples/sec: 707.35 - lr: 0.050000\n",
      "2020-10-21 23:51:19,814 epoch 43 - iter 108/368 - loss 0.56555016 - samples/sec: 719.59 - lr: 0.050000\n",
      "2020-10-21 23:51:21,550 epoch 43 - iter 144/368 - loss 0.56519424 - samples/sec: 689.66 - lr: 0.050000\n",
      "2020-10-21 23:51:23,279 epoch 43 - iter 180/368 - loss 0.56846351 - samples/sec: 693.86 - lr: 0.050000\n",
      "2020-10-21 23:51:24,893 epoch 43 - iter 216/368 - loss 0.57086720 - samples/sec: 744.32 - lr: 0.050000\n",
      "2020-10-21 23:51:26,484 epoch 43 - iter 252/368 - loss 0.56486149 - samples/sec: 755.62 - lr: 0.050000\n",
      "2020-10-21 23:51:28,138 epoch 43 - iter 288/368 - loss 0.56900644 - samples/sec: 727.28 - lr: 0.050000\n",
      "2020-10-21 23:51:29,816 epoch 43 - iter 324/368 - loss 0.57256470 - samples/sec: 717.18 - lr: 0.050000\n",
      "2020-10-21 23:51:31,421 epoch 43 - iter 360/368 - loss 0.57172261 - samples/sec: 750.26 - lr: 0.050000\n",
      "2020-10-21 23:51:33,898 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:51:33,898 EPOCH 43 done: loss 0.5725 - lr 0.0500000\n",
      "2020-10-21 23:51:40,118 DEV : loss 0.5957353711128235 - score 0.7589\n",
      "2020-10-21 23:51:42,005 BAD EPOCHS (no improvement): 4\n",
      "2020-10-21 23:51:42,006 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:51:44,107 epoch 44 - iter 36/368 - loss 0.59149364 - samples/sec: 649.26 - lr: 0.050000\n",
      "2020-10-21 23:51:45,854 epoch 44 - iter 72/368 - loss 0.57975323 - samples/sec: 686.35 - lr: 0.050000\n",
      "2020-10-21 23:51:49,799 epoch 44 - iter 108/368 - loss 0.56836941 - samples/sec: 674.05 - lr: 0.050000\n",
      "2020-10-21 23:51:51,380 epoch 44 - iter 144/368 - loss 0.56879252 - samples/sec: 758.60 - lr: 0.050000\n",
      "2020-10-21 23:51:52,878 epoch 44 - iter 180/368 - loss 0.57239300 - samples/sec: 804.29 - lr: 0.050000\n",
      "2020-10-21 23:51:54,549 epoch 44 - iter 216/368 - loss 0.57514318 - samples/sec: 716.00 - lr: 0.050000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-21 23:51:56,106 epoch 44 - iter 252/368 - loss 0.57350114 - samples/sec: 772.12 - lr: 0.050000\n",
      "2020-10-21 23:51:57,656 epoch 44 - iter 288/368 - loss 0.57407963 - samples/sec: 775.60 - lr: 0.050000\n",
      "2020-10-21 23:51:59,246 epoch 44 - iter 324/368 - loss 0.57679555 - samples/sec: 752.15 - lr: 0.050000\n",
      "2020-10-21 23:52:00,920 epoch 44 - iter 360/368 - loss 0.57841598 - samples/sec: 715.00 - lr: 0.050000\n",
      "2020-10-21 23:52:03,411 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:52:03,412 EPOCH 44 done: loss 0.5792 - lr 0.0500000\n",
      "2020-10-21 23:52:09,721 DEV : loss 0.6020042300224304 - score 0.7553\n",
      "2020-10-21 23:52:11,619 BAD EPOCHS (no improvement): 5\n",
      "2020-10-21 23:52:11,619 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:52:13,792 epoch 45 - iter 36/368 - loss 0.56390259 - samples/sec: 623.59 - lr: 0.050000\n",
      "2020-10-21 23:52:15,505 epoch 45 - iter 72/368 - loss 0.53728537 - samples/sec: 702.00 - lr: 0.050000\n",
      "2020-10-21 23:52:17,087 epoch 45 - iter 108/368 - loss 0.54607161 - samples/sec: 762.24 - lr: 0.050000\n",
      "2020-10-21 23:52:20,860 epoch 45 - iter 144/368 - loss 0.55061126 - samples/sec: 750.73 - lr: 0.050000\n",
      "2020-10-21 23:52:22,540 epoch 45 - iter 180/368 - loss 0.56291926 - samples/sec: 712.79 - lr: 0.050000\n",
      "2020-10-21 23:52:24,149 epoch 45 - iter 216/368 - loss 0.55618735 - samples/sec: 746.82 - lr: 0.050000\n",
      "2020-10-21 23:52:25,707 epoch 45 - iter 252/368 - loss 0.55992560 - samples/sec: 771.06 - lr: 0.050000\n",
      "2020-10-21 23:52:27,308 epoch 45 - iter 288/368 - loss 0.56081986 - samples/sec: 751.67 - lr: 0.050000\n",
      "2020-10-21 23:52:28,868 epoch 45 - iter 324/368 - loss 0.56162284 - samples/sec: 775.72 - lr: 0.050000\n",
      "2020-10-21 23:52:30,505 epoch 45 - iter 360/368 - loss 0.56328988 - samples/sec: 734.68 - lr: 0.050000\n",
      "2020-10-21 23:52:30,952 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:52:30,953 EPOCH 45 done: loss 0.5635 - lr 0.0500000\n",
      "2020-10-21 23:52:49,474 DEV : loss 0.632942259311676 - score 0.7512\n",
      "Epoch    45: reducing learning rate of group 0 to 2.5000e-02.\n",
      "2020-10-21 23:52:51,353 BAD EPOCHS (no improvement): 6\n",
      "2020-10-21 23:52:51,354 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:52:53,462 epoch 46 - iter 36/368 - loss 0.57950569 - samples/sec: 645.09 - lr: 0.025000\n",
      "2020-10-21 23:52:55,171 epoch 46 - iter 72/368 - loss 0.56034092 - samples/sec: 704.28 - lr: 0.025000\n",
      "2020-10-21 23:52:56,864 epoch 46 - iter 108/368 - loss 0.55139728 - samples/sec: 706.95 - lr: 0.025000\n",
      "2020-10-21 23:53:00,727 epoch 46 - iter 144/368 - loss 0.54779743 - samples/sec: 705.08 - lr: 0.025000\n",
      "2020-10-21 23:53:02,368 epoch 46 - iter 180/368 - loss 0.55109624 - samples/sec: 731.90 - lr: 0.025000\n",
      "2020-10-21 23:53:03,970 epoch 46 - iter 216/368 - loss 0.55666786 - samples/sec: 750.59 - lr: 0.025000\n",
      "2020-10-21 23:53:05,608 epoch 46 - iter 252/368 - loss 0.55464392 - samples/sec: 731.53 - lr: 0.025000\n",
      "2020-10-21 23:53:07,165 epoch 46 - iter 288/368 - loss 0.55547985 - samples/sec: 772.93 - lr: 0.025000\n",
      "2020-10-21 23:53:08,772 epoch 46 - iter 324/368 - loss 0.55570596 - samples/sec: 748.73 - lr: 0.025000\n",
      "2020-10-21 23:53:10,438 epoch 46 - iter 360/368 - loss 0.55354820 - samples/sec: 721.35 - lr: 0.025000\n",
      "2020-10-21 23:53:10,881 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:53:10,882 EPOCH 46 done: loss 0.5548 - lr 0.0250000\n",
      "2020-10-21 23:53:25,702 DEV : loss 0.6103323101997375 - score 0.7645\n",
      "2020-10-21 23:53:27,619 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-21 23:53:29,261 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:53:31,392 epoch 47 - iter 36/368 - loss 0.50764426 - samples/sec: 631.94 - lr: 0.025000\n",
      "2020-10-21 23:53:33,073 epoch 47 - iter 72/368 - loss 0.53803637 - samples/sec: 715.48 - lr: 0.025000\n",
      "2020-10-21 23:53:34,696 epoch 47 - iter 108/368 - loss 0.53459505 - samples/sec: 742.48 - lr: 0.025000\n",
      "2020-10-21 23:53:38,530 epoch 47 - iter 144/368 - loss 0.54802107 - samples/sec: 723.55 - lr: 0.025000\n",
      "2020-10-21 23:53:40,136 epoch 47 - iter 180/368 - loss 0.54634416 - samples/sec: 747.61 - lr: 0.025000\n",
      "2020-10-21 23:53:41,774 epoch 47 - iter 216/368 - loss 0.55236274 - samples/sec: 734.95 - lr: 0.025000\n",
      "2020-10-21 23:53:43,370 epoch 47 - iter 252/368 - loss 0.54934647 - samples/sec: 756.40 - lr: 0.025000\n",
      "2020-10-21 23:53:45,051 epoch 47 - iter 288/368 - loss 0.54939375 - samples/sec: 716.49 - lr: 0.025000\n",
      "2020-10-21 23:53:46,724 epoch 47 - iter 324/368 - loss 0.54955605 - samples/sec: 719.61 - lr: 0.025000\n",
      "2020-10-21 23:53:48,331 epoch 47 - iter 360/368 - loss 0.55145924 - samples/sec: 748.78 - lr: 0.025000\n",
      "2020-10-21 23:53:48,764 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:53:48,765 EPOCH 47 done: loss 0.5509 - lr 0.0250000\n",
      "2020-10-21 23:53:57,177 DEV : loss 0.5795863270759583 - score 0.7694\n",
      "2020-10-21 23:53:59,084 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-21 23:54:00,731 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:54:02,932 epoch 48 - iter 36/368 - loss 0.57075034 - samples/sec: 615.83 - lr: 0.025000\n",
      "2020-10-21 23:54:04,614 epoch 48 - iter 72/368 - loss 0.55202883 - samples/sec: 717.56 - lr: 0.025000\n",
      "2020-10-21 23:54:06,229 epoch 48 - iter 108/368 - loss 0.55471278 - samples/sec: 746.64 - lr: 0.025000\n",
      "2020-10-21 23:54:07,900 epoch 48 - iter 144/368 - loss 0.55099483 - samples/sec: 720.29 - lr: 0.025000\n",
      "2020-10-21 23:54:11,637 epoch 48 - iter 180/368 - loss 0.54716830 - samples/sec: 761.05 - lr: 0.025000\n",
      "2020-10-21 23:54:13,236 epoch 48 - iter 216/368 - loss 0.55134837 - samples/sec: 751.42 - lr: 0.025000\n",
      "2020-10-21 23:54:14,771 epoch 48 - iter 252/368 - loss 0.55133505 - samples/sec: 781.85 - lr: 0.025000\n",
      "2020-10-21 23:54:16,349 epoch 48 - iter 288/368 - loss 0.55249855 - samples/sec: 762.75 - lr: 0.025000\n",
      "2020-10-21 23:54:17,997 epoch 48 - iter 324/368 - loss 0.55328681 - samples/sec: 726.56 - lr: 0.025000\n",
      "2020-10-21 23:54:19,646 epoch 48 - iter 360/368 - loss 0.55378625 - samples/sec: 727.30 - lr: 0.025000\n",
      "2020-10-21 23:54:20,100 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:54:20,101 EPOCH 48 done: loss 0.5525 - lr 0.0250000\n",
      "2020-10-21 23:54:28,421 DEV : loss 0.5771927237510681 - score 0.7699\n",
      "2020-10-21 23:54:30,357 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-21 23:54:31,999 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:54:34,134 epoch 49 - iter 36/368 - loss 0.54198904 - samples/sec: 638.83 - lr: 0.025000\n",
      "2020-10-21 23:54:35,825 epoch 49 - iter 72/368 - loss 0.55594842 - samples/sec: 711.18 - lr: 0.025000\n",
      "2020-10-21 23:54:37,463 epoch 49 - iter 108/368 - loss 0.54908330 - samples/sec: 734.98 - lr: 0.025000\n",
      "2020-10-21 23:54:39,110 epoch 49 - iter 144/368 - loss 0.54046654 - samples/sec: 727.96 - lr: 0.025000\n",
      "2020-10-21 23:54:43,032 epoch 49 - iter 180/368 - loss 0.53726013 - samples/sec: 695.70 - lr: 0.025000\n",
      "2020-10-21 23:54:44,742 epoch 49 - iter 216/368 - loss 0.53997260 - samples/sec: 702.71 - lr: 0.025000\n",
      "2020-10-21 23:54:46,416 epoch 49 - iter 252/368 - loss 0.54014127 - samples/sec: 718.36 - lr: 0.025000\n",
      "2020-10-21 23:54:48,009 epoch 49 - iter 288/368 - loss 0.54089993 - samples/sec: 758.40 - lr: 0.025000\n",
      "2020-10-21 23:54:49,574 epoch 49 - iter 324/368 - loss 0.54119567 - samples/sec: 771.08 - lr: 0.025000\n",
      "2020-10-21 23:54:51,165 epoch 49 - iter 360/368 - loss 0.54460718 - samples/sec: 752.21 - lr: 0.025000\n",
      "2020-10-21 23:54:51,584 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:54:51,585 EPOCH 49 done: loss 0.5455 - lr 0.0250000\n",
      "2020-10-21 23:55:00,052 DEV : loss 0.6439708471298218 - score 0.753\n",
      "2020-10-21 23:55:01,947 BAD EPOCHS (no improvement): 1\n",
      "2020-10-21 23:55:01,948 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-21 23:55:04,027 epoch 50 - iter 36/368 - loss 0.52880050 - samples/sec: 639.72 - lr: 0.025000\n",
      "2020-10-21 23:55:05,769 epoch 50 - iter 72/368 - loss 0.55378627 - samples/sec: 692.33 - lr: 0.025000\n",
      "2020-10-21 23:55:07,487 epoch 50 - iter 108/368 - loss 0.54427359 - samples/sec: 699.36 - lr: 0.025000\n",
      "2020-10-21 23:55:09,134 epoch 50 - iter 144/368 - loss 0.55007847 - samples/sec: 728.54 - lr: 0.025000\n",
      "2020-10-21 23:55:10,780 epoch 50 - iter 180/368 - loss 0.55188596 - samples/sec: 728.21 - lr: 0.025000\n",
      "2020-10-21 23:55:12,428 epoch 50 - iter 216/368 - loss 0.55163858 - samples/sec: 725.77 - lr: 0.025000\n",
      "2020-10-21 23:55:16,235 epoch 50 - iter 252/368 - loss 0.55229783 - samples/sec: 736.45 - lr: 0.025000\n",
      "2020-10-21 23:55:17,828 epoch 50 - iter 288/368 - loss 0.54870663 - samples/sec: 753.64 - lr: 0.025000\n",
      "2020-10-21 23:55:19,465 epoch 50 - iter 324/368 - loss 0.54721876 - samples/sec: 732.81 - lr: 0.025000\n",
      "2020-10-21 23:55:21,118 epoch 50 - iter 360/368 - loss 0.54590359 - samples/sec: 725.10 - lr: 0.025000\n",
      "2020-10-21 23:55:21,592 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:55:21,593 EPOCH 50 done: loss 0.5453 - lr 0.0250000\n",
      "2020-10-21 23:55:30,006 DEV : loss 0.6015822291374207 - score 0.7655\n",
      "2020-10-21 23:55:31,916 BAD EPOCHS (no improvement): 2\n",
      "2020-10-21 23:55:31,917 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:55:34,157 epoch 51 - iter 36/368 - loss 0.53211401 - samples/sec: 599.75 - lr: 0.025000\n",
      "2020-10-21 23:55:35,914 epoch 51 - iter 72/368 - loss 0.53043855 - samples/sec: 682.18 - lr: 0.025000\n",
      "2020-10-21 23:55:37,630 epoch 51 - iter 108/368 - loss 0.53541587 - samples/sec: 699.18 - lr: 0.025000\n",
      "2020-10-21 23:55:39,321 epoch 51 - iter 144/368 - loss 0.53092935 - samples/sec: 711.17 - lr: 0.025000\n",
      "2020-10-21 23:55:41,010 epoch 51 - iter 180/368 - loss 0.52909974 - samples/sec: 713.73 - lr: 0.025000\n",
      "2020-10-21 23:55:42,766 epoch 51 - iter 216/368 - loss 0.52748085 - samples/sec: 684.21 - lr: 0.025000\n",
      "2020-10-21 23:55:46,525 epoch 51 - iter 252/368 - loss 0.53115063 - samples/sec: 753.17 - lr: 0.025000\n",
      "2020-10-21 23:55:48,148 epoch 51 - iter 288/368 - loss 0.53388206 - samples/sec: 740.77 - lr: 0.025000\n",
      "2020-10-21 23:55:49,740 epoch 51 - iter 324/368 - loss 0.53446052 - samples/sec: 754.40 - lr: 0.025000\n",
      "2020-10-21 23:55:51,338 epoch 51 - iter 360/368 - loss 0.53251065 - samples/sec: 749.14 - lr: 0.025000\n",
      "2020-10-21 23:55:51,767 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:55:51,768 EPOCH 51 done: loss 0.5334 - lr 0.0250000\n",
      "2020-10-21 23:55:57,967 DEV : loss 0.5638996362686157 - score 0.7788\n",
      "2020-10-21 23:56:01,971 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-21 23:56:03,614 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:56:05,793 epoch 52 - iter 36/368 - loss 0.50476067 - samples/sec: 615.10 - lr: 0.025000\n",
      "2020-10-21 23:56:07,474 epoch 52 - iter 72/368 - loss 0.51256401 - samples/sec: 718.66 - lr: 0.025000\n",
      "2020-10-21 23:56:09,028 epoch 52 - iter 108/368 - loss 0.52435453 - samples/sec: 778.73 - lr: 0.025000\n",
      "2020-10-21 23:56:10,617 epoch 52 - iter 144/368 - loss 0.51458863 - samples/sec: 757.95 - lr: 0.025000\n",
      "2020-10-21 23:56:12,181 epoch 52 - iter 180/368 - loss 0.52408266 - samples/sec: 771.89 - lr: 0.025000\n",
      "2020-10-21 23:56:13,761 epoch 52 - iter 216/368 - loss 0.53192082 - samples/sec: 762.36 - lr: 0.025000\n",
      "2020-10-21 23:56:17,539 epoch 52 - iter 252/368 - loss 0.53605559 - samples/sec: 750.73 - lr: 0.025000\n",
      "2020-10-21 23:56:19,194 epoch 52 - iter 288/368 - loss 0.53338813 - samples/sec: 721.45 - lr: 0.025000\n",
      "2020-10-21 23:56:20,776 epoch 52 - iter 324/368 - loss 0.53919380 - samples/sec: 758.45 - lr: 0.025000\n",
      "2020-10-21 23:56:22,418 epoch 52 - iter 360/368 - loss 0.54052123 - samples/sec: 733.79 - lr: 0.025000\n",
      "2020-10-21 23:56:22,856 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:56:22,857 EPOCH 52 done: loss 0.5396 - lr 0.0250000\n",
      "2020-10-21 23:56:29,022 DEV : loss 0.5998940467834473 - score 0.7627\n",
      "2020-10-21 23:56:33,000 BAD EPOCHS (no improvement): 1\n",
      "2020-10-21 23:56:33,000 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:56:35,101 epoch 53 - iter 36/368 - loss 0.51245769 - samples/sec: 626.59 - lr: 0.025000\n",
      "2020-10-21 23:56:36,945 epoch 53 - iter 72/368 - loss 0.52337355 - samples/sec: 652.99 - lr: 0.025000\n",
      "2020-10-21 23:56:38,607 epoch 53 - iter 108/368 - loss 0.52335216 - samples/sec: 724.06 - lr: 0.025000\n",
      "2020-10-21 23:56:40,211 epoch 53 - iter 144/368 - loss 0.52591164 - samples/sec: 756.94 - lr: 0.025000\n",
      "2020-10-21 23:56:41,856 epoch 53 - iter 180/368 - loss 0.53210165 - samples/sec: 736.87 - lr: 0.025000\n",
      "2020-10-21 23:56:43,595 epoch 53 - iter 216/368 - loss 0.52988165 - samples/sec: 695.06 - lr: 0.025000\n",
      "2020-10-21 23:56:45,249 epoch 53 - iter 252/368 - loss 0.53343187 - samples/sec: 729.28 - lr: 0.025000\n",
      "2020-10-21 23:56:46,866 epoch 53 - iter 288/368 - loss 0.53363388 - samples/sec: 745.61 - lr: 0.025000\n",
      "2020-10-21 23:56:50,611 epoch 53 - iter 324/368 - loss 0.53435245 - samples/sec: 765.07 - lr: 0.025000\n",
      "2020-10-21 23:56:52,312 epoch 53 - iter 360/368 - loss 0.53413522 - samples/sec: 707.00 - lr: 0.025000\n",
      "2020-10-21 23:56:52,761 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:56:52,761 EPOCH 53 done: loss 0.5330 - lr 0.0250000\n",
      "2020-10-21 23:56:59,007 DEV : loss 0.589947521686554 - score 0.7706\n",
      "2020-10-21 23:57:00,931 BAD EPOCHS (no improvement): 2\n",
      "2020-10-21 23:57:00,932 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:57:02,984 epoch 54 - iter 36/368 - loss 0.51418726 - samples/sec: 649.73 - lr: 0.025000\n",
      "2020-10-21 23:57:06,870 epoch 54 - iter 72/368 - loss 0.51803217 - samples/sec: 703.09 - lr: 0.025000\n",
      "2020-10-21 23:57:08,490 epoch 54 - iter 108/368 - loss 0.50784305 - samples/sec: 743.78 - lr: 0.025000\n",
      "2020-10-21 23:57:10,140 epoch 54 - iter 144/368 - loss 0.51651989 - samples/sec: 732.37 - lr: 0.025000\n",
      "2020-10-21 23:57:11,753 epoch 54 - iter 180/368 - loss 0.51761979 - samples/sec: 746.84 - lr: 0.025000\n",
      "2020-10-21 23:57:13,229 epoch 54 - iter 216/368 - loss 0.52429385 - samples/sec: 816.71 - lr: 0.025000\n",
      "2020-10-21 23:57:14,833 epoch 54 - iter 252/368 - loss 0.53015610 - samples/sec: 749.69 - lr: 0.025000\n",
      "2020-10-21 23:57:16,515 epoch 54 - iter 288/368 - loss 0.53453490 - samples/sec: 711.30 - lr: 0.025000\n",
      "2020-10-21 23:57:18,203 epoch 54 - iter 324/368 - loss 0.53277785 - samples/sec: 709.15 - lr: 0.025000\n",
      "2020-10-21 23:57:21,913 epoch 54 - iter 360/368 - loss 0.53147381 - samples/sec: 718.48 - lr: 0.025000\n",
      "2020-10-21 23:57:22,356 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:57:22,357 EPOCH 54 done: loss 0.5317 - lr 0.0250000\n",
      "2020-10-21 23:57:28,620 DEV : loss 0.6360602378845215 - score 0.7612\n",
      "2020-10-21 23:57:30,533 BAD EPOCHS (no improvement): 3\n",
      "2020-10-21 23:57:30,534 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:57:32,554 epoch 55 - iter 36/368 - loss 0.58235397 - samples/sec: 669.97 - lr: 0.025000\n",
      "2020-10-21 23:57:34,217 epoch 55 - iter 72/368 - loss 0.55566418 - samples/sec: 722.22 - lr: 0.025000\n",
      "2020-10-21 23:57:38,026 epoch 55 - iter 108/368 - loss 0.54871412 - samples/sec: 733.68 - lr: 0.025000\n",
      "2020-10-21 23:57:39,611 epoch 55 - iter 144/368 - loss 0.54900270 - samples/sec: 757.50 - lr: 0.025000\n",
      "2020-10-21 23:57:41,257 epoch 55 - iter 180/368 - loss 0.53810947 - samples/sec: 730.65 - lr: 0.025000\n",
      "2020-10-21 23:57:42,905 epoch 55 - iter 216/368 - loss 0.53932169 - samples/sec: 729.23 - lr: 0.025000\n",
      "2020-10-21 23:57:44,607 epoch 55 - iter 252/368 - loss 0.53759337 - samples/sec: 703.62 - lr: 0.025000\n",
      "2020-10-21 23:57:46,271 epoch 55 - iter 288/368 - loss 0.53358079 - samples/sec: 721.48 - lr: 0.025000\n",
      "2020-10-21 23:57:47,962 epoch 55 - iter 324/368 - loss 0.53192506 - samples/sec: 709.05 - lr: 0.025000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-21 23:57:51,618 epoch 55 - iter 360/368 - loss 0.53133018 - samples/sec: 729.24 - lr: 0.025000\n",
      "2020-10-21 23:57:52,085 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:57:52,086 EPOCH 55 done: loss 0.5303 - lr 0.0250000\n",
      "2020-10-21 23:57:58,293 DEV : loss 0.568246603012085 - score 0.775\n",
      "2020-10-21 23:58:00,195 BAD EPOCHS (no improvement): 4\n",
      "2020-10-21 23:58:00,196 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:58:02,397 epoch 56 - iter 36/368 - loss 0.52235101 - samples/sec: 615.88 - lr: 0.025000\n",
      "2020-10-21 23:58:04,176 epoch 56 - iter 72/368 - loss 0.52217986 - samples/sec: 676.49 - lr: 0.025000\n",
      "2020-10-21 23:58:08,029 epoch 56 - iter 108/368 - loss 0.51239761 - samples/sec: 720.15 - lr: 0.025000\n",
      "2020-10-21 23:58:09,675 epoch 56 - iter 144/368 - loss 0.50639201 - samples/sec: 729.34 - lr: 0.025000\n",
      "2020-10-21 23:58:11,359 epoch 56 - iter 180/368 - loss 0.51336095 - samples/sec: 715.28 - lr: 0.025000\n",
      "2020-10-21 23:58:12,926 epoch 56 - iter 216/368 - loss 0.52374643 - samples/sec: 769.02 - lr: 0.025000\n",
      "2020-10-21 23:58:14,586 epoch 56 - iter 252/368 - loss 0.52285394 - samples/sec: 723.13 - lr: 0.025000\n",
      "2020-10-21 23:58:16,253 epoch 56 - iter 288/368 - loss 0.52506981 - samples/sec: 717.91 - lr: 0.025000\n",
      "2020-10-21 23:58:17,853 epoch 56 - iter 324/368 - loss 0.52345365 - samples/sec: 748.59 - lr: 0.025000\n",
      "2020-10-21 23:58:21,454 epoch 56 - iter 360/368 - loss 0.52664352 - samples/sec: 774.32 - lr: 0.025000\n",
      "2020-10-21 23:58:21,875 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:58:21,875 EPOCH 56 done: loss 0.5265 - lr 0.0250000\n",
      "2020-10-21 23:58:28,085 DEV : loss 0.5820294618606567 - score 0.775\n",
      "2020-10-21 23:58:29,994 BAD EPOCHS (no improvement): 5\n",
      "2020-10-21 23:58:29,994 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:58:32,214 epoch 57 - iter 36/368 - loss 0.50317538 - samples/sec: 607.57 - lr: 0.025000\n",
      "2020-10-21 23:58:34,015 epoch 57 - iter 72/368 - loss 0.51520171 - samples/sec: 668.21 - lr: 0.025000\n",
      "2020-10-21 23:58:35,617 epoch 57 - iter 108/368 - loss 0.53154415 - samples/sec: 751.48 - lr: 0.025000\n",
      "2020-10-21 23:58:39,484 epoch 57 - iter 144/368 - loss 0.53076470 - samples/sec: 713.51 - lr: 0.025000\n",
      "2020-10-21 23:58:41,135 epoch 57 - iter 180/368 - loss 0.52289850 - samples/sec: 731.64 - lr: 0.025000\n",
      "2020-10-21 23:58:42,843 epoch 57 - iter 216/368 - loss 0.51847685 - samples/sec: 705.17 - lr: 0.025000\n",
      "2020-10-21 23:58:44,450 epoch 57 - iter 252/368 - loss 0.52109950 - samples/sec: 748.46 - lr: 0.025000\n",
      "2020-10-21 23:58:46,048 epoch 57 - iter 288/368 - loss 0.52131376 - samples/sec: 752.53 - lr: 0.025000\n",
      "2020-10-21 23:58:47,671 epoch 57 - iter 324/368 - loss 0.52713992 - samples/sec: 736.05 - lr: 0.025000\n",
      "2020-10-21 23:58:49,362 epoch 57 - iter 360/368 - loss 0.52424147 - samples/sec: 710.28 - lr: 0.025000\n",
      "2020-10-21 23:58:49,803 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:58:49,803 EPOCH 57 done: loss 0.5245 - lr 0.0250000\n",
      "2020-10-21 23:58:58,044 DEV : loss 0.5826287865638733 - score 0.7694\n",
      "Epoch    57: reducing learning rate of group 0 to 1.2500e-02.\n",
      "2020-10-21 23:58:59,970 BAD EPOCHS (no improvement): 6\n",
      "2020-10-21 23:58:59,971 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:59:02,107 epoch 58 - iter 36/368 - loss 0.49899413 - samples/sec: 631.93 - lr: 0.012500\n",
      "2020-10-21 23:59:03,799 epoch 58 - iter 72/368 - loss 0.50942487 - samples/sec: 715.05 - lr: 0.012500\n",
      "2020-10-21 23:59:05,469 epoch 58 - iter 108/368 - loss 0.50182040 - samples/sec: 722.04 - lr: 0.012500\n",
      "2020-10-21 23:59:09,342 epoch 58 - iter 144/368 - loss 0.50604288 - samples/sec: 698.21 - lr: 0.012500\n",
      "2020-10-21 23:59:10,984 epoch 58 - iter 180/368 - loss 0.50472799 - samples/sec: 730.33 - lr: 0.012500\n",
      "2020-10-21 23:59:12,557 epoch 58 - iter 216/368 - loss 0.50676360 - samples/sec: 762.51 - lr: 0.012500\n",
      "2020-10-21 23:59:14,228 epoch 58 - iter 252/368 - loss 0.50641677 - samples/sec: 715.31 - lr: 0.012500\n",
      "2020-10-21 23:59:15,844 epoch 58 - iter 288/368 - loss 0.50792821 - samples/sec: 740.48 - lr: 0.012500\n",
      "2020-10-21 23:59:17,443 epoch 58 - iter 324/368 - loss 0.50833110 - samples/sec: 748.84 - lr: 0.012500\n",
      "2020-10-21 23:59:18,985 epoch 58 - iter 360/368 - loss 0.51099353 - samples/sec: 777.41 - lr: 0.012500\n",
      "2020-10-21 23:59:19,425 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:59:19,426 EPOCH 58 done: loss 0.5087 - lr 0.0125000\n",
      "2020-10-21 23:59:27,690 DEV : loss 0.6159767508506775 - score 0.763\n",
      "2020-10-21 23:59:29,587 BAD EPOCHS (no improvement): 1\n",
      "2020-10-21 23:59:29,588 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:59:31,781 epoch 59 - iter 36/368 - loss 0.49676358 - samples/sec: 617.02 - lr: 0.012500\n",
      "2020-10-21 23:59:33,435 epoch 59 - iter 72/368 - loss 0.49141929 - samples/sec: 731.74 - lr: 0.012500\n",
      "2020-10-21 23:59:35,063 epoch 59 - iter 108/368 - loss 0.50000650 - samples/sec: 741.52 - lr: 0.012500\n",
      "2020-10-21 23:59:38,783 epoch 59 - iter 144/368 - loss 0.50493118 - samples/sec: 316.91 - lr: 0.012500\n",
      "2020-10-21 23:59:40,373 epoch 59 - iter 180/368 - loss 0.49975147 - samples/sec: 758.13 - lr: 0.012500\n",
      "2020-10-21 23:59:42,071 epoch 59 - iter 216/368 - loss 0.50176003 - samples/sec: 703.95 - lr: 0.012500\n",
      "2020-10-21 23:59:43,618 epoch 59 - iter 252/368 - loss 0.50473106 - samples/sec: 783.51 - lr: 0.012500\n",
      "2020-10-21 23:59:45,154 epoch 59 - iter 288/368 - loss 0.50288647 - samples/sec: 785.80 - lr: 0.012500\n",
      "2020-10-21 23:59:46,728 epoch 59 - iter 324/368 - loss 0.50461031 - samples/sec: 767.32 - lr: 0.012500\n",
      "2020-10-21 23:59:48,315 epoch 59 - iter 360/368 - loss 0.50491908 - samples/sec: 758.61 - lr: 0.012500\n",
      "2020-10-21 23:59:48,762 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-21 23:59:48,763 EPOCH 59 done: loss 0.5054 - lr 0.0125000\n",
      "2020-10-21 23:59:57,063 DEV : loss 0.5859919190406799 - score 0.7755\n",
      "2020-10-21 23:59:58,943 BAD EPOCHS (no improvement): 2\n",
      "2020-10-21 23:59:58,944 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:00:01,094 epoch 60 - iter 36/368 - loss 0.51732431 - samples/sec: 631.70 - lr: 0.012500\n",
      "2020-10-22 00:00:02,822 epoch 60 - iter 72/368 - loss 0.52031864 - samples/sec: 698.35 - lr: 0.012500\n",
      "2020-10-22 00:00:04,419 epoch 60 - iter 108/368 - loss 0.52757721 - samples/sec: 755.94 - lr: 0.012500\n",
      "2020-10-22 00:00:06,078 epoch 60 - iter 144/368 - loss 0.52222105 - samples/sec: 727.96 - lr: 0.012500\n",
      "2020-10-22 00:00:09,874 epoch 60 - iter 180/368 - loss 0.51641056 - samples/sec: 743.76 - lr: 0.012500\n",
      "2020-10-22 00:00:11,499 epoch 60 - iter 216/368 - loss 0.51723436 - samples/sec: 739.04 - lr: 0.012500\n",
      "2020-10-22 00:00:13,129 epoch 60 - iter 252/368 - loss 0.51696073 - samples/sec: 740.40 - lr: 0.012500\n",
      "2020-10-22 00:00:14,688 epoch 60 - iter 288/368 - loss 0.51279468 - samples/sec: 769.37 - lr: 0.012500\n",
      "2020-10-22 00:00:16,327 epoch 60 - iter 324/368 - loss 0.51387646 - samples/sec: 734.74 - lr: 0.012500\n",
      "2020-10-22 00:00:17,960 epoch 60 - iter 360/368 - loss 0.51454008 - samples/sec: 733.44 - lr: 0.012500\n",
      "2020-10-22 00:00:18,387 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:00:18,388 EPOCH 60 done: loss 0.5138 - lr 0.0125000\n",
      "2020-10-22 00:00:26,670 DEV : loss 0.5934488773345947 - score 0.7717\n",
      "2020-10-22 00:00:28,542 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 00:00:28,543 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:00:30,656 epoch 61 - iter 36/368 - loss 0.55691658 - samples/sec: 623.59 - lr: 0.012500\n",
      "2020-10-22 00:00:32,364 epoch 61 - iter 72/368 - loss 0.54190510 - samples/sec: 704.36 - lr: 0.012500\n",
      "2020-10-22 00:00:34,115 epoch 61 - iter 108/368 - loss 0.52194700 - samples/sec: 687.55 - lr: 0.012500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 00:00:35,744 epoch 61 - iter 144/368 - loss 0.51698937 - samples/sec: 738.75 - lr: 0.012500\n",
      "2020-10-22 00:00:39,497 epoch 61 - iter 180/368 - loss 0.51286459 - samples/sec: 744.92 - lr: 0.012500\n",
      "2020-10-22 00:00:41,146 epoch 61 - iter 216/368 - loss 0.51260120 - samples/sec: 727.97 - lr: 0.012500\n",
      "2020-10-22 00:00:42,729 epoch 61 - iter 252/368 - loss 0.51040675 - samples/sec: 761.67 - lr: 0.012500\n",
      "2020-10-22 00:00:44,377 epoch 61 - iter 288/368 - loss 0.51086716 - samples/sec: 727.55 - lr: 0.012500\n",
      "2020-10-22 00:00:45,977 epoch 61 - iter 324/368 - loss 0.51175125 - samples/sec: 750.18 - lr: 0.012500\n",
      "2020-10-22 00:00:47,593 epoch 61 - iter 360/368 - loss 0.51282159 - samples/sec: 743.31 - lr: 0.012500\n",
      "2020-10-22 00:00:48,063 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:00:48,064 EPOCH 61 done: loss 0.5130 - lr 0.0125000\n",
      "2020-10-22 00:00:56,431 DEV : loss 0.6094518899917603 - score 0.7686\n",
      "2020-10-22 00:00:58,379 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 00:00:58,380 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:01:00,434 epoch 62 - iter 36/368 - loss 0.53093411 - samples/sec: 660.22 - lr: 0.012500\n",
      "2020-10-22 00:01:02,198 epoch 62 - iter 72/368 - loss 0.52688349 - samples/sec: 677.57 - lr: 0.012500\n",
      "2020-10-22 00:01:03,916 epoch 62 - iter 108/368 - loss 0.52159579 - samples/sec: 702.74 - lr: 0.012500\n",
      "2020-10-22 00:01:05,668 epoch 62 - iter 144/368 - loss 0.51237934 - samples/sec: 685.84 - lr: 0.012500\n",
      "2020-10-22 00:01:09,395 epoch 62 - iter 180/368 - loss 0.51042232 - samples/sec: 760.71 - lr: 0.012500\n",
      "2020-10-22 00:01:11,051 epoch 62 - iter 216/368 - loss 0.51331627 - samples/sec: 724.64 - lr: 0.012500\n",
      "2020-10-22 00:01:12,745 epoch 62 - iter 252/368 - loss 0.51436463 - samples/sec: 708.61 - lr: 0.012500\n",
      "2020-10-22 00:01:14,327 epoch 62 - iter 288/368 - loss 0.51025304 - samples/sec: 761.10 - lr: 0.012500\n",
      "2020-10-22 00:01:15,927 epoch 62 - iter 324/368 - loss 0.51030399 - samples/sec: 752.77 - lr: 0.012500\n",
      "2020-10-22 00:01:17,476 epoch 62 - iter 360/368 - loss 0.51232425 - samples/sec: 775.66 - lr: 0.012500\n",
      "2020-10-22 00:01:17,923 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:01:17,924 EPOCH 62 done: loss 0.5135 - lr 0.0125000\n",
      "2020-10-22 00:01:26,198 DEV : loss 0.5873655676841736 - score 0.7747\n",
      "2020-10-22 00:01:28,101 BAD EPOCHS (no improvement): 5\n",
      "2020-10-22 00:01:28,101 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:01:30,314 epoch 63 - iter 36/368 - loss 0.48224077 - samples/sec: 610.95 - lr: 0.012500\n",
      "2020-10-22 00:01:32,060 epoch 63 - iter 72/368 - loss 0.47985697 - samples/sec: 689.38 - lr: 0.012500\n",
      "2020-10-22 00:01:33,779 epoch 63 - iter 108/368 - loss 0.48971589 - samples/sec: 700.92 - lr: 0.012500\n",
      "2020-10-22 00:01:35,501 epoch 63 - iter 144/368 - loss 0.49006816 - samples/sec: 698.79 - lr: 0.012500\n",
      "2020-10-22 00:01:37,209 epoch 63 - iter 180/368 - loss 0.49249204 - samples/sec: 705.32 - lr: 0.012500\n",
      "2020-10-22 00:01:40,924 epoch 63 - iter 216/368 - loss 0.49286788 - samples/sec: 779.61 - lr: 0.012500\n",
      "2020-10-22 00:01:42,590 epoch 63 - iter 252/368 - loss 0.49404508 - samples/sec: 721.48 - lr: 0.012500\n",
      "2020-10-22 00:01:44,177 epoch 63 - iter 288/368 - loss 0.49649024 - samples/sec: 755.59 - lr: 0.012500\n",
      "2020-10-22 00:01:45,791 epoch 63 - iter 324/368 - loss 0.49319189 - samples/sec: 742.18 - lr: 0.012500\n",
      "2020-10-22 00:01:47,317 epoch 63 - iter 360/368 - loss 0.49665454 - samples/sec: 787.56 - lr: 0.012500\n",
      "2020-10-22 00:01:47,717 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:01:47,718 EPOCH 63 done: loss 0.4977 - lr 0.0125000\n",
      "2020-10-22 00:01:56,194 DEV : loss 0.609870195388794 - score 0.7691\n",
      "Epoch    63: reducing learning rate of group 0 to 6.2500e-03.\n",
      "2020-10-22 00:01:58,098 BAD EPOCHS (no improvement): 6\n",
      "2020-10-22 00:01:58,099 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:02:00,218 epoch 64 - iter 36/368 - loss 0.52101450 - samples/sec: 641.51 - lr: 0.006250\n",
      "2020-10-22 00:02:01,835 epoch 64 - iter 72/368 - loss 0.53128367 - samples/sec: 743.14 - lr: 0.006250\n",
      "2020-10-22 00:02:03,510 epoch 64 - iter 108/368 - loss 0.52226068 - samples/sec: 720.24 - lr: 0.006250\n",
      "2020-10-22 00:02:05,145 epoch 64 - iter 144/368 - loss 0.51255907 - samples/sec: 739.48 - lr: 0.006250\n",
      "2020-10-22 00:02:06,838 epoch 64 - iter 180/368 - loss 0.51476292 - samples/sec: 715.11 - lr: 0.006250\n",
      "2020-10-22 00:02:08,492 epoch 64 - iter 216/368 - loss 0.51363132 - samples/sec: 732.42 - lr: 0.006250\n",
      "2020-10-22 00:02:12,301 epoch 64 - iter 252/368 - loss 0.51431709 - samples/sec: 714.86 - lr: 0.006250\n",
      "2020-10-22 00:02:13,969 epoch 64 - iter 288/368 - loss 0.50821832 - samples/sec: 720.57 - lr: 0.006250\n",
      "2020-10-22 00:02:15,622 epoch 64 - iter 324/368 - loss 0.50191465 - samples/sec: 726.20 - lr: 0.006250\n",
      "2020-10-22 00:02:17,309 epoch 64 - iter 360/368 - loss 0.50045641 - samples/sec: 709.97 - lr: 0.006250\n",
      "2020-10-22 00:02:17,719 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:02:17,720 EPOCH 64 done: loss 0.5016 - lr 0.0062500\n",
      "2020-10-22 00:02:23,804 DEV : loss 0.5979326367378235 - score 0.7722\n",
      "2020-10-22 00:02:27,777 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 00:02:27,778 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:02:29,890 epoch 65 - iter 36/368 - loss 0.51051792 - samples/sec: 647.14 - lr: 0.006250\n",
      "2020-10-22 00:02:31,496 epoch 65 - iter 72/368 - loss 0.50244912 - samples/sec: 753.03 - lr: 0.006250\n",
      "2020-10-22 00:02:33,043 epoch 65 - iter 108/368 - loss 0.50662359 - samples/sec: 782.81 - lr: 0.006250\n",
      "2020-10-22 00:02:34,820 epoch 65 - iter 144/368 - loss 0.50443102 - samples/sec: 672.33 - lr: 0.006250\n",
      "2020-10-22 00:02:36,412 epoch 65 - iter 180/368 - loss 0.50305286 - samples/sec: 756.78 - lr: 0.006250\n",
      "2020-10-22 00:02:37,911 epoch 65 - iter 216/368 - loss 0.50379570 - samples/sec: 804.51 - lr: 0.006250\n",
      "2020-10-22 00:02:41,587 epoch 65 - iter 252/368 - loss 0.50942680 - samples/sec: 780.93 - lr: 0.006250\n",
      "2020-10-22 00:02:43,174 epoch 65 - iter 288/368 - loss 0.51219530 - samples/sec: 755.36 - lr: 0.006250\n",
      "2020-10-22 00:02:44,848 epoch 65 - iter 324/368 - loss 0.50520274 - samples/sec: 717.74 - lr: 0.006250\n",
      "2020-10-22 00:02:46,432 epoch 65 - iter 360/368 - loss 0.50582458 - samples/sec: 759.93 - lr: 0.006250\n",
      "2020-10-22 00:02:46,872 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:02:46,873 EPOCH 65 done: loss 0.5064 - lr 0.0062500\n",
      "2020-10-22 00:02:52,984 DEV : loss 0.614861786365509 - score 0.7691\n",
      "2020-10-22 00:02:54,882 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 00:02:54,883 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:02:59,217 epoch 66 - iter 36/368 - loss 0.50073424 - samples/sec: 656.52 - lr: 0.006250\n",
      "2020-10-22 00:03:00,863 epoch 66 - iter 72/368 - loss 0.49856884 - samples/sec: 727.45 - lr: 0.006250\n",
      "2020-10-22 00:03:02,478 epoch 66 - iter 108/368 - loss 0.49480907 - samples/sec: 742.59 - lr: 0.006250\n",
      "2020-10-22 00:03:04,037 epoch 66 - iter 144/368 - loss 0.50602763 - samples/sec: 769.08 - lr: 0.006250\n",
      "2020-10-22 00:03:05,587 epoch 66 - iter 180/368 - loss 0.50482567 - samples/sec: 774.89 - lr: 0.006250\n",
      "2020-10-22 00:03:07,247 epoch 66 - iter 216/368 - loss 0.50119639 - samples/sec: 721.78 - lr: 0.006250\n",
      "2020-10-22 00:03:08,906 epoch 66 - iter 252/368 - loss 0.50179922 - samples/sec: 722.22 - lr: 0.006250\n",
      "2020-10-22 00:03:12,594 epoch 66 - iter 288/368 - loss 0.50399843 - samples/sec: 732.19 - lr: 0.006250\n",
      "2020-10-22 00:03:14,182 epoch 66 - iter 324/368 - loss 0.50423356 - samples/sec: 756.32 - lr: 0.006250\n",
      "2020-10-22 00:03:15,831 epoch 66 - iter 360/368 - loss 0.49907217 - samples/sec: 727.88 - lr: 0.006250\n",
      "2020-10-22 00:03:16,270 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 00:03:16,271 EPOCH 66 done: loss 0.4987 - lr 0.0062500\n",
      "2020-10-22 00:03:22,533 DEV : loss 0.6037938594818115 - score 0.7719\n",
      "2020-10-22 00:03:24,443 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 00:03:24,444 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:03:28,913 epoch 67 - iter 36/368 - loss 0.46868625 - samples/sec: 596.37 - lr: 0.006250\n",
      "2020-10-22 00:03:30,511 epoch 67 - iter 72/368 - loss 0.45895431 - samples/sec: 754.45 - lr: 0.006250\n",
      "2020-10-22 00:03:32,129 epoch 67 - iter 108/368 - loss 0.48265560 - samples/sec: 741.31 - lr: 0.006250\n",
      "2020-10-22 00:03:33,682 epoch 67 - iter 144/368 - loss 0.48881726 - samples/sec: 774.77 - lr: 0.006250\n",
      "2020-10-22 00:03:35,205 epoch 67 - iter 180/368 - loss 0.48896166 - samples/sec: 789.34 - lr: 0.006250\n",
      "2020-10-22 00:03:36,900 epoch 67 - iter 216/368 - loss 0.49793383 - samples/sec: 710.56 - lr: 0.006250\n",
      "2020-10-22 00:03:38,565 epoch 67 - iter 252/368 - loss 0.49760378 - samples/sec: 722.42 - lr: 0.006250\n",
      "2020-10-22 00:03:40,156 epoch 67 - iter 288/368 - loss 0.50023788 - samples/sec: 754.73 - lr: 0.006250\n",
      "2020-10-22 00:03:43,794 epoch 67 - iter 324/368 - loss 0.49935778 - samples/sec: 745.52 - lr: 0.006250\n",
      "2020-10-22 00:03:45,367 epoch 67 - iter 360/368 - loss 0.50358649 - samples/sec: 763.66 - lr: 0.006250\n",
      "2020-10-22 00:03:45,767 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:03:45,767 EPOCH 67 done: loss 0.5030 - lr 0.0062500\n",
      "2020-10-22 00:03:51,947 DEV : loss 0.5862394571304321 - score 0.7758\n",
      "2020-10-22 00:03:53,859 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 00:03:53,860 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:03:55,979 epoch 68 - iter 36/368 - loss 0.52222655 - samples/sec: 642.02 - lr: 0.006250\n",
      "2020-10-22 00:03:57,614 epoch 68 - iter 72/368 - loss 0.51093538 - samples/sec: 739.24 - lr: 0.006250\n",
      "2020-10-22 00:04:01,425 epoch 68 - iter 108/368 - loss 0.50707434 - samples/sec: 749.34 - lr: 0.006250\n",
      "2020-10-22 00:04:02,960 epoch 68 - iter 144/368 - loss 0.50251388 - samples/sec: 784.26 - lr: 0.006250\n",
      "2020-10-22 00:04:04,554 epoch 68 - iter 180/368 - loss 0.50420038 - samples/sec: 751.54 - lr: 0.006250\n",
      "2020-10-22 00:04:06,102 epoch 68 - iter 216/368 - loss 0.50264022 - samples/sec: 775.90 - lr: 0.006250\n",
      "2020-10-22 00:04:07,731 epoch 68 - iter 252/368 - loss 0.49650606 - samples/sec: 738.87 - lr: 0.006250\n",
      "2020-10-22 00:04:09,410 epoch 68 - iter 288/368 - loss 0.49496741 - samples/sec: 719.16 - lr: 0.006250\n",
      "2020-10-22 00:04:11,033 epoch 68 - iter 324/368 - loss 0.49551044 - samples/sec: 740.97 - lr: 0.006250\n",
      "2020-10-22 00:04:14,689 epoch 68 - iter 360/368 - loss 0.49582782 - samples/sec: 320.00 - lr: 0.006250\n",
      "2020-10-22 00:04:15,138 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:04:15,138 EPOCH 68 done: loss 0.4958 - lr 0.0062500\n",
      "2020-10-22 00:04:21,368 DEV : loss 0.5735877752304077 - score 0.7776\n",
      "2020-10-22 00:04:23,304 BAD EPOCHS (no improvement): 5\n",
      "2020-10-22 00:04:23,305 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:04:25,528 epoch 69 - iter 36/368 - loss 0.51770067 - samples/sec: 603.84 - lr: 0.006250\n",
      "2020-10-22 00:04:27,225 epoch 69 - iter 72/368 - loss 0.49958484 - samples/sec: 708.54 - lr: 0.006250\n",
      "2020-10-22 00:04:31,073 epoch 69 - iter 108/368 - loss 0.50057103 - samples/sec: 717.43 - lr: 0.006250\n",
      "2020-10-22 00:04:32,675 epoch 69 - iter 144/368 - loss 0.49234427 - samples/sec: 746.79 - lr: 0.006250\n",
      "2020-10-22 00:04:34,305 epoch 69 - iter 180/368 - loss 0.48878575 - samples/sec: 735.41 - lr: 0.006250\n",
      "2020-10-22 00:04:35,890 epoch 69 - iter 216/368 - loss 0.48919675 - samples/sec: 753.48 - lr: 0.006250\n",
      "2020-10-22 00:04:37,475 epoch 69 - iter 252/368 - loss 0.48809629 - samples/sec: 757.00 - lr: 0.006250\n",
      "2020-10-22 00:04:39,093 epoch 69 - iter 288/368 - loss 0.48824250 - samples/sec: 743.77 - lr: 0.006250\n",
      "2020-10-22 00:04:40,698 epoch 69 - iter 324/368 - loss 0.48783795 - samples/sec: 748.15 - lr: 0.006250\n",
      "2020-10-22 00:04:44,357 epoch 69 - iter 360/368 - loss 0.48778744 - samples/sec: 770.48 - lr: 0.006250\n",
      "2020-10-22 00:04:44,801 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:04:44,801 EPOCH 69 done: loss 0.4864 - lr 0.0062500\n",
      "2020-10-22 00:04:51,119 DEV : loss 0.58418869972229 - score 0.777\n",
      "Epoch    69: reducing learning rate of group 0 to 3.1250e-03.\n",
      "2020-10-22 00:04:53,048 BAD EPOCHS (no improvement): 6\n",
      "2020-10-22 00:04:53,049 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:04:55,222 epoch 70 - iter 36/368 - loss 0.48414315 - samples/sec: 617.77 - lr: 0.003125\n",
      "2020-10-22 00:04:56,948 epoch 70 - iter 72/368 - loss 0.50617314 - samples/sec: 694.12 - lr: 0.003125\n",
      "2020-10-22 00:05:00,802 epoch 70 - iter 108/368 - loss 0.50277494 - samples/sec: 707.94 - lr: 0.003125\n",
      "2020-10-22 00:05:02,484 epoch 70 - iter 144/368 - loss 0.50957982 - samples/sec: 711.94 - lr: 0.003125\n",
      "2020-10-22 00:05:04,135 epoch 70 - iter 180/368 - loss 0.50609374 - samples/sec: 726.21 - lr: 0.003125\n",
      "2020-10-22 00:05:05,825 epoch 70 - iter 216/368 - loss 0.50110191 - samples/sec: 711.94 - lr: 0.003125\n",
      "2020-10-22 00:05:07,489 epoch 70 - iter 252/368 - loss 0.49941078 - samples/sec: 720.30 - lr: 0.003125\n",
      "2020-10-22 00:05:09,119 epoch 70 - iter 288/368 - loss 0.49843540 - samples/sec: 736.68 - lr: 0.003125\n",
      "2020-10-22 00:05:10,778 epoch 70 - iter 324/368 - loss 0.50104830 - samples/sec: 729.91 - lr: 0.003125\n",
      "2020-10-22 00:05:14,478 epoch 70 - iter 360/368 - loss 0.49912887 - samples/sec: 736.94 - lr: 0.003125\n",
      "2020-10-22 00:05:14,950 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:05:14,951 EPOCH 70 done: loss 0.4991 - lr 0.0031250\n",
      "2020-10-22 00:05:21,231 DEV : loss 0.5755124092102051 - score 0.7814\n",
      "2020-10-22 00:05:23,154 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 00:05:24,820 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:05:27,010 epoch 71 - iter 36/368 - loss 0.49086347 - samples/sec: 609.02 - lr: 0.003125\n",
      "2020-10-22 00:05:28,767 epoch 71 - iter 72/368 - loss 0.48524937 - samples/sec: 683.67 - lr: 0.003125\n",
      "2020-10-22 00:05:30,472 epoch 71 - iter 108/368 - loss 0.48931846 - samples/sec: 704.82 - lr: 0.003125\n",
      "2020-10-22 00:05:34,242 epoch 71 - iter 144/368 - loss 0.49792083 - samples/sec: 767.65 - lr: 0.003125\n",
      "2020-10-22 00:05:35,813 epoch 71 - iter 180/368 - loss 0.49545935 - samples/sec: 766.39 - lr: 0.003125\n",
      "2020-10-22 00:05:37,359 epoch 71 - iter 216/368 - loss 0.49177936 - samples/sec: 781.16 - lr: 0.003125\n",
      "2020-10-22 00:05:38,998 epoch 71 - iter 252/368 - loss 0.48845126 - samples/sec: 734.59 - lr: 0.003125\n",
      "2020-10-22 00:05:40,662 epoch 71 - iter 288/368 - loss 0.49133658 - samples/sec: 721.75 - lr: 0.003125\n",
      "2020-10-22 00:05:42,300 epoch 71 - iter 324/368 - loss 0.49038382 - samples/sec: 732.19 - lr: 0.003125\n",
      "2020-10-22 00:05:45,963 epoch 71 - iter 360/368 - loss 0.49004999 - samples/sec: 751.15 - lr: 0.003125\n",
      "2020-10-22 00:05:46,387 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:05:46,388 EPOCH 71 done: loss 0.4888 - lr 0.0031250\n",
      "2020-10-22 00:05:52,673 DEV : loss 0.5937933921813965 - score 0.7752\n",
      "2020-10-22 00:05:54,610 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 00:05:54,611 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:05:56,887 epoch 72 - iter 36/368 - loss 0.51395722 - samples/sec: 587.20 - lr: 0.003125\n",
      "2020-10-22 00:05:58,587 epoch 72 - iter 72/368 - loss 0.49450515 - samples/sec: 706.30 - lr: 0.003125\n",
      "2020-10-22 00:06:02,473 epoch 72 - iter 108/368 - loss 0.49729861 - samples/sec: 699.14 - lr: 0.003125\n",
      "2020-10-22 00:06:04,108 epoch 72 - iter 144/368 - loss 0.50750517 - samples/sec: 735.18 - lr: 0.003125\n",
      "2020-10-22 00:06:05,778 epoch 72 - iter 180/368 - loss 0.50498128 - samples/sec: 716.93 - lr: 0.003125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 00:06:07,465 epoch 72 - iter 216/368 - loss 0.49933101 - samples/sec: 712.07 - lr: 0.003125\n",
      "2020-10-22 00:06:09,118 epoch 72 - iter 252/368 - loss 0.49351871 - samples/sec: 726.24 - lr: 0.003125\n",
      "2020-10-22 00:06:10,757 epoch 72 - iter 288/368 - loss 0.49458674 - samples/sec: 733.55 - lr: 0.003125\n",
      "2020-10-22 00:06:12,415 epoch 72 - iter 324/368 - loss 0.49406976 - samples/sec: 726.11 - lr: 0.003125\n",
      "2020-10-22 00:06:15,977 epoch 72 - iter 360/368 - loss 0.49640846 - samples/sec: 798.03 - lr: 0.003125\n",
      "2020-10-22 00:06:16,409 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:06:16,409 EPOCH 72 done: loss 0.4953 - lr 0.0031250\n",
      "2020-10-22 00:06:22,708 DEV : loss 0.5951624512672424 - score 0.7742\n",
      "2020-10-22 00:06:24,616 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 00:06:24,617 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:06:26,798 epoch 73 - iter 36/368 - loss 0.54361016 - samples/sec: 612.47 - lr: 0.003125\n",
      "2020-10-22 00:06:28,460 epoch 73 - iter 72/368 - loss 0.49354162 - samples/sec: 724.98 - lr: 0.003125\n",
      "2020-10-22 00:06:30,083 epoch 73 - iter 108/368 - loss 0.48954339 - samples/sec: 740.58 - lr: 0.003125\n",
      "2020-10-22 00:06:33,934 epoch 73 - iter 144/368 - loss 0.49279755 - samples/sec: 724.35 - lr: 0.003125\n",
      "2020-10-22 00:06:35,562 epoch 73 - iter 180/368 - loss 0.49427359 - samples/sec: 736.52 - lr: 0.003125\n",
      "2020-10-22 00:06:37,165 epoch 73 - iter 216/368 - loss 0.49083253 - samples/sec: 747.00 - lr: 0.003125\n",
      "2020-10-22 00:06:38,711 epoch 73 - iter 252/368 - loss 0.49222129 - samples/sec: 777.43 - lr: 0.003125\n",
      "2020-10-22 00:06:40,321 epoch 73 - iter 288/368 - loss 0.49103901 - samples/sec: 744.61 - lr: 0.003125\n",
      "2020-10-22 00:06:41,992 epoch 73 - iter 324/368 - loss 0.49015962 - samples/sec: 715.96 - lr: 0.003125\n",
      "2020-10-22 00:06:43,661 epoch 73 - iter 360/368 - loss 0.49366586 - samples/sec: 717.21 - lr: 0.003125\n",
      "2020-10-22 00:06:46,184 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:06:46,185 EPOCH 73 done: loss 0.4927 - lr 0.0031250\n",
      "2020-10-22 00:06:52,418 DEV : loss 0.5774874687194824 - score 0.7776\n",
      "2020-10-22 00:06:54,338 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 00:06:54,339 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:06:56,531 epoch 74 - iter 36/368 - loss 0.50492732 - samples/sec: 616.52 - lr: 0.003125\n",
      "2020-10-22 00:06:58,207 epoch 74 - iter 72/368 - loss 0.49138838 - samples/sec: 719.52 - lr: 0.003125\n",
      "2020-10-22 00:06:59,821 epoch 74 - iter 108/368 - loss 0.48213116 - samples/sec: 745.33 - lr: 0.003125\n",
      "2020-10-22 00:07:03,500 epoch 74 - iter 144/368 - loss 0.48335724 - samples/sec: 796.20 - lr: 0.003125\n",
      "2020-10-22 00:07:05,089 epoch 74 - iter 180/368 - loss 0.48375689 - samples/sec: 754.16 - lr: 0.003125\n",
      "2020-10-22 00:07:06,727 epoch 74 - iter 216/368 - loss 0.48295027 - samples/sec: 732.31 - lr: 0.003125\n",
      "2020-10-22 00:07:08,346 epoch 74 - iter 252/368 - loss 0.48672871 - samples/sec: 740.95 - lr: 0.003125\n",
      "2020-10-22 00:07:10,001 epoch 74 - iter 288/368 - loss 0.48785245 - samples/sec: 724.68 - lr: 0.003125\n",
      "2020-10-22 00:07:11,641 epoch 74 - iter 324/368 - loss 0.48854790 - samples/sec: 732.47 - lr: 0.003125\n",
      "2020-10-22 00:07:13,297 epoch 74 - iter 360/368 - loss 0.49027083 - samples/sec: 723.81 - lr: 0.003125\n",
      "2020-10-22 00:07:15,792 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:07:15,792 EPOCH 74 done: loss 0.4901 - lr 0.0031250\n",
      "2020-10-22 00:07:22,026 DEV : loss 0.5957274436950684 - score 0.7737\n",
      "2020-10-22 00:07:23,931 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 00:07:23,932 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:07:26,048 epoch 75 - iter 36/368 - loss 0.46924447 - samples/sec: 640.85 - lr: 0.003125\n",
      "2020-10-22 00:07:27,668 epoch 75 - iter 72/368 - loss 0.48606331 - samples/sec: 744.93 - lr: 0.003125\n",
      "2020-10-22 00:07:29,336 epoch 75 - iter 108/368 - loss 0.48791357 - samples/sec: 719.51 - lr: 0.003125\n",
      "2020-10-22 00:07:33,160 epoch 75 - iter 144/368 - loss 0.49055178 - samples/sec: 311.12 - lr: 0.003125\n",
      "2020-10-22 00:07:34,821 epoch 75 - iter 180/368 - loss 0.48588117 - samples/sec: 724.17 - lr: 0.003125\n",
      "2020-10-22 00:07:36,502 epoch 75 - iter 216/368 - loss 0.48892476 - samples/sec: 715.47 - lr: 0.003125\n",
      "2020-10-22 00:07:38,132 epoch 75 - iter 252/368 - loss 0.48864199 - samples/sec: 738.85 - lr: 0.003125\n",
      "2020-10-22 00:07:39,684 epoch 75 - iter 288/368 - loss 0.48410260 - samples/sec: 778.32 - lr: 0.003125\n",
      "2020-10-22 00:07:41,178 epoch 75 - iter 324/368 - loss 0.48786258 - samples/sec: 805.62 - lr: 0.003125\n",
      "2020-10-22 00:07:42,872 epoch 75 - iter 360/368 - loss 0.48643151 - samples/sec: 705.93 - lr: 0.003125\n",
      "2020-10-22 00:07:43,330 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:07:43,330 EPOCH 75 done: loss 0.4870 - lr 0.0031250\n",
      "2020-10-22 00:07:51,594 DEV : loss 0.5869073867797852 - score 0.7816\n",
      "2020-10-22 00:07:53,529 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 00:07:55,169 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:07:57,284 epoch 76 - iter 36/368 - loss 0.51745107 - samples/sec: 637.51 - lr: 0.003125\n",
      "2020-10-22 00:07:58,974 epoch 76 - iter 72/368 - loss 0.51599004 - samples/sec: 713.65 - lr: 0.003125\n",
      "2020-10-22 00:08:00,576 epoch 76 - iter 108/368 - loss 0.51581465 - samples/sec: 749.10 - lr: 0.003125\n",
      "2020-10-22 00:08:04,290 epoch 76 - iter 144/368 - loss 0.51008285 - samples/sec: 784.95 - lr: 0.003125\n",
      "2020-10-22 00:08:05,904 epoch 76 - iter 180/368 - loss 0.50254691 - samples/sec: 744.13 - lr: 0.003125\n",
      "2020-10-22 00:08:07,490 epoch 76 - iter 216/368 - loss 0.49805525 - samples/sec: 757.33 - lr: 0.003125\n",
      "2020-10-22 00:08:09,060 epoch 76 - iter 252/368 - loss 0.49541028 - samples/sec: 762.69 - lr: 0.003125\n",
      "2020-10-22 00:08:10,638 epoch 76 - iter 288/368 - loss 0.49208276 - samples/sec: 762.47 - lr: 0.003125\n",
      "2020-10-22 00:08:12,281 epoch 76 - iter 324/368 - loss 0.48962700 - samples/sec: 729.55 - lr: 0.003125\n",
      "2020-10-22 00:08:13,804 epoch 76 - iter 360/368 - loss 0.48933968 - samples/sec: 788.99 - lr: 0.003125\n",
      "2020-10-22 00:08:14,267 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:08:14,268 EPOCH 76 done: loss 0.4898 - lr 0.0031250\n",
      "2020-10-22 00:08:22,562 DEV : loss 0.594010591506958 - score 0.7783\n",
      "2020-10-22 00:08:24,482 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 00:08:24,483 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:08:26,561 epoch 77 - iter 36/368 - loss 0.45176045 - samples/sec: 630.23 - lr: 0.003125\n",
      "2020-10-22 00:08:28,264 epoch 77 - iter 72/368 - loss 0.48077049 - samples/sec: 708.16 - lr: 0.003125\n",
      "2020-10-22 00:08:29,939 epoch 77 - iter 108/368 - loss 0.48682393 - samples/sec: 717.95 - lr: 0.003125\n",
      "2020-10-22 00:08:31,531 epoch 77 - iter 144/368 - loss 0.49422561 - samples/sec: 759.17 - lr: 0.003125\n",
      "2020-10-22 00:08:35,320 epoch 77 - iter 180/368 - loss 0.49530734 - samples/sec: 742.87 - lr: 0.003125\n",
      "2020-10-22 00:08:36,972 epoch 77 - iter 216/368 - loss 0.49486080 - samples/sec: 728.00 - lr: 0.003125\n",
      "2020-10-22 00:08:38,552 epoch 77 - iter 252/368 - loss 0.49268686 - samples/sec: 761.80 - lr: 0.003125\n",
      "2020-10-22 00:08:40,258 epoch 77 - iter 288/368 - loss 0.49052692 - samples/sec: 703.73 - lr: 0.003125\n",
      "2020-10-22 00:08:41,903 epoch 77 - iter 324/368 - loss 0.48887207 - samples/sec: 729.70 - lr: 0.003125\n",
      "2020-10-22 00:08:43,491 epoch 77 - iter 360/368 - loss 0.49504403 - samples/sec: 755.43 - lr: 0.003125\n",
      "2020-10-22 00:08:43,943 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:08:43,944 EPOCH 77 done: loss 0.4956 - lr 0.0031250\n",
      "2020-10-22 00:08:52,285 DEV : loss 0.5913811922073364 - score 0.7755\n",
      "2020-10-22 00:08:54,220 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 00:08:54,221 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 00:08:56,278 epoch 78 - iter 36/368 - loss 0.46860944 - samples/sec: 664.11 - lr: 0.003125\n",
      "2020-10-22 00:08:57,989 epoch 78 - iter 72/368 - loss 0.47665452 - samples/sec: 702.42 - lr: 0.003125\n",
      "2020-10-22 00:08:59,644 epoch 78 - iter 108/368 - loss 0.48204628 - samples/sec: 728.79 - lr: 0.003125\n",
      "2020-10-22 00:09:01,332 epoch 78 - iter 144/368 - loss 0.48620361 - samples/sec: 713.12 - lr: 0.003125\n",
      "2020-10-22 00:09:02,965 epoch 78 - iter 180/368 - loss 0.48318881 - samples/sec: 739.83 - lr: 0.003125\n",
      "2020-10-22 00:09:06,825 epoch 78 - iter 216/368 - loss 0.48863978 - samples/sec: 701.68 - lr: 0.003125\n",
      "2020-10-22 00:09:08,497 epoch 78 - iter 252/368 - loss 0.48834822 - samples/sec: 717.45 - lr: 0.003125\n",
      "2020-10-22 00:09:10,173 epoch 78 - iter 288/368 - loss 0.48799227 - samples/sec: 715.47 - lr: 0.003125\n",
      "2020-10-22 00:09:11,819 epoch 78 - iter 324/368 - loss 0.48809788 - samples/sec: 730.08 - lr: 0.003125\n",
      "2020-10-22 00:09:13,478 epoch 78 - iter 360/368 - loss 0.48895554 - samples/sec: 725.59 - lr: 0.003125\n",
      "2020-10-22 00:09:13,940 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:09:13,941 EPOCH 78 done: loss 0.4872 - lr 0.0031250\n",
      "2020-10-22 00:09:22,358 DEV : loss 0.5802455544471741 - score 0.7816\n",
      "2020-10-22 00:09:24,284 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 00:09:25,952 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:09:28,141 epoch 79 - iter 36/368 - loss 0.47653441 - samples/sec: 620.93 - lr: 0.003125\n",
      "2020-10-22 00:09:29,902 epoch 79 - iter 72/368 - loss 0.49693164 - samples/sec: 685.13 - lr: 0.003125\n",
      "2020-10-22 00:09:31,602 epoch 79 - iter 108/368 - loss 0.48763380 - samples/sec: 708.98 - lr: 0.003125\n",
      "2020-10-22 00:09:33,189 epoch 79 - iter 144/368 - loss 0.49349690 - samples/sec: 763.07 - lr: 0.003125\n",
      "2020-10-22 00:09:34,828 epoch 79 - iter 180/368 - loss 0.49905307 - samples/sec: 736.08 - lr: 0.003125\n",
      "2020-10-22 00:09:36,463 epoch 79 - iter 216/368 - loss 0.50332409 - samples/sec: 734.55 - lr: 0.003125\n",
      "2020-10-22 00:09:40,298 epoch 79 - iter 252/368 - loss 0.49887293 - samples/sec: 727.12 - lr: 0.003125\n",
      "2020-10-22 00:09:41,801 epoch 79 - iter 288/368 - loss 0.49503033 - samples/sec: 804.79 - lr: 0.003125\n",
      "2020-10-22 00:09:43,451 epoch 79 - iter 324/368 - loss 0.48950055 - samples/sec: 728.65 - lr: 0.003125\n",
      "2020-10-22 00:09:44,940 epoch 79 - iter 360/368 - loss 0.49010343 - samples/sec: 810.66 - lr: 0.003125\n",
      "2020-10-22 00:09:45,328 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:09:45,328 EPOCH 79 done: loss 0.4904 - lr 0.0031250\n",
      "2020-10-22 00:09:53,852 DEV : loss 0.5726310014724731 - score 0.7801\n",
      "2020-10-22 00:09:55,776 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 00:09:55,777 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:09:57,910 epoch 80 - iter 36/368 - loss 0.49578259 - samples/sec: 631.21 - lr: 0.003125\n",
      "2020-10-22 00:09:59,652 epoch 80 - iter 72/368 - loss 0.48697467 - samples/sec: 692.21 - lr: 0.003125\n",
      "2020-10-22 00:10:01,341 epoch 80 - iter 108/368 - loss 0.48172477 - samples/sec: 714.59 - lr: 0.003125\n",
      "2020-10-22 00:10:02,922 epoch 80 - iter 144/368 - loss 0.48513615 - samples/sec: 760.93 - lr: 0.003125\n",
      "2020-10-22 00:10:04,456 epoch 80 - iter 180/368 - loss 0.48459109 - samples/sec: 786.02 - lr: 0.003125\n",
      "2020-10-22 00:10:06,069 epoch 80 - iter 216/368 - loss 0.48563035 - samples/sec: 744.67 - lr: 0.003125\n",
      "2020-10-22 00:10:09,927 epoch 80 - iter 252/368 - loss 0.48602487 - samples/sec: 734.40 - lr: 0.003125\n",
      "2020-10-22 00:10:11,536 epoch 80 - iter 288/368 - loss 0.48443648 - samples/sec: 745.72 - lr: 0.003125\n",
      "2020-10-22 00:10:13,245 epoch 80 - iter 324/368 - loss 0.48365210 - samples/sec: 700.89 - lr: 0.003125\n",
      "2020-10-22 00:10:14,921 epoch 80 - iter 360/368 - loss 0.48807139 - samples/sec: 716.71 - lr: 0.003125\n",
      "2020-10-22 00:10:15,354 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:10:15,354 EPOCH 80 done: loss 0.4875 - lr 0.0031250\n",
      "2020-10-22 00:10:23,800 DEV : loss 0.5753061175346375 - score 0.7806\n",
      "2020-10-22 00:10:25,729 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 00:10:25,729 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:10:27,796 epoch 81 - iter 36/368 - loss 0.46015016 - samples/sec: 643.72 - lr: 0.003125\n",
      "2020-10-22 00:10:29,448 epoch 81 - iter 72/368 - loss 0.48801379 - samples/sec: 731.18 - lr: 0.003125\n",
      "2020-10-22 00:10:31,084 epoch 81 - iter 108/368 - loss 0.48769027 - samples/sec: 738.27 - lr: 0.003125\n",
      "2020-10-22 00:10:32,729 epoch 81 - iter 144/368 - loss 0.48555284 - samples/sec: 731.82 - lr: 0.003125\n",
      "2020-10-22 00:10:34,374 epoch 81 - iter 180/368 - loss 0.48202107 - samples/sec: 737.29 - lr: 0.003125\n",
      "2020-10-22 00:10:36,026 epoch 81 - iter 216/368 - loss 0.48430642 - samples/sec: 727.30 - lr: 0.003125\n",
      "2020-10-22 00:10:37,666 epoch 81 - iter 252/368 - loss 0.48427983 - samples/sec: 731.76 - lr: 0.003125\n",
      "2020-10-22 00:10:41,409 epoch 81 - iter 288/368 - loss 0.48655390 - samples/sec: 762.88 - lr: 0.003125\n",
      "2020-10-22 00:10:43,004 epoch 81 - iter 324/368 - loss 0.48635419 - samples/sec: 753.83 - lr: 0.003125\n",
      "2020-10-22 00:10:44,589 epoch 81 - iter 360/368 - loss 0.48647676 - samples/sec: 758.93 - lr: 0.003125\n",
      "2020-10-22 00:10:45,029 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:10:45,029 EPOCH 81 done: loss 0.4853 - lr 0.0031250\n",
      "2020-10-22 00:10:51,225 DEV : loss 0.6124602556228638 - score 0.7722\n",
      "2020-10-22 00:10:53,135 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 00:10:53,136 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:10:57,500 epoch 82 - iter 36/368 - loss 0.48080419 - samples/sec: 654.71 - lr: 0.003125\n",
      "2020-10-22 00:10:59,116 epoch 82 - iter 72/368 - loss 0.46730142 - samples/sec: 742.74 - lr: 0.003125\n",
      "2020-10-22 00:11:00,769 epoch 82 - iter 108/368 - loss 0.47339694 - samples/sec: 727.32 - lr: 0.003125\n",
      "2020-10-22 00:11:02,437 epoch 82 - iter 144/368 - loss 0.47705376 - samples/sec: 720.78 - lr: 0.003125\n",
      "2020-10-22 00:11:04,120 epoch 82 - iter 180/368 - loss 0.48445857 - samples/sec: 714.05 - lr: 0.003125\n",
      "2020-10-22 00:11:05,723 epoch 82 - iter 216/368 - loss 0.48411585 - samples/sec: 749.98 - lr: 0.003125\n",
      "2020-10-22 00:11:07,260 epoch 82 - iter 252/368 - loss 0.48042129 - samples/sec: 780.33 - lr: 0.003125\n",
      "2020-10-22 00:11:10,879 epoch 82 - iter 288/368 - loss 0.48466601 - samples/sec: 757.19 - lr: 0.003125\n",
      "2020-10-22 00:11:12,467 epoch 82 - iter 324/368 - loss 0.48253957 - samples/sec: 752.77 - lr: 0.003125\n",
      "2020-10-22 00:11:14,034 epoch 82 - iter 360/368 - loss 0.48486147 - samples/sec: 762.13 - lr: 0.003125\n",
      "2020-10-22 00:11:14,474 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:11:14,474 EPOCH 82 done: loss 0.4858 - lr 0.0031250\n",
      "2020-10-22 00:11:20,655 DEV : loss 0.5811573266983032 - score 0.7786\n",
      "2020-10-22 00:11:22,579 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 00:11:22,580 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:11:24,670 epoch 83 - iter 36/368 - loss 0.47402460 - samples/sec: 655.36 - lr: 0.003125\n",
      "2020-10-22 00:11:28,594 epoch 83 - iter 72/368 - loss 0.47691871 - samples/sec: 696.82 - lr: 0.003125\n",
      "2020-10-22 00:11:30,173 epoch 83 - iter 108/368 - loss 0.47418738 - samples/sec: 758.83 - lr: 0.003125\n",
      "2020-10-22 00:11:31,904 epoch 83 - iter 144/368 - loss 0.47944087 - samples/sec: 692.76 - lr: 0.003125\n",
      "2020-10-22 00:11:33,490 epoch 83 - iter 180/368 - loss 0.47644789 - samples/sec: 755.57 - lr: 0.003125\n",
      "2020-10-22 00:11:35,137 epoch 83 - iter 216/368 - loss 0.48103522 - samples/sec: 728.88 - lr: 0.003125\n",
      "2020-10-22 00:11:36,811 epoch 83 - iter 252/368 - loss 0.48337352 - samples/sec: 714.04 - lr: 0.003125\n",
      "2020-10-22 00:11:38,467 epoch 83 - iter 288/368 - loss 0.48199751 - samples/sec: 723.08 - lr: 0.003125\n",
      "2020-10-22 00:11:42,159 epoch 83 - iter 324/368 - loss 0.48529642 - samples/sec: 733.14 - lr: 0.003125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 00:11:43,799 epoch 83 - iter 360/368 - loss 0.48651683 - samples/sec: 729.71 - lr: 0.003125\n",
      "2020-10-22 00:11:44,224 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:11:44,224 EPOCH 83 done: loss 0.4870 - lr 0.0031250\n",
      "2020-10-22 00:11:50,394 DEV : loss 0.579639196395874 - score 0.7827\n",
      "2020-10-22 00:11:52,315 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 00:11:53,949 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:11:56,166 epoch 84 - iter 36/368 - loss 0.47806207 - samples/sec: 604.10 - lr: 0.003125\n",
      "2020-10-22 00:12:00,093 epoch 84 - iter 72/368 - loss 0.48498031 - samples/sec: 709.42 - lr: 0.003125\n",
      "2020-10-22 00:12:01,721 epoch 84 - iter 108/368 - loss 0.48017066 - samples/sec: 734.48 - lr: 0.003125\n",
      "2020-10-22 00:12:03,466 epoch 84 - iter 144/368 - loss 0.48057049 - samples/sec: 687.00 - lr: 0.003125\n",
      "2020-10-22 00:12:05,154 epoch 84 - iter 180/368 - loss 0.47887135 - samples/sec: 712.03 - lr: 0.003125\n",
      "2020-10-22 00:12:06,760 epoch 84 - iter 216/368 - loss 0.47862016 - samples/sec: 747.66 - lr: 0.003125\n",
      "2020-10-22 00:12:08,333 epoch 84 - iter 252/368 - loss 0.47766323 - samples/sec: 765.06 - lr: 0.003125\n",
      "2020-10-22 00:12:09,957 epoch 84 - iter 288/368 - loss 0.48001175 - samples/sec: 743.15 - lr: 0.003125\n",
      "2020-10-22 00:12:11,535 epoch 84 - iter 324/368 - loss 0.48115165 - samples/sec: 762.76 - lr: 0.003125\n",
      "2020-10-22 00:12:15,185 epoch 84 - iter 360/368 - loss 0.48058331 - samples/sec: 740.83 - lr: 0.003125\n",
      "2020-10-22 00:12:15,614 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:12:15,615 EPOCH 84 done: loss 0.4808 - lr 0.0031250\n",
      "2020-10-22 00:12:21,719 DEV : loss 0.5913196802139282 - score 0.7801\n",
      "2020-10-22 00:12:23,622 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 00:12:23,623 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:12:25,734 epoch 85 - iter 36/368 - loss 0.50812034 - samples/sec: 645.57 - lr: 0.003125\n",
      "2020-10-22 00:12:27,429 epoch 85 - iter 72/368 - loss 0.51098588 - samples/sec: 710.12 - lr: 0.003125\n",
      "2020-10-22 00:12:31,260 epoch 85 - iter 108/368 - loss 0.50652433 - samples/sec: 715.21 - lr: 0.003125\n",
      "2020-10-22 00:12:32,907 epoch 85 - iter 144/368 - loss 0.50167720 - samples/sec: 729.70 - lr: 0.003125\n",
      "2020-10-22 00:12:34,678 epoch 85 - iter 180/368 - loss 0.49510734 - samples/sec: 676.65 - lr: 0.003125\n",
      "2020-10-22 00:12:36,341 epoch 85 - iter 216/368 - loss 0.49429200 - samples/sec: 720.41 - lr: 0.003125\n",
      "2020-10-22 00:12:38,008 epoch 85 - iter 252/368 - loss 0.49417898 - samples/sec: 719.69 - lr: 0.003125\n",
      "2020-10-22 00:12:39,645 epoch 85 - iter 288/368 - loss 0.49418418 - samples/sec: 731.14 - lr: 0.003125\n",
      "2020-10-22 00:12:41,287 epoch 85 - iter 324/368 - loss 0.49630764 - samples/sec: 729.92 - lr: 0.003125\n",
      "2020-10-22 00:12:44,937 epoch 85 - iter 360/368 - loss 0.49218186 - samples/sec: 745.91 - lr: 0.003125\n",
      "2020-10-22 00:12:45,386 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:12:45,387 EPOCH 85 done: loss 0.4913 - lr 0.0031250\n",
      "2020-10-22 00:12:51,675 DEV : loss 0.5741337537765503 - score 0.7819\n",
      "2020-10-22 00:12:53,614 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 00:12:53,615 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:12:55,825 epoch 86 - iter 36/368 - loss 0.47723737 - samples/sec: 612.40 - lr: 0.003125\n",
      "2020-10-22 00:12:57,454 epoch 86 - iter 72/368 - loss 0.48860020 - samples/sec: 739.74 - lr: 0.003125\n",
      "2020-10-22 00:13:01,194 epoch 86 - iter 108/368 - loss 0.48583856 - samples/sec: 768.78 - lr: 0.003125\n",
      "2020-10-22 00:13:02,737 epoch 86 - iter 144/368 - loss 0.48656288 - samples/sec: 778.70 - lr: 0.003125\n",
      "2020-10-22 00:13:04,408 epoch 86 - iter 180/368 - loss 0.48787552 - samples/sec: 718.35 - lr: 0.003125\n",
      "2020-10-22 00:13:06,034 epoch 86 - iter 216/368 - loss 0.49308171 - samples/sec: 741.62 - lr: 0.003125\n",
      "2020-10-22 00:13:07,627 epoch 86 - iter 252/368 - loss 0.49725674 - samples/sec: 753.08 - lr: 0.003125\n",
      "2020-10-22 00:13:09,312 epoch 86 - iter 288/368 - loss 0.49274876 - samples/sec: 710.98 - lr: 0.003125\n",
      "2020-10-22 00:13:10,947 epoch 86 - iter 324/368 - loss 0.49100690 - samples/sec: 732.46 - lr: 0.003125\n",
      "2020-10-22 00:13:14,625 epoch 86 - iter 360/368 - loss 0.48944692 - samples/sec: 728.78 - lr: 0.003125\n",
      "2020-10-22 00:13:15,030 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:13:15,030 EPOCH 86 done: loss 0.4901 - lr 0.0031250\n",
      "2020-10-22 00:13:21,251 DEV : loss 0.5679697394371033 - score 0.7819\n",
      "2020-10-22 00:13:23,153 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 00:13:23,154 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:13:25,301 epoch 87 - iter 36/368 - loss 0.49387390 - samples/sec: 623.13 - lr: 0.003125\n",
      "2020-10-22 00:13:26,908 epoch 87 - iter 72/368 - loss 0.48667599 - samples/sec: 751.92 - lr: 0.003125\n",
      "2020-10-22 00:13:30,734 epoch 87 - iter 108/368 - loss 0.48971986 - samples/sec: 731.60 - lr: 0.003125\n",
      "2020-10-22 00:13:32,360 epoch 87 - iter 144/368 - loss 0.49030094 - samples/sec: 738.85 - lr: 0.003125\n",
      "2020-10-22 00:13:33,996 epoch 87 - iter 180/368 - loss 0.49167701 - samples/sec: 732.86 - lr: 0.003125\n",
      "2020-10-22 00:13:35,629 epoch 87 - iter 216/368 - loss 0.48783855 - samples/sec: 736.42 - lr: 0.003125\n",
      "2020-10-22 00:13:37,357 epoch 87 - iter 252/368 - loss 0.48802102 - samples/sec: 694.34 - lr: 0.003125\n",
      "2020-10-22 00:13:39,018 epoch 87 - iter 288/368 - loss 0.48562727 - samples/sec: 720.33 - lr: 0.003125\n",
      "2020-10-22 00:13:40,674 epoch 87 - iter 324/368 - loss 0.48372262 - samples/sec: 724.84 - lr: 0.003125\n",
      "2020-10-22 00:13:42,283 epoch 87 - iter 360/368 - loss 0.48747907 - samples/sec: 744.06 - lr: 0.003125\n",
      "2020-10-22 00:13:44,773 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:13:44,774 EPOCH 87 done: loss 0.4867 - lr 0.0031250\n",
      "2020-10-22 00:13:51,044 DEV : loss 0.5895884037017822 - score 0.7755\n",
      "2020-10-22 00:13:52,953 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 00:13:52,954 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:13:55,142 epoch 88 - iter 36/368 - loss 0.47987653 - samples/sec: 621.94 - lr: 0.003125\n",
      "2020-10-22 00:13:56,862 epoch 88 - iter 72/368 - loss 0.48693820 - samples/sec: 705.28 - lr: 0.003125\n",
      "2020-10-22 00:13:58,511 epoch 88 - iter 108/368 - loss 0.48842787 - samples/sec: 731.88 - lr: 0.003125\n",
      "2020-10-22 00:14:02,252 epoch 88 - iter 144/368 - loss 0.49673107 - samples/sec: 770.37 - lr: 0.003125\n",
      "2020-10-22 00:14:03,804 epoch 88 - iter 180/368 - loss 0.49066854 - samples/sec: 776.00 - lr: 0.003125\n",
      "2020-10-22 00:14:05,382 epoch 88 - iter 216/368 - loss 0.48980173 - samples/sec: 764.01 - lr: 0.003125\n",
      "2020-10-22 00:14:07,009 epoch 88 - iter 252/368 - loss 0.48970092 - samples/sec: 741.16 - lr: 0.003125\n",
      "2020-10-22 00:14:08,628 epoch 88 - iter 288/368 - loss 0.49619849 - samples/sec: 741.90 - lr: 0.003125\n",
      "2020-10-22 00:14:10,316 epoch 88 - iter 324/368 - loss 0.49017415 - samples/sec: 711.11 - lr: 0.003125\n",
      "2020-10-22 00:14:12,004 epoch 88 - iter 360/368 - loss 0.48953025 - samples/sec: 709.63 - lr: 0.003125\n",
      "2020-10-22 00:14:12,453 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:14:12,453 EPOCH 88 done: loss 0.4888 - lr 0.0031250\n",
      "2020-10-22 00:14:20,757 DEV : loss 0.5836735367774963 - score 0.7801\n",
      "2020-10-22 00:14:22,684 BAD EPOCHS (no improvement): 5\n",
      "2020-10-22 00:14:22,685 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:14:24,920 epoch 89 - iter 36/368 - loss 0.45321821 - samples/sec: 603.71 - lr: 0.003125\n",
      "2020-10-22 00:14:26,586 epoch 89 - iter 72/368 - loss 0.47595416 - samples/sec: 721.44 - lr: 0.003125\n",
      "2020-10-22 00:14:28,260 epoch 89 - iter 108/368 - loss 0.47795569 - samples/sec: 721.51 - lr: 0.003125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 00:14:29,954 epoch 89 - iter 144/368 - loss 0.47267108 - samples/sec: 706.38 - lr: 0.003125\n",
      "2020-10-22 00:14:33,788 epoch 89 - iter 180/368 - loss 0.47718580 - samples/sec: 741.19 - lr: 0.003125\n",
      "2020-10-22 00:14:35,441 epoch 89 - iter 216/368 - loss 0.47646018 - samples/sec: 724.03 - lr: 0.003125\n",
      "2020-10-22 00:14:37,100 epoch 89 - iter 252/368 - loss 0.47370626 - samples/sec: 722.31 - lr: 0.003125\n",
      "2020-10-22 00:14:38,744 epoch 89 - iter 288/368 - loss 0.47468728 - samples/sec: 729.24 - lr: 0.003125\n",
      "2020-10-22 00:14:40,375 epoch 89 - iter 324/368 - loss 0.47492149 - samples/sec: 733.72 - lr: 0.003125\n",
      "2020-10-22 00:14:41,996 epoch 89 - iter 360/368 - loss 0.47372390 - samples/sec: 741.56 - lr: 0.003125\n",
      "2020-10-22 00:14:42,477 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:14:42,478 EPOCH 89 done: loss 0.4742 - lr 0.0031250\n",
      "2020-10-22 00:14:50,910 DEV : loss 0.593375027179718 - score 0.7768\n",
      "Epoch    89: reducing learning rate of group 0 to 1.5625e-03.\n",
      "2020-10-22 00:14:52,832 BAD EPOCHS (no improvement): 6\n",
      "2020-10-22 00:14:52,833 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:14:55,018 epoch 90 - iter 36/368 - loss 0.48098513 - samples/sec: 609.93 - lr: 0.001563\n",
      "2020-10-22 00:14:56,742 epoch 90 - iter 72/368 - loss 0.49021173 - samples/sec: 696.09 - lr: 0.001563\n",
      "2020-10-22 00:14:58,445 epoch 90 - iter 108/368 - loss 0.49601934 - samples/sec: 703.39 - lr: 0.001563\n",
      "2020-10-22 00:15:00,147 epoch 90 - iter 144/368 - loss 0.49306879 - samples/sec: 706.27 - lr: 0.001563\n",
      "2020-10-22 00:15:03,933 epoch 90 - iter 180/368 - loss 0.49241005 - samples/sec: 754.97 - lr: 0.001563\n",
      "2020-10-22 00:15:05,503 epoch 90 - iter 216/368 - loss 0.49323229 - samples/sec: 769.21 - lr: 0.001563\n",
      "2020-10-22 00:15:07,128 epoch 90 - iter 252/368 - loss 0.49327206 - samples/sec: 741.24 - lr: 0.001563\n",
      "2020-10-22 00:15:08,732 epoch 90 - iter 288/368 - loss 0.48973142 - samples/sec: 752.49 - lr: 0.001563\n",
      "2020-10-22 00:15:10,307 epoch 90 - iter 324/368 - loss 0.48811430 - samples/sec: 765.89 - lr: 0.001563\n",
      "2020-10-22 00:15:11,922 epoch 90 - iter 360/368 - loss 0.48711935 - samples/sec: 742.48 - lr: 0.001563\n",
      "2020-10-22 00:15:12,379 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:15:12,380 EPOCH 90 done: loss 0.4864 - lr 0.0015625\n",
      "2020-10-22 00:15:20,773 DEV : loss 0.5754668712615967 - score 0.7837\n",
      "2020-10-22 00:15:22,714 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 00:15:24,380 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:15:26,581 epoch 91 - iter 36/368 - loss 0.50246550 - samples/sec: 614.76 - lr: 0.001563\n",
      "2020-10-22 00:15:28,344 epoch 91 - iter 72/368 - loss 0.48568343 - samples/sec: 683.18 - lr: 0.001563\n",
      "2020-10-22 00:15:29,989 epoch 91 - iter 108/368 - loss 0.47923357 - samples/sec: 733.36 - lr: 0.001563\n",
      "2020-10-22 00:15:31,606 epoch 91 - iter 144/368 - loss 0.48566640 - samples/sec: 745.55 - lr: 0.001563\n",
      "2020-10-22 00:15:33,269 epoch 91 - iter 180/368 - loss 0.48725568 - samples/sec: 723.97 - lr: 0.001563\n",
      "2020-10-22 00:15:37,114 epoch 91 - iter 216/368 - loss 0.48381667 - samples/sec: 728.17 - lr: 0.001563\n",
      "2020-10-22 00:15:38,739 epoch 91 - iter 252/368 - loss 0.48472514 - samples/sec: 740.89 - lr: 0.001563\n",
      "2020-10-22 00:15:40,287 epoch 91 - iter 288/368 - loss 0.48074664 - samples/sec: 776.07 - lr: 0.001563\n",
      "2020-10-22 00:15:41,955 epoch 91 - iter 324/368 - loss 0.48234166 - samples/sec: 723.51 - lr: 0.001563\n",
      "2020-10-22 00:15:43,659 epoch 91 - iter 360/368 - loss 0.48298595 - samples/sec: 706.77 - lr: 0.001563\n",
      "2020-10-22 00:15:44,103 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:15:44,104 EPOCH 91 done: loss 0.4828 - lr 0.0015625\n",
      "2020-10-22 00:15:52,588 DEV : loss 0.5774306058883667 - score 0.7806\n",
      "2020-10-22 00:15:54,512 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 00:15:54,513 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:15:56,542 epoch 92 - iter 36/368 - loss 0.44500501 - samples/sec: 650.96 - lr: 0.001563\n",
      "2020-10-22 00:15:58,234 epoch 92 - iter 72/368 - loss 0.49147060 - samples/sec: 711.92 - lr: 0.001563\n",
      "2020-10-22 00:15:59,921 epoch 92 - iter 108/368 - loss 0.49504194 - samples/sec: 712.53 - lr: 0.001563\n",
      "2020-10-22 00:16:01,531 epoch 92 - iter 144/368 - loss 0.49330058 - samples/sec: 750.00 - lr: 0.001563\n",
      "2020-10-22 00:16:03,169 epoch 92 - iter 180/368 - loss 0.49001356 - samples/sec: 734.15 - lr: 0.001563\n",
      "2020-10-22 00:16:07,048 epoch 92 - iter 216/368 - loss 0.48575993 - samples/sec: 702.97 - lr: 0.001563\n",
      "2020-10-22 00:16:08,635 epoch 92 - iter 252/368 - loss 0.48288191 - samples/sec: 754.39 - lr: 0.001563\n",
      "2020-10-22 00:16:10,316 epoch 92 - iter 288/368 - loss 0.48085906 - samples/sec: 711.67 - lr: 0.001563\n",
      "2020-10-22 00:16:11,953 epoch 92 - iter 324/368 - loss 0.47833495 - samples/sec: 733.19 - lr: 0.001563\n",
      "2020-10-22 00:16:13,563 epoch 92 - iter 360/368 - loss 0.47918110 - samples/sec: 744.75 - lr: 0.001563\n",
      "2020-10-22 00:16:14,001 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:16:14,001 EPOCH 92 done: loss 0.4798 - lr 0.0015625\n",
      "2020-10-22 00:16:22,381 DEV : loss 0.5786880850791931 - score 0.7811\n",
      "2020-10-22 00:16:24,276 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 00:16:24,277 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:16:26,529 epoch 93 - iter 36/368 - loss 0.46387953 - samples/sec: 597.15 - lr: 0.001563\n",
      "2020-10-22 00:16:28,265 epoch 93 - iter 72/368 - loss 0.48086183 - samples/sec: 693.55 - lr: 0.001563\n",
      "2020-10-22 00:16:29,955 epoch 93 - iter 108/368 - loss 0.50541611 - samples/sec: 714.52 - lr: 0.001563\n",
      "2020-10-22 00:16:31,598 epoch 93 - iter 144/368 - loss 0.49287333 - samples/sec: 732.26 - lr: 0.001563\n",
      "2020-10-22 00:16:33,225 epoch 93 - iter 180/368 - loss 0.49192892 - samples/sec: 738.90 - lr: 0.001563\n",
      "2020-10-22 00:16:37,060 epoch 93 - iter 216/368 - loss 0.49289371 - samples/sec: 718.98 - lr: 0.001563\n",
      "2020-10-22 00:16:38,531 epoch 93 - iter 252/368 - loss 0.49442601 - samples/sec: 818.38 - lr: 0.001563\n",
      "2020-10-22 00:16:39,991 epoch 93 - iter 288/368 - loss 0.49187376 - samples/sec: 824.46 - lr: 0.001563\n",
      "2020-10-22 00:16:41,599 epoch 93 - iter 324/368 - loss 0.48700607 - samples/sec: 748.52 - lr: 0.001563\n",
      "2020-10-22 00:16:43,228 epoch 93 - iter 360/368 - loss 0.48580229 - samples/sec: 736.79 - lr: 0.001563\n",
      "2020-10-22 00:16:43,680 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:16:43,681 EPOCH 93 done: loss 0.4857 - lr 0.0015625\n",
      "2020-10-22 00:16:52,060 DEV : loss 0.5740349888801575 - score 0.7842\n",
      "2020-10-22 00:16:53,968 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 00:16:55,600 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:16:57,624 epoch 94 - iter 36/368 - loss 0.50746007 - samples/sec: 652.17 - lr: 0.001563\n",
      "2020-10-22 00:16:59,398 epoch 94 - iter 72/368 - loss 0.50073606 - samples/sec: 681.50 - lr: 0.001563\n",
      "2020-10-22 00:17:01,077 epoch 94 - iter 108/368 - loss 0.50444134 - samples/sec: 719.76 - lr: 0.001563\n",
      "2020-10-22 00:17:02,716 epoch 94 - iter 144/368 - loss 0.48821397 - samples/sec: 735.65 - lr: 0.001563\n",
      "2020-10-22 00:17:04,327 epoch 94 - iter 180/368 - loss 0.48980998 - samples/sec: 752.26 - lr: 0.001563\n",
      "2020-10-22 00:17:05,960 epoch 94 - iter 216/368 - loss 0.49173606 - samples/sec: 737.91 - lr: 0.001563\n",
      "2020-10-22 00:17:09,796 epoch 94 - iter 252/368 - loss 0.48792177 - samples/sec: 733.44 - lr: 0.001563\n",
      "2020-10-22 00:17:11,391 epoch 94 - iter 288/368 - loss 0.48658655 - samples/sec: 755.13 - lr: 0.001563\n",
      "2020-10-22 00:17:13,013 epoch 94 - iter 324/368 - loss 0.48657310 - samples/sec: 743.52 - lr: 0.001563\n",
      "2020-10-22 00:17:14,687 epoch 94 - iter 360/368 - loss 0.48644740 - samples/sec: 718.36 - lr: 0.001563\n",
      "2020-10-22 00:17:15,122 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 00:17:15,123 EPOCH 94 done: loss 0.4866 - lr 0.0015625\n",
      "2020-10-22 00:17:23,485 DEV : loss 0.585536777973175 - score 0.7814\n",
      "2020-10-22 00:17:25,411 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 00:17:25,412 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:17:27,606 epoch 95 - iter 36/368 - loss 0.45429086 - samples/sec: 615.24 - lr: 0.001563\n",
      "2020-10-22 00:17:29,277 epoch 95 - iter 72/368 - loss 0.47406397 - samples/sec: 720.00 - lr: 0.001563\n",
      "2020-10-22 00:17:30,979 epoch 95 - iter 108/368 - loss 0.47783762 - samples/sec: 705.16 - lr: 0.001563\n",
      "2020-10-22 00:17:32,636 epoch 95 - iter 144/368 - loss 0.48098466 - samples/sec: 725.06 - lr: 0.001563\n",
      "2020-10-22 00:17:34,309 epoch 95 - iter 180/368 - loss 0.47794133 - samples/sec: 721.84 - lr: 0.001563\n",
      "2020-10-22 00:17:36,050 epoch 95 - iter 216/368 - loss 0.47851074 - samples/sec: 689.74 - lr: 0.001563\n",
      "2020-10-22 00:17:37,752 epoch 95 - iter 252/368 - loss 0.48517195 - samples/sec: 706.15 - lr: 0.001563\n",
      "2020-10-22 00:17:41,638 epoch 95 - iter 288/368 - loss 0.48124855 - samples/sec: 726.14 - lr: 0.001563\n",
      "2020-10-22 00:17:43,234 epoch 95 - iter 324/368 - loss 0.48102196 - samples/sec: 753.60 - lr: 0.001563\n",
      "2020-10-22 00:17:44,896 epoch 95 - iter 360/368 - loss 0.48223822 - samples/sec: 721.27 - lr: 0.001563\n",
      "2020-10-22 00:17:45,323 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:17:45,324 EPOCH 95 done: loss 0.4829 - lr 0.0015625\n",
      "2020-10-22 00:17:51,553 DEV : loss 0.5809628367424011 - score 0.7832\n",
      "2020-10-22 00:17:53,497 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 00:17:53,497 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:17:57,845 epoch 96 - iter 36/368 - loss 0.46744492 - samples/sec: 644.74 - lr: 0.001563\n",
      "2020-10-22 00:17:59,549 epoch 96 - iter 72/368 - loss 0.47908853 - samples/sec: 704.11 - lr: 0.001563\n",
      "2020-10-22 00:18:01,210 epoch 96 - iter 108/368 - loss 0.46825066 - samples/sec: 723.86 - lr: 0.001563\n",
      "2020-10-22 00:18:02,762 epoch 96 - iter 144/368 - loss 0.47566965 - samples/sec: 776.53 - lr: 0.001563\n",
      "2020-10-22 00:18:04,316 epoch 96 - iter 180/368 - loss 0.48024481 - samples/sec: 774.05 - lr: 0.001563\n",
      "2020-10-22 00:18:05,984 epoch 96 - iter 216/368 - loss 0.47624381 - samples/sec: 721.05 - lr: 0.001563\n",
      "2020-10-22 00:18:07,539 epoch 96 - iter 252/368 - loss 0.48048417 - samples/sec: 776.97 - lr: 0.001563\n",
      "2020-10-22 00:18:09,136 epoch 96 - iter 288/368 - loss 0.48290602 - samples/sec: 751.30 - lr: 0.001563\n",
      "2020-10-22 00:18:12,790 epoch 96 - iter 324/368 - loss 0.48394936 - samples/sec: 734.95 - lr: 0.001563\n",
      "2020-10-22 00:18:14,480 epoch 96 - iter 360/368 - loss 0.48544636 - samples/sec: 712.39 - lr: 0.001563\n",
      "2020-10-22 00:18:14,916 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:18:14,916 EPOCH 96 done: loss 0.4859 - lr 0.0015625\n",
      "2020-10-22 00:18:21,138 DEV : loss 0.5787898898124695 - score 0.7829\n",
      "2020-10-22 00:18:23,065 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 00:18:23,066 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:18:25,123 epoch 97 - iter 36/368 - loss 0.47718025 - samples/sec: 656.07 - lr: 0.001563\n",
      "2020-10-22 00:18:28,965 epoch 97 - iter 72/368 - loss 0.47683055 - samples/sec: 730.15 - lr: 0.001563\n",
      "2020-10-22 00:18:30,542 epoch 97 - iter 108/368 - loss 0.48862320 - samples/sec: 764.19 - lr: 0.001563\n",
      "2020-10-22 00:18:32,157 epoch 97 - iter 144/368 - loss 0.48863447 - samples/sec: 745.59 - lr: 0.001563\n",
      "2020-10-22 00:18:33,777 epoch 97 - iter 180/368 - loss 0.48438193 - samples/sec: 742.42 - lr: 0.001563\n",
      "2020-10-22 00:18:35,371 epoch 97 - iter 216/368 - loss 0.48763372 - samples/sec: 754.40 - lr: 0.001563\n",
      "2020-10-22 00:18:36,983 epoch 97 - iter 252/368 - loss 0.48519472 - samples/sec: 746.89 - lr: 0.001563\n",
      "2020-10-22 00:18:38,556 epoch 97 - iter 288/368 - loss 0.48506398 - samples/sec: 767.38 - lr: 0.001563\n",
      "2020-10-22 00:18:40,164 epoch 97 - iter 324/368 - loss 0.48530966 - samples/sec: 750.16 - lr: 0.001563\n",
      "2020-10-22 00:18:43,717 epoch 97 - iter 360/368 - loss 0.48591395 - samples/sec: 790.57 - lr: 0.001563\n",
      "2020-10-22 00:18:44,155 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:18:44,156 EPOCH 97 done: loss 0.4869 - lr 0.0015625\n",
      "2020-10-22 00:18:50,330 DEV : loss 0.5847861766815186 - score 0.7811\n",
      "2020-10-22 00:18:52,240 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 00:18:52,241 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:18:54,378 epoch 98 - iter 36/368 - loss 0.53447306 - samples/sec: 630.76 - lr: 0.001563\n",
      "2020-10-22 00:18:56,068 epoch 98 - iter 72/368 - loss 0.48637414 - samples/sec: 711.72 - lr: 0.001563\n",
      "2020-10-22 00:18:59,961 epoch 98 - iter 108/368 - loss 0.48443625 - samples/sec: 301.44 - lr: 0.001563\n",
      "2020-10-22 00:19:01,617 epoch 98 - iter 144/368 - loss 0.48529818 - samples/sec: 721.38 - lr: 0.001563\n",
      "2020-10-22 00:19:03,306 epoch 98 - iter 180/368 - loss 0.48004997 - samples/sec: 710.13 - lr: 0.001563\n",
      "2020-10-22 00:19:04,911 epoch 98 - iter 216/368 - loss 0.47644715 - samples/sec: 747.20 - lr: 0.001563\n",
      "2020-10-22 00:19:06,594 epoch 98 - iter 252/368 - loss 0.47226985 - samples/sec: 713.18 - lr: 0.001563\n",
      "2020-10-22 00:19:08,304 epoch 98 - iter 288/368 - loss 0.47893969 - samples/sec: 697.69 - lr: 0.001563\n",
      "2020-10-22 00:19:11,913 epoch 98 - iter 324/368 - loss 0.47772748 - samples/sec: 765.74 - lr: 0.001563\n",
      "2020-10-22 00:19:13,559 epoch 98 - iter 360/368 - loss 0.48306853 - samples/sec: 728.34 - lr: 0.001563\n",
      "2020-10-22 00:19:13,999 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:19:14,000 EPOCH 98 done: loss 0.4801 - lr 0.0015625\n",
      "2020-10-22 00:19:20,164 DEV : loss 0.5833483338356018 - score 0.7822\n",
      "2020-10-22 00:19:22,090 BAD EPOCHS (no improvement): 5\n",
      "2020-10-22 00:19:22,091 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:19:24,293 epoch 99 - iter 36/368 - loss 0.46936746 - samples/sec: 615.38 - lr: 0.001563\n",
      "2020-10-22 00:19:26,085 epoch 99 - iter 72/368 - loss 0.46121320 - samples/sec: 670.94 - lr: 0.001563\n",
      "2020-10-22 00:19:29,966 epoch 99 - iter 108/368 - loss 0.46703044 - samples/sec: 708.51 - lr: 0.001563\n",
      "2020-10-22 00:19:31,572 epoch 99 - iter 144/368 - loss 0.47339493 - samples/sec: 745.74 - lr: 0.001563\n",
      "2020-10-22 00:19:33,258 epoch 99 - iter 180/368 - loss 0.47393084 - samples/sec: 711.68 - lr: 0.001563\n",
      "2020-10-22 00:19:34,838 epoch 99 - iter 216/368 - loss 0.47840781 - samples/sec: 760.26 - lr: 0.001563\n",
      "2020-10-22 00:19:36,464 epoch 99 - iter 252/368 - loss 0.47943073 - samples/sec: 739.73 - lr: 0.001563\n",
      "2020-10-22 00:19:38,080 epoch 99 - iter 288/368 - loss 0.47781734 - samples/sec: 743.76 - lr: 0.001563\n",
      "2020-10-22 00:19:39,611 epoch 99 - iter 324/368 - loss 0.48213163 - samples/sec: 786.88 - lr: 0.001563\n",
      "2020-10-22 00:19:43,367 epoch 99 - iter 360/368 - loss 0.48166042 - samples/sec: 708.33 - lr: 0.001563\n",
      "2020-10-22 00:19:43,833 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:19:43,834 EPOCH 99 done: loss 0.4804 - lr 0.0015625\n",
      "2020-10-22 00:19:50,093 DEV : loss 0.5924681425094604 - score 0.7778\n",
      "Epoch    99: reducing learning rate of group 0 to 7.8125e-04.\n",
      "2020-10-22 00:19:52,024 BAD EPOCHS (no improvement): 6\n",
      "2020-10-22 00:19:52,025 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:19:54,302 epoch 100 - iter 36/368 - loss 0.50448482 - samples/sec: 586.83 - lr: 0.000781\n",
      "2020-10-22 00:19:55,912 epoch 100 - iter 72/368 - loss 0.48049193 - samples/sec: 753.08 - lr: 0.000781\n",
      "2020-10-22 00:19:59,674 epoch 100 - iter 108/368 - loss 0.47053123 - samples/sec: 762.53 - lr: 0.000781\n",
      "2020-10-22 00:20:01,395 epoch 100 - iter 144/368 - loss 0.47723653 - samples/sec: 698.68 - lr: 0.000781\n",
      "2020-10-22 00:20:03,047 epoch 100 - iter 180/368 - loss 0.48292431 - samples/sec: 727.71 - lr: 0.000781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 00:20:04,646 epoch 100 - iter 216/368 - loss 0.48473669 - samples/sec: 751.73 - lr: 0.000781\n",
      "2020-10-22 00:20:06,271 epoch 100 - iter 252/368 - loss 0.47904748 - samples/sec: 739.84 - lr: 0.000781\n",
      "2020-10-22 00:20:07,892 epoch 100 - iter 288/368 - loss 0.47648268 - samples/sec: 740.50 - lr: 0.000781\n",
      "2020-10-22 00:20:09,504 epoch 100 - iter 324/368 - loss 0.47251173 - samples/sec: 748.58 - lr: 0.000781\n",
      "2020-10-22 00:20:11,072 epoch 100 - iter 360/368 - loss 0.47580548 - samples/sec: 768.06 - lr: 0.000781\n",
      "2020-10-22 00:20:13,558 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:20:13,559 EPOCH 100 done: loss 0.4759 - lr 0.0007813\n",
      "2020-10-22 00:20:19,744 DEV : loss 0.5817830562591553 - score 0.7827\n",
      "2020-10-22 00:20:21,669 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 00:20:21,670 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:20:23,853 epoch 101 - iter 36/368 - loss 0.46790876 - samples/sec: 616.12 - lr: 0.000781\n",
      "2020-10-22 00:20:25,651 epoch 101 - iter 72/368 - loss 0.48234535 - samples/sec: 668.95 - lr: 0.000781\n",
      "2020-10-22 00:20:27,398 epoch 101 - iter 108/368 - loss 0.47836709 - samples/sec: 687.64 - lr: 0.000781\n",
      "2020-10-22 00:20:31,248 epoch 101 - iter 144/368 - loss 0.48324079 - samples/sec: 726.48 - lr: 0.000781\n",
      "2020-10-22 00:20:32,916 epoch 101 - iter 180/368 - loss 0.47617337 - samples/sec: 718.92 - lr: 0.000781\n",
      "2020-10-22 00:20:34,588 epoch 101 - iter 216/368 - loss 0.47906752 - samples/sec: 715.69 - lr: 0.000781\n",
      "2020-10-22 00:20:36,176 epoch 101 - iter 252/368 - loss 0.48055867 - samples/sec: 756.24 - lr: 0.000781\n",
      "2020-10-22 00:20:37,836 epoch 101 - iter 288/368 - loss 0.48125842 - samples/sec: 721.49 - lr: 0.000781\n",
      "2020-10-22 00:20:39,509 epoch 101 - iter 324/368 - loss 0.47783678 - samples/sec: 717.05 - lr: 0.000781\n",
      "2020-10-22 00:20:41,071 epoch 101 - iter 360/368 - loss 0.48052631 - samples/sec: 769.19 - lr: 0.000781\n",
      "2020-10-22 00:20:43,562 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:20:43,562 EPOCH 101 done: loss 0.4799 - lr 0.0007813\n",
      "2020-10-22 00:20:49,753 DEV : loss 0.5797204375267029 - score 0.7819\n",
      "2020-10-22 00:20:51,662 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 00:20:51,663 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:20:53,732 epoch 102 - iter 36/368 - loss 0.46493551 - samples/sec: 658.85 - lr: 0.000781\n",
      "2020-10-22 00:20:55,425 epoch 102 - iter 72/368 - loss 0.47061982 - samples/sec: 709.79 - lr: 0.000781\n",
      "2020-10-22 00:20:57,064 epoch 102 - iter 108/368 - loss 0.48038157 - samples/sec: 733.23 - lr: 0.000781\n",
      "2020-10-22 00:21:00,852 epoch 102 - iter 144/368 - loss 0.47526463 - samples/sec: 731.46 - lr: 0.000781\n",
      "2020-10-22 00:21:02,385 epoch 102 - iter 180/368 - loss 0.48119763 - samples/sec: 781.54 - lr: 0.000781\n",
      "2020-10-22 00:21:04,048 epoch 102 - iter 216/368 - loss 0.47670516 - samples/sec: 719.21 - lr: 0.000781\n",
      "2020-10-22 00:21:05,784 epoch 102 - iter 252/368 - loss 0.47691233 - samples/sec: 694.43 - lr: 0.000781\n",
      "2020-10-22 00:21:07,388 epoch 102 - iter 288/368 - loss 0.47791712 - samples/sec: 747.54 - lr: 0.000781\n",
      "2020-10-22 00:21:09,025 epoch 102 - iter 324/368 - loss 0.48059022 - samples/sec: 733.19 - lr: 0.000781\n",
      "2020-10-22 00:21:10,656 epoch 102 - iter 360/368 - loss 0.48171641 - samples/sec: 735.37 - lr: 0.000781\n",
      "2020-10-22 00:21:13,133 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:21:13,134 EPOCH 102 done: loss 0.4827 - lr 0.0007813\n",
      "2020-10-22 00:21:19,392 DEV : loss 0.5863975882530212 - score 0.7834\n",
      "2020-10-22 00:21:21,326 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 00:21:21,327 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:21:23,483 epoch 103 - iter 36/368 - loss 0.50871277 - samples/sec: 625.50 - lr: 0.000781\n",
      "2020-10-22 00:21:25,325 epoch 103 - iter 72/368 - loss 0.49572612 - samples/sec: 655.26 - lr: 0.000781\n",
      "2020-10-22 00:21:26,937 epoch 103 - iter 108/368 - loss 0.48385261 - samples/sec: 749.03 - lr: 0.000781\n",
      "2020-10-22 00:21:30,883 epoch 103 - iter 144/368 - loss 0.48149943 - samples/sec: 678.34 - lr: 0.000781\n",
      "2020-10-22 00:21:32,545 epoch 103 - iter 180/368 - loss 0.48110072 - samples/sec: 724.12 - lr: 0.000781\n",
      "2020-10-22 00:21:34,217 epoch 103 - iter 216/368 - loss 0.47835004 - samples/sec: 722.51 - lr: 0.000781\n",
      "2020-10-22 00:21:35,819 epoch 103 - iter 252/368 - loss 0.47734338 - samples/sec: 751.21 - lr: 0.000781\n",
      "2020-10-22 00:21:37,490 epoch 103 - iter 288/368 - loss 0.47531367 - samples/sec: 719.30 - lr: 0.000781\n",
      "2020-10-22 00:21:39,173 epoch 103 - iter 324/368 - loss 0.46941475 - samples/sec: 714.51 - lr: 0.000781\n",
      "2020-10-22 00:21:40,903 epoch 103 - iter 360/368 - loss 0.47383998 - samples/sec: 692.50 - lr: 0.000781\n",
      "2020-10-22 00:21:41,365 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:21:41,366 EPOCH 103 done: loss 0.4739 - lr 0.0007813\n",
      "2020-10-22 00:21:49,671 DEV : loss 0.5767564177513123 - score 0.7832\n",
      "2020-10-22 00:21:51,579 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 00:21:51,580 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:21:53,709 epoch 104 - iter 36/368 - loss 0.49137583 - samples/sec: 633.19 - lr: 0.000781\n",
      "2020-10-22 00:21:55,372 epoch 104 - iter 72/368 - loss 0.47606178 - samples/sec: 723.75 - lr: 0.000781\n",
      "2020-10-22 00:21:57,067 epoch 104 - iter 108/368 - loss 0.47212180 - samples/sec: 707.21 - lr: 0.000781\n",
      "2020-10-22 00:22:01,000 epoch 104 - iter 144/368 - loss 0.47806042 - samples/sec: 706.03 - lr: 0.000781\n",
      "2020-10-22 00:22:02,702 epoch 104 - iter 180/368 - loss 0.47805444 - samples/sec: 702.76 - lr: 0.000781\n",
      "2020-10-22 00:22:04,322 epoch 104 - iter 216/368 - loss 0.47588363 - samples/sec: 739.49 - lr: 0.000781\n",
      "2020-10-22 00:22:05,928 epoch 104 - iter 252/368 - loss 0.47728566 - samples/sec: 744.98 - lr: 0.000781\n",
      "2020-10-22 00:22:07,722 epoch 104 - iter 288/368 - loss 0.47811674 - samples/sec: 667.92 - lr: 0.000781\n",
      "2020-10-22 00:22:09,452 epoch 104 - iter 324/368 - loss 0.47743017 - samples/sec: 694.38 - lr: 0.000781\n",
      "2020-10-22 00:22:11,190 epoch 104 - iter 360/368 - loss 0.47796054 - samples/sec: 693.20 - lr: 0.000781\n",
      "2020-10-22 00:22:11,640 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:22:11,640 EPOCH 104 done: loss 0.4792 - lr 0.0007813\n",
      "2020-10-22 00:22:20,169 DEV : loss 0.5859490036964417 - score 0.7827\n",
      "2020-10-22 00:22:22,094 BAD EPOCHS (no improvement): 5\n",
      "2020-10-22 00:22:22,095 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:22:24,151 epoch 105 - iter 36/368 - loss 0.50763580 - samples/sec: 664.38 - lr: 0.000781\n",
      "2020-10-22 00:22:25,868 epoch 105 - iter 72/368 - loss 0.50458614 - samples/sec: 703.78 - lr: 0.000781\n",
      "2020-10-22 00:22:27,578 epoch 105 - iter 108/368 - loss 0.49401057 - samples/sec: 703.64 - lr: 0.000781\n",
      "2020-10-22 00:22:29,242 epoch 105 - iter 144/368 - loss 0.48435037 - samples/sec: 722.27 - lr: 0.000781\n",
      "2020-10-22 00:22:33,029 epoch 105 - iter 180/368 - loss 0.49240884 - samples/sec: 746.80 - lr: 0.000781\n",
      "2020-10-22 00:22:34,699 epoch 105 - iter 216/368 - loss 0.49308445 - samples/sec: 719.78 - lr: 0.000781\n",
      "2020-10-22 00:22:36,454 epoch 105 - iter 252/368 - loss 0.49079900 - samples/sec: 685.01 - lr: 0.000781\n",
      "2020-10-22 00:22:38,068 epoch 105 - iter 288/368 - loss 0.48435416 - samples/sec: 747.19 - lr: 0.000781\n",
      "2020-10-22 00:22:39,709 epoch 105 - iter 324/368 - loss 0.48224532 - samples/sec: 733.28 - lr: 0.000781\n",
      "2020-10-22 00:22:41,347 epoch 105 - iter 360/368 - loss 0.48066123 - samples/sec: 735.25 - lr: 0.000781\n",
      "2020-10-22 00:22:41,793 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:22:41,794 EPOCH 105 done: loss 0.4808 - lr 0.0007813\n",
      "2020-10-22 00:22:50,220 DEV : loss 0.5821990966796875 - score 0.7827\n",
      "Epoch   105: reducing learning rate of group 0 to 3.9063e-04.\n",
      "2020-10-22 00:22:52,163 BAD EPOCHS (no improvement): 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 00:22:52,164 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:22:54,361 epoch 106 - iter 36/368 - loss 0.44022814 - samples/sec: 613.12 - lr: 0.000391\n",
      "2020-10-22 00:22:56,168 epoch 106 - iter 72/368 - loss 0.45736753 - samples/sec: 665.78 - lr: 0.000391\n",
      "2020-10-22 00:22:57,821 epoch 106 - iter 108/368 - loss 0.47360443 - samples/sec: 726.85 - lr: 0.000391\n",
      "2020-10-22 00:22:59,539 epoch 106 - iter 144/368 - loss 0.47645261 - samples/sec: 698.98 - lr: 0.000391\n",
      "2020-10-22 00:23:03,458 epoch 106 - iter 180/368 - loss 0.47635900 - samples/sec: 299.58 - lr: 0.000391\n",
      "2020-10-22 00:23:05,154 epoch 106 - iter 216/368 - loss 0.47604843 - samples/sec: 708.66 - lr: 0.000391\n",
      "2020-10-22 00:23:06,812 epoch 106 - iter 252/368 - loss 0.47168294 - samples/sec: 724.02 - lr: 0.000391\n",
      "2020-10-22 00:23:08,457 epoch 106 - iter 288/368 - loss 0.47200430 - samples/sec: 728.51 - lr: 0.000391\n",
      "2020-10-22 00:23:10,032 epoch 106 - iter 324/368 - loss 0.47658816 - samples/sec: 763.75 - lr: 0.000391\n",
      "2020-10-22 00:23:11,706 epoch 106 - iter 360/368 - loss 0.47803776 - samples/sec: 718.86 - lr: 0.000391\n",
      "2020-10-22 00:23:12,146 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:23:12,147 EPOCH 106 done: loss 0.4783 - lr 0.0003906\n",
      "2020-10-22 00:23:20,729 DEV : loss 0.5872005224227905 - score 0.7809\n",
      "2020-10-22 00:23:22,654 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 00:23:22,655 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:23:24,805 epoch 107 - iter 36/368 - loss 0.45269435 - samples/sec: 613.33 - lr: 0.000391\n",
      "2020-10-22 00:23:26,598 epoch 107 - iter 72/368 - loss 0.45353163 - samples/sec: 670.82 - lr: 0.000391\n",
      "2020-10-22 00:23:28,318 epoch 107 - iter 108/368 - loss 0.46224562 - samples/sec: 700.32 - lr: 0.000391\n",
      "2020-10-22 00:23:30,080 epoch 107 - iter 144/368 - loss 0.46436878 - samples/sec: 681.52 - lr: 0.000391\n",
      "2020-10-22 00:23:31,750 epoch 107 - iter 180/368 - loss 0.47288780 - samples/sec: 720.14 - lr: 0.000391\n",
      "2020-10-22 00:23:35,536 epoch 107 - iter 216/368 - loss 0.47759348 - samples/sec: 309.98 - lr: 0.000391\n",
      "2020-10-22 00:23:37,206 epoch 107 - iter 252/368 - loss 0.47501439 - samples/sec: 720.84 - lr: 0.000391\n",
      "2020-10-22 00:23:38,883 epoch 107 - iter 288/368 - loss 0.47285288 - samples/sec: 715.83 - lr: 0.000391\n",
      "2020-10-22 00:23:40,492 epoch 107 - iter 324/368 - loss 0.47318436 - samples/sec: 745.33 - lr: 0.000391\n",
      "2020-10-22 00:23:42,159 epoch 107 - iter 360/368 - loss 0.47447195 - samples/sec: 717.65 - lr: 0.000391\n",
      "2020-10-22 00:23:42,598 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:23:42,598 EPOCH 107 done: loss 0.4736 - lr 0.0003906\n",
      "2020-10-22 00:23:51,120 DEV : loss 0.5765308141708374 - score 0.7829\n",
      "2020-10-22 00:23:53,033 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 00:23:53,034 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:23:55,299 epoch 108 - iter 36/368 - loss 0.47669409 - samples/sec: 596.87 - lr: 0.000391\n",
      "2020-10-22 00:23:57,093 epoch 108 - iter 72/368 - loss 0.47210145 - samples/sec: 671.97 - lr: 0.000391\n",
      "2020-10-22 00:23:58,759 epoch 108 - iter 108/368 - loss 0.46515549 - samples/sec: 721.89 - lr: 0.000391\n",
      "2020-10-22 00:24:00,440 epoch 108 - iter 144/368 - loss 0.46694189 - samples/sec: 718.16 - lr: 0.000391\n",
      "2020-10-22 00:24:02,112 epoch 108 - iter 180/368 - loss 0.46605830 - samples/sec: 719.38 - lr: 0.000391\n",
      "2020-10-22 00:24:05,903 epoch 108 - iter 216/368 - loss 0.47164658 - samples/sec: 732.52 - lr: 0.000391\n",
      "2020-10-22 00:24:07,523 epoch 108 - iter 252/368 - loss 0.47800879 - samples/sec: 742.70 - lr: 0.000391\n",
      "2020-10-22 00:24:09,148 epoch 108 - iter 288/368 - loss 0.47895292 - samples/sec: 737.71 - lr: 0.000391\n",
      "2020-10-22 00:24:10,717 epoch 108 - iter 324/368 - loss 0.48134620 - samples/sec: 764.67 - lr: 0.000391\n",
      "2020-10-22 00:24:12,359 epoch 108 - iter 360/368 - loss 0.48158283 - samples/sec: 730.14 - lr: 0.000391\n",
      "2020-10-22 00:24:12,802 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:24:12,803 EPOCH 108 done: loss 0.4813 - lr 0.0003906\n",
      "2020-10-22 00:24:21,454 DEV : loss 0.5831867456436157 - score 0.7824\n",
      "2020-10-22 00:24:23,379 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 00:24:23,380 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:24:25,594 epoch 109 - iter 36/368 - loss 0.46287227 - samples/sec: 614.26 - lr: 0.000391\n",
      "2020-10-22 00:24:27,407 epoch 109 - iter 72/368 - loss 0.44841154 - samples/sec: 665.91 - lr: 0.000391\n",
      "2020-10-22 00:24:29,161 epoch 109 - iter 108/368 - loss 0.45718437 - samples/sec: 689.62 - lr: 0.000391\n",
      "2020-10-22 00:24:31,037 epoch 109 - iter 144/368 - loss 0.45918877 - samples/sec: 644.89 - lr: 0.000391\n",
      "2020-10-22 00:24:32,811 epoch 109 - iter 180/368 - loss 0.46890352 - samples/sec: 678.75 - lr: 0.000391\n",
      "2020-10-22 00:24:34,596 epoch 109 - iter 216/368 - loss 0.47119857 - samples/sec: 674.89 - lr: 0.000391\n",
      "2020-10-22 00:24:36,329 epoch 109 - iter 252/368 - loss 0.47187632 - samples/sec: 693.11 - lr: 0.000391\n",
      "2020-10-22 00:24:40,302 epoch 109 - iter 288/368 - loss 0.47678251 - samples/sec: 696.90 - lr: 0.000391\n",
      "2020-10-22 00:24:42,030 epoch 109 - iter 324/368 - loss 0.47701953 - samples/sec: 695.09 - lr: 0.000391\n",
      "2020-10-22 00:24:43,784 epoch 109 - iter 360/368 - loss 0.47583011 - samples/sec: 686.79 - lr: 0.000391\n",
      "2020-10-22 00:24:44,252 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:24:44,252 EPOCH 109 done: loss 0.4746 - lr 0.0003906\n",
      "2020-10-22 00:24:50,834 DEV : loss 0.5874083638191223 - score 0.7811\n",
      "2020-10-22 00:24:52,796 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 00:24:52,797 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:24:57,410 epoch 110 - iter 36/368 - loss 0.43183604 - samples/sec: 611.95 - lr: 0.000391\n",
      "2020-10-22 00:24:59,084 epoch 110 - iter 72/368 - loss 0.46066140 - samples/sec: 717.63 - lr: 0.000391\n",
      "2020-10-22 00:25:00,787 epoch 110 - iter 108/368 - loss 0.45915032 - samples/sec: 708.86 - lr: 0.000391\n",
      "2020-10-22 00:25:02,462 epoch 110 - iter 144/368 - loss 0.46697363 - samples/sec: 717.11 - lr: 0.000391\n",
      "2020-10-22 00:25:03,939 epoch 110 - iter 180/368 - loss 0.47211498 - samples/sec: 819.37 - lr: 0.000391\n",
      "2020-10-22 00:25:05,432 epoch 110 - iter 216/368 - loss 0.47674309 - samples/sec: 808.85 - lr: 0.000391\n",
      "2020-10-22 00:25:09,101 epoch 110 - iter 252/368 - loss 0.47634195 - samples/sec: 748.18 - lr: 0.000391\n",
      "2020-10-22 00:25:17,054 epoch 110 - iter 288/368 - loss 0.47645988 - samples/sec: 725.16 - lr: 0.000391\n",
      "2020-10-22 00:25:20,808 epoch 110 - iter 324/368 - loss 0.48152974 - samples/sec: 704.27 - lr: 0.000391\n",
      "2020-10-22 00:25:22,425 epoch 110 - iter 360/368 - loss 0.47945236 - samples/sec: 741.44 - lr: 0.000391\n",
      "2020-10-22 00:25:22,964 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:25:22,965 EPOCH 110 done: loss 0.4785 - lr 0.0003906\n",
      "2020-10-22 00:25:29,083 DEV : loss 0.5796419978141785 - score 0.7806\n",
      "2020-10-22 00:25:31,008 BAD EPOCHS (no improvement): 5\n",
      "2020-10-22 00:25:31,008 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:25:33,230 epoch 111 - iter 36/368 - loss 0.48761089 - samples/sec: 608.65 - lr: 0.000391\n",
      "2020-10-22 00:25:37,009 epoch 111 - iter 72/368 - loss 0.48756695 - samples/sec: 762.80 - lr: 0.000391\n",
      "2020-10-22 00:25:38,590 epoch 111 - iter 108/368 - loss 0.48338767 - samples/sec: 758.93 - lr: 0.000391\n",
      "2020-10-22 00:25:40,262 epoch 111 - iter 144/368 - loss 0.48122362 - samples/sec: 719.84 - lr: 0.000391\n",
      "2020-10-22 00:25:41,863 epoch 111 - iter 180/368 - loss 0.47950346 - samples/sec: 753.93 - lr: 0.000391\n",
      "2020-10-22 00:25:43,424 epoch 111 - iter 216/368 - loss 0.47813396 - samples/sec: 769.45 - lr: 0.000391\n",
      "2020-10-22 00:25:44,966 epoch 111 - iter 252/368 - loss 0.47894416 - samples/sec: 779.75 - lr: 0.000391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 00:25:46,458 epoch 111 - iter 288/368 - loss 0.48230134 - samples/sec: 807.66 - lr: 0.000391\n",
      "2020-10-22 00:25:50,079 epoch 111 - iter 324/368 - loss 0.48483508 - samples/sec: 771.85 - lr: 0.000391\n",
      "2020-10-22 00:25:51,716 epoch 111 - iter 360/368 - loss 0.48844734 - samples/sec: 732.82 - lr: 0.000391\n",
      "2020-10-22 00:25:52,182 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:25:52,183 EPOCH 111 done: loss 0.4878 - lr 0.0003906\n",
      "2020-10-22 00:25:58,499 DEV : loss 0.5836184620857239 - score 0.7811\n",
      "Epoch   111: reducing learning rate of group 0 to 1.9531e-04.\n",
      "2020-10-22 00:26:00,418 BAD EPOCHS (no improvement): 6\n",
      "2020-10-22 00:26:00,419 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:26:02,597 epoch 112 - iter 36/368 - loss 0.45687327 - samples/sec: 613.19 - lr: 0.000195\n",
      "2020-10-22 00:26:04,337 epoch 112 - iter 72/368 - loss 0.46682370 - samples/sec: 690.36 - lr: 0.000195\n",
      "2020-10-22 00:26:08,199 epoch 112 - iter 108/368 - loss 0.48496451 - samples/sec: 707.31 - lr: 0.000195\n",
      "2020-10-22 00:26:09,779 epoch 112 - iter 144/368 - loss 0.48618210 - samples/sec: 761.93 - lr: 0.000195\n",
      "2020-10-22 00:26:11,437 epoch 112 - iter 180/368 - loss 0.48629899 - samples/sec: 722.97 - lr: 0.000195\n",
      "2020-10-22 00:26:13,005 epoch 112 - iter 216/368 - loss 0.48720574 - samples/sec: 766.24 - lr: 0.000195\n",
      "2020-10-22 00:26:14,636 epoch 112 - iter 252/368 - loss 0.48359540 - samples/sec: 736.45 - lr: 0.000195\n",
      "2020-10-22 00:26:16,387 epoch 112 - iter 288/368 - loss 0.48276740 - samples/sec: 689.34 - lr: 0.000195\n",
      "2020-10-22 00:26:18,104 epoch 112 - iter 324/368 - loss 0.48184329 - samples/sec: 698.87 - lr: 0.000195\n",
      "2020-10-22 00:26:21,870 epoch 112 - iter 360/368 - loss 0.48213267 - samples/sec: 707.39 - lr: 0.000195\n",
      "2020-10-22 00:26:22,310 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:26:22,311 EPOCH 112 done: loss 0.4834 - lr 0.0001953\n",
      "2020-10-22 00:26:28,576 DEV : loss 0.5813762545585632 - score 0.7814\n",
      "2020-10-22 00:26:30,477 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 00:26:30,478 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:26:32,695 epoch 113 - iter 36/368 - loss 0.43949957 - samples/sec: 604.22 - lr: 0.000195\n",
      "2020-10-22 00:26:34,444 epoch 113 - iter 72/368 - loss 0.45033755 - samples/sec: 688.95 - lr: 0.000195\n",
      "2020-10-22 00:26:38,298 epoch 113 - iter 108/368 - loss 0.46305754 - samples/sec: 707.10 - lr: 0.000195\n",
      "2020-10-22 00:26:39,933 epoch 113 - iter 144/368 - loss 0.47339274 - samples/sec: 735.97 - lr: 0.000195\n",
      "2020-10-22 00:26:41,606 epoch 113 - iter 180/368 - loss 0.46731096 - samples/sec: 720.77 - lr: 0.000195\n",
      "2020-10-22 00:26:43,203 epoch 113 - iter 216/368 - loss 0.47189963 - samples/sec: 754.92 - lr: 0.000195\n",
      "2020-10-22 00:26:44,909 epoch 113 - iter 252/368 - loss 0.47394856 - samples/sec: 703.91 - lr: 0.000195\n",
      "2020-10-22 00:26:46,658 epoch 113 - iter 288/368 - loss 0.47640112 - samples/sec: 687.28 - lr: 0.000195\n",
      "2020-10-22 00:26:48,242 epoch 113 - iter 324/368 - loss 0.47797275 - samples/sec: 762.58 - lr: 0.000195\n",
      "2020-10-22 00:26:49,929 epoch 113 - iter 360/368 - loss 0.48046922 - samples/sec: 712.27 - lr: 0.000195\n",
      "2020-10-22 00:26:50,461 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:26:50,462 EPOCH 113 done: loss 0.4802 - lr 0.0001953\n",
      "2020-10-22 00:26:58,982 DEV : loss 0.581044614315033 - score 0.7819\n",
      "2020-10-22 00:27:00,893 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 00:27:00,894 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:27:03,177 epoch 114 - iter 36/368 - loss 0.46535234 - samples/sec: 579.01 - lr: 0.000195\n",
      "2020-10-22 00:27:04,926 epoch 114 - iter 72/368 - loss 0.47653936 - samples/sec: 690.39 - lr: 0.000195\n",
      "2020-10-22 00:27:06,614 epoch 114 - iter 108/368 - loss 0.48885318 - samples/sec: 715.33 - lr: 0.000195\n",
      "2020-10-22 00:27:08,157 epoch 114 - iter 144/368 - loss 0.48676723 - samples/sec: 780.24 - lr: 0.000195\n",
      "2020-10-22 00:27:11,945 epoch 114 - iter 180/368 - loss 0.49067010 - samples/sec: 309.55 - lr: 0.000195\n",
      "2020-10-22 00:27:13,562 epoch 114 - iter 216/368 - loss 0.49182058 - samples/sec: 745.14 - lr: 0.000195\n",
      "2020-10-22 00:27:15,286 epoch 114 - iter 252/368 - loss 0.48435730 - samples/sec: 698.22 - lr: 0.000195\n",
      "2020-10-22 00:27:16,983 epoch 114 - iter 288/368 - loss 0.48146582 - samples/sec: 706.84 - lr: 0.000195\n",
      "2020-10-22 00:27:18,604 epoch 114 - iter 324/368 - loss 0.48034879 - samples/sec: 739.28 - lr: 0.000195\n",
      "2020-10-22 00:27:20,229 epoch 114 - iter 360/368 - loss 0.48085434 - samples/sec: 739.10 - lr: 0.000195\n",
      "2020-10-22 00:27:20,684 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:27:20,685 EPOCH 114 done: loss 0.4799 - lr 0.0001953\n",
      "2020-10-22 00:27:29,050 DEV : loss 0.5827165842056274 - score 0.7801\n",
      "2020-10-22 00:27:30,966 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 00:27:30,966 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:27:33,108 epoch 115 - iter 36/368 - loss 0.45730321 - samples/sec: 640.24 - lr: 0.000195\n",
      "2020-10-22 00:27:34,822 epoch 115 - iter 72/368 - loss 0.47907153 - samples/sec: 703.31 - lr: 0.000195\n",
      "2020-10-22 00:27:36,363 epoch 115 - iter 108/368 - loss 0.48023351 - samples/sec: 784.53 - lr: 0.000195\n",
      "2020-10-22 00:27:38,049 epoch 115 - iter 144/368 - loss 0.47685305 - samples/sec: 715.08 - lr: 0.000195\n",
      "2020-10-22 00:27:41,816 epoch 115 - iter 180/368 - loss 0.47801320 - samples/sec: 744.70 - lr: 0.000195\n",
      "2020-10-22 00:27:43,453 epoch 115 - iter 216/368 - loss 0.47614334 - samples/sec: 730.68 - lr: 0.000195\n",
      "2020-10-22 00:27:45,050 epoch 115 - iter 252/368 - loss 0.48032227 - samples/sec: 751.28 - lr: 0.000195\n",
      "2020-10-22 00:27:46,693 epoch 115 - iter 288/368 - loss 0.47574883 - samples/sec: 733.41 - lr: 0.000195\n",
      "2020-10-22 00:27:48,336 epoch 115 - iter 324/368 - loss 0.47610309 - samples/sec: 729.95 - lr: 0.000195\n",
      "2020-10-22 00:27:49,991 epoch 115 - iter 360/368 - loss 0.47832183 - samples/sec: 722.81 - lr: 0.000195\n",
      "2020-10-22 00:27:50,415 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:27:50,416 EPOCH 115 done: loss 0.4789 - lr 0.0001953\n",
      "2020-10-22 00:27:58,782 DEV : loss 0.5814670324325562 - score 0.7814\n",
      "2020-10-22 00:28:00,705 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 00:28:00,705 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:28:02,887 epoch 116 - iter 36/368 - loss 0.45739504 - samples/sec: 624.29 - lr: 0.000195\n",
      "2020-10-22 00:28:04,537 epoch 116 - iter 72/368 - loss 0.45794825 - samples/sec: 733.22 - lr: 0.000195\n",
      "2020-10-22 00:28:06,170 epoch 116 - iter 108/368 - loss 0.46636354 - samples/sec: 737.73 - lr: 0.000195\n",
      "2020-10-22 00:28:07,763 epoch 116 - iter 144/368 - loss 0.47688073 - samples/sec: 755.83 - lr: 0.000195\n",
      "2020-10-22 00:28:09,433 epoch 116 - iter 180/368 - loss 0.47843961 - samples/sec: 719.66 - lr: 0.000195\n",
      "2020-10-22 00:28:13,190 epoch 116 - iter 216/368 - loss 0.48115381 - samples/sec: 313.21 - lr: 0.000195\n",
      "2020-10-22 00:28:14,757 epoch 116 - iter 252/368 - loss 0.48355251 - samples/sec: 769.93 - lr: 0.000195\n",
      "2020-10-22 00:28:16,316 epoch 116 - iter 288/368 - loss 0.47835307 - samples/sec: 774.07 - lr: 0.000195\n",
      "2020-10-22 00:28:17,945 epoch 116 - iter 324/368 - loss 0.47920046 - samples/sec: 739.32 - lr: 0.000195\n",
      "2020-10-22 00:28:19,438 epoch 116 - iter 360/368 - loss 0.48091626 - samples/sec: 809.80 - lr: 0.000195\n",
      "2020-10-22 00:28:19,891 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:28:19,891 EPOCH 116 done: loss 0.4806 - lr 0.0001953\n",
      "2020-10-22 00:28:28,388 DEV : loss 0.5823658108711243 - score 0.7806\n",
      "2020-10-22 00:28:30,321 BAD EPOCHS (no improvement): 5\n",
      "2020-10-22 00:28:30,322 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 00:28:32,591 epoch 117 - iter 36/368 - loss 0.44484593 - samples/sec: 594.28 - lr: 0.000195\n",
      "2020-10-22 00:28:34,322 epoch 117 - iter 72/368 - loss 0.45819084 - samples/sec: 697.76 - lr: 0.000195\n",
      "2020-10-22 00:28:35,900 epoch 117 - iter 108/368 - loss 0.46395852 - samples/sec: 765.60 - lr: 0.000195\n",
      "2020-10-22 00:28:37,548 epoch 117 - iter 144/368 - loss 0.46154677 - samples/sec: 737.57 - lr: 0.000195\n",
      "2020-10-22 00:28:39,216 epoch 117 - iter 180/368 - loss 0.46453326 - samples/sec: 723.39 - lr: 0.000195\n",
      "2020-10-22 00:28:40,892 epoch 117 - iter 216/368 - loss 0.46760760 - samples/sec: 719.47 - lr: 0.000195\n",
      "2020-10-22 00:28:44,668 epoch 117 - iter 252/368 - loss 0.47318098 - samples/sec: 752.29 - lr: 0.000195\n",
      "2020-10-22 00:28:46,412 epoch 117 - iter 288/368 - loss 0.47503049 - samples/sec: 688.98 - lr: 0.000195\n",
      "2020-10-22 00:28:48,096 epoch 117 - iter 324/368 - loss 0.47390440 - samples/sec: 715.52 - lr: 0.000195\n",
      "2020-10-22 00:28:49,677 epoch 117 - iter 360/368 - loss 0.47584448 - samples/sec: 762.38 - lr: 0.000195\n",
      "2020-10-22 00:28:50,127 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:28:50,127 EPOCH 117 done: loss 0.4766 - lr 0.0001953\n",
      "2020-10-22 00:28:56,419 DEV : loss 0.5809748768806458 - score 0.7809\n",
      "Epoch   117: reducing learning rate of group 0 to 9.7656e-05.\n",
      "2020-10-22 00:28:58,359 BAD EPOCHS (no improvement): 6\n",
      "2020-10-22 00:28:58,359 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:28:58,360 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:28:58,360 learning rate too small - quitting training!\n",
      "2020-10-22 00:28:58,360 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:29:00,071 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 00:29:00,071 Testing using best model ...\n",
      "2020-10-22 00:29:00,072 loading file classifiers/spooky_authorship_classifier/best-model.pt\n",
      "2020-10-22 00:29:06,264 \t0.7824\n",
      "2020-10-22 00:29:06,264 \n",
      "Results:\n",
      "- F-score (micro) 0.7824\n",
      "- F-score (macro) 0.7802\n",
      "- Accuracy 0.7824\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         EAP     0.7579    0.8340    0.7941      1554\n",
      "         MWS     0.8546    0.6802    0.7575      1210\n",
      "         HPL     0.7599    0.8205    0.7891      1142\n",
      "\n",
      "   micro avg     0.7824    0.7824    0.7824      3906\n",
      "   macro avg     0.7908    0.7782    0.7802      3906\n",
      "weighted avg     0.7885    0.7824    0.7813      3906\n",
      " samples avg     0.7824    0.7824    0.7824      3906\n",
      "\n",
      "2020-10-22 00:29:06,265 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.7824,\n",
       " 'dev_score_history': [0.5098,\n",
       "  0.4845,\n",
       "  0.5687,\n",
       "  0.3728,\n",
       "  0.6339,\n",
       "  0.6249,\n",
       "  0.6349,\n",
       "  0.6305,\n",
       "  0.6707,\n",
       "  0.6446,\n",
       "  0.686,\n",
       "  0.6911,\n",
       "  0.6137,\n",
       "  0.5566,\n",
       "  0.6916,\n",
       "  0.7111,\n",
       "  0.6796,\n",
       "  0.7095,\n",
       "  0.7236,\n",
       "  0.6898,\n",
       "  0.674,\n",
       "  0.7185,\n",
       "  0.7095,\n",
       "  0.732,\n",
       "  0.7037,\n",
       "  0.6988,\n",
       "  0.6883,\n",
       "  0.6975,\n",
       "  0.7504,\n",
       "  0.7443,\n",
       "  0.7274,\n",
       "  0.7558,\n",
       "  0.754,\n",
       "  0.6824,\n",
       "  0.7072,\n",
       "  0.7369,\n",
       "  0.6939,\n",
       "  0.7481,\n",
       "  0.763,\n",
       "  0.7466,\n",
       "  0.7515,\n",
       "  0.7579,\n",
       "  0.7589,\n",
       "  0.7553,\n",
       "  0.7512,\n",
       "  0.7645,\n",
       "  0.7694,\n",
       "  0.7699,\n",
       "  0.753,\n",
       "  0.7655,\n",
       "  0.7788,\n",
       "  0.7627,\n",
       "  0.7706,\n",
       "  0.7612,\n",
       "  0.775,\n",
       "  0.775,\n",
       "  0.7694,\n",
       "  0.763,\n",
       "  0.7755,\n",
       "  0.7717,\n",
       "  0.7686,\n",
       "  0.7747,\n",
       "  0.7691,\n",
       "  0.7722,\n",
       "  0.7691,\n",
       "  0.7719,\n",
       "  0.7758,\n",
       "  0.7776,\n",
       "  0.777,\n",
       "  0.7814,\n",
       "  0.7752,\n",
       "  0.7742,\n",
       "  0.7776,\n",
       "  0.7737,\n",
       "  0.7816,\n",
       "  0.7783,\n",
       "  0.7755,\n",
       "  0.7816,\n",
       "  0.7801,\n",
       "  0.7806,\n",
       "  0.7722,\n",
       "  0.7786,\n",
       "  0.7827,\n",
       "  0.7801,\n",
       "  0.7819,\n",
       "  0.7819,\n",
       "  0.7755,\n",
       "  0.7801,\n",
       "  0.7768,\n",
       "  0.7837,\n",
       "  0.7806,\n",
       "  0.7811,\n",
       "  0.7842,\n",
       "  0.7814,\n",
       "  0.7832,\n",
       "  0.7829,\n",
       "  0.7811,\n",
       "  0.7822,\n",
       "  0.7778,\n",
       "  0.7827,\n",
       "  0.7819,\n",
       "  0.7834,\n",
       "  0.7832,\n",
       "  0.7827,\n",
       "  0.7827,\n",
       "  0.7809,\n",
       "  0.7829,\n",
       "  0.7824,\n",
       "  0.7811,\n",
       "  0.7806,\n",
       "  0.7811,\n",
       "  0.7814,\n",
       "  0.7819,\n",
       "  0.7801,\n",
       "  0.7814,\n",
       "  0.7806,\n",
       "  0.7809],\n",
       " 'train_loss_history': [1.0694002452427926,\n",
       "  1.0190100264937982,\n",
       "  0.9793004315832387,\n",
       "  0.9528946474842404,\n",
       "  0.9314063364720863,\n",
       "  0.9117941297590733,\n",
       "  0.8990690918720287,\n",
       "  0.8819458470072435,\n",
       "  0.8645146557170412,\n",
       "  0.8460338237168996,\n",
       "  0.8283896679463594,\n",
       "  0.8233060282857522,\n",
       "  0.8122792367054068,\n",
       "  0.795451697933933,\n",
       "  0.7842421481466811,\n",
       "  0.7848352692697359,\n",
       "  0.7711068847743066,\n",
       "  0.7626214536797741,\n",
       "  0.7528174860483926,\n",
       "  0.7499072635141404,\n",
       "  0.7463455878846024,\n",
       "  0.7341926836449167,\n",
       "  0.7286079892807681,\n",
       "  0.7216896059234506,\n",
       "  0.7146381280668404,\n",
       "  0.7061702156358439,\n",
       "  0.698240286792102,\n",
       "  0.6997289870582197,\n",
       "  0.693856695909863,\n",
       "  0.6809755527292904,\n",
       "  0.6757562947257058,\n",
       "  0.673440819039293,\n",
       "  0.6713932076388079,\n",
       "  0.6622712051738864,\n",
       "  0.6473957277510477,\n",
       "  0.652531096468801,\n",
       "  0.6381201292995525,\n",
       "  0.6345167883226405,\n",
       "  0.5988093764399705,\n",
       "  0.5866463318791079,\n",
       "  0.5877209532520046,\n",
       "  0.5738105990559511,\n",
       "  0.5724511695215884,\n",
       "  0.5791672979198073,\n",
       "  0.5634522025837846,\n",
       "  0.5547899494514518,\n",
       "  0.5509342563783993,\n",
       "  0.5525270246131264,\n",
       "  0.5454709310003597,\n",
       "  0.5453064782625955,\n",
       "  0.5333660069610113,\n",
       "  0.5396183295094449,\n",
       "  0.5329615067204704,\n",
       "  0.531658182973447,\n",
       "  0.5303240657338629,\n",
       "  0.5264961648246517,\n",
       "  0.5244557504825618,\n",
       "  0.5087119356283675,\n",
       "  0.5053981172892711,\n",
       "  0.5137779410604549,\n",
       "  0.5129540262176938,\n",
       "  0.5135323834484038,\n",
       "  0.4977072630401539,\n",
       "  0.5016434826361744,\n",
       "  0.5063949153232186,\n",
       "  0.4986797056525298,\n",
       "  0.5030124941840768,\n",
       "  0.4958251954420753,\n",
       "  0.48639479486028786,\n",
       "  0.4991248491746576,\n",
       "  0.4887958619662601,\n",
       "  0.4953037920286474,\n",
       "  0.49266198605460965,\n",
       "  0.4901297300568093,\n",
       "  0.48700587479802576,\n",
       "  0.48981866831688775,\n",
       "  0.4955858370775114,\n",
       "  0.48716490209588537,\n",
       "  0.49043361093525006,\n",
       "  0.48753431674254977,\n",
       "  0.4852810286633346,\n",
       "  0.48584638337564207,\n",
       "  0.4869879044835334,\n",
       "  0.4808262669602814,\n",
       "  0.49130028121821256,\n",
       "  0.49013745971024036,\n",
       "  0.4866813352817427,\n",
       "  0.4887606967240572,\n",
       "  0.47417909162038047,\n",
       "  0.4864444417231109,\n",
       "  0.4827995469145801,\n",
       "  0.4798122628227524,\n",
       "  0.48570153186016757,\n",
       "  0.4865933576922702,\n",
       "  0.48293594347879937,\n",
       "  0.48587237569786934,\n",
       "  0.4868765346220006,\n",
       "  0.4801057249550586,\n",
       "  0.48040267638862133,\n",
       "  0.47594038822242746,\n",
       "  0.4799389101402915,\n",
       "  0.4826533232370149,\n",
       "  0.4739452153849213,\n",
       "  0.4791628230444115,\n",
       "  0.4808376711671767,\n",
       "  0.4783288631183298,\n",
       "  0.4735854226366981,\n",
       "  0.4812970114062014,\n",
       "  0.4745980559888741,\n",
       "  0.478522440985493,\n",
       "  0.48777023569235334,\n",
       "  0.48340584592812735,\n",
       "  0.4801944433104085,\n",
       "  0.4798747655004263,\n",
       "  0.47890340014482324,\n",
       "  0.4806205519758489,\n",
       "  0.47662293392678967],\n",
       " 'dev_loss_history': [0.9999428391456604,\n",
       "  1.0232622623443604,\n",
       "  0.9181423187255859,\n",
       "  1.2456282377243042,\n",
       "  0.8543479442596436,\n",
       "  0.8451018333435059,\n",
       "  0.8209620118141174,\n",
       "  0.8540104627609253,\n",
       "  0.7853684425354004,\n",
       "  0.8141556978225708,\n",
       "  0.7375808358192444,\n",
       "  0.730599582195282,\n",
       "  0.9572136402130127,\n",
       "  0.9923636317253113,\n",
       "  0.7425697445869446,\n",
       "  0.6886066794395447,\n",
       "  0.8168845772743225,\n",
       "  0.6903313994407654,\n",
       "  0.6710543632507324,\n",
       "  0.7346181273460388,\n",
       "  0.7354001402854919,\n",
       "  0.6590310335159302,\n",
       "  0.714730978012085,\n",
       "  0.6431719064712524,\n",
       "  0.7292117476463318,\n",
       "  0.7858922481536865,\n",
       "  0.7510592937469482,\n",
       "  0.7850872278213501,\n",
       "  0.5956150889396667,\n",
       "  0.6293452382087708,\n",
       "  0.6436154246330261,\n",
       "  0.6124259829521179,\n",
       "  0.592469334602356,\n",
       "  0.8097596764564514,\n",
       "  0.7293943166732788,\n",
       "  0.6759738922119141,\n",
       "  0.8755925297737122,\n",
       "  0.6200039982795715,\n",
       "  0.5956435203552246,\n",
       "  0.6526654958724976,\n",
       "  0.6356345415115356,\n",
       "  0.6122890710830688,\n",
       "  0.5957353711128235,\n",
       "  0.6020042300224304,\n",
       "  0.632942259311676,\n",
       "  0.6103323101997375,\n",
       "  0.5795863270759583,\n",
       "  0.5771927237510681,\n",
       "  0.6439708471298218,\n",
       "  0.6015822291374207,\n",
       "  0.5638996362686157,\n",
       "  0.5998940467834473,\n",
       "  0.589947521686554,\n",
       "  0.6360602378845215,\n",
       "  0.568246603012085,\n",
       "  0.5820294618606567,\n",
       "  0.5826287865638733,\n",
       "  0.6159767508506775,\n",
       "  0.5859919190406799,\n",
       "  0.5934488773345947,\n",
       "  0.6094518899917603,\n",
       "  0.5873655676841736,\n",
       "  0.609870195388794,\n",
       "  0.5979326367378235,\n",
       "  0.614861786365509,\n",
       "  0.6037938594818115,\n",
       "  0.5862394571304321,\n",
       "  0.5735877752304077,\n",
       "  0.58418869972229,\n",
       "  0.5755124092102051,\n",
       "  0.5937933921813965,\n",
       "  0.5951624512672424,\n",
       "  0.5774874687194824,\n",
       "  0.5957274436950684,\n",
       "  0.5869073867797852,\n",
       "  0.594010591506958,\n",
       "  0.5913811922073364,\n",
       "  0.5802455544471741,\n",
       "  0.5726310014724731,\n",
       "  0.5753061175346375,\n",
       "  0.6124602556228638,\n",
       "  0.5811573266983032,\n",
       "  0.579639196395874,\n",
       "  0.5913196802139282,\n",
       "  0.5741337537765503,\n",
       "  0.5679697394371033,\n",
       "  0.5895884037017822,\n",
       "  0.5836735367774963,\n",
       "  0.593375027179718,\n",
       "  0.5754668712615967,\n",
       "  0.5774306058883667,\n",
       "  0.5786880850791931,\n",
       "  0.5740349888801575,\n",
       "  0.585536777973175,\n",
       "  0.5809628367424011,\n",
       "  0.5787898898124695,\n",
       "  0.5847861766815186,\n",
       "  0.5833483338356018,\n",
       "  0.5924681425094604,\n",
       "  0.5817830562591553,\n",
       "  0.5797204375267029,\n",
       "  0.5863975882530212,\n",
       "  0.5767564177513123,\n",
       "  0.5859490036964417,\n",
       "  0.5821990966796875,\n",
       "  0.5872005224227905,\n",
       "  0.5765308141708374,\n",
       "  0.5831867456436157,\n",
       "  0.5874083638191223,\n",
       "  0.5796419978141785,\n",
       "  0.5836184620857239,\n",
       "  0.5813762545585632,\n",
       "  0.581044614315033,\n",
       "  0.5827165842056274,\n",
       "  0.5814670324325562,\n",
       "  0.5823658108711243,\n",
       "  0.5809748768806458]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings = [WordEmbeddings('glove')]\n",
    "\n",
    "document_embeddings = DocumentRNNEmbeddings(word_embeddings, hidden_size=256)\n",
    "\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)\n",
    "\n",
    "trainer = ModelTrainer(classifier, corpus)\n",
    "\n",
    "trainer.train('classifiers/spooky_authorship_classifier_glove',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              anneal_factor=0.5,\n",
    "              patience=5,\n",
    "              max_epochs=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# glove + for/backward flair embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 05:39:29,219 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 05:39:29,220 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.05, inplace=False)\n",
      "          (encoder): Embedding(300, 100)\n",
      "          (rnn): LSTM(100, 2048)\n",
      "          (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_2): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.05, inplace=False)\n",
      "          (encoder): Embedding(300, 100)\n",
      "          (rnn): LSTM(100, 2048)\n",
      "          (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=4196, out_features=4196, bias=True)\n",
      "    (rnn): GRU(4196, 256, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=256, out_features=3, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2020-10-22 05:39:29,220 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 05:39:29,221 Corpus: \"Corpus: 11762 train + 3911 dev + 3906 test sentences\"\n",
      "2020-10-22 05:39:29,221 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 05:39:29,221 Parameters:\n",
      "2020-10-22 05:39:29,222  - learning_rate: \"0.1\"\n",
      "2020-10-22 05:39:29,222  - mini_batch_size: \"16\"\n",
      "2020-10-22 05:39:29,223  - patience: \"5\"\n",
      "2020-10-22 05:39:29,223  - anneal_factor: \"0.5\"\n",
      "2020-10-22 05:39:29,223  - max_epochs: \"150\"\n",
      "2020-10-22 05:39:29,224  - shuffle: \"True\"\n",
      "2020-10-22 05:39:29,224  - train_with_dev: \"False\"\n",
      "2020-10-22 05:39:29,224  - batch_growth_annealing: \"False\"\n",
      "2020-10-22 05:39:29,225 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 05:39:29,225 Model training base path: \"classifiers/spooky_authorship_classifier_glove&news-fbflair\"\n",
      "2020-10-22 05:39:29,225 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 05:39:29,226 Device: cuda:0\n",
      "2020-10-22 05:39:29,226 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 05:39:29,226 Embeddings storage mode: cpu\n",
      "2020-10-22 05:39:29,229 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 05:39:49,756 epoch 1 - iter 73/736 - loss 1.48772971 - samples/sec: 57.85 - lr: 0.100000\n",
      "2020-10-22 05:40:09,154 epoch 1 - iter 146/736 - loss 1.28876612 - samples/sec: 62.15 - lr: 0.100000\n",
      "2020-10-22 05:40:27,418 epoch 1 - iter 219/736 - loss 1.20485677 - samples/sec: 64.25 - lr: 0.100000\n",
      "2020-10-22 05:40:45,009 epoch 1 - iter 292/736 - loss 1.16136581 - samples/sec: 67.73 - lr: 0.100000\n",
      "2020-10-22 05:41:04,522 epoch 1 - iter 365/736 - loss 1.12735124 - samples/sec: 60.94 - lr: 0.100000\n",
      "2020-10-22 05:41:23,658 epoch 1 - iter 438/736 - loss 1.09742288 - samples/sec: 62.24 - lr: 0.100000\n",
      "2020-10-22 05:41:42,003 epoch 1 - iter 511/736 - loss 1.07279999 - samples/sec: 64.91 - lr: 0.100000\n",
      "2020-10-22 05:42:00,170 epoch 1 - iter 584/736 - loss 1.05082189 - samples/sec: 65.51 - lr: 0.100000\n",
      "2020-10-22 05:42:18,426 epoch 1 - iter 657/736 - loss 1.03659677 - samples/sec: 64.25 - lr: 0.100000\n",
      "2020-10-22 05:42:36,513 epoch 1 - iter 730/736 - loss 1.02069895 - samples/sec: 66.90 - lr: 0.100000\n",
      "2020-10-22 05:42:38,108 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 05:42:38,108 EPOCH 1 done: loss 1.0200 - lr 0.1000000\n",
      "2020-10-22 05:43:38,239 DEV : loss 1.009886622428894 - score 0.5313\n",
      "2020-10-22 05:43:40,140 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 05:43:42,010 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 05:44:02,480 epoch 2 - iter 73/736 - loss 0.85368307 - samples/sec: 57.63 - lr: 0.100000\n",
      "2020-10-22 05:44:21,854 epoch 2 - iter 146/736 - loss 0.84893048 - samples/sec: 62.26 - lr: 0.100000\n",
      "2020-10-22 05:44:39,498 epoch 2 - iter 219/736 - loss 0.85061455 - samples/sec: 67.53 - lr: 0.100000\n",
      "2020-10-22 05:44:57,411 epoch 2 - iter 292/736 - loss 0.83804595 - samples/sec: 65.45 - lr: 0.100000\n",
      "2020-10-22 05:45:15,547 epoch 2 - iter 365/736 - loss 0.84155793 - samples/sec: 65.68 - lr: 0.100000\n",
      "2020-10-22 05:45:33,898 epoch 2 - iter 438/736 - loss 0.83716801 - samples/sec: 64.89 - lr: 0.100000\n",
      "2020-10-22 05:45:50,945 epoch 2 - iter 511/736 - loss 0.83567962 - samples/sec: 69.99 - lr: 0.100000\n",
      "2020-10-22 05:46:09,836 epoch 2 - iter 584/736 - loss 0.83370468 - samples/sec: 63.02 - lr: 0.100000\n",
      "2020-10-22 05:46:29,088 epoch 2 - iter 657/736 - loss 0.83115195 - samples/sec: 61.80 - lr: 0.100000\n",
      "2020-10-22 05:46:48,479 epoch 2 - iter 730/736 - loss 0.82915076 - samples/sec: 61.32 - lr: 0.100000\n",
      "2020-10-22 05:46:49,799 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 05:46:49,800 EPOCH 2 done: loss 0.8304 - lr 0.1000000\n",
      "2020-10-22 05:47:50,328 DEV : loss 1.1358106136322021 - score 0.5973\n",
      "2020-10-22 05:47:52,225 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 05:47:54,205 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 05:48:13,166 epoch 3 - iter 73/736 - loss 0.78700950 - samples/sec: 63.23 - lr: 0.100000\n",
      "2020-10-22 05:48:31,362 epoch 3 - iter 146/736 - loss 0.76798114 - samples/sec: 64.45 - lr: 0.100000\n",
      "2020-10-22 05:48:49,196 epoch 3 - iter 219/736 - loss 0.77284937 - samples/sec: 65.83 - lr: 0.100000\n",
      "2020-10-22 05:49:06,725 epoch 3 - iter 292/736 - loss 0.77264609 - samples/sec: 67.97 - lr: 0.100000\n",
      "2020-10-22 05:49:24,520 epoch 3 - iter 365/736 - loss 0.76851303 - samples/sec: 67.03 - lr: 0.100000\n",
      "2020-10-22 05:49:43,198 epoch 3 - iter 438/736 - loss 0.76492161 - samples/sec: 62.79 - lr: 0.100000\n",
      "2020-10-22 05:50:03,594 epoch 3 - iter 511/736 - loss 0.76055494 - samples/sec: 58.26 - lr: 0.100000\n",
      "2020-10-22 05:50:22,896 epoch 3 - iter 584/736 - loss 0.75656530 - samples/sec: 61.56 - lr: 0.100000\n",
      "2020-10-22 05:50:41,824 epoch 3 - iter 657/736 - loss 0.75608693 - samples/sec: 62.94 - lr: 0.100000\n",
      "2020-10-22 05:51:00,344 epoch 3 - iter 730/736 - loss 0.75554640 - samples/sec: 64.35 - lr: 0.100000\n",
      "2020-10-22 05:51:01,670 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 05:51:01,670 EPOCH 3 done: loss 0.7542 - lr 0.1000000\n",
      "2020-10-22 05:52:02,455 DEV : loss 0.8620967864990234 - score 0.6129\n",
      "2020-10-22 05:52:04,380 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 05:52:06,330 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 05:52:24,822 epoch 4 - iter 73/736 - loss 0.68002913 - samples/sec: 63.81 - lr: 0.100000\n",
      "2020-10-22 05:52:44,356 epoch 4 - iter 146/736 - loss 0.72562063 - samples/sec: 61.84 - lr: 0.100000\n",
      "2020-10-22 05:53:03,701 epoch 4 - iter 219/736 - loss 0.71602631 - samples/sec: 60.65 - lr: 0.100000\n",
      "2020-10-22 05:53:21,258 epoch 4 - iter 292/736 - loss 0.71844562 - samples/sec: 67.83 - lr: 0.100000\n",
      "2020-10-22 05:53:39,690 epoch 4 - iter 365/736 - loss 0.71770030 - samples/sec: 64.56 - lr: 0.100000\n",
      "2020-10-22 05:53:57,432 epoch 4 - iter 438/736 - loss 0.71560597 - samples/sec: 67.19 - lr: 0.100000\n",
      "2020-10-22 05:54:16,158 epoch 4 - iter 511/736 - loss 0.71040076 - samples/sec: 63.55 - lr: 0.100000\n",
      "2020-10-22 05:54:34,306 epoch 4 - iter 584/736 - loss 0.70500868 - samples/sec: 65.67 - lr: 0.100000\n",
      "2020-10-22 05:54:53,226 epoch 4 - iter 657/736 - loss 0.70627623 - samples/sec: 61.99 - lr: 0.100000\n",
      "2020-10-22 05:55:12,433 epoch 4 - iter 730/736 - loss 0.70770170 - samples/sec: 61.11 - lr: 0.100000\n",
      "2020-10-22 05:55:14,081 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 05:55:14,081 EPOCH 4 done: loss 0.7073 - lr 0.1000000\n",
      "2020-10-22 05:56:14,354 DEV : loss 1.021492600440979 - score 0.5883\n",
      "2020-10-22 05:56:16,260 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 05:56:16,261 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 05:56:36,800 epoch 5 - iter 73/736 - loss 0.67823635 - samples/sec: 58.21 - lr: 0.100000\n",
      "2020-10-22 05:56:55,847 epoch 5 - iter 146/736 - loss 0.70018424 - samples/sec: 62.51 - lr: 0.100000\n",
      "2020-10-22 05:57:14,514 epoch 5 - iter 219/736 - loss 0.68725666 - samples/sec: 63.77 - lr: 0.100000\n",
      "2020-10-22 05:57:33,527 epoch 5 - iter 292/736 - loss 0.66753892 - samples/sec: 61.70 - lr: 0.100000\n",
      "2020-10-22 05:57:51,318 epoch 5 - iter 365/736 - loss 0.66906751 - samples/sec: 67.03 - lr: 0.100000\n",
      "2020-10-22 05:58:10,088 epoch 5 - iter 438/736 - loss 0.67636088 - samples/sec: 63.49 - lr: 0.100000\n",
      "2020-10-22 05:58:28,429 epoch 5 - iter 511/736 - loss 0.68132020 - samples/sec: 64.95 - lr: 0.100000\n",
      "2020-10-22 05:58:46,223 epoch 5 - iter 584/736 - loss 0.68250804 - samples/sec: 67.01 - lr: 0.100000\n",
      "2020-10-22 05:59:04,065 epoch 5 - iter 657/736 - loss 0.67657692 - samples/sec: 65.80 - lr: 0.100000\n",
      "2020-10-22 05:59:22,914 epoch 5 - iter 730/736 - loss 0.67603077 - samples/sec: 63.18 - lr: 0.100000\n",
      "2020-10-22 05:59:24,303 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 05:59:24,304 EPOCH 5 done: loss 0.6752 - lr 0.1000000\n",
      "2020-10-22 06:00:24,656 DEV : loss 0.6200922131538391 - score 0.7433\n",
      "2020-10-22 06:00:26,551 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 06:00:28,504 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 06:00:47,874 epoch 6 - iter 73/736 - loss 0.61446690 - samples/sec: 60.91 - lr: 0.100000\n",
      "2020-10-22 06:01:05,823 epoch 6 - iter 146/736 - loss 0.64375969 - samples/sec: 66.44 - lr: 0.100000\n",
      "2020-10-22 06:01:23,486 epoch 6 - iter 219/736 - loss 0.65172764 - samples/sec: 67.45 - lr: 0.100000\n",
      "2020-10-22 06:01:41,937 epoch 6 - iter 292/736 - loss 0.64901439 - samples/sec: 64.62 - lr: 0.100000\n",
      "2020-10-22 06:01:59,541 epoch 6 - iter 365/736 - loss 0.64403154 - samples/sec: 67.75 - lr: 0.100000\n",
      "2020-10-22 06:02:18,482 epoch 6 - iter 438/736 - loss 0.64886022 - samples/sec: 62.94 - lr: 0.100000\n",
      "2020-10-22 06:02:38,104 epoch 6 - iter 511/736 - loss 0.65530469 - samples/sec: 60.65 - lr: 0.100000\n",
      "2020-10-22 06:02:57,601 epoch 6 - iter 584/736 - loss 0.65058325 - samples/sec: 61.96 - lr: 0.100000\n",
      "2020-10-22 06:03:16,899 epoch 6 - iter 657/736 - loss 0.65285557 - samples/sec: 61.61 - lr: 0.100000\n",
      "2020-10-22 06:03:34,523 epoch 6 - iter 730/736 - loss 0.65293469 - samples/sec: 67.61 - lr: 0.100000\n",
      "2020-10-22 06:03:35,754 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 06:03:35,754 EPOCH 6 done: loss 0.6519 - lr 0.1000000\n",
      "2020-10-22 06:04:36,298 DEV : loss 0.5613307952880859 - score 0.7686\n",
      "2020-10-22 06:04:38,201 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 06:04:40,203 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 06:04:58,137 epoch 7 - iter 73/736 - loss 0.64170209 - samples/sec: 66.88 - lr: 0.100000\n",
      "2020-10-22 06:05:17,221 epoch 7 - iter 146/736 - loss 0.64571356 - samples/sec: 63.23 - lr: 0.100000\n",
      "2020-10-22 06:05:36,316 epoch 7 - iter 219/736 - loss 0.63553925 - samples/sec: 61.42 - lr: 0.100000\n",
      "2020-10-22 06:05:54,863 epoch 7 - iter 292/736 - loss 0.63796881 - samples/sec: 64.25 - lr: 0.100000\n",
      "2020-10-22 06:06:13,778 epoch 7 - iter 365/736 - loss 0.63862569 - samples/sec: 62.04 - lr: 0.100000\n",
      "2020-10-22 06:06:32,039 epoch 7 - iter 438/736 - loss 0.63740907 - samples/sec: 66.23 - lr: 0.100000\n",
      "2020-10-22 06:06:51,062 epoch 7 - iter 511/736 - loss 0.63688365 - samples/sec: 62.53 - lr: 0.100000\n",
      "2020-10-22 06:07:09,572 epoch 7 - iter 584/736 - loss 0.63230016 - samples/sec: 64.29 - lr: 0.100000\n",
      "2020-10-22 06:07:28,179 epoch 7 - iter 657/736 - loss 0.63123111 - samples/sec: 64.95 - lr: 0.100000\n",
      "2020-10-22 06:07:45,597 epoch 7 - iter 730/736 - loss 0.63184423 - samples/sec: 67.35 - lr: 0.100000\n",
      "2020-10-22 06:07:46,939 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 06:07:46,939 EPOCH 7 done: loss 0.6309 - lr 0.1000000\n",
      "2020-10-22 06:08:47,116 DEV : loss 0.6456136703491211 - score 0.7246\n",
      "2020-10-22 06:08:49,275 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 06:08:49,276 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 06:09:08,313 epoch 8 - iter 73/736 - loss 0.60398493 - samples/sec: 61.99 - lr: 0.100000\n",
      "2020-10-22 06:09:25,505 epoch 8 - iter 146/736 - loss 0.60406200 - samples/sec: 69.31 - lr: 0.100000\n",
      "2020-10-22 06:09:43,387 epoch 8 - iter 219/736 - loss 0.60249867 - samples/sec: 65.59 - lr: 0.100000\n",
      "2020-10-22 06:10:04,242 epoch 8 - iter 292/736 - loss 0.59534906 - samples/sec: 56.97 - lr: 0.100000\n",
      "2020-10-22 06:10:22,692 epoch 8 - iter 365/736 - loss 0.59336231 - samples/sec: 64.55 - lr: 0.100000\n",
      "2020-10-22 06:10:42,015 epoch 8 - iter 438/736 - loss 0.60161946 - samples/sec: 61.66 - lr: 0.100000\n",
      "2020-10-22 06:11:00,731 epoch 8 - iter 511/736 - loss 0.60632341 - samples/sec: 64.63 - lr: 0.100000\n",
      "2020-10-22 06:11:19,124 epoch 8 - iter 584/736 - loss 0.60781460 - samples/sec: 64.76 - lr: 0.100000\n",
      "2020-10-22 06:11:37,315 epoch 8 - iter 657/736 - loss 0.60908948 - samples/sec: 65.44 - lr: 0.100000\n",
      "2020-10-22 06:11:55,839 epoch 8 - iter 730/736 - loss 0.61247775 - samples/sec: 64.23 - lr: 0.100000\n",
      "2020-10-22 06:11:57,093 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 06:11:57,094 EPOCH 8 done: loss 0.6123 - lr 0.1000000\n",
      "2020-10-22 06:12:57,709 DEV : loss 0.5962257385253906 - score 0.7428\n",
      "2020-10-22 06:12:59,651 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 06:12:59,652 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 06:13:19,471 epoch 9 - iter 73/736 - loss 0.60381570 - samples/sec: 60.49 - lr: 0.100000\n",
      "2020-10-22 06:13:38,504 epoch 9 - iter 146/736 - loss 0.59290510 - samples/sec: 62.51 - lr: 0.100000\n",
      "2020-10-22 06:13:57,499 epoch 9 - iter 219/736 - loss 0.58832678 - samples/sec: 62.65 - lr: 0.100000\n",
      "2020-10-22 06:14:15,908 epoch 9 - iter 292/736 - loss 0.59128691 - samples/sec: 64.74 - lr: 0.100000\n",
      "2020-10-22 06:14:34,129 epoch 9 - iter 365/736 - loss 0.59009014 - samples/sec: 65.42 - lr: 0.100000\n",
      "2020-10-22 06:14:54,011 epoch 9 - iter 438/736 - loss 0.59189496 - samples/sec: 59.76 - lr: 0.100000\n",
      "2020-10-22 06:15:11,517 epoch 9 - iter 511/736 - loss 0.59574207 - samples/sec: 68.07 - lr: 0.100000\n",
      "2020-10-22 06:15:30,944 epoch 9 - iter 584/736 - loss 0.60255597 - samples/sec: 60.39 - lr: 0.100000\n",
      "2020-10-22 06:15:48,416 epoch 9 - iter 657/736 - loss 0.59484477 - samples/sec: 67.24 - lr: 0.100000\n",
      "2020-10-22 06:16:06,390 epoch 9 - iter 730/736 - loss 0.59220463 - samples/sec: 65.28 - lr: 0.100000\n",
      "2020-10-22 06:16:07,747 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 06:16:07,748 EPOCH 9 done: loss 0.5913 - lr 0.1000000\n",
      "2020-10-22 06:17:08,034 DEV : loss 0.5528645515441895 - score 0.776\n",
      "2020-10-22 06:17:09,955 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 06:17:11,961 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 06:17:32,253 epoch 10 - iter 73/736 - loss 0.57745857 - samples/sec: 60.20 - lr: 0.100000\n",
      "2020-10-22 06:17:49,666 epoch 10 - iter 146/736 - loss 0.59199659 - samples/sec: 68.46 - lr: 0.100000\n",
      "2020-10-22 06:18:08,390 epoch 10 - iter 219/736 - loss 0.58378137 - samples/sec: 63.56 - lr: 0.100000\n",
      "2020-10-22 06:18:27,289 epoch 10 - iter 292/736 - loss 0.57496993 - samples/sec: 63.00 - lr: 0.100000\n",
      "2020-10-22 06:18:46,823 epoch 10 - iter 365/736 - loss 0.56874487 - samples/sec: 60.90 - lr: 0.100000\n",
      "2020-10-22 06:19:04,398 epoch 10 - iter 438/736 - loss 0.56428999 - samples/sec: 67.83 - lr: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 06:19:22,747 epoch 10 - iter 511/736 - loss 0.56972459 - samples/sec: 64.91 - lr: 0.100000\n",
      "2020-10-22 06:19:41,728 epoch 10 - iter 584/736 - loss 0.56812148 - samples/sec: 61.84 - lr: 0.100000\n",
      "2020-10-22 06:20:00,440 epoch 10 - iter 657/736 - loss 0.57327429 - samples/sec: 63.72 - lr: 0.100000\n",
      "2020-10-22 06:20:18,870 epoch 10 - iter 730/736 - loss 0.57654182 - samples/sec: 64.66 - lr: 0.100000\n",
      "2020-10-22 06:20:20,272 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 06:20:20,273 EPOCH 10 done: loss 0.5753 - lr 0.1000000\n",
      "2020-10-22 06:21:20,555 DEV : loss 0.5725451707839966 - score 0.7683\n",
      "2020-10-22 06:21:22,450 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 06:21:22,451 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 06:21:41,893 epoch 11 - iter 73/736 - loss 0.48916072 - samples/sec: 61.57 - lr: 0.100000\n",
      "2020-10-22 06:22:00,466 epoch 11 - iter 146/736 - loss 0.52361447 - samples/sec: 64.10 - lr: 0.100000\n",
      "2020-10-22 06:22:18,590 epoch 11 - iter 219/736 - loss 0.53048897 - samples/sec: 66.79 - lr: 0.100000\n",
      "2020-10-22 06:22:35,904 epoch 11 - iter 292/736 - loss 0.53440242 - samples/sec: 68.87 - lr: 0.100000\n",
      "2020-10-22 06:22:53,657 epoch 11 - iter 365/736 - loss 0.54540802 - samples/sec: 66.06 - lr: 0.100000\n",
      "2020-10-22 06:23:12,517 epoch 11 - iter 438/736 - loss 0.54929375 - samples/sec: 63.17 - lr: 0.100000\n",
      "2020-10-22 06:23:30,977 epoch 11 - iter 511/736 - loss 0.54788232 - samples/sec: 64.56 - lr: 0.100000\n",
      "2020-10-22 06:23:51,906 epoch 11 - iter 584/736 - loss 0.54720160 - samples/sec: 56.86 - lr: 0.100000\n",
      "2020-10-22 06:24:10,798 epoch 11 - iter 657/736 - loss 0.55127271 - samples/sec: 63.06 - lr: 0.100000\n",
      "2020-10-22 06:24:29,036 epoch 11 - iter 730/736 - loss 0.55039222 - samples/sec: 65.30 - lr: 0.100000\n",
      "2020-10-22 06:24:30,550 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 06:24:30,551 EPOCH 11 done: loss 0.5494 - lr 0.1000000\n",
      "2020-10-22 06:25:30,970 DEV : loss 0.630522608757019 - score 0.764\n",
      "2020-10-22 06:25:32,874 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 06:25:32,875 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 06:25:50,572 epoch 12 - iter 73/736 - loss 0.55257244 - samples/sec: 67.95 - lr: 0.100000\n",
      "2020-10-22 06:26:09,957 epoch 12 - iter 146/736 - loss 0.52495920 - samples/sec: 61.35 - lr: 0.100000\n",
      "2020-10-22 06:26:28,759 epoch 12 - iter 219/736 - loss 0.52673080 - samples/sec: 63.32 - lr: 0.100000\n",
      "2020-10-22 06:26:48,034 epoch 12 - iter 292/736 - loss 0.53195859 - samples/sec: 61.68 - lr: 0.100000\n",
      "2020-10-22 06:27:06,643 epoch 12 - iter 365/736 - loss 0.54045088 - samples/sec: 64.05 - lr: 0.100000\n",
      "2020-10-22 06:27:26,181 epoch 12 - iter 438/736 - loss 0.54221095 - samples/sec: 61.79 - lr: 0.100000\n",
      "2020-10-22 06:27:44,053 epoch 12 - iter 511/736 - loss 0.53626272 - samples/sec: 66.68 - lr: 0.100000\n",
      "2020-10-22 06:28:03,189 epoch 12 - iter 584/736 - loss 0.53969701 - samples/sec: 62.26 - lr: 0.100000\n",
      "2020-10-22 06:28:21,786 epoch 12 - iter 657/736 - loss 0.54275509 - samples/sec: 64.12 - lr: 0.100000\n",
      "2020-10-22 06:28:39,850 epoch 12 - iter 730/736 - loss 0.54396044 - samples/sec: 65.97 - lr: 0.100000\n",
      "2020-10-22 06:28:41,635 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 06:28:41,636 EPOCH 12 done: loss 0.5427 - lr 0.1000000\n",
      "2020-10-22 06:29:41,932 DEV : loss 0.5371719002723694 - score 0.7891\n",
      "2020-10-22 06:29:43,878 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 06:29:45,878 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 06:30:03,662 epoch 13 - iter 73/736 - loss 0.51506838 - samples/sec: 66.38 - lr: 0.100000\n",
      "2020-10-22 06:30:21,207 epoch 13 - iter 146/736 - loss 0.51978324 - samples/sec: 66.93 - lr: 0.100000\n",
      "2020-10-22 06:30:39,450 epoch 13 - iter 219/736 - loss 0.52076890 - samples/sec: 66.35 - lr: 0.100000\n",
      "2020-10-22 06:30:57,514 epoch 13 - iter 292/736 - loss 0.51914114 - samples/sec: 65.99 - lr: 0.100000\n",
      "2020-10-22 06:31:17,845 epoch 13 - iter 365/736 - loss 0.52221563 - samples/sec: 58.55 - lr: 0.100000\n",
      "2020-10-22 06:31:37,215 epoch 13 - iter 438/736 - loss 0.52171226 - samples/sec: 61.46 - lr: 0.100000\n",
      "2020-10-22 06:31:55,516 epoch 13 - iter 511/736 - loss 0.51697374 - samples/sec: 65.04 - lr: 0.100000\n",
      "2020-10-22 06:32:14,210 epoch 13 - iter 584/736 - loss 0.51880400 - samples/sec: 64.70 - lr: 0.100000\n",
      "2020-10-22 06:32:34,283 epoch 13 - iter 657/736 - loss 0.51866469 - samples/sec: 59.23 - lr: 0.100000\n",
      "2020-10-22 06:32:52,644 epoch 13 - iter 730/736 - loss 0.52139779 - samples/sec: 65.93 - lr: 0.100000\n",
      "2020-10-22 06:32:54,198 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 06:32:54,199 EPOCH 13 done: loss 0.5202 - lr 0.1000000\n",
      "2020-10-22 06:33:54,595 DEV : loss 0.6477855443954468 - score 0.7415\n",
      "2020-10-22 06:33:56,491 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 06:33:56,492 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 06:34:16,034 epoch 14 - iter 73/736 - loss 0.47288425 - samples/sec: 62.30 - lr: 0.100000\n",
      "2020-10-22 06:34:33,498 epoch 14 - iter 146/736 - loss 0.45967643 - samples/sec: 67.24 - lr: 0.100000\n",
      "2020-10-22 06:34:52,181 epoch 14 - iter 219/736 - loss 0.48987346 - samples/sec: 62.85 - lr: 0.100000\n",
      "2020-10-22 06:35:11,805 epoch 14 - iter 292/736 - loss 0.50111804 - samples/sec: 59.78 - lr: 0.100000\n",
      "2020-10-22 06:35:29,363 epoch 14 - iter 365/736 - loss 0.50246507 - samples/sec: 67.88 - lr: 0.100000\n",
      "2020-10-22 06:35:49,199 epoch 14 - iter 438/736 - loss 0.49772111 - samples/sec: 60.00 - lr: 0.100000\n",
      "2020-10-22 06:36:07,903 epoch 14 - iter 511/736 - loss 0.49701314 - samples/sec: 63.69 - lr: 0.100000\n",
      "2020-10-22 06:36:25,370 epoch 14 - iter 584/736 - loss 0.50410621 - samples/sec: 68.26 - lr: 0.100000\n",
      "2020-10-22 06:36:43,722 epoch 14 - iter 657/736 - loss 0.50365280 - samples/sec: 63.93 - lr: 0.100000\n",
      "2020-10-22 06:37:02,364 epoch 14 - iter 730/736 - loss 0.50452625 - samples/sec: 63.89 - lr: 0.100000\n",
      "2020-10-22 06:37:03,925 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 06:37:03,925 EPOCH 14 done: loss 0.5044 - lr 0.1000000\n",
      "2020-10-22 06:38:04,215 DEV : loss 0.5209782123565674 - score 0.7954\n",
      "2020-10-22 06:38:06,105 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 06:38:08,048 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 06:38:26,850 epoch 15 - iter 73/736 - loss 0.48524462 - samples/sec: 64.79 - lr: 0.100000\n",
      "2020-10-22 06:38:45,963 epoch 15 - iter 146/736 - loss 0.49318061 - samples/sec: 62.23 - lr: 0.100000\n",
      "2020-10-22 06:39:03,477 epoch 15 - iter 219/736 - loss 0.49730471 - samples/sec: 67.00 - lr: 0.100000\n",
      "2020-10-22 06:39:21,309 epoch 15 - iter 292/736 - loss 0.48539991 - samples/sec: 66.82 - lr: 0.100000\n",
      "2020-10-22 06:39:39,789 epoch 15 - iter 365/736 - loss 0.49132616 - samples/sec: 64.47 - lr: 0.100000\n",
      "2020-10-22 06:39:58,088 epoch 15 - iter 438/736 - loss 0.49598231 - samples/sec: 64.99 - lr: 0.100000\n",
      "2020-10-22 06:40:16,789 epoch 15 - iter 511/736 - loss 0.50390655 - samples/sec: 63.68 - lr: 0.100000\n",
      "2020-10-22 06:40:35,550 epoch 15 - iter 584/736 - loss 0.49842265 - samples/sec: 62.57 - lr: 0.100000\n",
      "2020-10-22 06:40:54,498 epoch 15 - iter 657/736 - loss 0.49922067 - samples/sec: 61.93 - lr: 0.100000\n",
      "2020-10-22 06:41:14,480 epoch 15 - iter 730/736 - loss 0.50202525 - samples/sec: 58.71 - lr: 0.100000\n",
      "2020-10-22 06:41:16,208 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 06:41:16,208 EPOCH 15 done: loss 0.5016 - lr 0.1000000\n",
      "2020-10-22 06:42:16,449 DEV : loss 0.5579744577407837 - score 0.7724\n",
      "2020-10-22 06:42:18,345 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 06:42:18,346 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 06:42:35,941 epoch 16 - iter 73/736 - loss 0.49346438 - samples/sec: 68.29 - lr: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 06:42:54,838 epoch 16 - iter 146/736 - loss 0.48044030 - samples/sec: 62.06 - lr: 0.100000\n",
      "2020-10-22 06:43:13,309 epoch 16 - iter 219/736 - loss 0.48963711 - samples/sec: 65.41 - lr: 0.100000\n",
      "2020-10-22 06:43:32,176 epoch 16 - iter 292/736 - loss 0.49337707 - samples/sec: 63.12 - lr: 0.100000\n",
      "2020-10-22 06:43:49,431 epoch 16 - iter 365/736 - loss 0.48550541 - samples/sec: 69.08 - lr: 0.100000\n",
      "2020-10-22 06:44:08,423 epoch 16 - iter 438/736 - loss 0.48504848 - samples/sec: 62.65 - lr: 0.100000\n",
      "2020-10-22 06:44:26,719 epoch 16 - iter 511/736 - loss 0.48881208 - samples/sec: 64.10 - lr: 0.100000\n",
      "2020-10-22 06:44:45,827 epoch 16 - iter 584/736 - loss 0.48812099 - samples/sec: 62.30 - lr: 0.100000\n",
      "2020-10-22 06:45:04,432 epoch 16 - iter 657/736 - loss 0.49027505 - samples/sec: 64.02 - lr: 0.100000\n",
      "2020-10-22 06:45:24,350 epoch 16 - iter 730/736 - loss 0.48663807 - samples/sec: 60.54 - lr: 0.100000\n",
      "2020-10-22 06:45:25,830 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 06:45:25,831 EPOCH 16 done: loss 0.4870 - lr 0.1000000\n",
      "2020-10-22 06:46:26,183 DEV : loss 0.5080968141555786 - score 0.7919\n",
      "2020-10-22 06:46:28,095 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 06:46:28,096 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 06:46:47,894 epoch 17 - iter 73/736 - loss 0.49008481 - samples/sec: 60.46 - lr: 0.100000\n",
      "2020-10-22 06:47:06,471 epoch 17 - iter 146/736 - loss 0.47722890 - samples/sec: 64.16 - lr: 0.100000\n",
      "2020-10-22 06:47:25,482 epoch 17 - iter 219/736 - loss 0.48965588 - samples/sec: 62.71 - lr: 0.100000\n",
      "2020-10-22 06:47:44,866 epoch 17 - iter 292/736 - loss 0.48818284 - samples/sec: 61.42 - lr: 0.100000\n",
      "2020-10-22 06:48:03,501 epoch 17 - iter 365/736 - loss 0.48362727 - samples/sec: 63.99 - lr: 0.100000\n",
      "2020-10-22 06:48:20,320 epoch 17 - iter 438/736 - loss 0.47880685 - samples/sec: 70.98 - lr: 0.100000\n",
      "2020-10-22 06:48:39,091 epoch 17 - iter 511/736 - loss 0.48079627 - samples/sec: 62.53 - lr: 0.100000\n",
      "2020-10-22 06:48:57,437 epoch 17 - iter 584/736 - loss 0.47961403 - samples/sec: 63.96 - lr: 0.100000\n",
      "2020-10-22 06:49:15,864 epoch 17 - iter 657/736 - loss 0.48412634 - samples/sec: 63.73 - lr: 0.100000\n",
      "2020-10-22 06:49:35,238 epoch 17 - iter 730/736 - loss 0.48689770 - samples/sec: 61.43 - lr: 0.100000\n",
      "2020-10-22 06:49:36,466 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 06:49:36,467 EPOCH 17 done: loss 0.4866 - lr 0.1000000\n",
      "2020-10-22 06:50:37,011 DEV : loss 0.6652133464813232 - score 0.7384\n",
      "2020-10-22 06:50:38,906 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 06:50:38,906 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 06:50:59,185 epoch 18 - iter 73/736 - loss 0.47255754 - samples/sec: 58.18 - lr: 0.100000\n",
      "2020-10-22 06:51:16,731 epoch 18 - iter 146/736 - loss 0.47707620 - samples/sec: 66.88 - lr: 0.100000\n",
      "2020-10-22 06:51:34,579 epoch 18 - iter 219/736 - loss 0.47420259 - samples/sec: 66.90 - lr: 0.100000\n",
      "2020-10-22 06:51:53,407 epoch 18 - iter 292/736 - loss 0.46865998 - samples/sec: 63.24 - lr: 0.100000\n",
      "2020-10-22 06:52:12,296 epoch 18 - iter 365/736 - loss 0.46872810 - samples/sec: 63.07 - lr: 0.100000\n",
      "2020-10-22 06:52:30,563 epoch 18 - iter 438/736 - loss 0.46941299 - samples/sec: 66.26 - lr: 0.100000\n",
      "2020-10-22 06:52:48,885 epoch 18 - iter 511/736 - loss 0.46977521 - samples/sec: 64.08 - lr: 0.100000\n",
      "2020-10-22 06:53:09,058 epoch 18 - iter 584/736 - loss 0.47150211 - samples/sec: 58.21 - lr: 0.100000\n",
      "2020-10-22 06:53:27,520 epoch 18 - iter 657/736 - loss 0.46775187 - samples/sec: 63.59 - lr: 0.100000\n",
      "2020-10-22 06:53:44,939 epoch 18 - iter 730/736 - loss 0.46650455 - samples/sec: 67.46 - lr: 0.100000\n",
      "2020-10-22 06:53:46,248 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 06:53:46,249 EPOCH 18 done: loss 0.4678 - lr 0.1000000\n",
      "2020-10-22 06:54:46,626 DEV : loss 0.5257486701011658 - score 0.7908\n",
      "2020-10-22 06:54:48,538 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 06:54:48,539 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 06:55:07,716 epoch 19 - iter 73/736 - loss 0.45004887 - samples/sec: 61.51 - lr: 0.100000\n",
      "2020-10-22 06:55:26,418 epoch 19 - iter 146/736 - loss 0.44993580 - samples/sec: 64.65 - lr: 0.100000\n",
      "2020-10-22 06:55:45,340 epoch 19 - iter 219/736 - loss 0.44188218 - samples/sec: 61.96 - lr: 0.100000\n",
      "2020-10-22 06:56:03,565 epoch 19 - iter 292/736 - loss 0.45016439 - samples/sec: 66.38 - lr: 0.100000\n",
      "2020-10-22 06:56:22,749 epoch 19 - iter 365/736 - loss 0.46360335 - samples/sec: 61.99 - lr: 0.100000\n",
      "2020-10-22 06:56:40,818 epoch 19 - iter 438/736 - loss 0.46585894 - samples/sec: 64.96 - lr: 0.100000\n",
      "2020-10-22 06:56:58,011 epoch 19 - iter 511/736 - loss 0.46781937 - samples/sec: 69.33 - lr: 0.100000\n",
      "2020-10-22 06:57:17,785 epoch 19 - iter 584/736 - loss 0.46520037 - samples/sec: 60.16 - lr: 0.100000\n",
      "2020-10-22 06:57:38,241 epoch 19 - iter 657/736 - loss 0.46547076 - samples/sec: 58.08 - lr: 0.100000\n",
      "2020-10-22 06:57:55,722 epoch 19 - iter 730/736 - loss 0.46788376 - samples/sec: 68.15 - lr: 0.100000\n",
      "2020-10-22 06:57:57,089 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 06:57:57,089 EPOCH 19 done: loss 0.4680 - lr 0.1000000\n",
      "2020-10-22 06:58:57,641 DEV : loss 0.5615853667259216 - score 0.7768\n",
      "2020-10-22 06:58:59,554 BAD EPOCHS (no improvement): 5\n",
      "2020-10-22 06:58:59,555 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 06:59:18,498 epoch 20 - iter 73/736 - loss 0.44099403 - samples/sec: 63.27 - lr: 0.100000\n",
      "2020-10-22 06:59:36,979 epoch 20 - iter 146/736 - loss 0.45657370 - samples/sec: 64.37 - lr: 0.100000\n",
      "2020-10-22 06:59:55,800 epoch 20 - iter 219/736 - loss 0.44135586 - samples/sec: 62.30 - lr: 0.100000\n",
      "2020-10-22 07:00:14,524 epoch 20 - iter 292/736 - loss 0.45860706 - samples/sec: 63.57 - lr: 0.100000\n",
      "2020-10-22 07:00:32,661 epoch 20 - iter 365/736 - loss 0.45707481 - samples/sec: 64.71 - lr: 0.100000\n",
      "2020-10-22 07:00:50,938 epoch 20 - iter 438/736 - loss 0.45109652 - samples/sec: 65.18 - lr: 0.100000\n",
      "2020-10-22 07:01:09,292 epoch 20 - iter 511/736 - loss 0.45131312 - samples/sec: 64.93 - lr: 0.100000\n",
      "2020-10-22 07:01:29,084 epoch 20 - iter 584/736 - loss 0.44602225 - samples/sec: 59.28 - lr: 0.100000\n",
      "2020-10-22 07:01:47,191 epoch 20 - iter 657/736 - loss 0.44717582 - samples/sec: 65.82 - lr: 0.100000\n",
      "2020-10-22 07:02:05,785 epoch 20 - iter 730/736 - loss 0.44916448 - samples/sec: 64.04 - lr: 0.100000\n",
      "2020-10-22 07:02:07,079 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 07:02:07,080 EPOCH 20 done: loss 0.4493 - lr 0.1000000\n",
      "2020-10-22 07:03:07,615 DEV : loss 0.5070930123329163 - score 0.7977\n",
      "2020-10-22 07:03:09,520 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 07:03:11,474 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 07:03:30,358 epoch 21 - iter 73/736 - loss 0.42863017 - samples/sec: 63.41 - lr: 0.100000\n",
      "2020-10-22 07:03:48,294 epoch 21 - iter 146/736 - loss 0.43580928 - samples/sec: 66.45 - lr: 0.100000\n",
      "2020-10-22 07:04:06,232 epoch 21 - iter 219/736 - loss 0.44162190 - samples/sec: 66.44 - lr: 0.100000\n",
      "2020-10-22 07:04:25,081 epoch 21 - iter 292/736 - loss 0.44027720 - samples/sec: 63.19 - lr: 0.100000\n",
      "2020-10-22 07:04:43,231 epoch 21 - iter 365/736 - loss 0.43683617 - samples/sec: 65.67 - lr: 0.100000\n",
      "2020-10-22 07:05:00,363 epoch 21 - iter 438/736 - loss 0.44062964 - samples/sec: 68.53 - lr: 0.100000\n",
      "2020-10-22 07:05:19,654 epoch 21 - iter 511/736 - loss 0.44413196 - samples/sec: 62.58 - lr: 0.100000\n",
      "2020-10-22 07:05:39,242 epoch 21 - iter 584/736 - loss 0.44265907 - samples/sec: 60.75 - lr: 0.100000\n",
      "2020-10-22 07:05:58,935 epoch 21 - iter 657/736 - loss 0.44592626 - samples/sec: 60.41 - lr: 0.100000\n",
      "2020-10-22 07:06:17,087 epoch 21 - iter 730/736 - loss 0.44186208 - samples/sec: 65.61 - lr: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 07:06:18,648 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 07:06:18,648 EPOCH 21 done: loss 0.4434 - lr 0.1000000\n",
      "2020-10-22 07:07:18,931 DEV : loss 0.5002753734588623 - score 0.8057\n",
      "2020-10-22 07:07:20,837 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 07:07:22,824 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 07:07:41,767 epoch 22 - iter 73/736 - loss 0.38669641 - samples/sec: 64.27 - lr: 0.100000\n",
      "2020-10-22 07:07:59,639 epoch 22 - iter 146/736 - loss 0.40790390 - samples/sec: 66.63 - lr: 0.100000\n",
      "2020-10-22 07:08:19,275 epoch 22 - iter 219/736 - loss 0.42489670 - samples/sec: 59.77 - lr: 0.100000\n",
      "2020-10-22 07:08:38,260 epoch 22 - iter 292/736 - loss 0.41745021 - samples/sec: 62.65 - lr: 0.100000\n",
      "2020-10-22 07:08:56,715 epoch 22 - iter 365/736 - loss 0.42424755 - samples/sec: 64.51 - lr: 0.100000\n",
      "2020-10-22 07:09:15,882 epoch 22 - iter 438/736 - loss 0.42901281 - samples/sec: 63.07 - lr: 0.100000\n",
      "2020-10-22 07:09:34,898 epoch 22 - iter 511/736 - loss 0.42685785 - samples/sec: 62.70 - lr: 0.100000\n",
      "2020-10-22 07:09:52,937 epoch 22 - iter 584/736 - loss 0.42689969 - samples/sec: 65.09 - lr: 0.100000\n",
      "2020-10-22 07:10:11,992 epoch 22 - iter 657/736 - loss 0.42706188 - samples/sec: 62.50 - lr: 0.100000\n",
      "2020-10-22 07:10:30,664 epoch 22 - iter 730/736 - loss 0.43501249 - samples/sec: 63.75 - lr: 0.100000\n",
      "2020-10-22 07:10:31,966 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 07:10:31,967 EPOCH 22 done: loss 0.4360 - lr 0.1000000\n",
      "2020-10-22 07:11:32,521 DEV : loss 0.5911500453948975 - score 0.7763\n",
      "2020-10-22 07:11:34,448 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 07:11:34,448 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 07:11:53,392 epoch 23 - iter 73/736 - loss 0.39990788 - samples/sec: 63.26 - lr: 0.100000\n",
      "2020-10-22 07:12:12,647 epoch 23 - iter 146/736 - loss 0.41471079 - samples/sec: 61.86 - lr: 0.100000\n",
      "2020-10-22 07:12:30,713 epoch 23 - iter 219/736 - loss 0.42564739 - samples/sec: 65.94 - lr: 0.100000\n",
      "2020-10-22 07:12:49,776 epoch 23 - iter 292/736 - loss 0.41939160 - samples/sec: 62.36 - lr: 0.100000\n",
      "2020-10-22 07:13:07,570 epoch 23 - iter 365/736 - loss 0.42871334 - samples/sec: 66.98 - lr: 0.100000\n",
      "2020-10-22 07:13:26,411 epoch 23 - iter 438/736 - loss 0.42738617 - samples/sec: 63.19 - lr: 0.100000\n",
      "2020-10-22 07:13:44,155 epoch 23 - iter 511/736 - loss 0.42551840 - samples/sec: 66.10 - lr: 0.100000\n",
      "2020-10-22 07:14:03,203 epoch 23 - iter 584/736 - loss 0.42989145 - samples/sec: 62.51 - lr: 0.100000\n",
      "2020-10-22 07:14:20,772 epoch 23 - iter 657/736 - loss 0.43204580 - samples/sec: 67.85 - lr: 0.100000\n",
      "2020-10-22 07:14:40,097 epoch 23 - iter 730/736 - loss 0.42912626 - samples/sec: 61.60 - lr: 0.100000\n",
      "2020-10-22 07:14:41,457 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 07:14:41,457 EPOCH 23 done: loss 0.4334 - lr 0.1000000\n",
      "2020-10-22 07:15:41,736 DEV : loss 0.48096325993537903 - score 0.8113\n",
      "2020-10-22 07:15:43,664 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 07:15:45,664 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 07:16:05,240 epoch 24 - iter 73/736 - loss 0.39185740 - samples/sec: 61.29 - lr: 0.100000\n",
      "2020-10-22 07:16:24,339 epoch 24 - iter 146/736 - loss 0.40900170 - samples/sec: 62.33 - lr: 0.100000\n",
      "2020-10-22 07:16:43,742 epoch 24 - iter 219/736 - loss 0.40983752 - samples/sec: 60.42 - lr: 0.100000\n",
      "2020-10-22 07:17:02,623 epoch 24 - iter 292/736 - loss 0.41277456 - samples/sec: 62.12 - lr: 0.100000\n",
      "2020-10-22 07:17:20,781 epoch 24 - iter 365/736 - loss 0.41712999 - samples/sec: 65.64 - lr: 0.100000\n",
      "2020-10-22 07:17:38,811 epoch 24 - iter 438/736 - loss 0.42208602 - samples/sec: 66.09 - lr: 0.100000\n",
      "2020-10-22 07:17:56,828 epoch 24 - iter 511/736 - loss 0.42198728 - samples/sec: 66.19 - lr: 0.100000\n",
      "2020-10-22 07:18:14,566 epoch 24 - iter 584/736 - loss 0.42449440 - samples/sec: 67.22 - lr: 0.100000\n",
      "2020-10-22 07:18:33,111 epoch 24 - iter 657/736 - loss 0.41849500 - samples/sec: 64.28 - lr: 0.100000\n",
      "2020-10-22 07:18:52,132 epoch 24 - iter 730/736 - loss 0.42107445 - samples/sec: 62.59 - lr: 0.100000\n",
      "2020-10-22 07:18:53,925 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 07:18:53,926 EPOCH 24 done: loss 0.4203 - lr 0.1000000\n",
      "2020-10-22 07:19:54,208 DEV : loss 0.5367706418037415 - score 0.798\n",
      "2020-10-22 07:19:56,114 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 07:19:56,115 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 07:20:15,846 epoch 25 - iter 73/736 - loss 0.37373283 - samples/sec: 60.67 - lr: 0.100000\n",
      "2020-10-22 07:20:35,730 epoch 25 - iter 146/736 - loss 0.38586186 - samples/sec: 60.62 - lr: 0.100000\n",
      "2020-10-22 07:20:53,970 epoch 25 - iter 219/736 - loss 0.38797478 - samples/sec: 65.25 - lr: 0.100000\n",
      "2020-10-22 07:21:13,369 epoch 25 - iter 292/736 - loss 0.39074402 - samples/sec: 61.36 - lr: 0.100000\n",
      "2020-10-22 07:21:31,025 epoch 25 - iter 365/736 - loss 0.40267715 - samples/sec: 67.58 - lr: 0.100000\n",
      "2020-10-22 07:21:49,870 epoch 25 - iter 438/736 - loss 0.40127536 - samples/sec: 63.20 - lr: 0.100000\n",
      "2020-10-22 07:22:07,281 epoch 25 - iter 511/736 - loss 0.40468112 - samples/sec: 68.48 - lr: 0.100000\n",
      "2020-10-22 07:22:25,120 epoch 25 - iter 584/736 - loss 0.39791597 - samples/sec: 66.91 - lr: 0.100000\n",
      "2020-10-22 07:22:43,767 epoch 25 - iter 657/736 - loss 0.40884345 - samples/sec: 63.02 - lr: 0.100000\n",
      "2020-10-22 07:23:02,299 epoch 25 - iter 730/736 - loss 0.40761631 - samples/sec: 64.30 - lr: 0.100000\n",
      "2020-10-22 07:23:03,550 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 07:23:03,550 EPOCH 25 done: loss 0.4080 - lr 0.1000000\n",
      "2020-10-22 07:24:04,111 DEV : loss 0.5383281707763672 - score 0.7949\n",
      "2020-10-22 07:24:06,007 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 07:24:06,008 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 07:24:25,330 epoch 26 - iter 73/736 - loss 0.41462125 - samples/sec: 61.97 - lr: 0.100000\n",
      "2020-10-22 07:24:42,346 epoch 26 - iter 146/736 - loss 0.41037815 - samples/sec: 70.14 - lr: 0.100000\n",
      "2020-10-22 07:25:01,241 epoch 26 - iter 219/736 - loss 0.40179384 - samples/sec: 62.14 - lr: 0.100000\n",
      "2020-10-22 07:25:19,358 epoch 26 - iter 292/736 - loss 0.40643100 - samples/sec: 65.74 - lr: 0.100000\n",
      "2020-10-22 07:25:38,917 epoch 26 - iter 365/736 - loss 0.41156912 - samples/sec: 61.70 - lr: 0.100000\n",
      "2020-10-22 07:25:57,243 epoch 26 - iter 438/736 - loss 0.41615600 - samples/sec: 65.02 - lr: 0.100000\n",
      "2020-10-22 07:26:15,964 epoch 26 - iter 511/736 - loss 0.42004582 - samples/sec: 63.59 - lr: 0.100000\n",
      "2020-10-22 07:26:33,974 epoch 26 - iter 584/736 - loss 0.41572720 - samples/sec: 65.19 - lr: 0.100000\n",
      "2020-10-22 07:26:52,757 epoch 26 - iter 657/736 - loss 0.41557843 - samples/sec: 63.39 - lr: 0.100000\n",
      "2020-10-22 07:27:10,456 epoch 26 - iter 730/736 - loss 0.41878784 - samples/sec: 67.38 - lr: 0.100000\n",
      "2020-10-22 07:27:12,961 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 07:27:12,962 EPOCH 26 done: loss 0.4182 - lr 0.1000000\n",
      "2020-10-22 07:28:13,385 DEV : loss 0.5701597332954407 - score 0.787\n",
      "2020-10-22 07:28:15,325 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 07:28:15,326 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 07:28:34,318 epoch 27 - iter 73/736 - loss 0.36366568 - samples/sec: 62.13 - lr: 0.100000\n",
      "2020-10-22 07:28:53,734 epoch 27 - iter 146/736 - loss 0.37367778 - samples/sec: 61.28 - lr: 0.100000\n",
      "2020-10-22 07:29:11,721 epoch 27 - iter 219/736 - loss 0.37374408 - samples/sec: 66.23 - lr: 0.100000\n",
      "2020-10-22 07:29:31,345 epoch 27 - iter 292/736 - loss 0.38664238 - samples/sec: 60.62 - lr: 0.100000\n",
      "2020-10-22 07:29:50,695 epoch 27 - iter 365/736 - loss 0.38033844 - samples/sec: 60.63 - lr: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 07:30:09,852 epoch 27 - iter 438/736 - loss 0.38299003 - samples/sec: 62.17 - lr: 0.100000\n",
      "2020-10-22 07:30:28,189 epoch 27 - iter 511/736 - loss 0.38922438 - samples/sec: 63.97 - lr: 0.100000\n",
      "2020-10-22 07:30:46,530 epoch 27 - iter 584/736 - loss 0.39161635 - samples/sec: 63.96 - lr: 0.100000\n",
      "2020-10-22 07:31:04,957 epoch 27 - iter 657/736 - loss 0.39466972 - samples/sec: 64.67 - lr: 0.100000\n",
      "2020-10-22 07:31:22,770 epoch 27 - iter 730/736 - loss 0.39801308 - samples/sec: 67.94 - lr: 0.100000\n",
      "2020-10-22 07:31:24,040 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 07:31:24,040 EPOCH 27 done: loss 0.3973 - lr 0.1000000\n",
      "2020-10-22 07:32:24,425 DEV : loss 0.5126873850822449 - score 0.8072\n",
      "2020-10-22 07:32:26,329 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 07:32:26,330 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 07:32:44,142 epoch 28 - iter 73/736 - loss 0.40051940 - samples/sec: 67.45 - lr: 0.100000\n",
      "2020-10-22 07:33:03,265 epoch 28 - iter 146/736 - loss 0.40676783 - samples/sec: 63.16 - lr: 0.100000\n",
      "2020-10-22 07:33:21,300 epoch 28 - iter 219/736 - loss 0.39554999 - samples/sec: 66.09 - lr: 0.100000\n",
      "2020-10-22 07:33:42,535 epoch 28 - iter 292/736 - loss 0.39521627 - samples/sec: 55.99 - lr: 0.100000\n",
      "2020-10-22 07:34:01,499 epoch 28 - iter 365/736 - loss 0.38629042 - samples/sec: 62.81 - lr: 0.100000\n",
      "2020-10-22 07:34:20,153 epoch 28 - iter 438/736 - loss 0.38359996 - samples/sec: 63.78 - lr: 0.100000\n",
      "2020-10-22 07:34:38,675 epoch 28 - iter 511/736 - loss 0.38526058 - samples/sec: 63.29 - lr: 0.100000\n",
      "2020-10-22 07:34:56,620 epoch 28 - iter 584/736 - loss 0.39036068 - samples/sec: 66.44 - lr: 0.100000\n",
      "2020-10-22 07:35:15,812 epoch 28 - iter 657/736 - loss 0.39009253 - samples/sec: 62.02 - lr: 0.100000\n",
      "2020-10-22 07:35:34,611 epoch 28 - iter 730/736 - loss 0.39225603 - samples/sec: 63.33 - lr: 0.100000\n",
      "2020-10-22 07:35:35,771 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 07:35:35,772 EPOCH 28 done: loss 0.3917 - lr 0.1000000\n",
      "2020-10-22 07:36:36,213 DEV : loss 0.594586193561554 - score 0.8021\n",
      "2020-10-22 07:36:38,127 BAD EPOCHS (no improvement): 5\n",
      "2020-10-22 07:36:38,127 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 07:36:55,883 epoch 29 - iter 73/736 - loss 0.36532913 - samples/sec: 67.64 - lr: 0.100000\n",
      "2020-10-22 07:37:15,190 epoch 29 - iter 146/736 - loss 0.39825873 - samples/sec: 61.69 - lr: 0.100000\n",
      "2020-10-22 07:37:33,812 epoch 29 - iter 219/736 - loss 0.39559982 - samples/sec: 62.99 - lr: 0.100000\n",
      "2020-10-22 07:37:51,620 epoch 29 - iter 292/736 - loss 0.39472733 - samples/sec: 65.93 - lr: 0.100000\n",
      "2020-10-22 07:38:10,409 epoch 29 - iter 365/736 - loss 0.39233412 - samples/sec: 63.45 - lr: 0.100000\n",
      "2020-10-22 07:38:28,548 epoch 29 - iter 438/736 - loss 0.39180874 - samples/sec: 65.73 - lr: 0.100000\n",
      "2020-10-22 07:38:47,215 epoch 29 - iter 511/736 - loss 0.39752721 - samples/sec: 63.77 - lr: 0.100000\n",
      "2020-10-22 07:39:06,174 epoch 29 - iter 584/736 - loss 0.39582229 - samples/sec: 62.81 - lr: 0.100000\n",
      "2020-10-22 07:39:25,746 epoch 29 - iter 657/736 - loss 0.39286439 - samples/sec: 60.80 - lr: 0.100000\n",
      "2020-10-22 07:39:44,444 epoch 29 - iter 730/736 - loss 0.39867626 - samples/sec: 64.58 - lr: 0.100000\n",
      "2020-10-22 07:39:45,781 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 07:39:45,782 EPOCH 29 done: loss 0.3981 - lr 0.1000000\n",
      "2020-10-22 07:40:45,997 DEV : loss 0.6212007999420166 - score 0.785\n",
      "Epoch    29: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2020-10-22 07:40:47,895 BAD EPOCHS (no improvement): 6\n",
      "2020-10-22 07:40:47,896 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 07:41:07,116 epoch 30 - iter 73/736 - loss 0.39146702 - samples/sec: 62.33 - lr: 0.050000\n",
      "2020-10-22 07:41:25,097 epoch 30 - iter 146/736 - loss 0.37410289 - samples/sec: 66.31 - lr: 0.050000\n",
      "2020-10-22 07:41:44,372 epoch 30 - iter 219/736 - loss 0.35465890 - samples/sec: 60.90 - lr: 0.050000\n",
      "2020-10-22 07:42:02,683 epoch 30 - iter 292/736 - loss 0.34909478 - samples/sec: 65.07 - lr: 0.050000\n",
      "2020-10-22 07:42:22,306 epoch 30 - iter 365/736 - loss 0.34241563 - samples/sec: 59.82 - lr: 0.050000\n",
      "2020-10-22 07:42:40,154 epoch 30 - iter 438/736 - loss 0.34052922 - samples/sec: 66.78 - lr: 0.050000\n",
      "2020-10-22 07:42:57,806 epoch 30 - iter 511/736 - loss 0.34157500 - samples/sec: 67.54 - lr: 0.050000\n",
      "2020-10-22 07:43:16,135 epoch 30 - iter 584/736 - loss 0.34258297 - samples/sec: 64.04 - lr: 0.050000\n",
      "2020-10-22 07:43:33,921 epoch 30 - iter 657/736 - loss 0.34301259 - samples/sec: 67.04 - lr: 0.050000\n",
      "2020-10-22 07:43:54,109 epoch 30 - iter 730/736 - loss 0.33881167 - samples/sec: 58.89 - lr: 0.050000\n",
      "2020-10-22 07:43:55,328 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 07:43:55,328 EPOCH 30 done: loss 0.3388 - lr 0.0500000\n",
      "2020-10-22 07:44:55,806 DEV : loss 0.521003246307373 - score 0.8179\n",
      "2020-10-22 07:44:57,705 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 07:44:59,652 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 07:45:19,290 epoch 31 - iter 73/736 - loss 0.28144575 - samples/sec: 60.10 - lr: 0.050000\n",
      "2020-10-22 07:45:37,061 epoch 31 - iter 146/736 - loss 0.28908245 - samples/sec: 66.01 - lr: 0.050000\n",
      "2020-10-22 07:45:54,555 epoch 31 - iter 219/736 - loss 0.29009329 - samples/sec: 67.04 - lr: 0.050000\n",
      "2020-10-22 07:46:14,396 epoch 31 - iter 292/736 - loss 0.29479441 - samples/sec: 59.94 - lr: 0.050000\n",
      "2020-10-22 07:46:31,533 epoch 31 - iter 365/736 - loss 0.29660745 - samples/sec: 69.60 - lr: 0.050000\n",
      "2020-10-22 07:46:49,662 epoch 31 - iter 438/736 - loss 0.29464643 - samples/sec: 65.75 - lr: 0.050000\n",
      "2020-10-22 07:47:08,121 epoch 31 - iter 511/736 - loss 0.29368579 - samples/sec: 64.54 - lr: 0.050000\n",
      "2020-10-22 07:47:26,671 epoch 31 - iter 584/736 - loss 0.29814535 - samples/sec: 65.18 - lr: 0.050000\n",
      "2020-10-22 07:47:46,746 epoch 31 - iter 657/736 - loss 0.29879298 - samples/sec: 59.28 - lr: 0.050000\n",
      "2020-10-22 07:48:05,930 epoch 31 - iter 730/736 - loss 0.29728455 - samples/sec: 61.15 - lr: 0.050000\n",
      "2020-10-22 07:48:07,337 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 07:48:07,338 EPOCH 31 done: loss 0.2970 - lr 0.0500000\n",
      "2020-10-22 07:49:07,984 DEV : loss 0.5170812010765076 - score 0.8192\n",
      "2020-10-22 07:49:09,885 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 07:49:11,837 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 07:49:30,094 epoch 32 - iter 73/736 - loss 0.28418297 - samples/sec: 65.79 - lr: 0.050000\n",
      "2020-10-22 07:49:47,414 epoch 32 - iter 146/736 - loss 0.28159923 - samples/sec: 67.73 - lr: 0.050000\n",
      "2020-10-22 07:50:06,810 epoch 32 - iter 219/736 - loss 0.28952680 - samples/sec: 61.34 - lr: 0.050000\n",
      "2020-10-22 07:50:24,951 epoch 32 - iter 292/736 - loss 0.29411703 - samples/sec: 64.70 - lr: 0.050000\n",
      "2020-10-22 07:50:44,105 epoch 32 - iter 365/736 - loss 0.29219389 - samples/sec: 61.30 - lr: 0.050000\n",
      "2020-10-22 07:51:02,494 epoch 32 - iter 438/736 - loss 0.28607648 - samples/sec: 64.77 - lr: 0.050000\n",
      "2020-10-22 07:51:22,644 epoch 32 - iter 511/736 - loss 0.28678906 - samples/sec: 58.99 - lr: 0.050000\n",
      "2020-10-22 07:51:41,293 epoch 32 - iter 584/736 - loss 0.28632572 - samples/sec: 63.88 - lr: 0.050000\n",
      "2020-10-22 07:51:59,324 epoch 32 - iter 657/736 - loss 0.28894681 - samples/sec: 66.05 - lr: 0.050000\n",
      "2020-10-22 07:52:18,496 epoch 32 - iter 730/736 - loss 0.29264027 - samples/sec: 62.03 - lr: 0.050000\n",
      "2020-10-22 07:52:19,893 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 07:52:19,893 EPOCH 32 done: loss 0.2935 - lr 0.0500000\n",
      "2020-10-22 07:53:20,867 DEV : loss 0.5035133957862854 - score 0.8259\n",
      "2020-10-22 07:53:22,788 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving best model\n",
      "2020-10-22 07:53:24,767 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 07:53:42,727 epoch 33 - iter 73/736 - loss 0.23453749 - samples/sec: 66.84 - lr: 0.050000\n",
      "2020-10-22 07:54:00,536 epoch 33 - iter 146/736 - loss 0.25535620 - samples/sec: 65.87 - lr: 0.050000\n",
      "2020-10-22 07:54:19,779 epoch 33 - iter 219/736 - loss 0.25479829 - samples/sec: 61.00 - lr: 0.050000\n",
      "2020-10-22 07:54:39,943 epoch 33 - iter 292/736 - loss 0.26273323 - samples/sec: 58.96 - lr: 0.050000\n",
      "2020-10-22 07:54:58,559 epoch 33 - iter 365/736 - loss 0.26508840 - samples/sec: 64.00 - lr: 0.050000\n",
      "2020-10-22 07:55:17,063 epoch 33 - iter 438/736 - loss 0.26743068 - samples/sec: 64.40 - lr: 0.050000\n",
      "2020-10-22 07:55:36,426 epoch 33 - iter 511/736 - loss 0.26624148 - samples/sec: 62.36 - lr: 0.050000\n",
      "2020-10-22 07:55:55,827 epoch 33 - iter 584/736 - loss 0.26869872 - samples/sec: 61.35 - lr: 0.050000\n",
      "2020-10-22 07:56:13,845 epoch 33 - iter 657/736 - loss 0.27450685 - samples/sec: 66.10 - lr: 0.050000\n",
      "2020-10-22 07:56:31,248 epoch 33 - iter 730/736 - loss 0.27475319 - samples/sec: 68.53 - lr: 0.050000\n",
      "2020-10-22 07:56:32,978 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 07:56:32,978 EPOCH 33 done: loss 0.2750 - lr 0.0500000\n",
      "2020-10-22 07:57:33,320 DEV : loss 0.4999881684780121 - score 0.8307\n",
      "2020-10-22 07:57:35,230 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 07:57:37,194 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 07:57:55,786 epoch 34 - iter 73/736 - loss 0.24766067 - samples/sec: 64.45 - lr: 0.050000\n",
      "2020-10-22 07:58:14,016 epoch 34 - iter 146/736 - loss 0.25112220 - samples/sec: 66.30 - lr: 0.050000\n",
      "2020-10-22 07:58:32,926 epoch 34 - iter 219/736 - loss 0.25958439 - samples/sec: 62.95 - lr: 0.050000\n",
      "2020-10-22 07:58:52,026 epoch 34 - iter 292/736 - loss 0.26317203 - samples/sec: 61.46 - lr: 0.050000\n",
      "2020-10-22 07:59:10,157 epoch 34 - iter 365/736 - loss 0.27066001 - samples/sec: 64.74 - lr: 0.050000\n",
      "2020-10-22 07:59:28,830 epoch 34 - iter 438/736 - loss 0.26991734 - samples/sec: 63.78 - lr: 0.050000\n",
      "2020-10-22 07:59:46,875 epoch 34 - iter 511/736 - loss 0.27255710 - samples/sec: 65.04 - lr: 0.050000\n",
      "2020-10-22 08:00:05,731 epoch 34 - iter 584/736 - loss 0.27556108 - samples/sec: 62.23 - lr: 0.050000\n",
      "2020-10-22 08:00:24,140 epoch 34 - iter 657/736 - loss 0.27172954 - samples/sec: 63.74 - lr: 0.050000\n",
      "2020-10-22 08:00:42,296 epoch 34 - iter 730/736 - loss 0.27281810 - samples/sec: 65.57 - lr: 0.050000\n",
      "2020-10-22 08:00:43,933 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 08:00:43,933 EPOCH 34 done: loss 0.2730 - lr 0.0500000\n",
      "2020-10-22 08:01:44,330 DEV : loss 0.5365239381790161 - score 0.8213\n",
      "2020-10-22 08:01:46,228 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 08:01:46,229 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 08:02:05,190 epoch 35 - iter 73/736 - loss 0.24297387 - samples/sec: 63.29 - lr: 0.050000\n",
      "2020-10-22 08:02:24,377 epoch 35 - iter 146/736 - loss 0.24326136 - samples/sec: 61.14 - lr: 0.050000\n",
      "2020-10-22 08:02:42,843 epoch 35 - iter 219/736 - loss 0.24754569 - samples/sec: 63.59 - lr: 0.050000\n",
      "2020-10-22 08:03:02,961 epoch 35 - iter 292/736 - loss 0.24246151 - samples/sec: 59.10 - lr: 0.050000\n",
      "2020-10-22 08:03:20,989 epoch 35 - iter 365/736 - loss 0.24545512 - samples/sec: 67.20 - lr: 0.050000\n",
      "2020-10-22 08:03:38,482 epoch 35 - iter 438/736 - loss 0.24844604 - samples/sec: 68.17 - lr: 0.050000\n",
      "2020-10-22 08:03:56,558 epoch 35 - iter 511/736 - loss 0.25172858 - samples/sec: 65.91 - lr: 0.050000\n",
      "2020-10-22 08:04:15,231 epoch 35 - iter 584/736 - loss 0.25471634 - samples/sec: 63.76 - lr: 0.050000\n",
      "2020-10-22 08:04:32,718 epoch 35 - iter 657/736 - loss 0.25642633 - samples/sec: 68.16 - lr: 0.050000\n",
      "2020-10-22 08:04:51,604 epoch 35 - iter 730/736 - loss 0.25562839 - samples/sec: 63.09 - lr: 0.050000\n",
      "2020-10-22 08:04:53,009 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 08:04:53,010 EPOCH 35 done: loss 0.2561 - lr 0.0500000\n",
      "2020-10-22 08:05:53,438 DEV : loss 0.5796636343002319 - score 0.8151\n",
      "2020-10-22 08:05:55,338 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 08:05:55,338 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 08:06:15,206 epoch 36 - iter 73/736 - loss 0.22587659 - samples/sec: 60.32 - lr: 0.050000\n",
      "2020-10-22 08:06:32,665 epoch 36 - iter 146/736 - loss 0.24377159 - samples/sec: 68.37 - lr: 0.050000\n",
      "2020-10-22 08:06:50,329 epoch 36 - iter 219/736 - loss 0.25201533 - samples/sec: 68.58 - lr: 0.050000\n",
      "2020-10-22 08:07:07,947 epoch 36 - iter 292/736 - loss 0.25768936 - samples/sec: 67.68 - lr: 0.050000\n",
      "2020-10-22 08:07:26,615 epoch 36 - iter 365/736 - loss 0.25141618 - samples/sec: 63.77 - lr: 0.050000\n",
      "2020-10-22 08:07:46,071 epoch 36 - iter 438/736 - loss 0.25227709 - samples/sec: 61.15 - lr: 0.050000\n",
      "2020-10-22 08:08:03,404 epoch 36 - iter 511/736 - loss 0.25330508 - samples/sec: 68.82 - lr: 0.050000\n",
      "2020-10-22 08:08:22,992 epoch 36 - iter 584/736 - loss 0.25626860 - samples/sec: 60.72 - lr: 0.050000\n",
      "2020-10-22 08:08:41,861 epoch 36 - iter 657/736 - loss 0.25493910 - samples/sec: 63.11 - lr: 0.050000\n",
      "2020-10-22 08:09:02,346 epoch 36 - iter 730/736 - loss 0.25770588 - samples/sec: 58.85 - lr: 0.050000\n",
      "2020-10-22 08:09:03,646 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 08:09:03,646 EPOCH 36 done: loss 0.2570 - lr 0.0500000\n",
      "2020-10-22 08:10:04,234 DEV : loss 0.5197863578796387 - score 0.8266\n",
      "2020-10-22 08:10:06,157 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 08:10:06,158 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 08:10:24,054 epoch 37 - iter 73/736 - loss 0.27110631 - samples/sec: 67.06 - lr: 0.050000\n",
      "2020-10-22 08:10:42,172 epoch 37 - iter 146/736 - loss 0.24180570 - samples/sec: 65.81 - lr: 0.050000\n",
      "2020-10-22 08:11:01,120 epoch 37 - iter 219/736 - loss 0.24420067 - samples/sec: 62.79 - lr: 0.050000\n",
      "2020-10-22 08:11:19,590 epoch 37 - iter 292/736 - loss 0.24679286 - samples/sec: 65.47 - lr: 0.050000\n",
      "2020-10-22 08:11:39,793 epoch 37 - iter 365/736 - loss 0.24082769 - samples/sec: 58.82 - lr: 0.050000\n",
      "2020-10-22 08:11:57,276 epoch 37 - iter 438/736 - loss 0.24166023 - samples/sec: 67.10 - lr: 0.050000\n",
      "2020-10-22 08:12:16,499 epoch 37 - iter 511/736 - loss 0.25119682 - samples/sec: 61.91 - lr: 0.050000\n",
      "2020-10-22 08:12:35,408 epoch 37 - iter 584/736 - loss 0.24784464 - samples/sec: 63.01 - lr: 0.050000\n",
      "2020-10-22 08:12:53,636 epoch 37 - iter 657/736 - loss 0.25010648 - samples/sec: 65.32 - lr: 0.050000\n",
      "2020-10-22 08:13:11,384 epoch 37 - iter 730/736 - loss 0.25246103 - samples/sec: 66.12 - lr: 0.050000\n",
      "2020-10-22 08:13:12,719 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 08:13:12,719 EPOCH 37 done: loss 0.2515 - lr 0.0500000\n",
      "2020-10-22 08:14:13,072 DEV : loss 0.49242648482322693 - score 0.832\n",
      "2020-10-22 08:14:14,989 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 08:14:16,968 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 08:14:35,284 epoch 38 - iter 73/736 - loss 0.24320068 - samples/sec: 65.53 - lr: 0.050000\n",
      "2020-10-22 08:14:54,652 epoch 38 - iter 146/736 - loss 0.23093105 - samples/sec: 62.38 - lr: 0.050000\n",
      "2020-10-22 08:15:13,012 epoch 38 - iter 219/736 - loss 0.23346654 - samples/sec: 63.92 - lr: 0.050000\n",
      "2020-10-22 08:15:31,069 epoch 38 - iter 292/736 - loss 0.24252035 - samples/sec: 66.12 - lr: 0.050000\n",
      "2020-10-22 08:15:49,686 epoch 38 - iter 365/736 - loss 0.24075562 - samples/sec: 64.05 - lr: 0.050000\n",
      "2020-10-22 08:16:08,558 epoch 38 - iter 438/736 - loss 0.24491583 - samples/sec: 63.15 - lr: 0.050000\n",
      "2020-10-22 08:16:30,079 epoch 38 - iter 511/736 - loss 0.24142811 - samples/sec: 55.93 - lr: 0.050000\n",
      "2020-10-22 08:16:47,923 epoch 38 - iter 584/736 - loss 0.24102542 - samples/sec: 66.82 - lr: 0.050000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 08:17:05,312 epoch 38 - iter 657/736 - loss 0.24077881 - samples/sec: 68.55 - lr: 0.050000\n",
      "2020-10-22 08:17:23,558 epoch 38 - iter 730/736 - loss 0.24036327 - samples/sec: 64.26 - lr: 0.050000\n",
      "2020-10-22 08:17:24,922 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 08:17:24,923 EPOCH 38 done: loss 0.2415 - lr 0.0500000\n",
      "2020-10-22 08:18:25,209 DEV : loss 0.5293952822685242 - score 0.8249\n",
      "2020-10-22 08:18:27,115 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 08:18:27,116 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 08:18:45,612 epoch 39 - iter 73/736 - loss 0.23415036 - samples/sec: 64.81 - lr: 0.050000\n",
      "2020-10-22 08:19:03,479 epoch 39 - iter 146/736 - loss 0.22992241 - samples/sec: 66.68 - lr: 0.050000\n",
      "2020-10-22 08:19:21,679 epoch 39 - iter 219/736 - loss 0.22542867 - samples/sec: 65.44 - lr: 0.050000\n",
      "2020-10-22 08:19:40,190 epoch 39 - iter 292/736 - loss 0.22347130 - samples/sec: 64.42 - lr: 0.050000\n",
      "2020-10-22 08:19:58,248 epoch 39 - iter 365/736 - loss 0.22161886 - samples/sec: 65.96 - lr: 0.050000\n",
      "2020-10-22 08:20:17,140 epoch 39 - iter 438/736 - loss 0.22568461 - samples/sec: 63.01 - lr: 0.050000\n",
      "2020-10-22 08:20:36,613 epoch 39 - iter 511/736 - loss 0.22178448 - samples/sec: 62.10 - lr: 0.050000\n",
      "2020-10-22 08:20:54,400 epoch 39 - iter 584/736 - loss 0.22560673 - samples/sec: 65.95 - lr: 0.050000\n",
      "2020-10-22 08:21:13,692 epoch 39 - iter 657/736 - loss 0.22797032 - samples/sec: 61.70 - lr: 0.050000\n",
      "2020-10-22 08:21:33,312 epoch 39 - iter 730/736 - loss 0.23351052 - samples/sec: 59.78 - lr: 0.050000\n",
      "2020-10-22 08:21:34,848 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 08:21:34,849 EPOCH 39 done: loss 0.2326 - lr 0.0500000\n",
      "2020-10-22 08:22:35,121 DEV : loss 0.5343804359436035 - score 0.8297\n",
      "2020-10-22 08:22:37,043 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 08:22:37,044 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 08:22:57,861 epoch 40 - iter 73/736 - loss 0.20984652 - samples/sec: 57.44 - lr: 0.050000\n",
      "2020-10-22 08:23:17,078 epoch 40 - iter 146/736 - loss 0.21465113 - samples/sec: 61.97 - lr: 0.050000\n",
      "2020-10-22 08:23:35,167 epoch 40 - iter 219/736 - loss 0.22509296 - samples/sec: 64.91 - lr: 0.050000\n",
      "2020-10-22 08:23:53,099 epoch 40 - iter 292/736 - loss 0.22645145 - samples/sec: 65.47 - lr: 0.050000\n",
      "2020-10-22 08:24:12,923 epoch 40 - iter 365/736 - loss 0.23285086 - samples/sec: 59.96 - lr: 0.050000\n",
      "2020-10-22 08:24:31,185 epoch 40 - iter 438/736 - loss 0.23067494 - samples/sec: 65.21 - lr: 0.050000\n",
      "2020-10-22 08:24:49,404 epoch 40 - iter 511/736 - loss 0.22948468 - samples/sec: 65.46 - lr: 0.050000\n",
      "2020-10-22 08:25:08,723 epoch 40 - iter 584/736 - loss 0.23135351 - samples/sec: 60.73 - lr: 0.050000\n",
      "2020-10-22 08:25:25,641 epoch 40 - iter 657/736 - loss 0.23176687 - samples/sec: 69.41 - lr: 0.050000\n",
      "2020-10-22 08:25:43,109 epoch 40 - iter 730/736 - loss 0.23048985 - samples/sec: 68.22 - lr: 0.050000\n",
      "2020-10-22 08:25:44,417 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 08:25:44,417 EPOCH 40 done: loss 0.2304 - lr 0.0500000\n",
      "2020-10-22 08:26:45,052 DEV : loss 0.5304630398750305 - score 0.8346\n",
      "2020-10-22 08:26:46,984 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 08:26:48,947 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 08:27:07,107 epoch 41 - iter 73/736 - loss 0.24221261 - samples/sec: 66.06 - lr: 0.050000\n",
      "2020-10-22 08:27:25,939 epoch 41 - iter 146/736 - loss 0.22973383 - samples/sec: 64.25 - lr: 0.050000\n",
      "2020-10-22 08:27:44,820 epoch 41 - iter 219/736 - loss 0.23509721 - samples/sec: 63.05 - lr: 0.050000\n",
      "2020-10-22 08:28:02,878 epoch 41 - iter 292/736 - loss 0.23810535 - samples/sec: 65.00 - lr: 0.050000\n",
      "2020-10-22 08:28:21,978 epoch 41 - iter 365/736 - loss 0.23651105 - samples/sec: 62.34 - lr: 0.050000\n",
      "2020-10-22 08:28:39,813 epoch 41 - iter 438/736 - loss 0.23279667 - samples/sec: 66.80 - lr: 0.050000\n",
      "2020-10-22 08:28:58,517 epoch 41 - iter 511/736 - loss 0.22989919 - samples/sec: 62.77 - lr: 0.050000\n",
      "2020-10-22 08:29:16,753 epoch 41 - iter 584/736 - loss 0.22420789 - samples/sec: 64.32 - lr: 0.050000\n",
      "2020-10-22 08:29:34,909 epoch 41 - iter 657/736 - loss 0.22532261 - samples/sec: 64.67 - lr: 0.050000\n",
      "2020-10-22 08:29:55,648 epoch 41 - iter 730/736 - loss 0.22758982 - samples/sec: 57.30 - lr: 0.050000\n",
      "2020-10-22 08:29:57,182 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 08:29:57,183 EPOCH 41 done: loss 0.2281 - lr 0.0500000\n",
      "2020-10-22 08:30:57,681 DEV : loss 0.5368749499320984 - score 0.8266\n",
      "2020-10-22 08:30:59,577 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 08:30:59,578 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 08:31:18,495 epoch 42 - iter 73/736 - loss 0.22058527 - samples/sec: 62.39 - lr: 0.050000\n",
      "2020-10-22 08:31:36,510 epoch 42 - iter 146/736 - loss 0.22443111 - samples/sec: 66.15 - lr: 0.050000\n",
      "2020-10-22 08:31:54,903 epoch 42 - iter 219/736 - loss 0.21789038 - samples/sec: 64.78 - lr: 0.050000\n",
      "2020-10-22 08:32:12,722 epoch 42 - iter 292/736 - loss 0.22404571 - samples/sec: 66.89 - lr: 0.050000\n",
      "2020-10-22 08:32:31,573 epoch 42 - iter 365/736 - loss 0.21852505 - samples/sec: 63.19 - lr: 0.050000\n",
      "2020-10-22 08:32:51,303 epoch 42 - iter 438/736 - loss 0.21606431 - samples/sec: 59.49 - lr: 0.050000\n",
      "2020-10-22 08:33:08,699 epoch 42 - iter 511/736 - loss 0.21114209 - samples/sec: 68.57 - lr: 0.050000\n",
      "2020-10-22 08:33:27,677 epoch 42 - iter 584/736 - loss 0.21204262 - samples/sec: 61.89 - lr: 0.050000\n",
      "2020-10-22 08:33:47,214 epoch 42 - iter 657/736 - loss 0.21212946 - samples/sec: 60.07 - lr: 0.050000\n",
      "2020-10-22 08:34:05,644 epoch 42 - iter 730/736 - loss 0.21362167 - samples/sec: 65.59 - lr: 0.050000\n",
      "2020-10-22 08:34:07,510 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 08:34:07,511 EPOCH 42 done: loss 0.2140 - lr 0.0500000\n",
      "2020-10-22 08:35:07,668 DEV : loss 0.5558646321296692 - score 0.8289\n",
      "2020-10-22 08:35:09,558 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 08:35:09,559 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 08:35:27,029 epoch 43 - iter 73/736 - loss 0.18700336 - samples/sec: 68.82 - lr: 0.050000\n",
      "2020-10-22 08:35:45,300 epoch 43 - iter 146/736 - loss 0.18719774 - samples/sec: 66.17 - lr: 0.050000\n",
      "2020-10-22 08:36:04,468 epoch 43 - iter 219/736 - loss 0.20780076 - samples/sec: 62.13 - lr: 0.050000\n",
      "2020-10-22 08:36:22,855 epoch 43 - iter 292/736 - loss 0.20815102 - samples/sec: 64.74 - lr: 0.050000\n",
      "2020-10-22 08:36:41,848 epoch 43 - iter 365/736 - loss 0.20547866 - samples/sec: 63.64 - lr: 0.050000\n",
      "2020-10-22 08:37:00,273 epoch 43 - iter 438/736 - loss 0.20351189 - samples/sec: 64.68 - lr: 0.050000\n",
      "2020-10-22 08:37:20,383 epoch 43 - iter 511/736 - loss 0.20525589 - samples/sec: 59.15 - lr: 0.050000\n",
      "2020-10-22 08:37:39,312 epoch 43 - iter 584/736 - loss 0.20584528 - samples/sec: 62.02 - lr: 0.050000\n",
      "2020-10-22 08:37:57,134 epoch 43 - iter 657/736 - loss 0.20768765 - samples/sec: 65.80 - lr: 0.050000\n",
      "2020-10-22 08:38:16,296 epoch 43 - iter 730/736 - loss 0.21216410 - samples/sec: 63.03 - lr: 0.050000\n",
      "2020-10-22 08:38:17,665 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 08:38:17,665 EPOCH 43 done: loss 0.2111 - lr 0.0500000\n",
      "2020-10-22 08:39:18,127 DEV : loss 0.5683118104934692 - score 0.8233\n",
      "2020-10-22 08:39:20,301 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 08:39:20,301 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 08:39:39,535 epoch 44 - iter 73/736 - loss 0.18491577 - samples/sec: 62.22 - lr: 0.050000\n",
      "2020-10-22 08:39:57,428 epoch 44 - iter 146/736 - loss 0.20978453 - samples/sec: 65.63 - lr: 0.050000\n",
      "2020-10-22 08:40:16,083 epoch 44 - iter 219/736 - loss 0.20401041 - samples/sec: 63.89 - lr: 0.050000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 08:40:34,225 epoch 44 - iter 292/736 - loss 0.21702861 - samples/sec: 65.73 - lr: 0.050000\n",
      "2020-10-22 08:40:52,513 epoch 44 - iter 365/736 - loss 0.21923958 - samples/sec: 64.20 - lr: 0.050000\n",
      "2020-10-22 08:41:10,934 epoch 44 - iter 438/736 - loss 0.21762593 - samples/sec: 65.72 - lr: 0.050000\n",
      "2020-10-22 08:41:29,587 epoch 44 - iter 511/736 - loss 0.21971656 - samples/sec: 62.98 - lr: 0.050000\n",
      "2020-10-22 08:41:48,904 epoch 44 - iter 584/736 - loss 0.21976363 - samples/sec: 60.81 - lr: 0.050000\n",
      "2020-10-22 08:42:07,012 epoch 44 - iter 657/736 - loss 0.21767871 - samples/sec: 65.88 - lr: 0.050000\n",
      "2020-10-22 08:42:26,709 epoch 44 - iter 730/736 - loss 0.21686411 - samples/sec: 60.43 - lr: 0.050000\n",
      "2020-10-22 08:42:28,180 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 08:42:28,181 EPOCH 44 done: loss 0.2161 - lr 0.0500000\n",
      "2020-10-22 08:43:28,618 DEV : loss 0.5766856074333191 - score 0.8295\n",
      "2020-10-22 08:43:30,531 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 08:43:30,532 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 08:43:49,843 epoch 45 - iter 73/736 - loss 0.19080343 - samples/sec: 62.08 - lr: 0.050000\n",
      "2020-10-22 08:44:08,494 epoch 45 - iter 146/736 - loss 0.19114748 - samples/sec: 63.88 - lr: 0.050000\n",
      "2020-10-22 08:44:26,088 epoch 45 - iter 219/736 - loss 0.19664877 - samples/sec: 67.79 - lr: 0.050000\n",
      "2020-10-22 08:44:43,742 epoch 45 - iter 292/736 - loss 0.20849908 - samples/sec: 67.54 - lr: 0.050000\n",
      "2020-10-22 08:45:03,476 epoch 45 - iter 365/736 - loss 0.20296398 - samples/sec: 60.28 - lr: 0.050000\n",
      "2020-10-22 08:45:22,664 epoch 45 - iter 438/736 - loss 0.20814323 - samples/sec: 61.10 - lr: 0.050000\n",
      "2020-10-22 08:45:40,487 epoch 45 - iter 511/736 - loss 0.20658720 - samples/sec: 66.89 - lr: 0.050000\n",
      "2020-10-22 08:45:58,008 epoch 45 - iter 584/736 - loss 0.20922526 - samples/sec: 68.13 - lr: 0.050000\n",
      "2020-10-22 08:46:16,614 epoch 45 - iter 657/736 - loss 0.21024203 - samples/sec: 63.14 - lr: 0.050000\n",
      "2020-10-22 08:46:35,471 epoch 45 - iter 730/736 - loss 0.21023918 - samples/sec: 63.18 - lr: 0.050000\n",
      "2020-10-22 08:46:37,016 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 08:46:37,017 EPOCH 45 done: loss 0.2111 - lr 0.0500000\n",
      "2020-10-22 08:47:37,474 DEV : loss 0.5627546310424805 - score 0.8249\n",
      "2020-10-22 08:47:39,392 BAD EPOCHS (no improvement): 5\n",
      "2020-10-22 08:47:39,393 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 08:47:57,924 epoch 46 - iter 73/736 - loss 0.21204543 - samples/sec: 63.76 - lr: 0.050000\n",
      "2020-10-22 08:48:17,477 epoch 46 - iter 146/736 - loss 0.20019707 - samples/sec: 60.86 - lr: 0.050000\n",
      "2020-10-22 08:48:36,543 epoch 46 - iter 219/736 - loss 0.20440578 - samples/sec: 61.55 - lr: 0.050000\n",
      "2020-10-22 08:48:54,740 epoch 46 - iter 292/736 - loss 0.21290276 - samples/sec: 65.46 - lr: 0.050000\n",
      "2020-10-22 08:49:13,220 epoch 46 - iter 365/736 - loss 0.21838390 - samples/sec: 64.43 - lr: 0.050000\n",
      "2020-10-22 08:49:31,891 epoch 46 - iter 438/736 - loss 0.21886701 - samples/sec: 64.70 - lr: 0.050000\n",
      "2020-10-22 08:49:49,500 epoch 46 - iter 511/736 - loss 0.21520679 - samples/sec: 67.72 - lr: 0.050000\n",
      "2020-10-22 08:50:07,610 epoch 46 - iter 584/736 - loss 0.21549604 - samples/sec: 65.83 - lr: 0.050000\n",
      "2020-10-22 08:50:27,399 epoch 46 - iter 657/736 - loss 0.21491733 - samples/sec: 60.10 - lr: 0.050000\n",
      "2020-10-22 08:50:46,139 epoch 46 - iter 730/736 - loss 0.21402937 - samples/sec: 62.58 - lr: 0.050000\n",
      "2020-10-22 08:50:47,636 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 08:50:47,637 EPOCH 46 done: loss 0.2148 - lr 0.0500000\n",
      "2020-10-22 08:51:48,005 DEV : loss 0.5851114392280579 - score 0.8246\n",
      "Epoch    46: reducing learning rate of group 0 to 2.5000e-02.\n",
      "2020-10-22 08:51:49,946 BAD EPOCHS (no improvement): 6\n",
      "2020-10-22 08:51:49,947 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 08:52:09,603 epoch 47 - iter 73/736 - loss 0.17047367 - samples/sec: 60.90 - lr: 0.025000\n",
      "2020-10-22 08:52:27,800 epoch 47 - iter 146/736 - loss 0.17949603 - samples/sec: 65.48 - lr: 0.025000\n",
      "2020-10-22 08:52:45,224 epoch 47 - iter 219/736 - loss 0.18095376 - samples/sec: 68.35 - lr: 0.025000\n",
      "2020-10-22 08:53:04,115 epoch 47 - iter 292/736 - loss 0.17143835 - samples/sec: 62.08 - lr: 0.025000\n",
      "2020-10-22 08:53:21,246 epoch 47 - iter 365/736 - loss 0.17298517 - samples/sec: 68.45 - lr: 0.025000\n",
      "2020-10-22 08:53:41,617 epoch 47 - iter 438/736 - loss 0.17731773 - samples/sec: 58.35 - lr: 0.025000\n",
      "2020-10-22 08:53:59,837 epoch 47 - iter 511/736 - loss 0.17846844 - samples/sec: 65.42 - lr: 0.025000\n",
      "2020-10-22 08:54:19,152 epoch 47 - iter 584/736 - loss 0.18083528 - samples/sec: 60.76 - lr: 0.025000\n",
      "2020-10-22 08:54:36,996 epoch 47 - iter 657/736 - loss 0.17959215 - samples/sec: 65.74 - lr: 0.025000\n",
      "2020-10-22 08:54:54,981 epoch 47 - iter 730/736 - loss 0.17863523 - samples/sec: 66.31 - lr: 0.025000\n",
      "2020-10-22 08:54:57,524 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 08:54:57,525 EPOCH 47 done: loss 0.1779 - lr 0.0250000\n",
      "2020-10-22 08:55:58,078 DEV : loss 0.5643427968025208 - score 0.8292\n",
      "2020-10-22 08:56:00,018 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 08:56:00,019 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 08:56:19,138 epoch 48 - iter 73/736 - loss 0.14324722 - samples/sec: 62.70 - lr: 0.025000\n",
      "2020-10-22 08:56:37,427 epoch 48 - iter 146/736 - loss 0.15419969 - samples/sec: 65.19 - lr: 0.025000\n",
      "2020-10-22 08:56:55,421 epoch 48 - iter 219/736 - loss 0.15910280 - samples/sec: 66.24 - lr: 0.025000\n",
      "2020-10-22 08:57:13,919 epoch 48 - iter 292/736 - loss 0.16744923 - samples/sec: 64.39 - lr: 0.025000\n",
      "2020-10-22 08:57:31,912 epoch 48 - iter 365/736 - loss 0.16102340 - samples/sec: 66.28 - lr: 0.025000\n",
      "2020-10-22 08:57:49,249 epoch 48 - iter 438/736 - loss 0.16443726 - samples/sec: 68.91 - lr: 0.025000\n",
      "2020-10-22 08:58:09,498 epoch 48 - iter 511/736 - loss 0.16335090 - samples/sec: 58.69 - lr: 0.025000\n",
      "2020-10-22 08:58:28,483 epoch 48 - iter 584/736 - loss 0.16589240 - samples/sec: 61.76 - lr: 0.025000\n",
      "2020-10-22 08:58:47,746 epoch 48 - iter 657/736 - loss 0.16611812 - samples/sec: 60.89 - lr: 0.025000\n",
      "2020-10-22 08:59:05,414 epoch 48 - iter 730/736 - loss 0.16630932 - samples/sec: 67.48 - lr: 0.025000\n",
      "2020-10-22 08:59:07,285 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 08:59:07,286 EPOCH 48 done: loss 0.1662 - lr 0.0250000\n",
      "2020-10-22 09:00:07,854 DEV : loss 0.5872879028320312 - score 0.8333\n",
      "2020-10-22 09:00:09,755 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 09:00:09,755 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 09:00:27,470 epoch 49 - iter 73/736 - loss 0.16142675 - samples/sec: 67.77 - lr: 0.025000\n",
      "2020-10-22 09:00:45,765 epoch 49 - iter 146/736 - loss 0.15924622 - samples/sec: 64.10 - lr: 0.025000\n",
      "2020-10-22 09:01:04,126 epoch 49 - iter 219/736 - loss 0.15771317 - samples/sec: 63.95 - lr: 0.025000\n",
      "2020-10-22 09:01:22,424 epoch 49 - iter 292/736 - loss 0.15601044 - samples/sec: 65.12 - lr: 0.025000\n",
      "2020-10-22 09:01:41,264 epoch 49 - iter 365/736 - loss 0.16274335 - samples/sec: 63.20 - lr: 0.025000\n",
      "2020-10-22 09:01:59,511 epoch 49 - iter 438/736 - loss 0.16520412 - samples/sec: 65.37 - lr: 0.025000\n",
      "2020-10-22 09:02:18,063 epoch 49 - iter 511/736 - loss 0.16412192 - samples/sec: 64.27 - lr: 0.025000\n",
      "2020-10-22 09:02:37,187 epoch 49 - iter 584/736 - loss 0.16430532 - samples/sec: 61.34 - lr: 0.025000\n",
      "2020-10-22 09:02:55,174 epoch 49 - iter 657/736 - loss 0.16306498 - samples/sec: 66.25 - lr: 0.025000\n",
      "2020-10-22 09:03:15,929 epoch 49 - iter 730/736 - loss 0.16259957 - samples/sec: 57.24 - lr: 0.025000\n",
      "2020-10-22 09:03:17,522 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 09:03:17,522 EPOCH 49 done: loss 0.1627 - lr 0.0250000\n",
      "2020-10-22 09:04:18,008 DEV : loss 0.579181432723999 - score 0.8346\n",
      "2020-10-22 09:04:19,898 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 09:04:19,899 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 09:04:39,092 epoch 50 - iter 73/736 - loss 0.13416733 - samples/sec: 62.50 - lr: 0.025000\n",
      "2020-10-22 09:04:58,199 epoch 50 - iter 146/736 - loss 0.14528287 - samples/sec: 62.23 - lr: 0.025000\n",
      "2020-10-22 09:05:17,877 epoch 50 - iter 219/736 - loss 0.14773228 - samples/sec: 61.35 - lr: 0.025000\n",
      "2020-10-22 09:05:35,464 epoch 50 - iter 292/736 - loss 0.15245274 - samples/sec: 66.67 - lr: 0.025000\n",
      "2020-10-22 09:05:54,075 epoch 50 - iter 365/736 - loss 0.14650395 - samples/sec: 63.03 - lr: 0.025000\n",
      "2020-10-22 09:06:13,033 epoch 50 - iter 438/736 - loss 0.14865621 - samples/sec: 62.75 - lr: 0.025000\n",
      "2020-10-22 09:06:31,650 epoch 50 - iter 511/736 - loss 0.14715849 - samples/sec: 64.99 - lr: 0.025000\n",
      "2020-10-22 09:06:49,026 epoch 50 - iter 584/736 - loss 0.14838783 - samples/sec: 68.62 - lr: 0.025000\n",
      "2020-10-22 09:07:08,093 epoch 50 - iter 657/736 - loss 0.15102123 - samples/sec: 61.57 - lr: 0.025000\n",
      "2020-10-22 09:07:27,073 epoch 50 - iter 730/736 - loss 0.15294102 - samples/sec: 62.79 - lr: 0.025000\n",
      "2020-10-22 09:07:28,302 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 09:07:28,302 EPOCH 50 done: loss 0.1526 - lr 0.0250000\n",
      "2020-10-22 09:08:28,849 DEV : loss 0.5931603908538818 - score 0.8366\n",
      "2020-10-22 09:08:30,732 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 09:08:32,664 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 09:08:50,094 epoch 51 - iter 73/736 - loss 0.16075476 - samples/sec: 68.89 - lr: 0.025000\n",
      "2020-10-22 09:09:08,908 epoch 51 - iter 146/736 - loss 0.15064822 - samples/sec: 63.30 - lr: 0.025000\n",
      "2020-10-22 09:09:29,299 epoch 51 - iter 219/736 - loss 0.14943631 - samples/sec: 58.31 - lr: 0.025000\n",
      "2020-10-22 09:09:47,003 epoch 51 - iter 292/736 - loss 0.14820135 - samples/sec: 66.32 - lr: 0.025000\n",
      "2020-10-22 09:10:05,442 epoch 51 - iter 365/736 - loss 0.15176123 - samples/sec: 64.58 - lr: 0.025000\n",
      "2020-10-22 09:10:24,999 epoch 51 - iter 438/736 - loss 0.14995318 - samples/sec: 61.73 - lr: 0.025000\n",
      "2020-10-22 09:10:42,923 epoch 51 - iter 511/736 - loss 0.15075668 - samples/sec: 66.49 - lr: 0.025000\n",
      "2020-10-22 09:11:02,230 epoch 51 - iter 584/736 - loss 0.15274386 - samples/sec: 61.52 - lr: 0.025000\n",
      "2020-10-22 09:11:20,090 epoch 51 - iter 657/736 - loss 0.15240930 - samples/sec: 65.65 - lr: 0.025000\n",
      "2020-10-22 09:11:38,831 epoch 51 - iter 730/736 - loss 0.15364690 - samples/sec: 63.49 - lr: 0.025000\n",
      "2020-10-22 09:11:40,403 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 09:11:40,403 EPOCH 51 done: loss 0.1537 - lr 0.0250000\n",
      "2020-10-22 09:12:40,730 DEV : loss 0.6113426089286804 - score 0.8333\n",
      "2020-10-22 09:12:42,636 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 09:12:42,637 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 09:13:00,041 epoch 52 - iter 73/736 - loss 0.17680645 - samples/sec: 67.90 - lr: 0.025000\n",
      "2020-10-22 09:13:18,324 epoch 52 - iter 146/736 - loss 0.16332303 - samples/sec: 65.19 - lr: 0.025000\n",
      "2020-10-22 09:13:36,520 epoch 52 - iter 219/736 - loss 0.15884432 - samples/sec: 65.53 - lr: 0.025000\n",
      "2020-10-22 09:13:54,978 epoch 52 - iter 292/736 - loss 0.15306701 - samples/sec: 64.57 - lr: 0.025000\n",
      "2020-10-22 09:14:14,715 epoch 52 - iter 365/736 - loss 0.15801342 - samples/sec: 60.31 - lr: 0.025000\n",
      "2020-10-22 09:14:33,623 epoch 52 - iter 438/736 - loss 0.15784039 - samples/sec: 62.02 - lr: 0.025000\n",
      "2020-10-22 09:14:52,757 epoch 52 - iter 511/736 - loss 0.15775715 - samples/sec: 63.14 - lr: 0.025000\n",
      "2020-10-22 09:15:11,152 epoch 52 - iter 584/736 - loss 0.15916416 - samples/sec: 64.68 - lr: 0.025000\n",
      "2020-10-22 09:15:30,299 epoch 52 - iter 657/736 - loss 0.15905986 - samples/sec: 62.14 - lr: 0.025000\n",
      "2020-10-22 09:15:49,707 epoch 52 - iter 730/736 - loss 0.16139613 - samples/sec: 61.29 - lr: 0.025000\n",
      "2020-10-22 09:15:51,117 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 09:15:51,118 EPOCH 52 done: loss 0.1634 - lr 0.0250000\n",
      "2020-10-22 09:16:51,242 DEV : loss 0.5649566054344177 - score 0.8394\n",
      "2020-10-22 09:16:53,160 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 09:16:55,146 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 09:17:13,587 epoch 53 - iter 73/736 - loss 0.14547179 - samples/sec: 65.11 - lr: 0.025000\n",
      "2020-10-22 09:17:31,494 epoch 53 - iter 146/736 - loss 0.13624411 - samples/sec: 66.59 - lr: 0.025000\n",
      "2020-10-22 09:17:50,377 epoch 53 - iter 219/736 - loss 0.14038025 - samples/sec: 63.08 - lr: 0.025000\n",
      "2020-10-22 09:18:09,535 epoch 53 - iter 292/736 - loss 0.13600862 - samples/sec: 62.13 - lr: 0.025000\n",
      "2020-10-22 09:18:27,247 epoch 53 - iter 365/736 - loss 0.13874686 - samples/sec: 67.37 - lr: 0.025000\n",
      "2020-10-22 09:18:48,303 epoch 53 - iter 438/736 - loss 0.14228551 - samples/sec: 55.69 - lr: 0.025000\n",
      "2020-10-22 09:19:07,016 epoch 53 - iter 511/736 - loss 0.14418736 - samples/sec: 63.57 - lr: 0.025000\n",
      "2020-10-22 09:19:25,484 epoch 53 - iter 584/736 - loss 0.14561991 - samples/sec: 65.43 - lr: 0.025000\n",
      "2020-10-22 09:19:44,119 epoch 53 - iter 657/736 - loss 0.14541491 - samples/sec: 63.95 - lr: 0.025000\n",
      "2020-10-22 09:20:02,842 epoch 53 - iter 730/736 - loss 0.14722212 - samples/sec: 63.55 - lr: 0.025000\n",
      "2020-10-22 09:20:04,028 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 09:20:04,028 EPOCH 53 done: loss 0.1478 - lr 0.0250000\n",
      "2020-10-22 09:21:04,528 DEV : loss 0.5942766666412354 - score 0.8338\n",
      "2020-10-22 09:21:06,413 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 09:21:06,414 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 09:21:25,446 epoch 54 - iter 73/736 - loss 0.15229365 - samples/sec: 62.10 - lr: 0.025000\n",
      "2020-10-22 09:21:43,108 epoch 54 - iter 146/736 - loss 0.14007625 - samples/sec: 67.58 - lr: 0.025000\n",
      "2020-10-22 09:22:01,681 epoch 54 - iter 219/736 - loss 0.13772075 - samples/sec: 64.16 - lr: 0.025000\n",
      "2020-10-22 09:22:19,493 epoch 54 - iter 292/736 - loss 0.13583801 - samples/sec: 65.90 - lr: 0.025000\n",
      "2020-10-22 09:22:38,245 epoch 54 - iter 365/736 - loss 0.13609948 - samples/sec: 63.57 - lr: 0.025000\n",
      "2020-10-22 09:22:58,885 epoch 54 - iter 438/736 - loss 0.14191166 - samples/sec: 57.61 - lr: 0.025000\n",
      "2020-10-22 09:23:17,930 epoch 54 - iter 511/736 - loss 0.14000184 - samples/sec: 61.62 - lr: 0.025000\n",
      "2020-10-22 09:23:36,456 epoch 54 - iter 584/736 - loss 0.13995393 - samples/sec: 63.43 - lr: 0.025000\n",
      "2020-10-22 09:23:54,594 epoch 54 - iter 657/736 - loss 0.14181616 - samples/sec: 65.72 - lr: 0.025000\n",
      "2020-10-22 09:24:11,796 epoch 54 - iter 730/736 - loss 0.14235886 - samples/sec: 69.39 - lr: 0.025000\n",
      "2020-10-22 09:24:13,351 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 09:24:13,351 EPOCH 54 done: loss 0.1415 - lr 0.0250000\n",
      "2020-10-22 09:25:13,668 DEV : loss 0.6105837821960449 - score 0.8346\n",
      "2020-10-22 09:25:15,560 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 09:25:15,561 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 09:25:35,904 epoch 55 - iter 73/736 - loss 0.11707654 - samples/sec: 59.82 - lr: 0.025000\n",
      "2020-10-22 09:25:53,952 epoch 55 - iter 146/736 - loss 0.12633681 - samples/sec: 66.10 - lr: 0.025000\n",
      "2020-10-22 09:26:11,593 epoch 55 - iter 219/736 - loss 0.12979308 - samples/sec: 67.59 - lr: 0.025000\n",
      "2020-10-22 09:26:30,975 epoch 55 - iter 292/736 - loss 0.13224692 - samples/sec: 61.47 - lr: 0.025000\n",
      "2020-10-22 09:26:51,368 epoch 55 - iter 365/736 - loss 0.13732135 - samples/sec: 58.32 - lr: 0.025000\n",
      "2020-10-22 09:27:09,456 epoch 55 - iter 438/736 - loss 0.13512457 - samples/sec: 66.99 - lr: 0.025000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 09:27:28,578 epoch 55 - iter 511/736 - loss 0.13697929 - samples/sec: 62.25 - lr: 0.025000\n",
      "2020-10-22 09:27:47,605 epoch 55 - iter 584/736 - loss 0.13978442 - samples/sec: 62.58 - lr: 0.025000\n",
      "2020-10-22 09:28:04,620 epoch 55 - iter 657/736 - loss 0.13966030 - samples/sec: 70.13 - lr: 0.025000\n",
      "2020-10-22 09:28:22,806 epoch 55 - iter 730/736 - loss 0.13790800 - samples/sec: 65.56 - lr: 0.025000\n",
      "2020-10-22 09:28:24,364 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 09:28:24,365 EPOCH 55 done: loss 0.1377 - lr 0.0250000\n",
      "2020-10-22 09:29:24,806 DEV : loss 0.6079531908035278 - score 0.8338\n",
      "2020-10-22 09:29:26,695 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 09:29:26,696 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 09:29:44,872 epoch 56 - iter 73/736 - loss 0.12719105 - samples/sec: 65.00 - lr: 0.025000\n",
      "2020-10-22 09:30:02,223 epoch 56 - iter 146/736 - loss 0.12021164 - samples/sec: 67.65 - lr: 0.025000\n",
      "2020-10-22 09:30:20,122 epoch 56 - iter 219/736 - loss 0.12867423 - samples/sec: 67.67 - lr: 0.025000\n",
      "2020-10-22 09:30:40,606 epoch 56 - iter 292/736 - loss 0.12988988 - samples/sec: 58.07 - lr: 0.025000\n",
      "2020-10-22 09:30:59,494 epoch 56 - iter 365/736 - loss 0.13035294 - samples/sec: 63.05 - lr: 0.025000\n",
      "2020-10-22 09:31:17,971 epoch 56 - iter 438/736 - loss 0.13183683 - samples/sec: 64.48 - lr: 0.025000\n",
      "2020-10-22 09:31:37,901 epoch 56 - iter 511/736 - loss 0.13509304 - samples/sec: 58.90 - lr: 0.025000\n",
      "2020-10-22 09:31:56,534 epoch 56 - iter 584/736 - loss 0.13818397 - samples/sec: 64.87 - lr: 0.025000\n",
      "2020-10-22 09:32:14,779 epoch 56 - iter 657/736 - loss 0.14288135 - samples/sec: 65.32 - lr: 0.025000\n",
      "2020-10-22 09:32:34,916 epoch 56 - iter 730/736 - loss 0.14391702 - samples/sec: 59.02 - lr: 0.025000\n",
      "2020-10-22 09:32:35,989 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 09:32:35,990 EPOCH 56 done: loss 0.1440 - lr 0.0250000\n",
      "2020-10-22 09:33:36,634 DEV : loss 0.6070231199264526 - score 0.8284\n",
      "2020-10-22 09:33:38,593 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 09:33:38,593 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 09:33:57,580 epoch 57 - iter 73/736 - loss 0.14186580 - samples/sec: 63.21 - lr: 0.025000\n",
      "2020-10-22 09:34:17,170 epoch 57 - iter 146/736 - loss 0.13712894 - samples/sec: 60.73 - lr: 0.025000\n",
      "2020-10-22 09:34:35,654 epoch 57 - iter 219/736 - loss 0.13588507 - samples/sec: 65.43 - lr: 0.025000\n",
      "2020-10-22 09:34:55,246 epoch 57 - iter 292/736 - loss 0.13408757 - samples/sec: 60.75 - lr: 0.025000\n",
      "2020-10-22 09:35:13,815 epoch 57 - iter 365/736 - loss 0.13617505 - samples/sec: 63.17 - lr: 0.025000\n",
      "2020-10-22 09:35:32,976 epoch 57 - iter 438/736 - loss 0.13414576 - samples/sec: 61.29 - lr: 0.025000\n",
      "2020-10-22 09:35:50,864 epoch 57 - iter 511/736 - loss 0.13990143 - samples/sec: 66.66 - lr: 0.025000\n",
      "2020-10-22 09:36:08,635 epoch 57 - iter 584/736 - loss 0.13809091 - samples/sec: 67.12 - lr: 0.025000\n",
      "2020-10-22 09:36:27,518 epoch 57 - iter 657/736 - loss 0.13728335 - samples/sec: 63.08 - lr: 0.025000\n",
      "2020-10-22 09:36:45,413 epoch 57 - iter 730/736 - loss 0.13840852 - samples/sec: 66.60 - lr: 0.025000\n",
      "2020-10-22 09:36:46,845 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 09:36:46,846 EPOCH 57 done: loss 0.1397 - lr 0.0250000\n",
      "2020-10-22 09:37:47,450 DEV : loss 0.6183484196662903 - score 0.8394\n",
      "2020-10-22 09:37:49,343 BAD EPOCHS (no improvement): 5\n",
      "2020-10-22 09:37:49,344 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 09:38:08,791 epoch 58 - iter 73/736 - loss 0.13877647 - samples/sec: 60.67 - lr: 0.025000\n",
      "2020-10-22 09:38:27,687 epoch 58 - iter 146/736 - loss 0.13010950 - samples/sec: 62.97 - lr: 0.025000\n",
      "2020-10-22 09:38:46,504 epoch 58 - iter 219/736 - loss 0.13232406 - samples/sec: 63.25 - lr: 0.025000\n",
      "2020-10-22 09:39:05,039 epoch 58 - iter 292/736 - loss 0.13223349 - samples/sec: 63.26 - lr: 0.025000\n",
      "2020-10-22 09:39:23,097 epoch 58 - iter 365/736 - loss 0.12982034 - samples/sec: 65.91 - lr: 0.025000\n",
      "2020-10-22 09:39:41,774 epoch 58 - iter 438/736 - loss 0.13042581 - samples/sec: 63.76 - lr: 0.025000\n",
      "2020-10-22 09:39:59,283 epoch 58 - iter 511/736 - loss 0.13070072 - samples/sec: 68.14 - lr: 0.025000\n",
      "2020-10-22 09:40:18,222 epoch 58 - iter 584/736 - loss 0.13162476 - samples/sec: 62.93 - lr: 0.025000\n",
      "2020-10-22 09:40:36,716 epoch 58 - iter 657/736 - loss 0.13218349 - samples/sec: 64.46 - lr: 0.025000\n",
      "2020-10-22 09:40:55,615 epoch 58 - iter 730/736 - loss 0.13193505 - samples/sec: 63.00 - lr: 0.025000\n",
      "2020-10-22 09:40:56,811 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 09:40:56,812 EPOCH 58 done: loss 0.1314 - lr 0.0250000\n",
      "2020-10-22 09:41:57,505 DEV : loss 0.6073762774467468 - score 0.8335\n",
      "Epoch    58: reducing learning rate of group 0 to 1.2500e-02.\n",
      "2020-10-22 09:41:59,447 BAD EPOCHS (no improvement): 6\n",
      "2020-10-22 09:41:59,448 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 09:42:19,271 epoch 59 - iter 73/736 - loss 0.12175400 - samples/sec: 60.37 - lr: 0.012500\n",
      "2020-10-22 09:42:37,993 epoch 59 - iter 146/736 - loss 0.11354683 - samples/sec: 64.59 - lr: 0.012500\n",
      "2020-10-22 09:42:56,255 epoch 59 - iter 219/736 - loss 0.11388132 - samples/sec: 65.31 - lr: 0.012500\n",
      "2020-10-22 09:43:14,369 epoch 59 - iter 292/736 - loss 0.11180266 - samples/sec: 65.87 - lr: 0.012500\n",
      "2020-10-22 09:43:32,333 epoch 59 - iter 365/736 - loss 0.11741011 - samples/sec: 65.31 - lr: 0.012500\n",
      "2020-10-22 09:43:51,297 epoch 59 - iter 438/736 - loss 0.11859175 - samples/sec: 61.89 - lr: 0.012500\n",
      "2020-10-22 09:44:10,559 epoch 59 - iter 511/736 - loss 0.11786181 - samples/sec: 61.81 - lr: 0.012500\n",
      "2020-10-22 09:44:28,964 epoch 59 - iter 584/736 - loss 0.11953119 - samples/sec: 63.79 - lr: 0.012500\n",
      "2020-10-22 09:44:47,102 epoch 59 - iter 657/736 - loss 0.12210079 - samples/sec: 65.67 - lr: 0.012500\n",
      "2020-10-22 09:45:05,649 epoch 59 - iter 730/736 - loss 0.12384781 - samples/sec: 64.17 - lr: 0.012500\n",
      "2020-10-22 09:45:06,929 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 09:45:06,930 EPOCH 59 done: loss 0.1235 - lr 0.0125000\n",
      "2020-10-22 09:46:07,509 DEV : loss 0.6304786801338196 - score 0.8415\n",
      "2020-10-22 09:46:09,416 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 09:46:11,367 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 09:46:30,217 epoch 60 - iter 73/736 - loss 0.11646573 - samples/sec: 63.67 - lr: 0.012500\n",
      "2020-10-22 09:46:48,996 epoch 60 - iter 146/736 - loss 0.10389183 - samples/sec: 63.41 - lr: 0.012500\n",
      "2020-10-22 09:47:07,799 epoch 60 - iter 219/736 - loss 0.10961841 - samples/sec: 63.27 - lr: 0.012500\n",
      "2020-10-22 09:47:25,928 epoch 60 - iter 292/736 - loss 0.10889249 - samples/sec: 65.69 - lr: 0.012500\n",
      "2020-10-22 09:47:43,473 epoch 60 - iter 365/736 - loss 0.10750548 - samples/sec: 67.93 - lr: 0.012500\n",
      "2020-10-22 09:48:03,291 epoch 60 - iter 438/736 - loss 0.11116743 - samples/sec: 59.25 - lr: 0.012500\n",
      "2020-10-22 09:48:22,042 epoch 60 - iter 511/736 - loss 0.11287509 - samples/sec: 63.52 - lr: 0.012500\n",
      "2020-10-22 09:48:40,846 epoch 60 - iter 584/736 - loss 0.11321979 - samples/sec: 62.43 - lr: 0.012500\n",
      "2020-10-22 09:48:59,394 epoch 60 - iter 657/736 - loss 0.11254331 - samples/sec: 64.19 - lr: 0.012500\n",
      "2020-10-22 09:49:18,813 epoch 60 - iter 730/736 - loss 0.11608780 - samples/sec: 61.30 - lr: 0.012500\n",
      "2020-10-22 09:49:20,170 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 09:49:20,171 EPOCH 60 done: loss 0.1163 - lr 0.0125000\n",
      "2020-10-22 09:50:20,770 DEV : loss 0.6157329082489014 - score 0.8394\n",
      "2020-10-22 09:50:22,686 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 09:50:22,686 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 09:50:42,944 epoch 61 - iter 73/736 - loss 0.11022888 - samples/sec: 59.16 - lr: 0.012500\n",
      "2020-10-22 09:51:01,108 epoch 61 - iter 146/736 - loss 0.10588165 - samples/sec: 65.60 - lr: 0.012500\n",
      "2020-10-22 09:51:18,552 epoch 61 - iter 219/736 - loss 0.10752810 - samples/sec: 67.29 - lr: 0.012500\n",
      "2020-10-22 09:51:37,543 epoch 61 - iter 292/736 - loss 0.11056165 - samples/sec: 62.65 - lr: 0.012500\n",
      "2020-10-22 09:51:55,059 epoch 61 - iter 365/736 - loss 0.10871672 - samples/sec: 68.06 - lr: 0.012500\n",
      "2020-10-22 09:52:12,391 epoch 61 - iter 438/736 - loss 0.10873290 - samples/sec: 67.69 - lr: 0.012500\n",
      "2020-10-22 09:52:31,414 epoch 61 - iter 511/736 - loss 0.11124307 - samples/sec: 63.48 - lr: 0.012500\n",
      "2020-10-22 09:52:49,675 epoch 61 - iter 584/736 - loss 0.11331592 - samples/sec: 65.29 - lr: 0.012500\n",
      "2020-10-22 09:53:08,936 epoch 61 - iter 657/736 - loss 0.11296281 - samples/sec: 61.79 - lr: 0.012500\n",
      "2020-10-22 09:53:28,553 epoch 61 - iter 730/736 - loss 0.11261002 - samples/sec: 60.65 - lr: 0.012500\n",
      "2020-10-22 09:53:29,854 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 09:53:29,854 EPOCH 61 done: loss 0.1123 - lr 0.0125000\n",
      "2020-10-22 09:54:30,422 DEV : loss 0.6354625225067139 - score 0.8402\n",
      "2020-10-22 09:54:32,346 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 09:54:32,347 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 09:54:50,812 epoch 62 - iter 73/736 - loss 0.13331525 - samples/sec: 65.02 - lr: 0.012500\n",
      "2020-10-22 09:55:08,455 epoch 62 - iter 146/736 - loss 0.12730256 - samples/sec: 66.51 - lr: 0.012500\n",
      "2020-10-22 09:55:27,378 epoch 62 - iter 219/736 - loss 0.11979983 - samples/sec: 62.01 - lr: 0.012500\n",
      "2020-10-22 09:55:46,607 epoch 62 - iter 292/736 - loss 0.12209907 - samples/sec: 61.89 - lr: 0.012500\n",
      "2020-10-22 09:56:06,110 epoch 62 - iter 365/736 - loss 0.11624475 - samples/sec: 61.88 - lr: 0.012500\n",
      "2020-10-22 09:56:24,758 epoch 62 - iter 438/736 - loss 0.11178243 - samples/sec: 63.84 - lr: 0.012500\n",
      "2020-10-22 09:56:42,623 epoch 62 - iter 511/736 - loss 0.11319046 - samples/sec: 66.70 - lr: 0.012500\n",
      "2020-10-22 09:57:00,953 epoch 62 - iter 584/736 - loss 0.11483561 - samples/sec: 64.91 - lr: 0.012500\n",
      "2020-10-22 09:57:19,862 epoch 62 - iter 657/736 - loss 0.11535796 - samples/sec: 62.99 - lr: 0.012500\n",
      "2020-10-22 09:57:38,305 epoch 62 - iter 730/736 - loss 0.11560918 - samples/sec: 64.61 - lr: 0.012500\n",
      "2020-10-22 09:57:39,728 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 09:57:39,729 EPOCH 62 done: loss 0.1153 - lr 0.0125000\n",
      "2020-10-22 09:58:39,876 DEV : loss 0.6503371596336365 - score 0.8394\n",
      "2020-10-22 09:58:41,760 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 09:58:41,761 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 09:59:01,690 epoch 63 - iter 73/736 - loss 0.11659120 - samples/sec: 60.14 - lr: 0.012500\n",
      "2020-10-22 09:59:20,769 epoch 63 - iter 146/736 - loss 0.11007789 - samples/sec: 63.39 - lr: 0.012500\n",
      "2020-10-22 09:59:38,034 epoch 63 - iter 219/736 - loss 0.11370764 - samples/sec: 69.09 - lr: 0.012500\n",
      "2020-10-22 09:59:58,488 epoch 63 - iter 292/736 - loss 0.11288428 - samples/sec: 58.14 - lr: 0.012500\n",
      "2020-10-22 10:00:16,868 epoch 63 - iter 365/736 - loss 0.11153976 - samples/sec: 64.82 - lr: 0.012500\n",
      "2020-10-22 10:00:35,085 epoch 63 - iter 438/736 - loss 0.11219082 - samples/sec: 65.41 - lr: 0.012500\n",
      "2020-10-22 10:00:52,702 epoch 63 - iter 511/736 - loss 0.11328316 - samples/sec: 68.74 - lr: 0.012500\n",
      "2020-10-22 10:01:11,761 epoch 63 - iter 584/736 - loss 0.11156894 - samples/sec: 61.58 - lr: 0.012500\n",
      "2020-10-22 10:01:29,877 epoch 63 - iter 657/736 - loss 0.11079875 - samples/sec: 65.80 - lr: 0.012500\n",
      "2020-10-22 10:01:48,278 epoch 63 - iter 730/736 - loss 0.11014894 - samples/sec: 64.77 - lr: 0.012500\n",
      "2020-10-22 10:01:49,424 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 10:01:49,425 EPOCH 63 done: loss 0.1104 - lr 0.0125000\n",
      "2020-10-22 10:02:49,875 DEV : loss 0.6459441184997559 - score 0.8399\n",
      "2020-10-22 10:02:51,785 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 10:02:51,785 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 10:03:11,188 epoch 64 - iter 73/736 - loss 0.10188461 - samples/sec: 60.84 - lr: 0.012500\n",
      "2020-10-22 10:03:32,109 epoch 64 - iter 146/736 - loss 0.10677213 - samples/sec: 56.78 - lr: 0.012500\n",
      "2020-10-22 10:03:49,473 epoch 64 - iter 219/736 - loss 0.10183577 - samples/sec: 68.60 - lr: 0.012500\n",
      "2020-10-22 10:04:07,821 epoch 64 - iter 292/736 - loss 0.10145709 - samples/sec: 63.91 - lr: 0.012500\n",
      "2020-10-22 10:04:24,773 epoch 64 - iter 365/736 - loss 0.10665971 - samples/sec: 70.33 - lr: 0.012500\n",
      "2020-10-22 10:04:44,397 epoch 64 - iter 438/736 - loss 0.10558484 - samples/sec: 61.50 - lr: 0.012500\n",
      "2020-10-22 10:05:02,760 epoch 64 - iter 511/736 - loss 0.10485196 - samples/sec: 64.89 - lr: 0.012500\n",
      "2020-10-22 10:05:22,690 epoch 64 - iter 584/736 - loss 0.10395188 - samples/sec: 59.66 - lr: 0.012500\n",
      "2020-10-22 10:05:40,971 epoch 64 - iter 657/736 - loss 0.10443599 - samples/sec: 66.21 - lr: 0.012500\n",
      "2020-10-22 10:05:59,370 epoch 64 - iter 730/736 - loss 0.10551813 - samples/sec: 64.78 - lr: 0.012500\n",
      "2020-10-22 10:06:00,484 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 10:06:00,485 EPOCH 64 done: loss 0.1053 - lr 0.0125000\n",
      "2020-10-22 10:07:00,724 DEV : loss 0.6526696085929871 - score 0.843\n",
      "2020-10-22 10:07:02,892 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 10:07:04,850 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 10:07:23,901 epoch 65 - iter 73/736 - loss 0.11296472 - samples/sec: 62.92 - lr: 0.012500\n",
      "2020-10-22 10:07:42,637 epoch 65 - iter 146/736 - loss 0.11600161 - samples/sec: 62.66 - lr: 0.012500\n",
      "2020-10-22 10:08:00,387 epoch 65 - iter 219/736 - loss 0.11102108 - samples/sec: 66.15 - lr: 0.012500\n",
      "2020-10-22 10:08:18,477 epoch 65 - iter 292/736 - loss 0.10636998 - samples/sec: 66.89 - lr: 0.012500\n",
      "2020-10-22 10:08:37,136 epoch 65 - iter 365/736 - loss 0.10330710 - samples/sec: 63.80 - lr: 0.012500\n",
      "2020-10-22 10:08:56,267 epoch 65 - iter 438/736 - loss 0.10292808 - samples/sec: 62.28 - lr: 0.012500\n",
      "2020-10-22 10:09:16,139 epoch 65 - iter 511/736 - loss 0.10450740 - samples/sec: 59.91 - lr: 0.012500\n",
      "2020-10-22 10:09:33,704 epoch 65 - iter 584/736 - loss 0.10868836 - samples/sec: 67.92 - lr: 0.012500\n",
      "2020-10-22 10:09:52,359 epoch 65 - iter 657/736 - loss 0.10956737 - samples/sec: 64.75 - lr: 0.012500\n",
      "2020-10-22 10:10:10,308 epoch 65 - iter 730/736 - loss 0.10936032 - samples/sec: 65.41 - lr: 0.012500\n",
      "2020-10-22 10:10:11,500 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 10:10:11,500 EPOCH 65 done: loss 0.1091 - lr 0.0125000\n",
      "2020-10-22 10:11:13,064 DEV : loss 0.652846097946167 - score 0.8425\n",
      "2020-10-22 10:11:14,970 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 10:11:14,971 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 10:11:33,306 epoch 66 - iter 73/736 - loss 0.13639470 - samples/sec: 64.39 - lr: 0.012500\n",
      "2020-10-22 10:11:52,922 epoch 66 - iter 146/736 - loss 0.12419213 - samples/sec: 61.55 - lr: 0.012500\n",
      "2020-10-22 10:12:11,649 epoch 66 - iter 219/736 - loss 0.12113325 - samples/sec: 63.61 - lr: 0.012500\n",
      "2020-10-22 10:12:31,027 epoch 66 - iter 292/736 - loss 0.11708480 - samples/sec: 61.40 - lr: 0.012500\n",
      "2020-10-22 10:12:49,773 epoch 66 - iter 365/736 - loss 0.11206747 - samples/sec: 64.50 - lr: 0.012500\n",
      "2020-10-22 10:13:08,345 epoch 66 - iter 438/736 - loss 0.10789214 - samples/sec: 63.17 - lr: 0.012500\n",
      "2020-10-22 10:13:27,938 epoch 66 - iter 511/736 - loss 0.10882766 - samples/sec: 60.77 - lr: 0.012500\n",
      "2020-10-22 10:13:46,060 epoch 66 - iter 584/736 - loss 0.10972157 - samples/sec: 65.77 - lr: 0.012500\n",
      "2020-10-22 10:14:03,799 epoch 66 - iter 657/736 - loss 0.10663823 - samples/sec: 67.15 - lr: 0.012500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 10:14:23,112 epoch 66 - iter 730/736 - loss 0.10744322 - samples/sec: 61.62 - lr: 0.012500\n",
      "2020-10-22 10:14:24,379 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 10:14:24,379 EPOCH 66 done: loss 0.1072 - lr 0.0125000\n",
      "2020-10-22 10:15:25,448 DEV : loss 0.6417397260665894 - score 0.8399\n",
      "2020-10-22 10:15:27,338 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 10:15:27,338 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 10:16:06,362 epoch 67 - iter 73/736 - loss 0.09482648 - samples/sec: 30.08 - lr: 0.012500\n",
      "2020-10-22 10:16:49,911 epoch 67 - iter 146/736 - loss 0.09827320 - samples/sec: 27.22 - lr: 0.012500\n",
      "2020-10-22 10:17:30,983 epoch 67 - iter 219/736 - loss 0.10084235 - samples/sec: 28.49 - lr: 0.012500\n",
      "2020-10-22 10:18:10,353 epoch 67 - iter 292/736 - loss 0.10215528 - samples/sec: 29.95 - lr: 0.012500\n",
      "2020-10-22 10:18:51,695 epoch 67 - iter 365/736 - loss 0.10794643 - samples/sec: 28.70 - lr: 0.012500\n",
      "2020-10-22 10:19:34,483 epoch 67 - iter 438/736 - loss 0.10466950 - samples/sec: 27.53 - lr: 0.012500\n",
      "2020-10-22 10:20:15,508 epoch 67 - iter 511/736 - loss 0.10399217 - samples/sec: 28.73 - lr: 0.012500\n",
      "2020-10-22 10:20:54,708 epoch 67 - iter 584/736 - loss 0.10273303 - samples/sec: 30.09 - lr: 0.012500\n",
      "2020-10-22 10:21:38,391 epoch 67 - iter 657/736 - loss 0.10465441 - samples/sec: 27.15 - lr: 0.012500\n",
      "2020-10-22 10:22:19,009 epoch 67 - iter 730/736 - loss 0.10402947 - samples/sec: 28.81 - lr: 0.012500\n",
      "2020-10-22 10:22:22,241 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 10:22:22,242 EPOCH 67 done: loss 0.1038 - lr 0.0125000\n",
      "2020-10-22 10:24:44,693 DEV : loss 0.6486195921897888 - score 0.8374\n",
      "2020-10-22 10:24:46,898 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 10:24:46,899 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 10:25:26,860 epoch 68 - iter 73/736 - loss 0.09131547 - samples/sec: 29.59 - lr: 0.012500\n",
      "2020-10-22 10:26:10,060 epoch 68 - iter 146/736 - loss 0.10754922 - samples/sec: 27.26 - lr: 0.012500\n",
      "2020-10-22 10:26:52,573 epoch 68 - iter 219/736 - loss 0.10458712 - samples/sec: 27.72 - lr: 0.012500\n",
      "2020-10-22 10:27:33,214 epoch 68 - iter 292/736 - loss 0.09841447 - samples/sec: 29.01 - lr: 0.012500\n",
      "2020-10-22 10:28:13,495 epoch 68 - iter 365/736 - loss 0.10012173 - samples/sec: 29.26 - lr: 0.012500\n",
      "2020-10-22 10:28:57,649 epoch 68 - iter 438/736 - loss 0.10126668 - samples/sec: 26.50 - lr: 0.012500\n",
      "2020-10-22 10:29:41,303 epoch 68 - iter 511/736 - loss 0.10000709 - samples/sec: 26.97 - lr: 0.012500\n",
      "2020-10-22 10:30:22,984 epoch 68 - iter 584/736 - loss 0.09841430 - samples/sec: 28.28 - lr: 0.012500\n",
      "2020-10-22 10:31:02,589 epoch 68 - iter 657/736 - loss 0.09847699 - samples/sec: 29.55 - lr: 0.012500\n",
      "2020-10-22 10:31:45,928 epoch 68 - iter 730/736 - loss 0.09776503 - samples/sec: 27.17 - lr: 0.012500\n",
      "2020-10-22 10:31:49,528 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 10:31:49,529 EPOCH 68 done: loss 0.0978 - lr 0.0125000\n",
      "2020-10-22 10:34:13,147 DEV : loss 0.6617417931556702 - score 0.844\n",
      "2020-10-22 10:34:15,081 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 10:34:17,068 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 10:34:55,628 epoch 69 - iter 73/736 - loss 0.08679316 - samples/sec: 30.68 - lr: 0.012500\n",
      "2020-10-22 10:35:15,182 epoch 69 - iter 146/736 - loss 0.09111618 - samples/sec: 59.99 - lr: 0.012500\n",
      "2020-10-22 10:35:34,792 epoch 69 - iter 219/736 - loss 0.09576067 - samples/sec: 60.62 - lr: 0.012500\n",
      "2020-10-22 10:35:53,402 epoch 69 - iter 292/736 - loss 0.09680170 - samples/sec: 63.97 - lr: 0.012500\n",
      "2020-10-22 10:36:13,018 epoch 69 - iter 365/736 - loss 0.09551137 - samples/sec: 60.62 - lr: 0.012500\n",
      "2020-10-22 10:36:32,926 epoch 69 - iter 438/736 - loss 0.09685058 - samples/sec: 58.89 - lr: 0.012500\n",
      "2020-10-22 10:36:51,937 epoch 69 - iter 511/736 - loss 0.10080418 - samples/sec: 61.69 - lr: 0.012500\n",
      "2020-10-22 10:37:10,956 epoch 69 - iter 584/736 - loss 0.10011850 - samples/sec: 61.64 - lr: 0.012500\n",
      "2020-10-22 10:37:29,758 epoch 69 - iter 657/736 - loss 0.10048894 - samples/sec: 62.42 - lr: 0.012500\n",
      "2020-10-22 10:37:48,298 epoch 69 - iter 730/736 - loss 0.09959228 - samples/sec: 63.30 - lr: 0.012500\n",
      "2020-10-22 10:37:49,830 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 10:37:49,831 EPOCH 69 done: loss 0.0994 - lr 0.0125000\n",
      "2020-10-22 10:38:51,051 DEV : loss 0.6613734364509583 - score 0.8405\n",
      "2020-10-22 10:38:52,952 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 10:38:52,953 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 10:39:14,449 epoch 70 - iter 73/736 - loss 0.10655524 - samples/sec: 54.87 - lr: 0.012500\n",
      "2020-10-22 10:39:32,842 epoch 70 - iter 146/736 - loss 0.10009259 - samples/sec: 65.72 - lr: 0.012500\n",
      "2020-10-22 10:39:54,034 epoch 70 - iter 219/736 - loss 0.10301799 - samples/sec: 55.31 - lr: 0.012500\n",
      "2020-10-22 10:40:12,739 epoch 70 - iter 292/736 - loss 0.09812733 - samples/sec: 63.68 - lr: 0.012500\n",
      "2020-10-22 10:40:30,759 epoch 70 - iter 365/736 - loss 0.09689650 - samples/sec: 66.07 - lr: 0.012500\n",
      "2020-10-22 10:40:49,906 epoch 70 - iter 438/736 - loss 0.09734425 - samples/sec: 62.20 - lr: 0.012500\n",
      "2020-10-22 10:41:07,616 epoch 70 - iter 511/736 - loss 0.09500847 - samples/sec: 66.21 - lr: 0.012500\n",
      "2020-10-22 10:41:26,221 epoch 70 - iter 584/736 - loss 0.09358161 - samples/sec: 64.03 - lr: 0.012500\n",
      "2020-10-22 10:41:44,716 epoch 70 - iter 657/736 - loss 0.09389650 - samples/sec: 63.50 - lr: 0.012500\n",
      "2020-10-22 10:42:02,345 epoch 70 - iter 730/736 - loss 0.09405392 - samples/sec: 66.59 - lr: 0.012500\n",
      "2020-10-22 10:42:04,097 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 10:42:04,098 EPOCH 70 done: loss 0.0938 - lr 0.0125000\n",
      "2020-10-22 10:43:06,010 DEV : loss 0.6841060519218445 - score 0.842\n",
      "2020-10-22 10:43:07,936 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 10:43:07,937 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 10:43:26,072 epoch 71 - iter 73/736 - loss 0.10772812 - samples/sec: 66.18 - lr: 0.012500\n",
      "2020-10-22 10:43:44,289 epoch 71 - iter 146/736 - loss 0.10079676 - samples/sec: 65.46 - lr: 0.012500\n",
      "2020-10-22 10:44:05,208 epoch 71 - iter 219/736 - loss 0.10296750 - samples/sec: 56.05 - lr: 0.012500\n",
      "2020-10-22 10:44:23,846 epoch 71 - iter 292/736 - loss 0.09962485 - samples/sec: 63.98 - lr: 0.012500\n",
      "2020-10-22 10:44:42,687 epoch 71 - iter 365/736 - loss 0.09961942 - samples/sec: 63.19 - lr: 0.012500\n",
      "2020-10-22 10:45:01,390 epoch 71 - iter 438/736 - loss 0.10185181 - samples/sec: 63.62 - lr: 0.012500\n",
      "2020-10-22 10:45:19,750 epoch 71 - iter 511/736 - loss 0.10178390 - samples/sec: 64.81 - lr: 0.012500\n",
      "2020-10-22 10:45:38,796 epoch 71 - iter 584/736 - loss 0.10413773 - samples/sec: 61.57 - lr: 0.012500\n",
      "2020-10-22 10:45:58,654 epoch 71 - iter 657/736 - loss 0.10208563 - samples/sec: 59.07 - lr: 0.012500\n",
      "2020-10-22 10:46:17,436 epoch 71 - iter 730/736 - loss 0.10128110 - samples/sec: 63.46 - lr: 0.012500\n",
      "2020-10-22 10:46:18,738 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 10:46:18,738 EPOCH 71 done: loss 0.1017 - lr 0.0125000\n",
      "2020-10-22 10:47:20,619 DEV : loss 0.687505841255188 - score 0.8387\n",
      "2020-10-22 10:47:22,547 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 10:47:22,548 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 10:47:41,949 epoch 72 - iter 73/736 - loss 0.09792910 - samples/sec: 61.80 - lr: 0.012500\n",
      "2020-10-22 10:48:01,476 epoch 72 - iter 146/736 - loss 0.09283593 - samples/sec: 60.99 - lr: 0.012500\n",
      "2020-10-22 10:48:20,177 epoch 72 - iter 219/736 - loss 0.08941363 - samples/sec: 63.62 - lr: 0.012500\n",
      "2020-10-22 10:48:39,949 epoch 72 - iter 292/736 - loss 0.08610124 - samples/sec: 59.30 - lr: 0.012500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 10:48:59,261 epoch 72 - iter 365/736 - loss 0.08501685 - samples/sec: 60.70 - lr: 0.012500\n",
      "2020-10-22 10:49:17,211 epoch 72 - iter 438/736 - loss 0.09218320 - samples/sec: 66.40 - lr: 0.012500\n",
      "2020-10-22 10:49:36,267 epoch 72 - iter 511/736 - loss 0.09539300 - samples/sec: 61.60 - lr: 0.012500\n",
      "2020-10-22 10:49:55,087 epoch 72 - iter 584/736 - loss 0.09630505 - samples/sec: 63.29 - lr: 0.012500\n",
      "2020-10-22 10:50:14,005 epoch 72 - iter 657/736 - loss 0.09732311 - samples/sec: 62.94 - lr: 0.012500\n",
      "2020-10-22 10:50:32,165 epoch 72 - iter 730/736 - loss 0.09625988 - samples/sec: 66.61 - lr: 0.012500\n",
      "2020-10-22 10:50:33,639 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 10:50:33,640 EPOCH 72 done: loss 0.0965 - lr 0.0125000\n",
      "2020-10-22 10:51:35,938 DEV : loss 0.6853747963905334 - score 0.8394\n",
      "2020-10-22 10:51:37,882 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 10:51:37,883 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 10:51:56,942 epoch 73 - iter 73/736 - loss 0.11307690 - samples/sec: 63.00 - lr: 0.012500\n",
      "2020-10-22 10:52:14,388 epoch 73 - iter 146/736 - loss 0.10444605 - samples/sec: 68.48 - lr: 0.012500\n",
      "2020-10-22 10:52:34,907 epoch 73 - iter 219/736 - loss 0.10023906 - samples/sec: 58.73 - lr: 0.012500\n",
      "2020-10-22 10:52:53,783 epoch 73 - iter 292/736 - loss 0.09496281 - samples/sec: 62.12 - lr: 0.012500\n",
      "2020-10-22 10:53:12,637 epoch 73 - iter 365/736 - loss 0.09543919 - samples/sec: 63.13 - lr: 0.012500\n",
      "2020-10-22 10:53:31,759 epoch 73 - iter 438/736 - loss 0.09758436 - samples/sec: 62.28 - lr: 0.012500\n",
      "2020-10-22 10:53:51,492 epoch 73 - iter 511/736 - loss 0.09452803 - samples/sec: 60.34 - lr: 0.012500\n",
      "2020-10-22 10:54:10,771 epoch 73 - iter 584/736 - loss 0.09408022 - samples/sec: 61.81 - lr: 0.012500\n",
      "2020-10-22 10:54:29,617 epoch 73 - iter 657/736 - loss 0.09319474 - samples/sec: 63.21 - lr: 0.012500\n",
      "2020-10-22 10:54:48,510 epoch 73 - iter 730/736 - loss 0.09418694 - samples/sec: 63.01 - lr: 0.012500\n",
      "2020-10-22 10:54:50,251 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 10:54:50,251 EPOCH 73 done: loss 0.0935 - lr 0.0125000\n",
      "2020-10-22 10:55:52,304 DEV : loss 0.6866753101348877 - score 0.842\n",
      "2020-10-22 10:55:54,272 BAD EPOCHS (no improvement): 5\n",
      "2020-10-22 10:55:54,273 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 10:56:12,812 epoch 74 - iter 73/736 - loss 0.08261474 - samples/sec: 64.88 - lr: 0.012500\n",
      "2020-10-22 10:56:31,834 epoch 74 - iter 146/736 - loss 0.07358209 - samples/sec: 61.74 - lr: 0.012500\n",
      "2020-10-22 10:56:50,835 epoch 74 - iter 219/736 - loss 0.07684623 - samples/sec: 62.62 - lr: 0.012500\n",
      "2020-10-22 10:57:10,025 epoch 74 - iter 292/736 - loss 0.08164098 - samples/sec: 61.99 - lr: 0.012500\n",
      "2020-10-22 10:57:30,948 epoch 74 - iter 365/736 - loss 0.08244201 - samples/sec: 56.02 - lr: 0.012500\n",
      "2020-10-22 10:57:50,161 epoch 74 - iter 438/736 - loss 0.08547664 - samples/sec: 61.89 - lr: 0.012500\n",
      "2020-10-22 10:58:09,265 epoch 74 - iter 511/736 - loss 0.08716828 - samples/sec: 63.29 - lr: 0.012500\n",
      "2020-10-22 10:58:27,067 epoch 74 - iter 584/736 - loss 0.09104164 - samples/sec: 66.97 - lr: 0.012500\n",
      "2020-10-22 10:58:45,761 epoch 74 - iter 657/736 - loss 0.09079691 - samples/sec: 63.67 - lr: 0.012500\n",
      "2020-10-22 10:59:03,396 epoch 74 - iter 730/736 - loss 0.08921348 - samples/sec: 67.60 - lr: 0.012500\n",
      "2020-10-22 10:59:04,716 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 10:59:04,716 EPOCH 74 done: loss 0.0891 - lr 0.0125000\n",
      "2020-10-22 11:00:05,853 DEV : loss 0.6824848651885986 - score 0.8381\n",
      "Epoch    74: reducing learning rate of group 0 to 6.2500e-03.\n",
      "2020-10-22 11:00:07,754 BAD EPOCHS (no improvement): 6\n",
      "2020-10-22 11:00:07,755 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 11:00:26,382 epoch 75 - iter 73/736 - loss 0.08960199 - samples/sec: 65.48 - lr: 0.006250\n",
      "2020-10-22 11:00:44,796 epoch 75 - iter 146/736 - loss 0.08247713 - samples/sec: 64.74 - lr: 0.006250\n",
      "2020-10-22 11:01:03,488 epoch 75 - iter 219/736 - loss 0.08820834 - samples/sec: 63.74 - lr: 0.006250\n",
      "2020-10-22 11:01:21,962 epoch 75 - iter 292/736 - loss 0.09352122 - samples/sec: 64.54 - lr: 0.006250\n",
      "2020-10-22 11:01:40,486 epoch 75 - iter 365/736 - loss 0.09318662 - samples/sec: 64.23 - lr: 0.006250\n",
      "2020-10-22 11:01:59,477 epoch 75 - iter 438/736 - loss 0.09049759 - samples/sec: 63.61 - lr: 0.006250\n",
      "2020-10-22 11:02:17,537 epoch 75 - iter 511/736 - loss 0.08970597 - samples/sec: 65.97 - lr: 0.006250\n",
      "2020-10-22 11:02:37,102 epoch 75 - iter 584/736 - loss 0.09234822 - samples/sec: 60.84 - lr: 0.006250\n",
      "2020-10-22 11:02:55,524 epoch 75 - iter 657/736 - loss 0.09115556 - samples/sec: 63.66 - lr: 0.006250\n",
      "2020-10-22 11:03:15,355 epoch 75 - iter 730/736 - loss 0.08983901 - samples/sec: 59.14 - lr: 0.006250\n",
      "2020-10-22 11:03:17,403 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 11:03:17,403 EPOCH 75 done: loss 0.0899 - lr 0.0062500\n",
      "2020-10-22 11:04:18,935 DEV : loss 0.6816048622131348 - score 0.8422\n",
      "2020-10-22 11:04:20,922 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 11:04:20,923 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 11:04:40,674 epoch 76 - iter 73/736 - loss 0.07840266 - samples/sec: 61.58 - lr: 0.006250\n",
      "2020-10-22 11:04:58,677 epoch 76 - iter 146/736 - loss 0.07440355 - samples/sec: 66.15 - lr: 0.006250\n",
      "2020-10-22 11:05:17,436 epoch 76 - iter 219/736 - loss 0.07969116 - samples/sec: 63.44 - lr: 0.006250\n",
      "2020-10-22 11:05:35,129 epoch 76 - iter 292/736 - loss 0.08202956 - samples/sec: 67.37 - lr: 0.006250\n",
      "2020-10-22 11:05:54,569 epoch 76 - iter 365/736 - loss 0.08330457 - samples/sec: 62.12 - lr: 0.006250\n",
      "2020-10-22 11:06:14,849 epoch 76 - iter 438/736 - loss 0.08615276 - samples/sec: 58.61 - lr: 0.006250\n",
      "2020-10-22 11:06:34,412 epoch 76 - iter 511/736 - loss 0.08737042 - samples/sec: 61.71 - lr: 0.006250\n",
      "2020-10-22 11:06:52,877 epoch 76 - iter 584/736 - loss 0.08789952 - samples/sec: 64.51 - lr: 0.006250\n",
      "2020-10-22 11:07:12,118 epoch 76 - iter 657/736 - loss 0.08736711 - samples/sec: 61.12 - lr: 0.006250\n",
      "2020-10-22 11:07:30,178 epoch 76 - iter 730/736 - loss 0.08976351 - samples/sec: 66.06 - lr: 0.006250\n",
      "2020-10-22 11:07:31,569 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 11:07:31,570 EPOCH 76 done: loss 0.0902 - lr 0.0062500\n",
      "2020-10-22 11:08:32,631 DEV : loss 0.694217324256897 - score 0.842\n",
      "2020-10-22 11:08:34,831 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 11:08:34,832 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 11:08:53,886 epoch 77 - iter 73/736 - loss 0.09010523 - samples/sec: 62.04 - lr: 0.006250\n",
      "2020-10-22 11:09:12,256 epoch 77 - iter 146/736 - loss 0.08503249 - samples/sec: 64.82 - lr: 0.006250\n",
      "2020-10-22 11:09:33,638 epoch 77 - iter 219/736 - loss 0.08811854 - samples/sec: 55.58 - lr: 0.006250\n",
      "2020-10-22 11:09:51,742 epoch 77 - iter 292/736 - loss 0.08573647 - samples/sec: 65.84 - lr: 0.006250\n",
      "2020-10-22 11:10:09,210 epoch 77 - iter 365/736 - loss 0.08561945 - samples/sec: 67.24 - lr: 0.006250\n",
      "2020-10-22 11:10:27,249 epoch 77 - iter 438/736 - loss 0.08241861 - samples/sec: 66.18 - lr: 0.006250\n",
      "2020-10-22 11:10:49,188 epoch 77 - iter 511/736 - loss 0.08432621 - samples/sec: 54.86 - lr: 0.006250\n",
      "2020-10-22 11:11:06,983 epoch 77 - iter 584/736 - loss 0.08480537 - samples/sec: 67.01 - lr: 0.006250\n",
      "2020-10-22 11:11:26,430 epoch 77 - iter 657/736 - loss 0.08316109 - samples/sec: 61.24 - lr: 0.006250\n",
      "2020-10-22 11:11:44,431 epoch 77 - iter 730/736 - loss 0.08403015 - samples/sec: 65.26 - lr: 0.006250\n",
      "2020-10-22 11:11:45,792 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 11:11:45,793 EPOCH 77 done: loss 0.0839 - lr 0.0062500\n",
      "2020-10-22 11:12:48,564 DEV : loss 0.6827808022499084 - score 0.8407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 11:12:50,670 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 11:12:50,671 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 11:13:10,431 epoch 78 - iter 73/736 - loss 0.06465170 - samples/sec: 59.77 - lr: 0.006250\n",
      "2020-10-22 11:13:29,470 epoch 78 - iter 146/736 - loss 0.08229151 - samples/sec: 61.62 - lr: 0.006250\n",
      "2020-10-22 11:13:49,259 epoch 78 - iter 219/736 - loss 0.08804072 - samples/sec: 60.15 - lr: 0.006250\n",
      "2020-10-22 11:14:07,487 epoch 78 - iter 292/736 - loss 0.09882081 - samples/sec: 65.43 - lr: 0.006250\n",
      "2020-10-22 11:14:26,610 epoch 78 - iter 365/736 - loss 0.09641091 - samples/sec: 62.28 - lr: 0.006250\n",
      "2020-10-22 11:14:45,055 epoch 78 - iter 438/736 - loss 0.09621811 - samples/sec: 63.57 - lr: 0.006250\n",
      "2020-10-22 11:15:04,770 epoch 78 - iter 511/736 - loss 0.09571910 - samples/sec: 59.48 - lr: 0.006250\n",
      "2020-10-22 11:15:23,205 epoch 78 - iter 584/736 - loss 0.09269978 - samples/sec: 64.62 - lr: 0.006250\n",
      "2020-10-22 11:15:43,058 epoch 78 - iter 657/736 - loss 0.08977966 - samples/sec: 59.90 - lr: 0.006250\n",
      "2020-10-22 11:16:00,959 epoch 78 - iter 730/736 - loss 0.08923826 - samples/sec: 65.50 - lr: 0.006250\n",
      "2020-10-22 11:16:02,224 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 11:16:02,225 EPOCH 78 done: loss 0.0891 - lr 0.0062500\n",
      "2020-10-22 11:17:03,112 DEV : loss 0.7002137303352356 - score 0.8417\n",
      "2020-10-22 11:17:05,045 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 11:17:05,046 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 11:17:24,104 epoch 79 - iter 73/736 - loss 0.08332600 - samples/sec: 62.87 - lr: 0.006250\n",
      "2020-10-22 11:17:43,108 epoch 79 - iter 146/736 - loss 0.08665939 - samples/sec: 62.71 - lr: 0.006250\n",
      "2020-10-22 11:18:02,169 epoch 79 - iter 219/736 - loss 0.08819348 - samples/sec: 62.50 - lr: 0.006250\n",
      "2020-10-22 11:18:20,882 epoch 79 - iter 292/736 - loss 0.08497153 - samples/sec: 63.67 - lr: 0.006250\n",
      "2020-10-22 11:18:40,737 epoch 79 - iter 365/736 - loss 0.08598481 - samples/sec: 59.90 - lr: 0.006250\n",
      "2020-10-22 11:18:59,590 epoch 79 - iter 438/736 - loss 0.08957939 - samples/sec: 63.23 - lr: 0.006250\n",
      "2020-10-22 11:19:19,146 epoch 79 - iter 511/736 - loss 0.08978517 - samples/sec: 61.74 - lr: 0.006250\n",
      "2020-10-22 11:19:36,852 epoch 79 - iter 584/736 - loss 0.08848538 - samples/sec: 67.42 - lr: 0.006250\n",
      "2020-10-22 11:19:54,625 epoch 79 - iter 657/736 - loss 0.08973462 - samples/sec: 67.11 - lr: 0.006250\n",
      "2020-10-22 11:20:13,336 epoch 79 - iter 730/736 - loss 0.08925405 - samples/sec: 62.70 - lr: 0.006250\n",
      "2020-10-22 11:20:14,805 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 11:20:14,806 EPOCH 79 done: loss 0.0889 - lr 0.0062500\n",
      "2020-10-22 11:21:15,981 DEV : loss 0.6890091300010681 - score 0.8402\n",
      "2020-10-22 11:21:18,181 BAD EPOCHS (no improvement): 5\n",
      "2020-10-22 11:21:18,182 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 11:21:36,168 epoch 80 - iter 73/736 - loss 0.07734504 - samples/sec: 66.81 - lr: 0.006250\n",
      "2020-10-22 11:21:54,688 epoch 80 - iter 146/736 - loss 0.07246410 - samples/sec: 64.36 - lr: 0.006250\n",
      "2020-10-22 11:22:12,411 epoch 80 - iter 219/736 - loss 0.07252322 - samples/sec: 67.30 - lr: 0.006250\n",
      "2020-10-22 11:22:33,075 epoch 80 - iter 292/736 - loss 0.07503460 - samples/sec: 57.59 - lr: 0.006250\n",
      "2020-10-22 11:22:53,460 epoch 80 - iter 365/736 - loss 0.07276021 - samples/sec: 57.64 - lr: 0.006250\n",
      "2020-10-22 11:23:12,245 epoch 80 - iter 438/736 - loss 0.07715277 - samples/sec: 63.44 - lr: 0.006250\n",
      "2020-10-22 11:23:30,340 epoch 80 - iter 511/736 - loss 0.07641355 - samples/sec: 65.91 - lr: 0.006250\n",
      "2020-10-22 11:23:49,357 epoch 80 - iter 584/736 - loss 0.07942122 - samples/sec: 62.70 - lr: 0.006250\n",
      "2020-10-22 11:24:07,394 epoch 80 - iter 657/736 - loss 0.08126135 - samples/sec: 65.07 - lr: 0.006250\n",
      "2020-10-22 11:24:25,351 epoch 80 - iter 730/736 - loss 0.08070242 - samples/sec: 66.37 - lr: 0.006250\n",
      "2020-10-22 11:24:26,699 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 11:24:26,700 EPOCH 80 done: loss 0.0809 - lr 0.0062500\n",
      "2020-10-22 11:25:27,878 DEV : loss 0.6866728663444519 - score 0.8415\n",
      "Epoch    80: reducing learning rate of group 0 to 3.1250e-03.\n",
      "2020-10-22 11:25:29,829 BAD EPOCHS (no improvement): 6\n",
      "2020-10-22 11:25:29,831 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 11:25:49,221 epoch 81 - iter 73/736 - loss 0.08530603 - samples/sec: 61.86 - lr: 0.003125\n",
      "2020-10-22 11:26:08,349 epoch 81 - iter 146/736 - loss 0.07545968 - samples/sec: 62.25 - lr: 0.003125\n",
      "2020-10-22 11:26:26,918 epoch 81 - iter 219/736 - loss 0.07621099 - samples/sec: 63.17 - lr: 0.003125\n",
      "2020-10-22 11:26:46,047 epoch 81 - iter 292/736 - loss 0.07931535 - samples/sec: 62.24 - lr: 0.003125\n",
      "2020-10-22 11:27:05,629 epoch 81 - iter 365/736 - loss 0.08252861 - samples/sec: 60.75 - lr: 0.003125\n",
      "2020-10-22 11:27:24,153 epoch 81 - iter 438/736 - loss 0.08335673 - samples/sec: 64.25 - lr: 0.003125\n",
      "2020-10-22 11:27:42,833 epoch 81 - iter 511/736 - loss 0.08612884 - samples/sec: 63.75 - lr: 0.003125\n",
      "2020-10-22 11:28:01,268 epoch 81 - iter 584/736 - loss 0.08453403 - samples/sec: 64.64 - lr: 0.003125\n",
      "2020-10-22 11:28:21,059 epoch 81 - iter 657/736 - loss 0.08519505 - samples/sec: 61.00 - lr: 0.003125\n",
      "2020-10-22 11:28:39,884 epoch 81 - iter 730/736 - loss 0.08301907 - samples/sec: 63.22 - lr: 0.003125\n",
      "2020-10-22 11:28:41,271 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 11:28:41,272 EPOCH 81 done: loss 0.0827 - lr 0.0031250\n",
      "2020-10-22 11:29:42,629 DEV : loss 0.6899042129516602 - score 0.841\n",
      "2020-10-22 11:29:44,832 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 11:29:44,832 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 11:30:04,149 epoch 82 - iter 73/736 - loss 0.08820794 - samples/sec: 62.06 - lr: 0.003125\n",
      "2020-10-22 11:30:24,064 epoch 82 - iter 146/736 - loss 0.09095887 - samples/sec: 58.91 - lr: 0.003125\n",
      "2020-10-22 11:30:43,777 epoch 82 - iter 219/736 - loss 0.08553360 - samples/sec: 60.38 - lr: 0.003125\n",
      "2020-10-22 11:31:01,796 epoch 82 - iter 292/736 - loss 0.08690917 - samples/sec: 66.24 - lr: 0.003125\n",
      "2020-10-22 11:31:21,857 epoch 82 - iter 365/736 - loss 0.08413778 - samples/sec: 59.33 - lr: 0.003125\n",
      "2020-10-22 11:31:40,546 epoch 82 - iter 438/736 - loss 0.08348680 - samples/sec: 62.78 - lr: 0.003125\n",
      "2020-10-22 11:31:58,671 epoch 82 - iter 511/736 - loss 0.08087534 - samples/sec: 65.76 - lr: 0.003125\n",
      "2020-10-22 11:32:17,401 epoch 82 - iter 584/736 - loss 0.07922800 - samples/sec: 62.61 - lr: 0.003125\n",
      "2020-10-22 11:32:36,906 epoch 82 - iter 657/736 - loss 0.07893307 - samples/sec: 61.00 - lr: 0.003125\n",
      "2020-10-22 11:32:56,705 epoch 82 - iter 730/736 - loss 0.07861981 - samples/sec: 60.10 - lr: 0.003125\n",
      "2020-10-22 11:32:58,107 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 11:32:58,108 EPOCH 82 done: loss 0.0785 - lr 0.0031250\n",
      "2020-10-22 11:34:00,768 DEV : loss 0.6886056065559387 - score 0.8435\n",
      "2020-10-22 11:34:02,716 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 11:34:02,717 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 11:34:22,616 epoch 83 - iter 73/736 - loss 0.07892129 - samples/sec: 61.15 - lr: 0.003125\n",
      "2020-10-22 11:34:40,481 epoch 83 - iter 146/736 - loss 0.07680047 - samples/sec: 65.66 - lr: 0.003125\n",
      "2020-10-22 11:35:00,529 epoch 83 - iter 219/736 - loss 0.07611100 - samples/sec: 59.29 - lr: 0.003125\n",
      "2020-10-22 11:35:20,036 epoch 83 - iter 292/736 - loss 0.07616549 - samples/sec: 61.06 - lr: 0.003125\n",
      "2020-10-22 11:35:38,224 epoch 83 - iter 365/736 - loss 0.07612527 - samples/sec: 66.61 - lr: 0.003125\n",
      "2020-10-22 11:35:57,263 epoch 83 - iter 438/736 - loss 0.07806270 - samples/sec: 61.62 - lr: 0.003125\n",
      "2020-10-22 11:36:15,890 epoch 83 - iter 511/736 - loss 0.07740076 - samples/sec: 62.94 - lr: 0.003125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 11:36:33,666 epoch 83 - iter 584/736 - loss 0.07599921 - samples/sec: 66.01 - lr: 0.003125\n",
      "2020-10-22 11:36:52,749 epoch 83 - iter 657/736 - loss 0.07653315 - samples/sec: 62.38 - lr: 0.003125\n",
      "2020-10-22 11:37:10,163 epoch 83 - iter 730/736 - loss 0.07587821 - samples/sec: 68.45 - lr: 0.003125\n",
      "2020-10-22 11:37:11,355 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 11:37:11,356 EPOCH 83 done: loss 0.0756 - lr 0.0031250\n",
      "2020-10-22 11:38:11,947 DEV : loss 0.7091188430786133 - score 0.8407\n",
      "2020-10-22 11:38:13,889 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 11:38:13,890 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 11:38:33,996 epoch 84 - iter 73/736 - loss 0.06955129 - samples/sec: 58.73 - lr: 0.003125\n",
      "2020-10-22 11:38:55,620 epoch 84 - iter 146/736 - loss 0.07719317 - samples/sec: 54.96 - lr: 0.003125\n",
      "2020-10-22 11:39:14,237 epoch 84 - iter 219/736 - loss 0.08091623 - samples/sec: 63.99 - lr: 0.003125\n",
      "2020-10-22 11:39:31,614 epoch 84 - iter 292/736 - loss 0.08610137 - samples/sec: 69.72 - lr: 0.003125\n",
      "2020-10-22 11:39:51,069 epoch 84 - iter 365/736 - loss 0.08794481 - samples/sec: 61.17 - lr: 0.003125\n",
      "2020-10-22 11:40:09,730 epoch 84 - iter 438/736 - loss 0.08460442 - samples/sec: 63.78 - lr: 0.003125\n",
      "2020-10-22 11:40:28,575 epoch 84 - iter 511/736 - loss 0.08605332 - samples/sec: 62.27 - lr: 0.003125\n",
      "2020-10-22 11:40:48,478 epoch 84 - iter 584/736 - loss 0.08558030 - samples/sec: 59.78 - lr: 0.003125\n",
      "2020-10-22 11:41:07,646 epoch 84 - iter 657/736 - loss 0.08348045 - samples/sec: 62.97 - lr: 0.003125\n",
      "2020-10-22 11:41:25,458 epoch 84 - iter 730/736 - loss 0.08221383 - samples/sec: 66.83 - lr: 0.003125\n",
      "2020-10-22 11:41:26,882 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 11:41:26,882 EPOCH 84 done: loss 0.0822 - lr 0.0031250\n",
      "2020-10-22 11:42:28,810 DEV : loss 0.7006726264953613 - score 0.8438\n",
      "2020-10-22 11:42:31,005 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 11:42:31,006 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 11:42:51,754 epoch 85 - iter 73/736 - loss 0.06716944 - samples/sec: 57.78 - lr: 0.003125\n",
      "2020-10-22 11:43:09,860 epoch 85 - iter 146/736 - loss 0.07160083 - samples/sec: 65.87 - lr: 0.003125\n",
      "2020-10-22 11:43:28,624 epoch 85 - iter 219/736 - loss 0.08108856 - samples/sec: 63.50 - lr: 0.003125\n",
      "2020-10-22 11:43:47,143 epoch 85 - iter 292/736 - loss 0.08228645 - samples/sec: 64.42 - lr: 0.003125\n",
      "2020-10-22 11:44:05,480 epoch 85 - iter 365/736 - loss 0.08259318 - samples/sec: 64.99 - lr: 0.003125\n",
      "2020-10-22 11:44:24,275 epoch 85 - iter 438/736 - loss 0.08137361 - samples/sec: 63.36 - lr: 0.003125\n",
      "2020-10-22 11:44:42,524 epoch 85 - iter 511/736 - loss 0.07782439 - samples/sec: 64.30 - lr: 0.003125\n",
      "2020-10-22 11:44:59,613 epoch 85 - iter 584/736 - loss 0.07581742 - samples/sec: 69.76 - lr: 0.003125\n",
      "2020-10-22 11:45:19,323 epoch 85 - iter 657/736 - loss 0.07357374 - samples/sec: 60.42 - lr: 0.003125\n",
      "2020-10-22 11:45:38,238 epoch 85 - iter 730/736 - loss 0.07480559 - samples/sec: 62.02 - lr: 0.003125\n",
      "2020-10-22 11:45:39,511 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 11:45:39,512 EPOCH 85 done: loss 0.0754 - lr 0.0031250\n",
      "2020-10-22 11:46:40,269 DEV : loss 0.7089893817901611 - score 0.8435\n",
      "2020-10-22 11:46:42,205 BAD EPOCHS (no improvement): 5\n",
      "2020-10-22 11:46:42,206 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 11:47:00,476 epoch 86 - iter 73/736 - loss 0.07283761 - samples/sec: 64.65 - lr: 0.003125\n",
      "2020-10-22 11:47:19,359 epoch 86 - iter 146/736 - loss 0.07893009 - samples/sec: 62.16 - lr: 0.003125\n",
      "2020-10-22 11:47:38,484 epoch 86 - iter 219/736 - loss 0.07418352 - samples/sec: 62.22 - lr: 0.003125\n",
      "2020-10-22 11:47:56,410 epoch 86 - iter 292/736 - loss 0.07202197 - samples/sec: 65.39 - lr: 0.003125\n",
      "2020-10-22 11:48:16,614 epoch 86 - iter 365/736 - loss 0.07309766 - samples/sec: 58.84 - lr: 0.003125\n",
      "2020-10-22 11:48:36,770 epoch 86 - iter 438/736 - loss 0.07449165 - samples/sec: 58.17 - lr: 0.003125\n",
      "2020-10-22 11:48:56,235 epoch 86 - iter 511/736 - loss 0.07262595 - samples/sec: 61.12 - lr: 0.003125\n",
      "2020-10-22 11:49:14,595 epoch 86 - iter 584/736 - loss 0.07270603 - samples/sec: 64.91 - lr: 0.003125\n",
      "2020-10-22 11:49:33,771 epoch 86 - iter 657/736 - loss 0.07350492 - samples/sec: 62.05 - lr: 0.003125\n",
      "2020-10-22 11:49:52,883 epoch 86 - iter 730/736 - loss 0.07216903 - samples/sec: 62.26 - lr: 0.003125\n",
      "2020-10-22 11:49:54,222 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 11:49:54,222 EPOCH 86 done: loss 0.0719 - lr 0.0031250\n",
      "2020-10-22 11:50:56,912 DEV : loss 0.7176063060760498 - score 0.8402\n",
      "Epoch    86: reducing learning rate of group 0 to 1.5625e-03.\n",
      "2020-10-22 11:50:58,874 BAD EPOCHS (no improvement): 6\n",
      "2020-10-22 11:50:58,875 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 11:51:19,434 epoch 87 - iter 73/736 - loss 0.08888713 - samples/sec: 57.39 - lr: 0.001563\n",
      "2020-10-22 11:51:37,602 epoch 87 - iter 146/736 - loss 0.09220429 - samples/sec: 65.64 - lr: 0.001563\n",
      "2020-10-22 11:51:57,667 epoch 87 - iter 219/736 - loss 0.09139150 - samples/sec: 59.27 - lr: 0.001563\n",
      "2020-10-22 11:52:16,410 epoch 87 - iter 292/736 - loss 0.09502621 - samples/sec: 63.58 - lr: 0.001563\n",
      "2020-10-22 11:52:36,878 epoch 87 - iter 365/736 - loss 0.09099102 - samples/sec: 58.12 - lr: 0.001563\n",
      "2020-10-22 11:52:56,207 epoch 87 - iter 438/736 - loss 0.08478590 - samples/sec: 61.52 - lr: 0.001563\n",
      "2020-10-22 11:53:14,778 epoch 87 - iter 511/736 - loss 0.08211113 - samples/sec: 64.23 - lr: 0.001563\n",
      "2020-10-22 11:53:34,156 epoch 87 - iter 584/736 - loss 0.08005627 - samples/sec: 62.44 - lr: 0.001563\n",
      "2020-10-22 11:53:52,384 epoch 87 - iter 657/736 - loss 0.07781828 - samples/sec: 64.38 - lr: 0.001563\n",
      "2020-10-22 11:54:10,639 epoch 87 - iter 730/736 - loss 0.07644258 - samples/sec: 64.28 - lr: 0.001563\n",
      "2020-10-22 11:54:12,136 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 11:54:12,137 EPOCH 87 done: loss 0.0759 - lr 0.0015625\n",
      "2020-10-22 11:55:14,424 DEV : loss 0.7124070525169373 - score 0.8453\n",
      "2020-10-22 11:55:16,375 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 11:55:18,394 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 11:55:38,986 epoch 88 - iter 73/736 - loss 0.07240060 - samples/sec: 58.19 - lr: 0.001563\n",
      "2020-10-22 11:55:56,569 epoch 88 - iter 146/736 - loss 0.07674711 - samples/sec: 67.87 - lr: 0.001563\n",
      "2020-10-22 11:56:15,708 epoch 88 - iter 219/736 - loss 0.07598597 - samples/sec: 62.23 - lr: 0.001563\n",
      "2020-10-22 11:56:34,498 epoch 88 - iter 292/736 - loss 0.07558609 - samples/sec: 63.41 - lr: 0.001563\n",
      "2020-10-22 11:56:53,455 epoch 88 - iter 365/736 - loss 0.07324046 - samples/sec: 62.80 - lr: 0.001563\n",
      "2020-10-22 11:57:11,242 epoch 88 - iter 438/736 - loss 0.07575257 - samples/sec: 66.95 - lr: 0.001563\n",
      "2020-10-22 11:57:31,434 epoch 88 - iter 511/736 - loss 0.07508834 - samples/sec: 58.91 - lr: 0.001563\n",
      "2020-10-22 11:57:51,275 epoch 88 - iter 584/736 - loss 0.07775409 - samples/sec: 59.95 - lr: 0.001563\n",
      "2020-10-22 11:58:09,895 epoch 88 - iter 657/736 - loss 0.08017398 - samples/sec: 63.97 - lr: 0.001563\n",
      "2020-10-22 11:58:30,265 epoch 88 - iter 730/736 - loss 0.08007537 - samples/sec: 58.38 - lr: 0.001563\n",
      "2020-10-22 11:58:31,970 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 11:58:31,971 EPOCH 88 done: loss 0.0795 - lr 0.0015625\n",
      "2020-10-22 11:59:32,345 DEV : loss 0.7151715159416199 - score 0.8428\n",
      "2020-10-22 11:59:34,262 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 11:59:34,263 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 11:59:54,390 epoch 89 - iter 73/736 - loss 0.08154318 - samples/sec: 58.64 - lr: 0.001563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 12:00:13,608 epoch 89 - iter 146/736 - loss 0.06770018 - samples/sec: 61.04 - lr: 0.001563\n",
      "2020-10-22 12:00:32,132 epoch 89 - iter 219/736 - loss 0.07738310 - samples/sec: 65.33 - lr: 0.001563\n",
      "2020-10-22 12:00:50,562 epoch 89 - iter 292/736 - loss 0.07864328 - samples/sec: 63.62 - lr: 0.001563\n",
      "2020-10-22 12:01:10,046 epoch 89 - iter 365/736 - loss 0.08015385 - samples/sec: 61.08 - lr: 0.001563\n",
      "2020-10-22 12:01:27,362 epoch 89 - iter 438/736 - loss 0.07869211 - samples/sec: 68.88 - lr: 0.001563\n",
      "2020-10-22 12:01:46,727 epoch 89 - iter 511/736 - loss 0.07833439 - samples/sec: 61.47 - lr: 0.001563\n",
      "2020-10-22 12:02:05,154 epoch 89 - iter 584/736 - loss 0.07848135 - samples/sec: 63.66 - lr: 0.001563\n",
      "2020-10-22 12:02:23,873 epoch 89 - iter 657/736 - loss 0.07773047 - samples/sec: 62.70 - lr: 0.001563\n",
      "2020-10-22 12:02:41,515 epoch 89 - iter 730/736 - loss 0.07688140 - samples/sec: 67.54 - lr: 0.001563\n",
      "2020-10-22 12:02:43,580 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:02:43,581 EPOCH 89 done: loss 0.0774 - lr 0.0015625\n",
      "2020-10-22 12:03:44,236 DEV : loss 0.7094969749450684 - score 0.8458\n",
      "2020-10-22 12:03:46,152 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 12:03:48,151 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:04:06,842 epoch 90 - iter 73/736 - loss 0.06858244 - samples/sec: 63.19 - lr: 0.001563\n",
      "2020-10-22 12:04:23,865 epoch 90 - iter 146/736 - loss 0.06587549 - samples/sec: 70.05 - lr: 0.001563\n",
      "2020-10-22 12:04:42,255 epoch 90 - iter 219/736 - loss 0.06732862 - samples/sec: 64.78 - lr: 0.001563\n",
      "2020-10-22 12:05:01,917 epoch 90 - iter 292/736 - loss 0.06888692 - samples/sec: 61.34 - lr: 0.001563\n",
      "2020-10-22 12:05:21,237 epoch 90 - iter 365/736 - loss 0.06858988 - samples/sec: 61.54 - lr: 0.001563\n",
      "2020-10-22 12:05:38,557 epoch 90 - iter 438/736 - loss 0.07003621 - samples/sec: 67.76 - lr: 0.001563\n",
      "2020-10-22 12:05:57,142 epoch 90 - iter 511/736 - loss 0.07289453 - samples/sec: 63.11 - lr: 0.001563\n",
      "2020-10-22 12:06:17,336 epoch 90 - iter 584/736 - loss 0.07400850 - samples/sec: 59.69 - lr: 0.001563\n",
      "2020-10-22 12:06:36,026 epoch 90 - iter 657/736 - loss 0.07581922 - samples/sec: 63.80 - lr: 0.001563\n",
      "2020-10-22 12:06:55,109 epoch 90 - iter 730/736 - loss 0.07720827 - samples/sec: 61.50 - lr: 0.001563\n",
      "2020-10-22 12:06:56,517 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:06:56,518 EPOCH 90 done: loss 0.0771 - lr 0.0015625\n",
      "2020-10-22 12:07:57,169 DEV : loss 0.7094692587852478 - score 0.844\n",
      "2020-10-22 12:07:59,340 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 12:07:59,340 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:08:19,876 epoch 91 - iter 73/736 - loss 0.07517650 - samples/sec: 58.27 - lr: 0.001563\n",
      "2020-10-22 12:08:37,198 epoch 91 - iter 146/736 - loss 0.07783086 - samples/sec: 68.93 - lr: 0.001563\n",
      "2020-10-22 12:08:54,593 epoch 91 - iter 219/736 - loss 0.07807228 - samples/sec: 68.62 - lr: 0.001563\n",
      "2020-10-22 12:09:13,060 epoch 91 - iter 292/736 - loss 0.07934639 - samples/sec: 65.45 - lr: 0.001563\n",
      "2020-10-22 12:09:32,808 epoch 91 - iter 365/736 - loss 0.07769317 - samples/sec: 59.37 - lr: 0.001563\n",
      "2020-10-22 12:09:52,933 epoch 91 - iter 438/736 - loss 0.07647524 - samples/sec: 59.07 - lr: 0.001563\n",
      "2020-10-22 12:10:11,221 epoch 91 - iter 511/736 - loss 0.07682973 - samples/sec: 65.18 - lr: 0.001563\n",
      "2020-10-22 12:10:29,920 epoch 91 - iter 584/736 - loss 0.07535773 - samples/sec: 63.70 - lr: 0.001563\n",
      "2020-10-22 12:10:47,922 epoch 91 - iter 657/736 - loss 0.07434605 - samples/sec: 66.21 - lr: 0.001563\n",
      "2020-10-22 12:11:06,924 epoch 91 - iter 730/736 - loss 0.07464152 - samples/sec: 62.72 - lr: 0.001563\n",
      "2020-10-22 12:11:08,527 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:11:08,527 EPOCH 91 done: loss 0.0744 - lr 0.0015625\n",
      "2020-10-22 12:12:09,522 DEV : loss 0.7044902443885803 - score 0.8445\n",
      "2020-10-22 12:12:11,459 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 12:12:11,460 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:12:28,815 epoch 92 - iter 73/736 - loss 0.08665535 - samples/sec: 69.31 - lr: 0.001563\n",
      "2020-10-22 12:12:47,087 epoch 92 - iter 146/736 - loss 0.08207271 - samples/sec: 64.17 - lr: 0.001563\n",
      "2020-10-22 12:13:06,969 epoch 92 - iter 219/736 - loss 0.08607731 - samples/sec: 60.62 - lr: 0.001563\n",
      "2020-10-22 12:13:26,073 epoch 92 - iter 292/736 - loss 0.08893388 - samples/sec: 61.36 - lr: 0.001563\n",
      "2020-10-22 12:13:47,243 epoch 92 - iter 365/736 - loss 0.08308540 - samples/sec: 56.09 - lr: 0.001563\n",
      "2020-10-22 12:14:05,503 epoch 92 - iter 438/736 - loss 0.08210951 - samples/sec: 65.30 - lr: 0.001563\n",
      "2020-10-22 12:14:23,408 epoch 92 - iter 511/736 - loss 0.08251251 - samples/sec: 66.57 - lr: 0.001563\n",
      "2020-10-22 12:14:41,865 epoch 92 - iter 584/736 - loss 0.07929299 - samples/sec: 64.57 - lr: 0.001563\n",
      "2020-10-22 12:14:58,778 epoch 92 - iter 657/736 - loss 0.07879883 - samples/sec: 70.53 - lr: 0.001563\n",
      "2020-10-22 12:15:17,706 epoch 92 - iter 730/736 - loss 0.08037736 - samples/sec: 62.93 - lr: 0.001563\n",
      "2020-10-22 12:15:19,221 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:15:19,222 EPOCH 92 done: loss 0.0802 - lr 0.0015625\n",
      "2020-10-22 12:16:19,837 DEV : loss 0.7093534469604492 - score 0.8438\n",
      "2020-10-22 12:16:21,757 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 12:16:21,758 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:16:40,906 epoch 93 - iter 73/736 - loss 0.06588465 - samples/sec: 61.69 - lr: 0.001563\n",
      "2020-10-22 12:16:59,300 epoch 93 - iter 146/736 - loss 0.07072607 - samples/sec: 64.76 - lr: 0.001563\n",
      "2020-10-22 12:17:20,183 epoch 93 - iter 219/736 - loss 0.07072347 - samples/sec: 56.93 - lr: 0.001563\n",
      "2020-10-22 12:17:38,020 epoch 93 - iter 292/736 - loss 0.07163855 - samples/sec: 66.91 - lr: 0.001563\n",
      "2020-10-22 12:17:58,558 epoch 93 - iter 365/736 - loss 0.07300760 - samples/sec: 57.92 - lr: 0.001563\n",
      "2020-10-22 12:18:17,126 epoch 93 - iter 438/736 - loss 0.07498937 - samples/sec: 64.15 - lr: 0.001563\n",
      "2020-10-22 12:18:35,267 epoch 93 - iter 511/736 - loss 0.07676299 - samples/sec: 65.67 - lr: 0.001563\n",
      "2020-10-22 12:18:52,618 epoch 93 - iter 584/736 - loss 0.07753574 - samples/sec: 68.81 - lr: 0.001563\n",
      "2020-10-22 12:19:09,723 epoch 93 - iter 657/736 - loss 0.08089059 - samples/sec: 68.61 - lr: 0.001563\n",
      "2020-10-22 12:19:27,137 epoch 93 - iter 730/736 - loss 0.07920154 - samples/sec: 67.41 - lr: 0.001563\n",
      "2020-10-22 12:19:28,579 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:19:28,580 EPOCH 93 done: loss 0.0793 - lr 0.0015625\n",
      "2020-10-22 12:20:29,519 DEV : loss 0.7067185044288635 - score 0.8458\n",
      "2020-10-22 12:20:31,431 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 12:20:33,405 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:20:53,696 epoch 94 - iter 73/736 - loss 0.06699276 - samples/sec: 58.97 - lr: 0.001563\n",
      "2020-10-22 12:21:11,995 epoch 94 - iter 146/736 - loss 0.06937128 - samples/sec: 65.18 - lr: 0.001563\n",
      "2020-10-22 12:21:29,646 epoch 94 - iter 219/736 - loss 0.06566051 - samples/sec: 67.50 - lr: 0.001563\n",
      "2020-10-22 12:21:47,516 epoch 94 - iter 292/736 - loss 0.06627497 - samples/sec: 66.71 - lr: 0.001563\n",
      "2020-10-22 12:22:05,647 epoch 94 - iter 365/736 - loss 0.06660414 - samples/sec: 66.78 - lr: 0.001563\n",
      "2020-10-22 12:22:25,403 epoch 94 - iter 438/736 - loss 0.06805193 - samples/sec: 60.19 - lr: 0.001563\n",
      "2020-10-22 12:22:44,014 epoch 94 - iter 511/736 - loss 0.06735956 - samples/sec: 64.00 - lr: 0.001563\n",
      "2020-10-22 12:23:02,353 epoch 94 - iter 584/736 - loss 0.06561716 - samples/sec: 64.06 - lr: 0.001563\n",
      "2020-10-22 12:23:21,750 epoch 94 - iter 657/736 - loss 0.06544979 - samples/sec: 62.26 - lr: 0.001563\n",
      "2020-10-22 12:23:41,855 epoch 94 - iter 730/736 - loss 0.06906170 - samples/sec: 58.34 - lr: 0.001563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 12:23:42,991 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:23:42,992 EPOCH 94 done: loss 0.0692 - lr 0.0015625\n",
      "2020-10-22 12:24:43,680 DEV : loss 0.7108713388442993 - score 0.8458\n",
      "2020-10-22 12:24:45,599 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 12:24:45,600 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:25:05,031 epoch 95 - iter 73/736 - loss 0.09707964 - samples/sec: 62.64 - lr: 0.001563\n",
      "2020-10-22 12:25:23,738 epoch 95 - iter 146/736 - loss 0.09389795 - samples/sec: 62.71 - lr: 0.001563\n",
      "2020-10-22 12:25:43,845 epoch 95 - iter 219/736 - loss 0.08636202 - samples/sec: 59.13 - lr: 0.001563\n",
      "2020-10-22 12:26:01,966 epoch 95 - iter 292/736 - loss 0.07765328 - samples/sec: 65.76 - lr: 0.001563\n",
      "2020-10-22 12:26:21,637 epoch 95 - iter 365/736 - loss 0.07632302 - samples/sec: 59.61 - lr: 0.001563\n",
      "2020-10-22 12:26:40,497 epoch 95 - iter 438/736 - loss 0.07595116 - samples/sec: 62.20 - lr: 0.001563\n",
      "2020-10-22 12:26:58,661 epoch 95 - iter 511/736 - loss 0.07516144 - samples/sec: 64.59 - lr: 0.001563\n",
      "2020-10-22 12:27:16,032 epoch 95 - iter 584/736 - loss 0.07468849 - samples/sec: 68.57 - lr: 0.001563\n",
      "2020-10-22 12:27:35,674 epoch 95 - iter 657/736 - loss 0.07401822 - samples/sec: 59.67 - lr: 0.001563\n",
      "2020-10-22 12:27:54,692 epoch 95 - iter 730/736 - loss 0.07708670 - samples/sec: 61.63 - lr: 0.001563\n",
      "2020-10-22 12:27:55,826 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:27:55,827 EPOCH 95 done: loss 0.0773 - lr 0.0015625\n",
      "2020-10-22 12:28:56,558 DEV : loss 0.7145946621894836 - score 0.8448\n",
      "2020-10-22 12:28:58,482 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 12:28:58,483 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:29:17,325 epoch 96 - iter 73/736 - loss 0.06544139 - samples/sec: 63.68 - lr: 0.001563\n",
      "2020-10-22 12:29:34,773 epoch 96 - iter 146/736 - loss 0.07463009 - samples/sec: 68.40 - lr: 0.001563\n",
      "2020-10-22 12:29:52,343 epoch 96 - iter 219/736 - loss 0.07696238 - samples/sec: 67.83 - lr: 0.001563\n",
      "2020-10-22 12:30:10,236 epoch 96 - iter 292/736 - loss 0.07497149 - samples/sec: 66.55 - lr: 0.001563\n",
      "2020-10-22 12:30:28,926 epoch 96 - iter 365/736 - loss 0.07106614 - samples/sec: 63.72 - lr: 0.001563\n",
      "2020-10-22 12:30:49,287 epoch 96 - iter 438/736 - loss 0.07227799 - samples/sec: 58.37 - lr: 0.001563\n",
      "2020-10-22 12:31:08,074 epoch 96 - iter 511/736 - loss 0.07386783 - samples/sec: 64.40 - lr: 0.001563\n",
      "2020-10-22 12:31:27,031 epoch 96 - iter 584/736 - loss 0.07624771 - samples/sec: 61.93 - lr: 0.001563\n",
      "2020-10-22 12:31:47,249 epoch 96 - iter 657/736 - loss 0.07430863 - samples/sec: 57.96 - lr: 0.001563\n",
      "2020-10-22 12:32:05,287 epoch 96 - iter 730/736 - loss 0.07341592 - samples/sec: 66.01 - lr: 0.001563\n",
      "2020-10-22 12:32:06,431 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:32:06,432 EPOCH 96 done: loss 0.0735 - lr 0.0015625\n",
      "2020-10-22 12:33:07,002 DEV : loss 0.7127903699874878 - score 0.8456\n",
      "2020-10-22 12:33:08,907 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 12:33:08,908 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:33:26,950 epoch 97 - iter 73/736 - loss 0.08769736 - samples/sec: 65.53 - lr: 0.001563\n",
      "2020-10-22 12:33:46,026 epoch 97 - iter 146/736 - loss 0.07488019 - samples/sec: 62.50 - lr: 0.001563\n",
      "2020-10-22 12:34:06,334 epoch 97 - iter 219/736 - loss 0.08538927 - samples/sec: 58.58 - lr: 0.001563\n",
      "2020-10-22 12:34:25,618 epoch 97 - iter 292/736 - loss 0.08163163 - samples/sec: 60.95 - lr: 0.001563\n",
      "2020-10-22 12:34:43,854 epoch 97 - iter 365/736 - loss 0.07919618 - samples/sec: 64.47 - lr: 0.001563\n",
      "2020-10-22 12:35:01,790 epoch 97 - iter 438/736 - loss 0.07767767 - samples/sec: 66.36 - lr: 0.001563\n",
      "2020-10-22 12:35:20,594 epoch 97 - iter 511/736 - loss 0.07679699 - samples/sec: 63.30 - lr: 0.001563\n",
      "2020-10-22 12:35:39,797 epoch 97 - iter 584/736 - loss 0.07847050 - samples/sec: 61.92 - lr: 0.001563\n",
      "2020-10-22 12:35:58,001 epoch 97 - iter 657/736 - loss 0.07771674 - samples/sec: 64.42 - lr: 0.001563\n",
      "2020-10-22 12:36:16,033 epoch 97 - iter 730/736 - loss 0.07683878 - samples/sec: 65.08 - lr: 0.001563\n",
      "2020-10-22 12:36:17,404 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:36:17,405 EPOCH 97 done: loss 0.0765 - lr 0.0015625\n",
      "2020-10-22 12:37:17,954 DEV : loss 0.7182106971740723 - score 0.8435\n",
      "2020-10-22 12:37:19,842 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 12:37:19,842 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:37:38,170 epoch 98 - iter 73/736 - loss 0.08228525 - samples/sec: 64.34 - lr: 0.001563\n",
      "2020-10-22 12:37:56,946 epoch 98 - iter 146/736 - loss 0.07886834 - samples/sec: 63.41 - lr: 0.001563\n",
      "2020-10-22 12:38:16,520 epoch 98 - iter 219/736 - loss 0.07310043 - samples/sec: 60.83 - lr: 0.001563\n",
      "2020-10-22 12:38:35,248 epoch 98 - iter 292/736 - loss 0.07807201 - samples/sec: 63.54 - lr: 0.001563\n",
      "2020-10-22 12:38:55,110 epoch 98 - iter 365/736 - loss 0.07720496 - samples/sec: 60.74 - lr: 0.001563\n",
      "2020-10-22 12:39:14,020 epoch 98 - iter 438/736 - loss 0.07620256 - samples/sec: 62.20 - lr: 0.001563\n",
      "2020-10-22 12:39:32,806 epoch 98 - iter 511/736 - loss 0.07452959 - samples/sec: 63.33 - lr: 0.001563\n",
      "2020-10-22 12:39:51,507 epoch 98 - iter 584/736 - loss 0.07236688 - samples/sec: 63.67 - lr: 0.001563\n",
      "2020-10-22 12:40:09,338 epoch 98 - iter 657/736 - loss 0.07276479 - samples/sec: 66.91 - lr: 0.001563\n",
      "2020-10-22 12:40:27,337 epoch 98 - iter 730/736 - loss 0.07276723 - samples/sec: 66.25 - lr: 0.001563\n",
      "2020-10-22 12:40:28,494 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:40:28,494 EPOCH 98 done: loss 0.0726 - lr 0.0015625\n",
      "2020-10-22 12:41:28,900 DEV : loss 0.7241418361663818 - score 0.8428\n",
      "2020-10-22 12:41:31,059 BAD EPOCHS (no improvement): 5\n",
      "2020-10-22 12:41:31,059 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:41:49,618 epoch 99 - iter 73/736 - loss 0.08708850 - samples/sec: 63.65 - lr: 0.001563\n",
      "2020-10-22 12:42:09,813 epoch 99 - iter 146/736 - loss 0.08846140 - samples/sec: 58.87 - lr: 0.001563\n",
      "2020-10-22 12:42:26,985 epoch 99 - iter 219/736 - loss 0.07715430 - samples/sec: 69.49 - lr: 0.001563\n",
      "2020-10-22 12:42:46,020 epoch 99 - iter 292/736 - loss 0.07764703 - samples/sec: 62.53 - lr: 0.001563\n",
      "2020-10-22 12:43:05,224 epoch 99 - iter 365/736 - loss 0.07633796 - samples/sec: 62.97 - lr: 0.001563\n",
      "2020-10-22 12:43:23,875 epoch 99 - iter 438/736 - loss 0.07638713 - samples/sec: 62.93 - lr: 0.001563\n",
      "2020-10-22 12:43:42,053 epoch 99 - iter 511/736 - loss 0.07517260 - samples/sec: 65.53 - lr: 0.001563\n",
      "2020-10-22 12:44:00,758 epoch 99 - iter 584/736 - loss 0.07760424 - samples/sec: 62.70 - lr: 0.001563\n",
      "2020-10-22 12:44:18,452 epoch 99 - iter 657/736 - loss 0.07729050 - samples/sec: 66.30 - lr: 0.001563\n",
      "2020-10-22 12:44:38,028 epoch 99 - iter 730/736 - loss 0.07691008 - samples/sec: 59.89 - lr: 0.001563\n",
      "2020-10-22 12:44:39,323 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:44:39,324 EPOCH 99 done: loss 0.0803 - lr 0.0015625\n",
      "2020-10-22 12:45:39,922 DEV : loss 0.713102400302887 - score 0.8453\n",
      "Epoch    99: reducing learning rate of group 0 to 7.8125e-04.\n",
      "2020-10-22 12:45:42,081 BAD EPOCHS (no improvement): 6\n",
      "2020-10-22 12:45:42,082 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:46:00,523 epoch 100 - iter 73/736 - loss 0.07043276 - samples/sec: 64.01 - lr: 0.000781\n",
      "2020-10-22 12:46:18,750 epoch 100 - iter 146/736 - loss 0.07453389 - samples/sec: 65.31 - lr: 0.000781\n",
      "2020-10-22 12:46:36,930 epoch 100 - iter 219/736 - loss 0.08099979 - samples/sec: 65.56 - lr: 0.000781\n",
      "2020-10-22 12:46:56,046 epoch 100 - iter 292/736 - loss 0.07280203 - samples/sec: 62.22 - lr: 0.000781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 12:47:14,543 epoch 100 - iter 365/736 - loss 0.07548293 - samples/sec: 64.33 - lr: 0.000781\n",
      "2020-10-22 12:47:33,489 epoch 100 - iter 438/736 - loss 0.07493269 - samples/sec: 61.91 - lr: 0.000781\n",
      "2020-10-22 12:47:53,510 epoch 100 - iter 511/736 - loss 0.07719064 - samples/sec: 60.26 - lr: 0.000781\n",
      "2020-10-22 12:48:12,984 epoch 100 - iter 584/736 - loss 0.07749062 - samples/sec: 61.04 - lr: 0.000781\n",
      "2020-10-22 12:48:30,609 epoch 100 - iter 657/736 - loss 0.07714540 - samples/sec: 66.54 - lr: 0.000781\n",
      "2020-10-22 12:48:48,755 epoch 100 - iter 730/736 - loss 0.07807375 - samples/sec: 65.66 - lr: 0.000781\n",
      "2020-10-22 12:48:50,392 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:48:50,393 EPOCH 100 done: loss 0.0782 - lr 0.0007813\n",
      "2020-10-22 12:49:50,780 DEV : loss 0.7138060927391052 - score 0.8448\n",
      "2020-10-22 12:49:52,667 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 12:49:52,667 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:50:10,900 epoch 101 - iter 73/736 - loss 0.09469211 - samples/sec: 65.84 - lr: 0.000781\n",
      "2020-10-22 12:50:29,740 epoch 101 - iter 146/736 - loss 0.08495017 - samples/sec: 64.15 - lr: 0.000781\n",
      "2020-10-22 12:50:47,928 epoch 101 - iter 219/736 - loss 0.07747255 - samples/sec: 65.50 - lr: 0.000781\n",
      "2020-10-22 12:51:07,850 epoch 101 - iter 292/736 - loss 0.07313014 - samples/sec: 59.68 - lr: 0.000781\n",
      "2020-10-22 12:51:27,890 epoch 101 - iter 365/736 - loss 0.07416504 - samples/sec: 59.35 - lr: 0.000781\n",
      "2020-10-22 12:51:45,655 epoch 101 - iter 438/736 - loss 0.07636086 - samples/sec: 67.05 - lr: 0.000781\n",
      "2020-10-22 12:52:04,565 epoch 101 - iter 511/736 - loss 0.07755708 - samples/sec: 62.89 - lr: 0.000781\n",
      "2020-10-22 12:52:22,944 epoch 101 - iter 584/736 - loss 0.07614210 - samples/sec: 64.75 - lr: 0.000781\n",
      "2020-10-22 12:52:41,329 epoch 101 - iter 657/736 - loss 0.07646289 - samples/sec: 64.71 - lr: 0.000781\n",
      "2020-10-22 12:52:59,414 epoch 101 - iter 730/736 - loss 0.07750598 - samples/sec: 65.90 - lr: 0.000781\n",
      "2020-10-22 12:53:00,736 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:53:00,737 EPOCH 101 done: loss 0.0777 - lr 0.0007813\n",
      "2020-10-22 12:54:01,462 DEV : loss 0.7173023819923401 - score 0.8456\n",
      "2020-10-22 12:54:03,344 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 12:54:03,344 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:54:23,142 epoch 102 - iter 73/736 - loss 0.06762617 - samples/sec: 59.53 - lr: 0.000781\n",
      "2020-10-22 12:54:41,594 epoch 102 - iter 146/736 - loss 0.07120159 - samples/sec: 64.53 - lr: 0.000781\n",
      "2020-10-22 12:54:59,156 epoch 102 - iter 219/736 - loss 0.07237098 - samples/sec: 67.87 - lr: 0.000781\n",
      "2020-10-22 12:55:17,651 epoch 102 - iter 292/736 - loss 0.06786093 - samples/sec: 64.41 - lr: 0.000781\n",
      "2020-10-22 12:55:35,099 epoch 102 - iter 365/736 - loss 0.06794423 - samples/sec: 68.39 - lr: 0.000781\n",
      "2020-10-22 12:55:53,625 epoch 102 - iter 438/736 - loss 0.06862035 - samples/sec: 64.25 - lr: 0.000781\n",
      "2020-10-22 12:56:11,824 epoch 102 - iter 511/736 - loss 0.07050727 - samples/sec: 66.40 - lr: 0.000781\n",
      "2020-10-22 12:56:31,273 epoch 102 - iter 584/736 - loss 0.07013615 - samples/sec: 61.17 - lr: 0.000781\n",
      "2020-10-22 12:56:51,049 epoch 102 - iter 657/736 - loss 0.06942403 - samples/sec: 60.17 - lr: 0.000781\n",
      "2020-10-22 12:57:09,792 epoch 102 - iter 730/736 - loss 0.06965785 - samples/sec: 63.46 - lr: 0.000781\n",
      "2020-10-22 12:57:11,225 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:57:11,226 EPOCH 102 done: loss 0.0697 - lr 0.0007813\n",
      "2020-10-22 12:58:11,822 DEV : loss 0.7184915542602539 - score 0.8445\n",
      "2020-10-22 12:58:13,714 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 12:58:13,715 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:58:34,695 epoch 103 - iter 73/736 - loss 0.08960822 - samples/sec: 56.99 - lr: 0.000781\n",
      "2020-10-22 12:58:53,154 epoch 103 - iter 146/736 - loss 0.08500821 - samples/sec: 63.55 - lr: 0.000781\n",
      "2020-10-22 12:59:12,853 epoch 103 - iter 219/736 - loss 0.08111323 - samples/sec: 60.40 - lr: 0.000781\n",
      "2020-10-22 12:59:30,861 epoch 103 - iter 292/736 - loss 0.08031854 - samples/sec: 67.22 - lr: 0.000781\n",
      "2020-10-22 12:59:48,357 epoch 103 - iter 365/736 - loss 0.07557052 - samples/sec: 68.18 - lr: 0.000781\n",
      "2020-10-22 13:00:06,908 epoch 103 - iter 438/736 - loss 0.07555393 - samples/sec: 63.27 - lr: 0.000781\n",
      "2020-10-22 13:00:24,456 epoch 103 - iter 511/736 - loss 0.07991951 - samples/sec: 67.93 - lr: 0.000781\n",
      "2020-10-22 13:00:42,679 epoch 103 - iter 584/736 - loss 0.07784949 - samples/sec: 65.44 - lr: 0.000781\n",
      "2020-10-22 13:01:01,410 epoch 103 - iter 657/736 - loss 0.07800237 - samples/sec: 63.59 - lr: 0.000781\n",
      "2020-10-22 13:01:20,108 epoch 103 - iter 730/736 - loss 0.07634540 - samples/sec: 62.81 - lr: 0.000781\n",
      "2020-10-22 13:01:21,667 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 13:01:21,668 EPOCH 103 done: loss 0.0763 - lr 0.0007813\n",
      "2020-10-22 13:02:22,132 DEV : loss 0.7160332202911377 - score 0.8445\n",
      "2020-10-22 13:02:24,058 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 13:02:24,059 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 13:02:42,205 epoch 104 - iter 73/736 - loss 0.07668197 - samples/sec: 65.12 - lr: 0.000781\n",
      "2020-10-22 13:03:00,373 epoch 104 - iter 146/736 - loss 0.07514583 - samples/sec: 65.56 - lr: 0.000781\n",
      "2020-10-22 13:03:19,473 epoch 104 - iter 219/736 - loss 0.08413322 - samples/sec: 61.39 - lr: 0.000781\n",
      "2020-10-22 13:03:38,260 epoch 104 - iter 292/736 - loss 0.07982876 - samples/sec: 63.31 - lr: 0.000781\n",
      "2020-10-22 13:03:55,683 epoch 104 - iter 365/736 - loss 0.07987609 - samples/sec: 69.60 - lr: 0.000781\n",
      "2020-10-22 13:04:16,237 epoch 104 - iter 438/736 - loss 0.08212872 - samples/sec: 57.84 - lr: 0.000781\n",
      "2020-10-22 13:04:33,688 epoch 104 - iter 511/736 - loss 0.08116667 - samples/sec: 67.30 - lr: 0.000781\n",
      "2020-10-22 13:04:53,402 epoch 104 - iter 584/736 - loss 0.08007659 - samples/sec: 59.49 - lr: 0.000781\n",
      "2020-10-22 13:05:12,750 epoch 104 - iter 657/736 - loss 0.07910593 - samples/sec: 61.47 - lr: 0.000781\n",
      "2020-10-22 13:05:31,592 epoch 104 - iter 730/736 - loss 0.07933734 - samples/sec: 63.18 - lr: 0.000781\n",
      "2020-10-22 13:05:32,936 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 13:05:32,936 EPOCH 104 done: loss 0.0794 - lr 0.0007813\n",
      "2020-10-22 13:06:32,769 DEV : loss 0.7149839401245117 - score 0.8453\n",
      "2020-10-22 13:06:34,656 BAD EPOCHS (no improvement): 5\n",
      "2020-10-22 13:06:34,657 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 13:06:54,331 epoch 105 - iter 73/736 - loss 0.07260002 - samples/sec: 60.00 - lr: 0.000781\n",
      "2020-10-22 13:07:15,182 epoch 105 - iter 146/736 - loss 0.07382213 - samples/sec: 56.22 - lr: 0.000781\n",
      "2020-10-22 13:07:33,420 epoch 105 - iter 219/736 - loss 0.07668860 - samples/sec: 64.31 - lr: 0.000781\n",
      "2020-10-22 13:07:51,099 epoch 105 - iter 292/736 - loss 0.07516075 - samples/sec: 67.40 - lr: 0.000781\n",
      "2020-10-22 13:08:08,407 epoch 105 - iter 365/736 - loss 0.07459057 - samples/sec: 68.88 - lr: 0.000781\n",
      "2020-10-22 13:08:26,765 epoch 105 - iter 438/736 - loss 0.07361605 - samples/sec: 64.90 - lr: 0.000781\n",
      "2020-10-22 13:08:45,992 epoch 105 - iter 511/736 - loss 0.07392771 - samples/sec: 61.86 - lr: 0.000781\n",
      "2020-10-22 13:09:04,637 epoch 105 - iter 584/736 - loss 0.07311971 - samples/sec: 62.92 - lr: 0.000781\n",
      "2020-10-22 13:09:23,999 epoch 105 - iter 657/736 - loss 0.07380046 - samples/sec: 62.43 - lr: 0.000781\n",
      "2020-10-22 13:09:42,064 epoch 105 - iter 730/736 - loss 0.07331507 - samples/sec: 65.94 - lr: 0.000781\n",
      "2020-10-22 13:09:43,507 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 13:09:43,508 EPOCH 105 done: loss 0.0731 - lr 0.0007813\n",
      "2020-10-22 13:10:45,280 DEV : loss 0.7148186564445496 - score 0.8445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   105: reducing learning rate of group 0 to 3.9063e-04.\n",
      "2020-10-22 13:10:47,190 BAD EPOCHS (no improvement): 6\n",
      "2020-10-22 13:10:47,191 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 13:11:05,877 epoch 106 - iter 73/736 - loss 0.06386210 - samples/sec: 64.16 - lr: 0.000391\n",
      "2020-10-22 13:11:24,167 epoch 106 - iter 146/736 - loss 0.06407240 - samples/sec: 65.09 - lr: 0.000391\n",
      "2020-10-22 13:11:41,890 epoch 106 - iter 219/736 - loss 0.06618554 - samples/sec: 66.18 - lr: 0.000391\n",
      "2020-10-22 13:11:59,351 epoch 106 - iter 292/736 - loss 0.07083982 - samples/sec: 68.22 - lr: 0.000391\n",
      "2020-10-22 13:12:18,912 epoch 106 - iter 365/736 - loss 0.07453130 - samples/sec: 60.78 - lr: 0.000391\n",
      "2020-10-22 13:12:36,366 epoch 106 - iter 438/736 - loss 0.07466258 - samples/sec: 67.22 - lr: 0.000391\n",
      "2020-10-22 13:12:56,661 epoch 106 - iter 511/736 - loss 0.07369853 - samples/sec: 58.56 - lr: 0.000391\n",
      "2020-10-22 13:13:15,057 epoch 106 - iter 584/736 - loss 0.07495385 - samples/sec: 64.71 - lr: 0.000391\n",
      "2020-10-22 13:13:33,206 epoch 106 - iter 657/736 - loss 0.07294242 - samples/sec: 65.62 - lr: 0.000391\n",
      "2020-10-22 13:13:52,405 epoch 106 - iter 730/736 - loss 0.07351013 - samples/sec: 61.05 - lr: 0.000391\n",
      "2020-10-22 13:13:54,575 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 13:13:54,576 EPOCH 106 done: loss 0.0732 - lr 0.0003906\n",
      "2020-10-22 13:14:54,739 DEV : loss 0.7143530249595642 - score 0.8448\n",
      "2020-10-22 13:14:56,624 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 13:14:56,625 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 13:15:14,826 epoch 107 - iter 73/736 - loss 0.08507014 - samples/sec: 66.06 - lr: 0.000391\n",
      "2020-10-22 13:15:32,428 epoch 107 - iter 146/736 - loss 0.08187823 - samples/sec: 67.84 - lr: 0.000391\n",
      "2020-10-22 13:15:51,820 epoch 107 - iter 219/736 - loss 0.07295634 - samples/sec: 62.32 - lr: 0.000391\n",
      "2020-10-22 13:16:10,851 epoch 107 - iter 292/736 - loss 0.07527211 - samples/sec: 61.69 - lr: 0.000391\n",
      "2020-10-22 13:16:29,351 epoch 107 - iter 365/736 - loss 0.07320418 - samples/sec: 63.41 - lr: 0.000391\n",
      "2020-10-22 13:16:47,131 epoch 107 - iter 438/736 - loss 0.07391251 - samples/sec: 67.02 - lr: 0.000391\n",
      "2020-10-22 13:17:06,048 epoch 107 - iter 511/736 - loss 0.07261596 - samples/sec: 62.95 - lr: 0.000391\n",
      "2020-10-22 13:17:25,607 epoch 107 - iter 584/736 - loss 0.07340831 - samples/sec: 60.05 - lr: 0.000391\n",
      "2020-10-22 13:17:45,442 epoch 107 - iter 657/736 - loss 0.07522068 - samples/sec: 59.94 - lr: 0.000391\n",
      "2020-10-22 13:18:04,594 epoch 107 - iter 730/736 - loss 0.07632440 - samples/sec: 61.23 - lr: 0.000391\n",
      "2020-10-22 13:18:06,022 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 13:18:06,023 EPOCH 107 done: loss 0.0759 - lr 0.0003906\n",
      "2020-10-22 13:19:07,454 DEV : loss 0.7146649956703186 - score 0.8453\n",
      "2020-10-22 13:19:09,415 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 13:19:09,416 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 13:19:27,557 epoch 108 - iter 73/736 - loss 0.06990322 - samples/sec: 66.32 - lr: 0.000391\n",
      "2020-10-22 13:19:46,065 epoch 108 - iter 146/736 - loss 0.07623059 - samples/sec: 64.37 - lr: 0.000391\n",
      "2020-10-22 13:20:05,380 epoch 108 - iter 219/736 - loss 0.07131205 - samples/sec: 61.62 - lr: 0.000391\n",
      "2020-10-22 13:20:24,191 epoch 108 - iter 292/736 - loss 0.07276669 - samples/sec: 63.35 - lr: 0.000391\n",
      "2020-10-22 13:20:43,031 epoch 108 - iter 365/736 - loss 0.07272838 - samples/sec: 63.20 - lr: 0.000391\n",
      "2020-10-22 13:21:01,891 epoch 108 - iter 438/736 - loss 0.07291772 - samples/sec: 63.20 - lr: 0.000391\n",
      "2020-10-22 13:21:20,700 epoch 108 - iter 511/736 - loss 0.07596554 - samples/sec: 63.32 - lr: 0.000391\n",
      "2020-10-22 13:21:39,355 epoch 108 - iter 584/736 - loss 0.07625980 - samples/sec: 62.94 - lr: 0.000391\n",
      "2020-10-22 13:21:59,275 epoch 108 - iter 657/736 - loss 0.07514091 - samples/sec: 59.70 - lr: 0.000391\n",
      "2020-10-22 13:22:19,914 epoch 108 - iter 730/736 - loss 0.07451666 - samples/sec: 57.63 - lr: 0.000391\n",
      "2020-10-22 13:22:20,960 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 13:22:20,961 EPOCH 108 done: loss 0.0750 - lr 0.0003906\n",
      "2020-10-22 13:23:21,547 DEV : loss 0.7138038277626038 - score 0.8453\n",
      "2020-10-22 13:23:23,455 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 13:23:23,456 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 13:23:41,908 epoch 109 - iter 73/736 - loss 0.07540473 - samples/sec: 65.07 - lr: 0.000391\n",
      "2020-10-22 13:24:01,433 epoch 109 - iter 146/736 - loss 0.06355795 - samples/sec: 60.94 - lr: 0.000391\n",
      "2020-10-22 13:24:22,001 epoch 109 - iter 219/736 - loss 0.06853644 - samples/sec: 57.77 - lr: 0.000391\n",
      "2020-10-22 13:24:42,185 epoch 109 - iter 292/736 - loss 0.06699754 - samples/sec: 58.09 - lr: 0.000391\n",
      "2020-10-22 13:24:59,825 epoch 109 - iter 365/736 - loss 0.06859777 - samples/sec: 67.53 - lr: 0.000391\n",
      "2020-10-22 13:25:19,485 epoch 109 - iter 438/736 - loss 0.07293443 - samples/sec: 61.35 - lr: 0.000391\n",
      "2020-10-22 13:25:36,659 epoch 109 - iter 511/736 - loss 0.07115818 - samples/sec: 69.38 - lr: 0.000391\n",
      "2020-10-22 13:25:55,174 epoch 109 - iter 584/736 - loss 0.07023537 - samples/sec: 63.34 - lr: 0.000391\n",
      "2020-10-22 13:26:13,747 epoch 109 - iter 657/736 - loss 0.07041000 - samples/sec: 64.06 - lr: 0.000391\n",
      "2020-10-22 13:26:32,054 epoch 109 - iter 730/736 - loss 0.07108569 - samples/sec: 66.12 - lr: 0.000391\n",
      "2020-10-22 13:26:33,823 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 13:26:33,824 EPOCH 109 done: loss 0.0712 - lr 0.0003906\n",
      "2020-10-22 13:27:34,341 DEV : loss 0.7136741876602173 - score 0.8453\n",
      "2020-10-22 13:27:36,244 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 13:27:36,245 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 13:27:54,942 epoch 110 - iter 73/736 - loss 0.07771963 - samples/sec: 64.14 - lr: 0.000391\n",
      "2020-10-22 13:28:13,566 epoch 110 - iter 146/736 - loss 0.07619533 - samples/sec: 63.96 - lr: 0.000391\n",
      "2020-10-22 13:28:31,993 epoch 110 - iter 219/736 - loss 0.08123909 - samples/sec: 64.68 - lr: 0.000391\n",
      "2020-10-22 13:28:50,016 epoch 110 - iter 292/736 - loss 0.07881832 - samples/sec: 65.15 - lr: 0.000391\n",
      "2020-10-22 13:29:08,699 epoch 110 - iter 365/736 - loss 0.07578393 - samples/sec: 62.80 - lr: 0.000391\n",
      "2020-10-22 13:29:27,382 epoch 110 - iter 438/736 - loss 0.07523877 - samples/sec: 63.73 - lr: 0.000391\n",
      "2020-10-22 13:29:46,627 epoch 110 - iter 511/736 - loss 0.07328750 - samples/sec: 62.77 - lr: 0.000391\n",
      "2020-10-22 13:30:04,965 epoch 110 - iter 584/736 - loss 0.07270647 - samples/sec: 63.97 - lr: 0.000391\n",
      "2020-10-22 13:30:25,388 epoch 110 - iter 657/736 - loss 0.07135639 - samples/sec: 58.27 - lr: 0.000391\n",
      "2020-10-22 13:30:44,012 epoch 110 - iter 730/736 - loss 0.07215487 - samples/sec: 64.02 - lr: 0.000391\n",
      "2020-10-22 13:30:45,428 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 13:30:45,429 EPOCH 110 done: loss 0.0726 - lr 0.0003906\n",
      "2020-10-22 13:31:46,345 DEV : loss 0.7164247035980225 - score 0.8451\n",
      "2020-10-22 13:31:48,269 BAD EPOCHS (no improvement): 5\n",
      "2020-10-22 13:31:48,270 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 13:32:07,274 epoch 111 - iter 73/736 - loss 0.06768361 - samples/sec: 62.10 - lr: 0.000391\n",
      "2020-10-22 13:32:25,173 epoch 111 - iter 146/736 - loss 0.07321902 - samples/sec: 66.56 - lr: 0.000391\n",
      "2020-10-22 13:32:43,735 epoch 111 - iter 219/736 - loss 0.07247799 - samples/sec: 64.18 - lr: 0.000391\n",
      "2020-10-22 13:33:02,165 epoch 111 - iter 292/736 - loss 0.07085427 - samples/sec: 65.67 - lr: 0.000391\n",
      "2020-10-22 13:33:19,952 epoch 111 - iter 365/736 - loss 0.07221695 - samples/sec: 67.04 - lr: 0.000391\n",
      "2020-10-22 13:33:40,017 epoch 111 - iter 438/736 - loss 0.07490471 - samples/sec: 59.30 - lr: 0.000391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 13:33:58,783 epoch 111 - iter 511/736 - loss 0.07121711 - samples/sec: 62.55 - lr: 0.000391\n",
      "2020-10-22 13:34:18,387 epoch 111 - iter 584/736 - loss 0.07290009 - samples/sec: 60.75 - lr: 0.000391\n",
      "2020-10-22 13:34:38,230 epoch 111 - iter 657/736 - loss 0.07342869 - samples/sec: 60.82 - lr: 0.000391\n",
      "2020-10-22 13:34:55,461 epoch 111 - iter 730/736 - loss 0.07343918 - samples/sec: 68.20 - lr: 0.000391\n",
      "2020-10-22 13:34:56,786 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 13:34:56,787 EPOCH 111 done: loss 0.0734 - lr 0.0003906\n",
      "2020-10-22 13:35:57,624 DEV : loss 0.7158766388893127 - score 0.8453\n",
      "Epoch   111: reducing learning rate of group 0 to 1.9531e-04.\n",
      "2020-10-22 13:35:59,518 BAD EPOCHS (no improvement): 6\n",
      "2020-10-22 13:35:59,519 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 13:36:18,497 epoch 112 - iter 73/736 - loss 0.06487043 - samples/sec: 62.25 - lr: 0.000195\n",
      "2020-10-22 13:36:37,148 epoch 112 - iter 146/736 - loss 0.07287822 - samples/sec: 63.87 - lr: 0.000195\n",
      "2020-10-22 13:36:57,112 epoch 112 - iter 219/736 - loss 0.07329381 - samples/sec: 58.74 - lr: 0.000195\n",
      "2020-10-22 13:37:16,114 epoch 112 - iter 292/736 - loss 0.07433066 - samples/sec: 62.65 - lr: 0.000195\n",
      "2020-10-22 13:37:33,325 epoch 112 - iter 365/736 - loss 0.07677353 - samples/sec: 69.28 - lr: 0.000195\n",
      "2020-10-22 13:37:52,350 epoch 112 - iter 438/736 - loss 0.07476249 - samples/sec: 62.57 - lr: 0.000195\n",
      "2020-10-22 13:38:11,498 epoch 112 - iter 511/736 - loss 0.07391090 - samples/sec: 62.22 - lr: 0.000195\n",
      "2020-10-22 13:38:29,526 epoch 112 - iter 584/736 - loss 0.07493251 - samples/sec: 66.11 - lr: 0.000195\n",
      "2020-10-22 13:38:48,075 epoch 112 - iter 657/736 - loss 0.07512353 - samples/sec: 63.28 - lr: 0.000195\n",
      "2020-10-22 13:39:05,847 epoch 112 - iter 730/736 - loss 0.07279276 - samples/sec: 66.09 - lr: 0.000195\n",
      "2020-10-22 13:39:07,012 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 13:39:07,013 EPOCH 112 done: loss 0.0725 - lr 0.0001953\n",
      "2020-10-22 13:40:07,823 DEV : loss 0.7154417037963867 - score 0.8445\n",
      "2020-10-22 13:40:09,717 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 13:40:09,717 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 13:40:28,632 epoch 113 - iter 73/736 - loss 0.07962785 - samples/sec: 63.41 - lr: 0.000195\n",
      "2020-10-22 13:40:47,692 epoch 113 - iter 146/736 - loss 0.07846068 - samples/sec: 61.59 - lr: 0.000195\n",
      "2020-10-22 13:41:09,617 epoch 113 - iter 219/736 - loss 0.07648694 - samples/sec: 54.20 - lr: 0.000195\n",
      "2020-10-22 13:41:27,764 epoch 113 - iter 292/736 - loss 0.07333182 - samples/sec: 65.74 - lr: 0.000195\n",
      "2020-10-22 13:41:45,250 epoch 113 - iter 365/736 - loss 0.07749589 - samples/sec: 68.24 - lr: 0.000195\n",
      "2020-10-22 13:42:02,489 epoch 113 - iter 438/736 - loss 0.07944976 - samples/sec: 69.18 - lr: 0.000195\n",
      "2020-10-22 13:42:21,140 epoch 113 - iter 511/736 - loss 0.07713287 - samples/sec: 63.82 - lr: 0.000195\n",
      "2020-10-22 13:42:40,596 epoch 113 - iter 584/736 - loss 0.07642839 - samples/sec: 62.03 - lr: 0.000195\n",
      "2020-10-22 13:42:58,184 epoch 113 - iter 657/736 - loss 0.07643570 - samples/sec: 66.73 - lr: 0.000195\n",
      "2020-10-22 13:43:16,179 epoch 113 - iter 730/736 - loss 0.07445554 - samples/sec: 66.25 - lr: 0.000195\n",
      "2020-10-22 13:43:17,360 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 13:43:17,360 EPOCH 113 done: loss 0.0742 - lr 0.0001953\n",
      "2020-10-22 13:44:18,247 DEV : loss 0.7161622047424316 - score 0.8453\n",
      "2020-10-22 13:44:20,152 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 13:44:20,152 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 13:44:38,498 epoch 114 - iter 73/736 - loss 0.08460188 - samples/sec: 64.36 - lr: 0.000195\n",
      "2020-10-22 13:44:57,661 epoch 114 - iter 146/736 - loss 0.07806078 - samples/sec: 63.03 - lr: 0.000195\n",
      "2020-10-22 13:45:15,702 epoch 114 - iter 219/736 - loss 0.07845584 - samples/sec: 66.03 - lr: 0.000195\n",
      "2020-10-22 13:45:34,773 epoch 114 - iter 292/736 - loss 0.07613892 - samples/sec: 62.42 - lr: 0.000195\n",
      "2020-10-22 13:45:53,974 epoch 114 - iter 365/736 - loss 0.07736669 - samples/sec: 61.99 - lr: 0.000195\n",
      "2020-10-22 13:46:12,495 epoch 114 - iter 438/736 - loss 0.07411350 - samples/sec: 65.34 - lr: 0.000195\n",
      "2020-10-22 13:46:30,855 epoch 114 - iter 511/736 - loss 0.07197121 - samples/sec: 64.89 - lr: 0.000195\n",
      "2020-10-22 13:46:50,474 epoch 114 - iter 584/736 - loss 0.07467109 - samples/sec: 60.63 - lr: 0.000195\n",
      "2020-10-22 13:47:09,037 epoch 114 - iter 657/736 - loss 0.07455876 - samples/sec: 65.15 - lr: 0.000195\n",
      "2020-10-22 13:47:26,966 epoch 114 - iter 730/736 - loss 0.07265023 - samples/sec: 66.46 - lr: 0.000195\n",
      "2020-10-22 13:47:28,604 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 13:47:28,605 EPOCH 114 done: loss 0.0725 - lr 0.0001953\n",
      "2020-10-22 13:48:29,339 DEV : loss 0.7151114344596863 - score 0.8448\n",
      "2020-10-22 13:48:31,244 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 13:48:31,245 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 13:48:49,971 epoch 115 - iter 73/736 - loss 0.06558629 - samples/sec: 63.11 - lr: 0.000195\n",
      "2020-10-22 13:49:08,081 epoch 115 - iter 146/736 - loss 0.06834682 - samples/sec: 64.78 - lr: 0.000195\n",
      "2020-10-22 13:49:26,618 epoch 115 - iter 219/736 - loss 0.07334983 - samples/sec: 64.25 - lr: 0.000195\n",
      "2020-10-22 13:49:48,289 epoch 115 - iter 292/736 - loss 0.07378854 - samples/sec: 55.57 - lr: 0.000195\n",
      "2020-10-22 13:50:05,165 epoch 115 - iter 365/736 - loss 0.07311285 - samples/sec: 70.77 - lr: 0.000195\n",
      "2020-10-22 13:50:23,707 epoch 115 - iter 438/736 - loss 0.07196964 - samples/sec: 64.33 - lr: 0.000195\n",
      "2020-10-22 13:50:42,874 epoch 115 - iter 511/736 - loss 0.07286795 - samples/sec: 61.26 - lr: 0.000195\n",
      "2020-10-22 13:51:01,591 epoch 115 - iter 584/736 - loss 0.07491266 - samples/sec: 62.74 - lr: 0.000195\n",
      "2020-10-22 13:51:20,970 epoch 115 - iter 657/736 - loss 0.07795011 - samples/sec: 61.38 - lr: 0.000195\n",
      "2020-10-22 13:51:39,362 epoch 115 - iter 730/736 - loss 0.07622694 - samples/sec: 64.78 - lr: 0.000195\n",
      "2020-10-22 13:51:40,592 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 13:51:40,593 EPOCH 115 done: loss 0.0769 - lr 0.0001953\n",
      "2020-10-22 13:52:41,385 DEV : loss 0.7154715061187744 - score 0.8445\n",
      "2020-10-22 13:52:43,330 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 13:52:43,330 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 13:53:02,422 epoch 116 - iter 73/736 - loss 0.05820900 - samples/sec: 62.77 - lr: 0.000195\n",
      "2020-10-22 13:53:22,546 epoch 116 - iter 146/736 - loss 0.06362522 - samples/sec: 58.33 - lr: 0.000195\n",
      "2020-10-22 13:53:42,058 epoch 116 - iter 219/736 - loss 0.06425555 - samples/sec: 60.99 - lr: 0.000195\n",
      "2020-10-22 13:53:59,906 epoch 116 - iter 292/736 - loss 0.06822606 - samples/sec: 66.71 - lr: 0.000195\n",
      "2020-10-22 13:54:18,880 epoch 116 - iter 365/736 - loss 0.06805474 - samples/sec: 64.03 - lr: 0.000195\n",
      "2020-10-22 13:54:36,878 epoch 116 - iter 438/736 - loss 0.06747225 - samples/sec: 66.21 - lr: 0.000195\n",
      "2020-10-22 13:54:57,322 epoch 116 - iter 511/736 - loss 0.07122480 - samples/sec: 57.37 - lr: 0.000195\n",
      "2020-10-22 13:55:14,772 epoch 116 - iter 584/736 - loss 0.07255819 - samples/sec: 68.32 - lr: 0.000195\n",
      "2020-10-22 13:55:33,816 epoch 116 - iter 657/736 - loss 0.07249004 - samples/sec: 62.58 - lr: 0.000195\n",
      "2020-10-22 13:55:52,213 epoch 116 - iter 730/736 - loss 0.07395245 - samples/sec: 63.78 - lr: 0.000195\n",
      "2020-10-22 13:55:53,469 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 13:55:53,469 EPOCH 116 done: loss 0.0736 - lr 0.0001953\n",
      "2020-10-22 13:56:54,361 DEV : loss 0.7162573337554932 - score 0.8448\n",
      "2020-10-22 13:56:56,282 BAD EPOCHS (no improvement): 5\n",
      "2020-10-22 13:56:56,283 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 13:57:15,598 epoch 117 - iter 73/736 - loss 0.07890967 - samples/sec: 61.11 - lr: 0.000195\n",
      "2020-10-22 13:57:33,078 epoch 117 - iter 146/736 - loss 0.09450423 - samples/sec: 67.14 - lr: 0.000195\n",
      "2020-10-22 13:57:52,854 epoch 117 - iter 219/736 - loss 0.08524608 - samples/sec: 59.35 - lr: 0.000195\n",
      "2020-10-22 13:58:11,174 epoch 117 - iter 292/736 - loss 0.08235634 - samples/sec: 65.02 - lr: 0.000195\n",
      "2020-10-22 13:58:29,317 epoch 117 - iter 365/736 - loss 0.07857722 - samples/sec: 65.77 - lr: 0.000195\n",
      "2020-10-22 13:58:48,658 epoch 117 - iter 438/736 - loss 0.07764626 - samples/sec: 61.59 - lr: 0.000195\n",
      "2020-10-22 13:59:07,196 epoch 117 - iter 511/736 - loss 0.07607066 - samples/sec: 64.25 - lr: 0.000195\n",
      "2020-10-22 13:59:26,489 epoch 117 - iter 584/736 - loss 0.07461531 - samples/sec: 60.79 - lr: 0.000195\n",
      "2020-10-22 13:59:45,802 epoch 117 - iter 657/736 - loss 0.07294729 - samples/sec: 61.57 - lr: 0.000195\n",
      "2020-10-22 14:00:04,218 epoch 117 - iter 730/736 - loss 0.07321712 - samples/sec: 64.66 - lr: 0.000195\n",
      "2020-10-22 14:00:05,648 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:00:05,649 EPOCH 117 done: loss 0.0739 - lr 0.0001953\n",
      "2020-10-22 14:01:06,432 DEV : loss 0.7152702212333679 - score 0.8445\n",
      "Epoch   117: reducing learning rate of group 0 to 9.7656e-05.\n",
      "2020-10-22 14:01:08,329 BAD EPOCHS (no improvement): 6\n",
      "2020-10-22 14:01:08,329 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:01:08,330 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:01:08,330 learning rate too small - quitting training!\n",
      "2020-10-22 14:01:08,331 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:01:10,238 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:01:10,239 Testing using best model ...\n",
      "2020-10-22 14:01:10,240 loading file classifiers/spooky_authorship_classifier_glove&news-fbflair/best-model.pt\n",
      "2020-10-22 14:02:06,730 \t0.8479\n",
      "2020-10-22 14:02:06,731 \n",
      "Results:\n",
      "- F-score (micro) 0.8479\n",
      "- F-score (macro) 0.8484\n",
      "- Accuracy 0.8479\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         EAP     0.8434    0.8456    0.8445      1554\n",
      "         MWS     0.8484    0.8322    0.8402      1210\n",
      "         HPL     0.8536    0.8678    0.8606      1142\n",
      "\n",
      "   micro avg     0.8479    0.8479    0.8479      3906\n",
      "   macro avg     0.8484    0.8485    0.8484      3906\n",
      "weighted avg     0.8479    0.8479    0.8479      3906\n",
      " samples avg     0.8479    0.8479    0.8479      3906\n",
      "\n",
      "2020-10-22 14:02:06,731 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.8479,\n",
       " 'dev_score_history': [0.5313,\n",
       "  0.5973,\n",
       "  0.6129,\n",
       "  0.5883,\n",
       "  0.7433,\n",
       "  0.7686,\n",
       "  0.7246,\n",
       "  0.7428,\n",
       "  0.776,\n",
       "  0.7683,\n",
       "  0.764,\n",
       "  0.7891,\n",
       "  0.7415,\n",
       "  0.7954,\n",
       "  0.7724,\n",
       "  0.7919,\n",
       "  0.7384,\n",
       "  0.7908,\n",
       "  0.7768,\n",
       "  0.7977,\n",
       "  0.8057,\n",
       "  0.7763,\n",
       "  0.8113,\n",
       "  0.798,\n",
       "  0.7949,\n",
       "  0.787,\n",
       "  0.8072,\n",
       "  0.8021,\n",
       "  0.785,\n",
       "  0.8179,\n",
       "  0.8192,\n",
       "  0.8259,\n",
       "  0.8307,\n",
       "  0.8213,\n",
       "  0.8151,\n",
       "  0.8266,\n",
       "  0.832,\n",
       "  0.8249,\n",
       "  0.8297,\n",
       "  0.8346,\n",
       "  0.8266,\n",
       "  0.8289,\n",
       "  0.8233,\n",
       "  0.8295,\n",
       "  0.8249,\n",
       "  0.8246,\n",
       "  0.8292,\n",
       "  0.8333,\n",
       "  0.8346,\n",
       "  0.8366,\n",
       "  0.8333,\n",
       "  0.8394,\n",
       "  0.8338,\n",
       "  0.8346,\n",
       "  0.8338,\n",
       "  0.8284,\n",
       "  0.8394,\n",
       "  0.8335,\n",
       "  0.8415,\n",
       "  0.8394,\n",
       "  0.8402,\n",
       "  0.8394,\n",
       "  0.8399,\n",
       "  0.843,\n",
       "  0.8425,\n",
       "  0.8399,\n",
       "  0.8374,\n",
       "  0.844,\n",
       "  0.8405,\n",
       "  0.842,\n",
       "  0.8387,\n",
       "  0.8394,\n",
       "  0.842,\n",
       "  0.8381,\n",
       "  0.8422,\n",
       "  0.842,\n",
       "  0.8407,\n",
       "  0.8417,\n",
       "  0.8402,\n",
       "  0.8415,\n",
       "  0.841,\n",
       "  0.8435,\n",
       "  0.8407,\n",
       "  0.8438,\n",
       "  0.8435,\n",
       "  0.8402,\n",
       "  0.8453,\n",
       "  0.8428,\n",
       "  0.8458,\n",
       "  0.844,\n",
       "  0.8445,\n",
       "  0.8438,\n",
       "  0.8458,\n",
       "  0.8458,\n",
       "  0.8448,\n",
       "  0.8456,\n",
       "  0.8435,\n",
       "  0.8428,\n",
       "  0.8453,\n",
       "  0.8448,\n",
       "  0.8456,\n",
       "  0.8445,\n",
       "  0.8445,\n",
       "  0.8453,\n",
       "  0.8445,\n",
       "  0.8448,\n",
       "  0.8453,\n",
       "  0.8453,\n",
       "  0.8453,\n",
       "  0.8451,\n",
       "  0.8453,\n",
       "  0.8445,\n",
       "  0.8453,\n",
       "  0.8448,\n",
       "  0.8445,\n",
       "  0.8448,\n",
       "  0.8445],\n",
       " 'train_loss_history': [1.0200067060473172,\n",
       "  0.8303772748609923,\n",
       "  0.754198162553265,\n",
       "  0.7072565125544434,\n",
       "  0.6751712359609487,\n",
       "  0.6518611201596365,\n",
       "  0.6309220282482388,\n",
       "  0.6123433555476367,\n",
       "  0.5913018859953255,\n",
       "  0.5753045669787199,\n",
       "  0.549362923119865,\n",
       "  0.5426916876129563,\n",
       "  0.5202101404960875,\n",
       "  0.5044255319871414,\n",
       "  0.5016233134994527,\n",
       "  0.48703559991174744,\n",
       "  0.48656625443381135,\n",
       "  0.4678380927577129,\n",
       "  0.46800756213538675,\n",
       "  0.44925086674329184,\n",
       "  0.4434007049194011,\n",
       "  0.436048117901563,\n",
       "  0.43336653296390304,\n",
       "  0.4203296890017278,\n",
       "  0.408012262469603,\n",
       "  0.4182022762617397,\n",
       "  0.39727311817746935,\n",
       "  0.39171956592421653,\n",
       "  0.3981281039659339,\n",
       "  0.3387665938049474,\n",
       "  0.2970435116674154,\n",
       "  0.2934602427931563,\n",
       "  0.2750058846523525,\n",
       "  0.27301456479598646,\n",
       "  0.2561242170340847,\n",
       "  0.2570422482588227,\n",
       "  0.25152403484706,\n",
       "  0.24146866516852955,\n",
       "  0.23258797421104924,\n",
       "  0.2304238386037152,\n",
       "  0.22813075152099255,\n",
       "  0.2140348434173654,\n",
       "  0.21108369992789053,\n",
       "  0.2161083625377733,\n",
       "  0.21110124378118716,\n",
       "  0.21480270501975293,\n",
       "  0.1779286881716436,\n",
       "  0.16621855026143906,\n",
       "  0.16268613751558209,\n",
       "  0.15257678828975654,\n",
       "  0.1536545178276593,\n",
       "  0.1633805488369114,\n",
       "  0.147812962816913,\n",
       "  0.14152235409817324,\n",
       "  0.13773935423571104,\n",
       "  0.144043157619545,\n",
       "  0.13971565963014576,\n",
       "  0.1313829821905842,\n",
       "  0.12353140806139297,\n",
       "  0.1163427979808662,\n",
       "  0.11227687840528233,\n",
       "  0.115343150746412,\n",
       "  0.11042951641296817,\n",
       "  0.10530222848525306,\n",
       "  0.10908012244387129,\n",
       "  0.10717370566333004,\n",
       "  0.1038463901820174,\n",
       "  0.09779786416441746,\n",
       "  0.09938462015732155,\n",
       "  0.09375983957496675,\n",
       "  0.10165470003539667,\n",
       "  0.09649329842645586,\n",
       "  0.09352996533408733,\n",
       "  0.08913403086982093,\n",
       "  0.08994699396314741,\n",
       "  0.09017768630545343,\n",
       "  0.08390825173825325,\n",
       "  0.08907705798499235,\n",
       "  0.08894493214148971,\n",
       "  0.08087948020855275,\n",
       "  0.08269086464551688,\n",
       "  0.07845306994880483,\n",
       "  0.07562086629647277,\n",
       "  0.08217356715668143,\n",
       "  0.07536297259315214,\n",
       "  0.07193884342639292,\n",
       "  0.07591549038822806,\n",
       "  0.07951984785627837,\n",
       "  0.07741915106496731,\n",
       "  0.07714286861362227,\n",
       "  0.07438022096288399,\n",
       "  0.08018305101164891,\n",
       "  0.07926309525385516,\n",
       "  0.06922477997057325,\n",
       "  0.07734096937549664,\n",
       "  0.07351936493279501,\n",
       "  0.0765478981167452,\n",
       "  0.07258716455656734,\n",
       "  0.08026618297774644,\n",
       "  0.07817219410832837,\n",
       "  0.07770976492623088,\n",
       "  0.06971684479092642,\n",
       "  0.07628933966296482,\n",
       "  0.07936038307593168,\n",
       "  0.0731347866530378,\n",
       "  0.07315869923039155,\n",
       "  0.07587542112413877,\n",
       "  0.07497173686503986,\n",
       "  0.07117801262078817,\n",
       "  0.07257596751688929,\n",
       "  0.07342166190258705,\n",
       "  0.07245439865889002,\n",
       "  0.07415169817642456,\n",
       "  0.07249856803046777,\n",
       "  0.076893627318342,\n",
       "  0.0736120331193888,\n",
       "  0.07393440555380415],\n",
       " 'dev_loss_history': [1.009886622428894,\n",
       "  1.1358106136322021,\n",
       "  0.8620967864990234,\n",
       "  1.021492600440979,\n",
       "  0.6200922131538391,\n",
       "  0.5613307952880859,\n",
       "  0.6456136703491211,\n",
       "  0.5962257385253906,\n",
       "  0.5528645515441895,\n",
       "  0.5725451707839966,\n",
       "  0.630522608757019,\n",
       "  0.5371719002723694,\n",
       "  0.6477855443954468,\n",
       "  0.5209782123565674,\n",
       "  0.5579744577407837,\n",
       "  0.5080968141555786,\n",
       "  0.6652133464813232,\n",
       "  0.5257486701011658,\n",
       "  0.5615853667259216,\n",
       "  0.5070930123329163,\n",
       "  0.5002753734588623,\n",
       "  0.5911500453948975,\n",
       "  0.48096325993537903,\n",
       "  0.5367706418037415,\n",
       "  0.5383281707763672,\n",
       "  0.5701597332954407,\n",
       "  0.5126873850822449,\n",
       "  0.594586193561554,\n",
       "  0.6212007999420166,\n",
       "  0.521003246307373,\n",
       "  0.5170812010765076,\n",
       "  0.5035133957862854,\n",
       "  0.4999881684780121,\n",
       "  0.5365239381790161,\n",
       "  0.5796636343002319,\n",
       "  0.5197863578796387,\n",
       "  0.49242648482322693,\n",
       "  0.5293952822685242,\n",
       "  0.5343804359436035,\n",
       "  0.5304630398750305,\n",
       "  0.5368749499320984,\n",
       "  0.5558646321296692,\n",
       "  0.5683118104934692,\n",
       "  0.5766856074333191,\n",
       "  0.5627546310424805,\n",
       "  0.5851114392280579,\n",
       "  0.5643427968025208,\n",
       "  0.5872879028320312,\n",
       "  0.579181432723999,\n",
       "  0.5931603908538818,\n",
       "  0.6113426089286804,\n",
       "  0.5649566054344177,\n",
       "  0.5942766666412354,\n",
       "  0.6105837821960449,\n",
       "  0.6079531908035278,\n",
       "  0.6070231199264526,\n",
       "  0.6183484196662903,\n",
       "  0.6073762774467468,\n",
       "  0.6304786801338196,\n",
       "  0.6157329082489014,\n",
       "  0.6354625225067139,\n",
       "  0.6503371596336365,\n",
       "  0.6459441184997559,\n",
       "  0.6526696085929871,\n",
       "  0.652846097946167,\n",
       "  0.6417397260665894,\n",
       "  0.6486195921897888,\n",
       "  0.6617417931556702,\n",
       "  0.6613734364509583,\n",
       "  0.6841060519218445,\n",
       "  0.687505841255188,\n",
       "  0.6853747963905334,\n",
       "  0.6866753101348877,\n",
       "  0.6824848651885986,\n",
       "  0.6816048622131348,\n",
       "  0.694217324256897,\n",
       "  0.6827808022499084,\n",
       "  0.7002137303352356,\n",
       "  0.6890091300010681,\n",
       "  0.6866728663444519,\n",
       "  0.6899042129516602,\n",
       "  0.6886056065559387,\n",
       "  0.7091188430786133,\n",
       "  0.7006726264953613,\n",
       "  0.7089893817901611,\n",
       "  0.7176063060760498,\n",
       "  0.7124070525169373,\n",
       "  0.7151715159416199,\n",
       "  0.7094969749450684,\n",
       "  0.7094692587852478,\n",
       "  0.7044902443885803,\n",
       "  0.7093534469604492,\n",
       "  0.7067185044288635,\n",
       "  0.7108713388442993,\n",
       "  0.7145946621894836,\n",
       "  0.7127903699874878,\n",
       "  0.7182106971740723,\n",
       "  0.7241418361663818,\n",
       "  0.713102400302887,\n",
       "  0.7138060927391052,\n",
       "  0.7173023819923401,\n",
       "  0.7184915542602539,\n",
       "  0.7160332202911377,\n",
       "  0.7149839401245117,\n",
       "  0.7148186564445496,\n",
       "  0.7143530249595642,\n",
       "  0.7146649956703186,\n",
       "  0.7138038277626038,\n",
       "  0.7136741876602173,\n",
       "  0.7164247035980225,\n",
       "  0.7158766388893127,\n",
       "  0.7154417037963867,\n",
       "  0.7161622047424316,\n",
       "  0.7151114344596863,\n",
       "  0.7154715061187744,\n",
       "  0.7162573337554932,\n",
       "  0.7152702212333679]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "word_embeddings = [WordEmbeddings('glove'), FlairEmbeddings('news-forward'), FlairEmbeddings('news-backward')]\n",
    "\n",
    "document_embeddings = DocumentRNNEmbeddings(word_embeddings, hidden_size=256)\n",
    "\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)\n",
    "\n",
    "trainer = ModelTrainer(classifier, corpus)\n",
    "\n",
    "trainer.train('classifiers/spooky_authorship_classifier_glove&news-fbflair',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=16,\n",
    "              anneal_factor=0.5,\n",
    "              patience=5,\n",
    "              max_epochs=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bert embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 14:02:09,538 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:02:09,540 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): TransformerWordEmbeddings(\n",
      "        (model): BertModel(\n",
      "          (embeddings): BertEmbeddings(\n",
      "            (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "            (position_embeddings): Embedding(512, 768)\n",
      "            (token_type_embeddings): Embedding(2, 768)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (encoder): BertEncoder(\n",
      "            (layer): ModuleList(\n",
      "              (0): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (1): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (2): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (3): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (4): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (5): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (6): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (7): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (8): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (9): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (10): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (11): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (pooler): BertPooler(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (activation): Tanh()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=3072, out_features=3072, bias=True)\n",
      "    (rnn): GRU(3072, 256, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=256, out_features=3, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 14:02:09,541 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:02:09,541 Corpus: \"Corpus: 11762 train + 3911 dev + 3906 test sentences\"\n",
      "2020-10-22 14:02:09,542 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:02:09,542 Parameters:\n",
      "2020-10-22 14:02:09,542  - learning_rate: \"0.1\"\n",
      "2020-10-22 14:02:09,543  - mini_batch_size: \"32\"\n",
      "2020-10-22 14:02:09,543  - patience: \"5\"\n",
      "2020-10-22 14:02:09,543  - anneal_factor: \"0.5\"\n",
      "2020-10-22 14:02:09,544  - max_epochs: \"150\"\n",
      "2020-10-22 14:02:09,544  - shuffle: \"True\"\n",
      "2020-10-22 14:02:09,544  - train_with_dev: \"False\"\n",
      "2020-10-22 14:02:09,544  - batch_growth_annealing: \"False\"\n",
      "2020-10-22 14:02:09,545 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:02:09,545 Model training base path: \"classifiers/spooky_authorship_classifier_bert\"\n",
      "2020-10-22 14:02:09,546 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:02:09,546 Device: cuda:0\n",
      "2020-10-22 14:02:09,546 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:02:09,547 Embeddings storage mode: cpu\n",
      "2020-10-22 14:02:09,549 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:02:27,062 epoch 1 - iter 36/368 - loss 1.66928314 - samples/sec: 67.95 - lr: 0.100000\n",
      "2020-10-22 14:02:43,245 epoch 1 - iter 72/368 - loss 1.41988285 - samples/sec: 72.52 - lr: 0.100000\n",
      "2020-10-22 14:02:59,619 epoch 1 - iter 108/368 - loss 1.26066699 - samples/sec: 70.65 - lr: 0.100000\n",
      "2020-10-22 14:03:16,274 epoch 1 - iter 144/368 - loss 1.15766541 - samples/sec: 70.46 - lr: 0.100000\n",
      "2020-10-22 14:03:32,818 epoch 1 - iter 180/368 - loss 1.08006881 - samples/sec: 70.90 - lr: 0.100000\n",
      "2020-10-22 14:03:49,503 epoch 1 - iter 216/368 - loss 1.02824719 - samples/sec: 70.36 - lr: 0.100000\n",
      "2020-10-22 14:04:06,308 epoch 1 - iter 252/368 - loss 0.99391001 - samples/sec: 69.81 - lr: 0.100000\n",
      "2020-10-22 14:04:22,839 epoch 1 - iter 288/368 - loss 0.96511438 - samples/sec: 70.97 - lr: 0.100000\n",
      "2020-10-22 14:04:39,356 epoch 1 - iter 324/368 - loss 0.94750314 - samples/sec: 70.04 - lr: 0.100000\n",
      "2020-10-22 14:04:55,949 epoch 1 - iter 360/368 - loss 0.92644379 - samples/sec: 70.72 - lr: 0.100000\n",
      "2020-10-22 14:04:59,387 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:04:59,387 EPOCH 1 done: loss 0.9221 - lr 0.1000000\n",
      "2020-10-22 14:05:47,031 DEV : loss 0.642713189125061 - score 0.7223\n",
      "2020-10-22 14:05:48,956 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 14:05:49,588 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:06:06,333 epoch 2 - iter 36/368 - loss 0.71681239 - samples/sec: 71.04 - lr: 0.100000\n",
      "2020-10-22 14:06:22,658 epoch 2 - iter 72/368 - loss 0.69224408 - samples/sec: 70.84 - lr: 0.100000\n",
      "2020-10-22 14:06:38,901 epoch 2 - iter 108/368 - loss 0.69091057 - samples/sec: 72.23 - lr: 0.100000\n",
      "2020-10-22 14:06:55,332 epoch 2 - iter 144/368 - loss 0.67512749 - samples/sec: 71.49 - lr: 0.100000\n",
      "2020-10-22 14:07:11,958 epoch 2 - iter 180/368 - loss 0.67132338 - samples/sec: 70.57 - lr: 0.100000\n",
      "2020-10-22 14:07:28,971 epoch 2 - iter 216/368 - loss 0.67124581 - samples/sec: 69.03 - lr: 0.100000\n",
      "2020-10-22 14:07:45,390 epoch 2 - iter 252/368 - loss 0.67349555 - samples/sec: 70.45 - lr: 0.100000\n",
      "2020-10-22 14:08:01,819 epoch 2 - iter 288/368 - loss 0.67678632 - samples/sec: 71.49 - lr: 0.100000\n",
      "2020-10-22 14:08:18,464 epoch 2 - iter 324/368 - loss 0.67850093 - samples/sec: 70.55 - lr: 0.100000\n",
      "2020-10-22 14:08:34,821 epoch 2 - iter 360/368 - loss 0.67649070 - samples/sec: 71.75 - lr: 0.100000\n",
      "2020-10-22 14:08:38,263 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:08:38,264 EPOCH 2 done: loss 0.6762 - lr 0.1000000\n",
      "2020-10-22 14:09:25,854 DEV : loss 0.6609243154525757 - score 0.7195\n",
      "2020-10-22 14:09:27,988 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 14:09:27,989 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:09:44,506 epoch 3 - iter 36/368 - loss 0.60335319 - samples/sec: 70.77 - lr: 0.100000\n",
      "2020-10-22 14:10:01,323 epoch 3 - iter 72/368 - loss 0.57914571 - samples/sec: 69.88 - lr: 0.100000\n",
      "2020-10-22 14:10:18,048 epoch 3 - iter 108/368 - loss 0.60200137 - samples/sec: 70.17 - lr: 0.100000\n",
      "2020-10-22 14:10:34,665 epoch 3 - iter 144/368 - loss 0.60657374 - samples/sec: 70.65 - lr: 0.100000\n",
      "2020-10-22 14:10:51,202 epoch 3 - iter 180/368 - loss 0.61319868 - samples/sec: 70.99 - lr: 0.100000\n",
      "2020-10-22 14:11:07,829 epoch 3 - iter 216/368 - loss 0.61334759 - samples/sec: 69.59 - lr: 0.100000\n",
      "2020-10-22 14:11:24,741 epoch 3 - iter 252/368 - loss 0.61971061 - samples/sec: 69.40 - lr: 0.100000\n",
      "2020-10-22 14:11:41,451 epoch 3 - iter 288/368 - loss 0.62270123 - samples/sec: 70.24 - lr: 0.100000\n",
      "2020-10-22 14:11:57,858 epoch 3 - iter 324/368 - loss 0.62752828 - samples/sec: 71.50 - lr: 0.100000\n",
      "2020-10-22 14:12:14,204 epoch 3 - iter 360/368 - loss 0.62327837 - samples/sec: 70.76 - lr: 0.100000\n",
      "2020-10-22 14:12:17,927 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:12:17,928 EPOCH 3 done: loss 0.6227 - lr 0.1000000\n",
      "2020-10-22 14:13:05,489 DEV : loss 0.5206485986709595 - score 0.7901\n",
      "2020-10-22 14:13:07,411 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 14:13:08,127 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:13:24,816 epoch 4 - iter 36/368 - loss 0.55711251 - samples/sec: 71.14 - lr: 0.100000\n",
      "2020-10-22 14:13:40,957 epoch 4 - iter 72/368 - loss 0.58890174 - samples/sec: 71.67 - lr: 0.100000\n",
      "2020-10-22 14:13:57,557 epoch 4 - iter 108/368 - loss 0.60856796 - samples/sec: 70.68 - lr: 0.100000\n",
      "2020-10-22 14:14:14,077 epoch 4 - iter 144/368 - loss 0.60141318 - samples/sec: 71.08 - lr: 0.100000\n",
      "2020-10-22 14:14:30,880 epoch 4 - iter 180/368 - loss 0.60589776 - samples/sec: 69.80 - lr: 0.100000\n",
      "2020-10-22 14:14:47,918 epoch 4 - iter 216/368 - loss 0.60971625 - samples/sec: 68.92 - lr: 0.100000\n",
      "2020-10-22 14:15:04,572 epoch 4 - iter 252/368 - loss 0.61374402 - samples/sec: 70.50 - lr: 0.100000\n",
      "2020-10-22 14:15:21,259 epoch 4 - iter 288/368 - loss 0.62045129 - samples/sec: 70.34 - lr: 0.100000\n",
      "2020-10-22 14:15:37,680 epoch 4 - iter 324/368 - loss 0.61729887 - samples/sec: 70.46 - lr: 0.100000\n",
      "2020-10-22 14:15:54,453 epoch 4 - iter 360/368 - loss 0.61518125 - samples/sec: 70.00 - lr: 0.100000\n",
      "2020-10-22 14:15:57,857 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:15:57,858 EPOCH 4 done: loss 0.6143 - lr 0.1000000\n",
      "2020-10-22 14:16:45,911 DEV : loss 0.5330621600151062 - score 0.7735\n",
      "2020-10-22 14:16:47,846 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 14:16:47,847 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:17:04,520 epoch 5 - iter 36/368 - loss 0.55478604 - samples/sec: 71.29 - lr: 0.100000\n",
      "2020-10-22 14:17:20,807 epoch 5 - iter 72/368 - loss 0.57210413 - samples/sec: 71.04 - lr: 0.100000\n",
      "2020-10-22 14:17:37,511 epoch 5 - iter 108/368 - loss 0.57625159 - samples/sec: 70.28 - lr: 0.100000\n",
      "2020-10-22 14:17:54,637 epoch 5 - iter 144/368 - loss 0.55873459 - samples/sec: 68.53 - lr: 0.100000\n",
      "2020-10-22 14:18:10,988 epoch 5 - iter 180/368 - loss 0.56094306 - samples/sec: 71.82 - lr: 0.100000\n",
      "2020-10-22 14:18:27,295 epoch 5 - iter 216/368 - loss 0.56104035 - samples/sec: 72.02 - lr: 0.100000\n",
      "2020-10-22 14:18:43,755 epoch 5 - iter 252/368 - loss 0.57170477 - samples/sec: 71.34 - lr: 0.100000\n",
      "2020-10-22 14:19:00,161 epoch 5 - iter 288/368 - loss 0.57353688 - samples/sec: 71.60 - lr: 0.100000\n",
      "2020-10-22 14:19:16,309 epoch 5 - iter 324/368 - loss 0.57806159 - samples/sec: 72.75 - lr: 0.100000\n",
      "2020-10-22 14:19:32,795 epoch 5 - iter 360/368 - loss 0.57861648 - samples/sec: 71.25 - lr: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 14:19:36,282 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:19:36,282 EPOCH 5 done: loss 0.5798 - lr 0.1000000\n",
      "2020-10-22 14:20:23,867 DEV : loss 0.7465242147445679 - score 0.6891\n",
      "2020-10-22 14:20:25,766 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 14:20:25,767 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:20:42,654 epoch 6 - iter 36/368 - loss 0.51457353 - samples/sec: 70.37 - lr: 0.100000\n",
      "2020-10-22 14:20:59,459 epoch 6 - iter 72/368 - loss 0.51202875 - samples/sec: 69.80 - lr: 0.100000\n",
      "2020-10-22 14:21:16,020 epoch 6 - iter 108/368 - loss 0.53477021 - samples/sec: 70.87 - lr: 0.100000\n",
      "2020-10-22 14:21:32,424 epoch 6 - iter 144/368 - loss 0.54743409 - samples/sec: 71.59 - lr: 0.100000\n",
      "2020-10-22 14:21:48,974 epoch 6 - iter 180/368 - loss 0.54946897 - samples/sec: 70.98 - lr: 0.100000\n",
      "2020-10-22 14:22:05,394 epoch 6 - iter 216/368 - loss 0.55672478 - samples/sec: 71.50 - lr: 0.100000\n",
      "2020-10-22 14:22:21,710 epoch 6 - iter 252/368 - loss 0.55330317 - samples/sec: 70.90 - lr: 0.100000\n",
      "2020-10-22 14:22:38,321 epoch 6 - iter 288/368 - loss 0.55045415 - samples/sec: 70.69 - lr: 0.100000\n",
      "2020-10-22 14:22:54,909 epoch 6 - iter 324/368 - loss 0.55486841 - samples/sec: 70.76 - lr: 0.100000\n",
      "2020-10-22 14:23:11,551 epoch 6 - iter 360/368 - loss 0.55001828 - samples/sec: 70.56 - lr: 0.100000\n",
      "2020-10-22 14:23:15,097 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:23:15,098 EPOCH 6 done: loss 0.5499 - lr 0.1000000\n",
      "2020-10-22 14:24:02,534 DEV : loss 0.6956577897071838 - score 0.7216\n",
      "2020-10-22 14:24:04,412 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 14:24:04,412 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:24:21,466 epoch 7 - iter 36/368 - loss 0.57972260 - samples/sec: 69.60 - lr: 0.100000\n",
      "2020-10-22 14:24:38,269 epoch 7 - iter 72/368 - loss 0.55716025 - samples/sec: 69.87 - lr: 0.100000\n",
      "2020-10-22 14:24:54,778 epoch 7 - iter 108/368 - loss 0.55057774 - samples/sec: 71.14 - lr: 0.100000\n",
      "2020-10-22 14:25:11,194 epoch 7 - iter 144/368 - loss 0.53919535 - samples/sec: 70.46 - lr: 0.100000\n",
      "2020-10-22 14:25:27,682 epoch 7 - iter 180/368 - loss 0.53952927 - samples/sec: 71.21 - lr: 0.100000\n",
      "2020-10-22 14:25:44,391 epoch 7 - iter 216/368 - loss 0.53682991 - samples/sec: 70.26 - lr: 0.100000\n",
      "2020-10-22 14:26:00,934 epoch 7 - iter 252/368 - loss 0.53884499 - samples/sec: 70.94 - lr: 0.100000\n",
      "2020-10-22 14:26:17,639 epoch 7 - iter 288/368 - loss 0.53987906 - samples/sec: 70.29 - lr: 0.100000\n",
      "2020-10-22 14:26:34,339 epoch 7 - iter 324/368 - loss 0.54025172 - samples/sec: 70.27 - lr: 0.100000\n",
      "2020-10-22 14:26:50,732 epoch 7 - iter 360/368 - loss 0.53687669 - samples/sec: 71.64 - lr: 0.100000\n",
      "2020-10-22 14:26:54,156 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:26:54,157 EPOCH 7 done: loss 0.5354 - lr 0.1000000\n",
      "2020-10-22 14:27:42,356 DEV : loss 0.49316585063934326 - score 0.7972\n",
      "2020-10-22 14:27:44,277 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 14:27:44,990 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:28:02,041 epoch 8 - iter 36/368 - loss 0.50303179 - samples/sec: 69.71 - lr: 0.100000\n",
      "2020-10-22 14:28:18,557 epoch 8 - iter 72/368 - loss 0.54035533 - samples/sec: 71.12 - lr: 0.100000\n",
      "2020-10-22 14:28:34,801 epoch 8 - iter 108/368 - loss 0.52998777 - samples/sec: 71.23 - lr: 0.100000\n",
      "2020-10-22 14:28:51,417 epoch 8 - iter 144/368 - loss 0.52707367 - samples/sec: 70.66 - lr: 0.100000\n",
      "2020-10-22 14:29:08,048 epoch 8 - iter 180/368 - loss 0.52020515 - samples/sec: 70.63 - lr: 0.100000\n",
      "2020-10-22 14:29:24,618 epoch 8 - iter 216/368 - loss 0.52014864 - samples/sec: 70.87 - lr: 0.100000\n",
      "2020-10-22 14:29:41,577 epoch 8 - iter 252/368 - loss 0.52015671 - samples/sec: 69.23 - lr: 0.100000\n",
      "2020-10-22 14:29:58,323 epoch 8 - iter 288/368 - loss 0.51808045 - samples/sec: 70.17 - lr: 0.100000\n",
      "2020-10-22 14:30:14,815 epoch 8 - iter 324/368 - loss 0.51587278 - samples/sec: 71.21 - lr: 0.100000\n",
      "2020-10-22 14:30:31,218 epoch 8 - iter 360/368 - loss 0.52100142 - samples/sec: 71.54 - lr: 0.100000\n",
      "2020-10-22 14:30:34,661 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:30:34,661 EPOCH 8 done: loss 0.5220 - lr 0.1000000\n",
      "2020-10-22 14:31:22,335 DEV : loss 0.5060697197914124 - score 0.7919\n",
      "2020-10-22 14:31:24,236 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 14:31:24,237 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:31:40,975 epoch 9 - iter 36/368 - loss 0.52510996 - samples/sec: 71.11 - lr: 0.100000\n",
      "2020-10-22 14:31:57,540 epoch 9 - iter 72/368 - loss 0.50812308 - samples/sec: 70.92 - lr: 0.100000\n",
      "2020-10-22 14:32:13,932 epoch 9 - iter 108/368 - loss 0.50007840 - samples/sec: 71.65 - lr: 0.100000\n",
      "2020-10-22 14:32:30,526 epoch 9 - iter 144/368 - loss 0.50872086 - samples/sec: 70.75 - lr: 0.100000\n",
      "2020-10-22 14:32:47,095 epoch 9 - iter 180/368 - loss 0.51447519 - samples/sec: 70.87 - lr: 0.100000\n",
      "2020-10-22 14:33:03,194 epoch 9 - iter 216/368 - loss 0.51971119 - samples/sec: 71.87 - lr: 0.100000\n",
      "2020-10-22 14:33:19,817 epoch 9 - iter 252/368 - loss 0.52043700 - samples/sec: 70.65 - lr: 0.100000\n",
      "2020-10-22 14:33:36,564 epoch 9 - iter 288/368 - loss 0.51892349 - samples/sec: 70.12 - lr: 0.100000\n",
      "2020-10-22 14:33:53,079 epoch 9 - iter 324/368 - loss 0.51942578 - samples/sec: 71.09 - lr: 0.100000\n",
      "2020-10-22 14:34:09,733 epoch 9 - iter 360/368 - loss 0.52350716 - samples/sec: 70.52 - lr: 0.100000\n",
      "2020-10-22 14:34:13,209 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:34:13,209 EPOCH 9 done: loss 0.5233 - lr 0.1000000\n",
      "2020-10-22 14:35:01,090 DEV : loss 0.5005537867546082 - score 0.7921\n",
      "2020-10-22 14:35:03,005 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 14:35:03,006 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:35:19,926 epoch 10 - iter 36/368 - loss 0.50047354 - samples/sec: 70.10 - lr: 0.100000\n",
      "2020-10-22 14:35:36,391 epoch 10 - iter 72/368 - loss 0.49925292 - samples/sec: 70.27 - lr: 0.100000\n",
      "2020-10-22 14:35:53,378 epoch 10 - iter 108/368 - loss 0.50512301 - samples/sec: 69.13 - lr: 0.100000\n",
      "2020-10-22 14:36:09,548 epoch 10 - iter 144/368 - loss 0.52141597 - samples/sec: 71.52 - lr: 0.100000\n",
      "2020-10-22 14:36:26,096 epoch 10 - iter 180/368 - loss 0.51873436 - samples/sec: 70.94 - lr: 0.100000\n",
      "2020-10-22 14:36:42,440 epoch 10 - iter 216/368 - loss 0.52095762 - samples/sec: 71.80 - lr: 0.100000\n",
      "2020-10-22 14:36:58,816 epoch 10 - iter 252/368 - loss 0.51842356 - samples/sec: 71.73 - lr: 0.100000\n",
      "2020-10-22 14:37:15,232 epoch 10 - iter 288/368 - loss 0.51732861 - samples/sec: 71.55 - lr: 0.100000\n",
      "2020-10-22 14:37:31,958 epoch 10 - iter 324/368 - loss 0.52299914 - samples/sec: 70.16 - lr: 0.100000\n",
      "2020-10-22 14:37:48,659 epoch 10 - iter 360/368 - loss 0.52133635 - samples/sec: 70.27 - lr: 0.100000\n",
      "2020-10-22 14:37:52,153 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:37:52,154 EPOCH 10 done: loss 0.5220 - lr 0.1000000\n",
      "2020-10-22 14:38:40,459 DEV : loss 0.4742196798324585 - score 0.8052\n",
      "2020-10-22 14:38:42,382 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 14:38:43,096 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:38:59,983 epoch 11 - iter 36/368 - loss 0.47697532 - samples/sec: 70.27 - lr: 0.100000\n",
      "2020-10-22 14:39:16,329 epoch 11 - iter 72/368 - loss 0.48110561 - samples/sec: 71.82 - lr: 0.100000\n",
      "2020-10-22 14:39:32,967 epoch 11 - iter 108/368 - loss 0.47170678 - samples/sec: 70.63 - lr: 0.100000\n",
      "2020-10-22 14:39:49,709 epoch 11 - iter 144/368 - loss 0.48036626 - samples/sec: 70.11 - lr: 0.100000\n",
      "2020-10-22 14:40:06,576 epoch 11 - iter 180/368 - loss 0.48138857 - samples/sec: 69.62 - lr: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 14:40:22,904 epoch 11 - iter 216/368 - loss 0.48324032 - samples/sec: 71.90 - lr: 0.100000\n",
      "2020-10-22 14:40:38,993 epoch 11 - iter 252/368 - loss 0.48514123 - samples/sec: 71.89 - lr: 0.100000\n",
      "2020-10-22 14:40:55,322 epoch 11 - iter 288/368 - loss 0.49061823 - samples/sec: 71.89 - lr: 0.100000\n",
      "2020-10-22 14:41:11,747 epoch 11 - iter 324/368 - loss 0.49279711 - samples/sec: 71.46 - lr: 0.100000\n",
      "2020-10-22 14:41:28,560 epoch 11 - iter 360/368 - loss 0.49154352 - samples/sec: 69.85 - lr: 0.100000\n",
      "2020-10-22 14:41:32,344 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:41:32,345 EPOCH 11 done: loss 0.4918 - lr 0.1000000\n",
      "2020-10-22 14:42:19,870 DEV : loss 0.5237590074539185 - score 0.7786\n",
      "2020-10-22 14:42:21,743 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 14:42:21,744 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:42:38,845 epoch 12 - iter 36/368 - loss 0.48254239 - samples/sec: 69.49 - lr: 0.100000\n",
      "2020-10-22 14:42:55,842 epoch 12 - iter 72/368 - loss 0.49803036 - samples/sec: 69.08 - lr: 0.100000\n",
      "2020-10-22 14:43:12,489 epoch 12 - iter 108/368 - loss 0.49313235 - samples/sec: 70.49 - lr: 0.100000\n",
      "2020-10-22 14:43:29,480 epoch 12 - iter 144/368 - loss 0.49635856 - samples/sec: 68.08 - lr: 0.100000\n",
      "2020-10-22 14:43:46,325 epoch 12 - iter 180/368 - loss 0.49807067 - samples/sec: 69.67 - lr: 0.100000\n",
      "2020-10-22 14:44:03,162 epoch 12 - iter 216/368 - loss 0.50060886 - samples/sec: 69.73 - lr: 0.100000\n",
      "2020-10-22 14:44:19,749 epoch 12 - iter 252/368 - loss 0.49878246 - samples/sec: 70.74 - lr: 0.100000\n",
      "2020-10-22 14:44:36,505 epoch 12 - iter 288/368 - loss 0.50405561 - samples/sec: 70.10 - lr: 0.100000\n",
      "2020-10-22 14:44:52,997 epoch 12 - iter 324/368 - loss 0.50734857 - samples/sec: 71.15 - lr: 0.100000\n",
      "2020-10-22 14:45:09,339 epoch 12 - iter 360/368 - loss 0.50501841 - samples/sec: 71.91 - lr: 0.100000\n",
      "2020-10-22 14:45:12,790 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:45:12,790 EPOCH 12 done: loss 0.5079 - lr 0.1000000\n",
      "2020-10-22 14:46:00,696 DEV : loss 0.4762105643749237 - score 0.8052\n",
      "2020-10-22 14:46:02,614 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 14:46:02,615 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:46:19,201 epoch 13 - iter 36/368 - loss 0.51937852 - samples/sec: 71.69 - lr: 0.100000\n",
      "2020-10-22 14:46:35,647 epoch 13 - iter 72/368 - loss 0.50466438 - samples/sec: 71.43 - lr: 0.100000\n",
      "2020-10-22 14:46:52,085 epoch 13 - iter 108/368 - loss 0.50747015 - samples/sec: 70.36 - lr: 0.100000\n",
      "2020-10-22 14:47:08,844 epoch 13 - iter 144/368 - loss 0.50402049 - samples/sec: 69.05 - lr: 0.100000\n",
      "2020-10-22 14:47:25,110 epoch 13 - iter 180/368 - loss 0.50911653 - samples/sec: 71.13 - lr: 0.100000\n",
      "2020-10-22 14:47:41,698 epoch 13 - iter 216/368 - loss 0.52036494 - samples/sec: 70.78 - lr: 0.100000\n",
      "2020-10-22 14:47:58,334 epoch 13 - iter 252/368 - loss 0.52309078 - samples/sec: 70.60 - lr: 0.100000\n",
      "2020-10-22 14:48:15,121 epoch 13 - iter 288/368 - loss 0.51784265 - samples/sec: 69.95 - lr: 0.100000\n",
      "2020-10-22 14:48:31,765 epoch 13 - iter 324/368 - loss 0.51755146 - samples/sec: 70.51 - lr: 0.100000\n",
      "2020-10-22 14:48:48,291 epoch 13 - iter 360/368 - loss 0.51311452 - samples/sec: 69.97 - lr: 0.100000\n",
      "2020-10-22 14:48:51,733 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:48:51,733 EPOCH 13 done: loss 0.5137 - lr 0.1000000\n",
      "2020-10-22 14:49:39,714 DEV : loss 0.5889406204223633 - score 0.7763\n",
      "2020-10-22 14:49:41,623 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 14:49:41,624 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:49:58,881 epoch 14 - iter 36/368 - loss 0.52009002 - samples/sec: 68.72 - lr: 0.100000\n",
      "2020-10-22 14:50:15,405 epoch 14 - iter 72/368 - loss 0.51101918 - samples/sec: 71.04 - lr: 0.100000\n",
      "2020-10-22 14:50:31,838 epoch 14 - iter 108/368 - loss 0.49886332 - samples/sec: 70.39 - lr: 0.100000\n",
      "2020-10-22 14:50:48,227 epoch 14 - iter 144/368 - loss 0.49680480 - samples/sec: 71.71 - lr: 0.100000\n",
      "2020-10-22 14:51:04,582 epoch 14 - iter 180/368 - loss 0.49585956 - samples/sec: 71.79 - lr: 0.100000\n",
      "2020-10-22 14:51:21,093 epoch 14 - iter 216/368 - loss 0.48417190 - samples/sec: 71.09 - lr: 0.100000\n",
      "2020-10-22 14:51:37,775 epoch 14 - iter 252/368 - loss 0.49043697 - samples/sec: 70.43 - lr: 0.100000\n",
      "2020-10-22 14:51:54,196 epoch 14 - iter 288/368 - loss 0.49846494 - samples/sec: 71.54 - lr: 0.100000\n",
      "2020-10-22 14:52:10,366 epoch 14 - iter 324/368 - loss 0.48914674 - samples/sec: 71.54 - lr: 0.100000\n",
      "2020-10-22 14:52:26,966 epoch 14 - iter 360/368 - loss 0.49085643 - samples/sec: 70.71 - lr: 0.100000\n",
      "2020-10-22 14:52:30,400 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:52:30,401 EPOCH 14 done: loss 0.4908 - lr 0.1000000\n",
      "2020-10-22 14:53:18,527 DEV : loss 0.4652252495288849 - score 0.8141\n",
      "2020-10-22 14:53:20,453 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 14:53:21,169 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:53:38,109 epoch 15 - iter 36/368 - loss 0.51973963 - samples/sec: 70.04 - lr: 0.100000\n",
      "2020-10-22 14:53:54,687 epoch 15 - iter 72/368 - loss 0.49722325 - samples/sec: 70.86 - lr: 0.100000\n",
      "2020-10-22 14:54:10,749 epoch 15 - iter 108/368 - loss 0.48865296 - samples/sec: 72.00 - lr: 0.100000\n",
      "2020-10-22 14:54:27,100 epoch 15 - iter 144/368 - loss 0.47417869 - samples/sec: 71.82 - lr: 0.100000\n",
      "2020-10-22 14:54:43,549 epoch 15 - iter 180/368 - loss 0.48568926 - samples/sec: 70.33 - lr: 0.100000\n",
      "2020-10-22 14:55:00,039 epoch 15 - iter 216/368 - loss 0.48396989 - samples/sec: 71.24 - lr: 0.100000\n",
      "2020-10-22 14:55:16,573 epoch 15 - iter 252/368 - loss 0.48101508 - samples/sec: 71.03 - lr: 0.100000\n",
      "2020-10-22 14:55:33,142 epoch 15 - iter 288/368 - loss 0.48340445 - samples/sec: 70.80 - lr: 0.100000\n",
      "2020-10-22 14:55:49,552 epoch 15 - iter 324/368 - loss 0.48770049 - samples/sec: 70.50 - lr: 0.100000\n",
      "2020-10-22 14:56:05,831 epoch 15 - iter 360/368 - loss 0.48614256 - samples/sec: 71.09 - lr: 0.100000\n",
      "2020-10-22 14:56:09,632 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:56:09,633 EPOCH 15 done: loss 0.4866 - lr 0.1000000\n",
      "2020-10-22 14:56:56,746 DEV : loss 0.4493841230869293 - score 0.8151\n",
      "2020-10-22 14:56:58,620 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 14:56:59,320 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:57:16,253 epoch 16 - iter 36/368 - loss 0.43066663 - samples/sec: 70.24 - lr: 0.100000\n",
      "2020-10-22 14:57:32,858 epoch 16 - iter 72/368 - loss 0.42116652 - samples/sec: 70.74 - lr: 0.100000\n",
      "2020-10-22 14:57:49,319 epoch 16 - iter 108/368 - loss 0.41780270 - samples/sec: 71.34 - lr: 0.100000\n",
      "2020-10-22 14:58:06,011 epoch 16 - iter 144/368 - loss 0.43551413 - samples/sec: 70.38 - lr: 0.100000\n",
      "2020-10-22 14:58:22,402 epoch 16 - iter 180/368 - loss 0.44023606 - samples/sec: 70.56 - lr: 0.100000\n",
      "2020-10-22 14:58:39,042 epoch 16 - iter 216/368 - loss 0.45519859 - samples/sec: 70.60 - lr: 0.100000\n",
      "2020-10-22 14:58:55,549 epoch 16 - iter 252/368 - loss 0.45619869 - samples/sec: 71.11 - lr: 0.100000\n",
      "2020-10-22 14:59:11,967 epoch 16 - iter 288/368 - loss 0.45864282 - samples/sec: 71.50 - lr: 0.100000\n",
      "2020-10-22 14:59:28,570 epoch 16 - iter 324/368 - loss 0.46325350 - samples/sec: 70.73 - lr: 0.100000\n",
      "2020-10-22 14:59:44,885 epoch 16 - iter 360/368 - loss 0.46655830 - samples/sec: 71.98 - lr: 0.100000\n",
      "2020-10-22 14:59:48,419 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 14:59:48,420 EPOCH 16 done: loss 0.4674 - lr 0.1000000\n",
      "2020-10-22 15:00:35,272 DEV : loss 0.4751187562942505 - score 0.8082\n",
      "2020-10-22 15:00:37,412 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 15:00:37,413 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 15:00:54,335 epoch 17 - iter 36/368 - loss 0.46092704 - samples/sec: 68.99 - lr: 0.100000\n",
      "2020-10-22 15:01:10,281 epoch 17 - iter 72/368 - loss 0.47088402 - samples/sec: 72.52 - lr: 0.100000\n",
      "2020-10-22 15:01:27,102 epoch 17 - iter 108/368 - loss 0.46656210 - samples/sec: 69.79 - lr: 0.100000\n",
      "2020-10-22 15:01:43,738 epoch 17 - iter 144/368 - loss 0.46607319 - samples/sec: 70.57 - lr: 0.100000\n",
      "2020-10-22 15:02:00,426 epoch 17 - iter 180/368 - loss 0.46985867 - samples/sec: 70.38 - lr: 0.100000\n",
      "2020-10-22 15:02:17,203 epoch 17 - iter 216/368 - loss 0.46655500 - samples/sec: 69.98 - lr: 0.100000\n",
      "2020-10-22 15:02:33,734 epoch 17 - iter 252/368 - loss 0.46984156 - samples/sec: 71.03 - lr: 0.100000\n",
      "2020-10-22 15:02:50,007 epoch 17 - iter 288/368 - loss 0.46923452 - samples/sec: 71.10 - lr: 0.100000\n",
      "2020-10-22 15:03:06,502 epoch 17 - iter 324/368 - loss 0.46761320 - samples/sec: 71.21 - lr: 0.100000\n",
      "2020-10-22 15:03:23,098 epoch 17 - iter 360/368 - loss 0.46933555 - samples/sec: 70.71 - lr: 0.100000\n",
      "2020-10-22 15:03:26,544 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 15:03:26,544 EPOCH 17 done: loss 0.4713 - lr 0.1000000\n",
      "2020-10-22 15:04:14,117 DEV : loss 0.46244534850120544 - score 0.81\n",
      "2020-10-22 15:04:16,233 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 15:04:16,233 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 15:04:33,009 epoch 18 - iter 36/368 - loss 0.42395920 - samples/sec: 69.61 - lr: 0.100000\n",
      "2020-10-22 15:04:49,652 epoch 18 - iter 72/368 - loss 0.44370591 - samples/sec: 70.64 - lr: 0.100000\n",
      "2020-10-22 15:05:06,610 epoch 18 - iter 108/368 - loss 0.43257610 - samples/sec: 69.21 - lr: 0.100000\n",
      "2020-10-22 15:05:23,335 epoch 18 - iter 144/368 - loss 0.45106661 - samples/sec: 70.25 - lr: 0.100000\n",
      "2020-10-22 15:05:39,708 epoch 18 - iter 180/368 - loss 0.46005888 - samples/sec: 71.68 - lr: 0.100000\n",
      "2020-10-22 15:05:56,121 epoch 18 - iter 216/368 - loss 0.47068474 - samples/sec: 71.54 - lr: 0.100000\n",
      "2020-10-22 15:06:12,723 epoch 18 - iter 252/368 - loss 0.46886585 - samples/sec: 70.76 - lr: 0.100000\n",
      "2020-10-22 15:06:29,278 epoch 18 - iter 288/368 - loss 0.47088407 - samples/sec: 70.88 - lr: 0.100000\n",
      "2020-10-22 15:06:45,944 epoch 18 - iter 324/368 - loss 0.46753180 - samples/sec: 70.39 - lr: 0.100000\n",
      "2020-10-22 15:07:02,276 epoch 18 - iter 360/368 - loss 0.46738338 - samples/sec: 71.99 - lr: 0.100000\n",
      "2020-10-22 15:07:05,665 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 15:07:05,666 EPOCH 18 done: loss 0.4664 - lr 0.1000000\n",
      "2020-10-22 15:07:53,280 DEV : loss 0.6470394134521484 - score 0.7435\n",
      "2020-10-22 15:07:55,189 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 15:07:55,190 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 15:08:12,298 epoch 19 - iter 36/368 - loss 0.49687931 - samples/sec: 68.24 - lr: 0.100000\n",
      "2020-10-22 15:08:29,053 epoch 19 - iter 72/368 - loss 0.46982696 - samples/sec: 69.08 - lr: 0.100000\n",
      "2020-10-22 15:08:45,736 epoch 19 - iter 108/368 - loss 0.46642390 - samples/sec: 70.36 - lr: 0.100000\n",
      "2020-10-22 15:09:02,287 epoch 19 - iter 144/368 - loss 0.46945240 - samples/sec: 70.94 - lr: 0.100000\n",
      "2020-10-22 15:09:18,316 epoch 19 - iter 180/368 - loss 0.46618981 - samples/sec: 72.18 - lr: 0.100000\n",
      "2020-10-22 15:09:35,030 epoch 19 - iter 216/368 - loss 0.45918180 - samples/sec: 70.25 - lr: 0.100000\n",
      "2020-10-22 15:09:51,449 epoch 19 - iter 252/368 - loss 0.45926669 - samples/sec: 71.50 - lr: 0.100000\n",
      "2020-10-22 15:10:08,044 epoch 19 - iter 288/368 - loss 0.45822014 - samples/sec: 70.79 - lr: 0.100000\n",
      "2020-10-22 15:10:24,449 epoch 19 - iter 324/368 - loss 0.46548798 - samples/sec: 71.57 - lr: 0.100000\n",
      "2020-10-22 15:10:41,398 epoch 19 - iter 360/368 - loss 0.46873670 - samples/sec: 69.23 - lr: 0.100000\n",
      "2020-10-22 15:10:44,847 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 15:10:44,847 EPOCH 19 done: loss 0.4693 - lr 0.1000000\n",
      "2020-10-22 15:11:31,512 DEV : loss 0.4592461884021759 - score 0.8141\n",
      "2020-10-22 15:11:33,386 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 15:11:33,387 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 15:11:50,106 epoch 20 - iter 36/368 - loss 0.45821247 - samples/sec: 71.14 - lr: 0.100000\n",
      "2020-10-22 15:12:06,664 epoch 20 - iter 72/368 - loss 0.46023143 - samples/sec: 70.85 - lr: 0.100000\n",
      "2020-10-22 15:12:23,348 epoch 20 - iter 108/368 - loss 0.47150665 - samples/sec: 70.43 - lr: 0.100000\n",
      "2020-10-22 15:12:39,875 epoch 20 - iter 144/368 - loss 0.46483087 - samples/sec: 69.98 - lr: 0.100000\n",
      "2020-10-22 15:12:56,517 epoch 20 - iter 180/368 - loss 0.46166596 - samples/sec: 70.51 - lr: 0.100000\n",
      "2020-10-22 15:13:13,239 epoch 20 - iter 216/368 - loss 0.45726567 - samples/sec: 69.16 - lr: 0.100000\n",
      "2020-10-22 15:13:29,687 epoch 20 - iter 252/368 - loss 0.45991963 - samples/sec: 71.38 - lr: 0.100000\n",
      "2020-10-22 15:13:46,384 epoch 20 - iter 288/368 - loss 0.45887516 - samples/sec: 70.31 - lr: 0.100000\n",
      "2020-10-22 15:14:02,814 epoch 20 - iter 324/368 - loss 0.45899485 - samples/sec: 71.53 - lr: 0.100000\n",
      "2020-10-22 15:14:19,015 epoch 20 - iter 360/368 - loss 0.46197284 - samples/sec: 72.44 - lr: 0.100000\n",
      "2020-10-22 15:14:22,537 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 15:14:22,538 EPOCH 20 done: loss 0.4611 - lr 0.1000000\n",
      "2020-10-22 15:15:09,766 DEV : loss 0.45337456464767456 - score 0.8133\n",
      "2020-10-22 15:15:11,867 BAD EPOCHS (no improvement): 5\n",
      "2020-10-22 15:15:11,867 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 15:15:28,145 epoch 21 - iter 36/368 - loss 0.47540360 - samples/sec: 71.77 - lr: 0.100000\n",
      "2020-10-22 15:15:44,601 epoch 21 - iter 72/368 - loss 0.46633762 - samples/sec: 71.48 - lr: 0.100000\n",
      "2020-10-22 15:16:01,105 epoch 21 - iter 108/368 - loss 0.45967724 - samples/sec: 70.09 - lr: 0.100000\n",
      "2020-10-22 15:16:17,351 epoch 21 - iter 144/368 - loss 0.45030843 - samples/sec: 72.30 - lr: 0.100000\n",
      "2020-10-22 15:16:33,652 epoch 21 - iter 180/368 - loss 0.45497038 - samples/sec: 72.04 - lr: 0.100000\n",
      "2020-10-22 15:16:49,748 epoch 21 - iter 216/368 - loss 0.45789421 - samples/sec: 71.87 - lr: 0.100000\n",
      "2020-10-22 15:17:06,265 epoch 21 - iter 252/368 - loss 0.45751219 - samples/sec: 71.10 - lr: 0.100000\n",
      "2020-10-22 15:17:22,841 epoch 21 - iter 288/368 - loss 0.45651668 - samples/sec: 70.81 - lr: 0.100000\n",
      "2020-10-22 15:17:39,464 epoch 21 - iter 324/368 - loss 0.45918971 - samples/sec: 70.63 - lr: 0.100000\n",
      "2020-10-22 15:17:56,169 epoch 21 - iter 360/368 - loss 0.46181102 - samples/sec: 70.34 - lr: 0.100000\n",
      "2020-10-22 15:17:59,703 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 15:17:59,703 EPOCH 21 done: loss 0.4631 - lr 0.1000000\n",
      "2020-10-22 15:18:47,289 DEV : loss 0.44286391139030457 - score 0.8167\n",
      "2020-10-22 15:18:49,174 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 15:18:49,876 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 15:19:06,684 epoch 22 - iter 36/368 - loss 0.46270904 - samples/sec: 70.74 - lr: 0.100000\n",
      "2020-10-22 15:19:23,068 epoch 22 - iter 72/368 - loss 0.46564942 - samples/sec: 71.67 - lr: 0.100000\n",
      "2020-10-22 15:19:39,332 epoch 22 - iter 108/368 - loss 0.47017129 - samples/sec: 71.13 - lr: 0.100000\n",
      "2020-10-22 15:19:55,781 epoch 22 - iter 144/368 - loss 0.46624075 - samples/sec: 70.30 - lr: 0.100000\n",
      "2020-10-22 15:20:11,789 epoch 22 - iter 180/368 - loss 0.46157425 - samples/sec: 73.39 - lr: 0.100000\n",
      "2020-10-22 15:20:27,763 epoch 22 - iter 216/368 - loss 0.46035661 - samples/sec: 72.45 - lr: 0.100000\n",
      "2020-10-22 15:20:43,964 epoch 22 - iter 252/368 - loss 0.46084106 - samples/sec: 72.51 - lr: 0.100000\n",
      "2020-10-22 15:21:00,626 epoch 22 - iter 288/368 - loss 0.45801498 - samples/sec: 70.48 - lr: 0.100000\n",
      "2020-10-22 15:21:16,789 epoch 22 - iter 324/368 - loss 0.45519665 - samples/sec: 72.66 - lr: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 15:21:33,280 epoch 22 - iter 360/368 - loss 0.45552193 - samples/sec: 71.18 - lr: 0.100000\n",
      "2020-10-22 15:21:36,612 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 15:21:36,613 EPOCH 22 done: loss 0.4553 - lr 0.1000000\n",
      "2020-10-22 15:22:23,942 DEV : loss 0.47379186749458313 - score 0.8062\n",
      "2020-10-22 15:22:25,849 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 15:22:25,850 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 15:22:43,171 epoch 23 - iter 36/368 - loss 0.44576302 - samples/sec: 68.52 - lr: 0.100000\n",
      "2020-10-22 15:22:59,609 epoch 23 - iter 72/368 - loss 0.45860343 - samples/sec: 70.37 - lr: 0.100000\n",
      "2020-10-22 15:23:16,013 epoch 23 - iter 108/368 - loss 0.45266330 - samples/sec: 71.56 - lr: 0.100000\n",
      "2020-10-22 15:23:32,584 epoch 23 - iter 144/368 - loss 0.44390097 - samples/sec: 70.88 - lr: 0.100000\n",
      "2020-10-22 15:23:49,304 epoch 23 - iter 180/368 - loss 0.43669335 - samples/sec: 70.23 - lr: 0.100000\n",
      "2020-10-22 15:24:06,006 epoch 23 - iter 216/368 - loss 0.44043080 - samples/sec: 69.28 - lr: 0.100000\n",
      "2020-10-22 15:24:22,674 epoch 23 - iter 252/368 - loss 0.43967548 - samples/sec: 70.38 - lr: 0.100000\n",
      "2020-10-22 15:24:39,168 epoch 23 - iter 288/368 - loss 0.43849633 - samples/sec: 71.22 - lr: 0.100000\n",
      "2020-10-22 15:24:55,606 epoch 23 - iter 324/368 - loss 0.44098611 - samples/sec: 70.38 - lr: 0.100000\n",
      "2020-10-22 15:25:11,941 epoch 23 - iter 360/368 - loss 0.44688698 - samples/sec: 71.90 - lr: 0.100000\n",
      "2020-10-22 15:25:15,406 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 15:25:15,406 EPOCH 23 done: loss 0.4463 - lr 0.1000000\n",
      "2020-10-22 15:26:02,333 DEV : loss 0.5050782561302185 - score 0.7837\n",
      "2020-10-22 15:26:04,449 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 15:26:04,450 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 15:26:21,067 epoch 24 - iter 36/368 - loss 0.43692681 - samples/sec: 70.32 - lr: 0.100000\n",
      "2020-10-22 15:26:37,288 epoch 24 - iter 72/368 - loss 0.43812798 - samples/sec: 72.53 - lr: 0.100000\n",
      "2020-10-22 15:26:53,547 epoch 24 - iter 108/368 - loss 0.44360695 - samples/sec: 71.15 - lr: 0.100000\n",
      "2020-10-22 15:27:09,693 epoch 24 - iter 144/368 - loss 0.44423710 - samples/sec: 72.76 - lr: 0.100000\n",
      "2020-10-22 15:27:26,178 epoch 24 - iter 180/368 - loss 0.44122280 - samples/sec: 71.21 - lr: 0.100000\n",
      "2020-10-22 15:27:41,967 epoch 24 - iter 216/368 - loss 0.43446662 - samples/sec: 73.28 - lr: 0.100000\n",
      "2020-10-22 15:27:58,814 epoch 24 - iter 252/368 - loss 0.44200862 - samples/sec: 69.70 - lr: 0.100000\n",
      "2020-10-22 15:28:15,231 epoch 24 - iter 288/368 - loss 0.44455913 - samples/sec: 71.54 - lr: 0.100000\n",
      "2020-10-22 15:28:31,724 epoch 24 - iter 324/368 - loss 0.44459965 - samples/sec: 71.21 - lr: 0.100000\n",
      "2020-10-22 15:28:48,369 epoch 24 - iter 360/368 - loss 0.43929329 - samples/sec: 70.52 - lr: 0.100000\n",
      "2020-10-22 15:28:51,838 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 15:28:51,839 EPOCH 24 done: loss 0.4368 - lr 0.1000000\n",
      "2020-10-22 15:29:39,538 DEV : loss 0.44784843921661377 - score 0.8251\n",
      "2020-10-22 15:29:41,692 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 15:29:42,399 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 15:29:59,447 epoch 25 - iter 36/368 - loss 0.46534236 - samples/sec: 69.59 - lr: 0.100000\n",
      "2020-10-22 15:30:15,857 epoch 25 - iter 72/368 - loss 0.44900240 - samples/sec: 70.49 - lr: 0.100000\n",
      "2020-10-22 15:30:32,512 epoch 25 - iter 108/368 - loss 0.45665549 - samples/sec: 70.51 - lr: 0.100000\n",
      "2020-10-22 15:30:49,222 epoch 25 - iter 144/368 - loss 0.45832766 - samples/sec: 70.30 - lr: 0.100000\n",
      "2020-10-22 15:31:05,795 epoch 25 - iter 180/368 - loss 0.45012629 - samples/sec: 70.85 - lr: 0.100000\n",
      "2020-10-22 15:31:22,540 epoch 25 - iter 216/368 - loss 0.44802203 - samples/sec: 70.13 - lr: 0.100000\n",
      "2020-10-22 15:31:38,768 epoch 25 - iter 252/368 - loss 0.44255958 - samples/sec: 72.37 - lr: 0.100000\n",
      "2020-10-22 15:31:55,343 epoch 25 - iter 288/368 - loss 0.43453161 - samples/sec: 70.82 - lr: 0.100000\n",
      "2020-10-22 15:32:11,936 epoch 25 - iter 324/368 - loss 0.43587094 - samples/sec: 70.81 - lr: 0.100000\n",
      "2020-10-22 15:32:28,515 epoch 25 - iter 360/368 - loss 0.43529638 - samples/sec: 70.82 - lr: 0.100000\n",
      "2020-10-22 15:32:31,926 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 15:32:31,927 EPOCH 25 done: loss 0.4343 - lr 0.1000000\n",
      "2020-10-22 15:33:19,293 DEV : loss 0.4581835865974426 - score 0.8192\n",
      "2020-10-22 15:33:21,165 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 15:33:21,166 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 15:33:37,872 epoch 26 - iter 36/368 - loss 0.41656241 - samples/sec: 71.04 - lr: 0.100000\n",
      "2020-10-22 15:33:54,119 epoch 26 - iter 72/368 - loss 0.40981594 - samples/sec: 71.23 - lr: 0.100000\n",
      "2020-10-22 15:34:10,245 epoch 26 - iter 108/368 - loss 0.42303308 - samples/sec: 72.88 - lr: 0.100000\n",
      "2020-10-22 15:34:26,508 epoch 26 - iter 144/368 - loss 0.42177188 - samples/sec: 72.24 - lr: 0.100000\n",
      "2020-10-22 15:34:43,058 epoch 26 - iter 180/368 - loss 0.42307453 - samples/sec: 70.95 - lr: 0.100000\n",
      "2020-10-22 15:34:59,638 epoch 26 - iter 216/368 - loss 0.42455961 - samples/sec: 69.75 - lr: 0.100000\n",
      "2020-10-22 15:35:16,283 epoch 26 - iter 252/368 - loss 0.42350698 - samples/sec: 70.51 - lr: 0.100000\n",
      "2020-10-22 15:35:32,848 epoch 26 - iter 288/368 - loss 0.42521792 - samples/sec: 70.84 - lr: 0.100000\n",
      "2020-10-22 15:35:49,508 epoch 26 - iter 324/368 - loss 0.42902368 - samples/sec: 70.46 - lr: 0.100000\n",
      "2020-10-22 15:36:05,920 epoch 26 - iter 360/368 - loss 0.43177933 - samples/sec: 71.62 - lr: 0.100000\n",
      "2020-10-22 15:36:09,365 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 15:36:09,366 EPOCH 26 done: loss 0.4329 - lr 0.1000000\n",
      "2020-10-22 15:36:55,992 DEV : loss 0.46119850873947144 - score 0.8172\n",
      "2020-10-22 15:36:58,096 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 15:36:58,097 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 15:37:14,218 epoch 27 - iter 36/368 - loss 0.45639875 - samples/sec: 72.48 - lr: 0.100000\n",
      "2020-10-22 15:37:30,549 epoch 27 - iter 72/368 - loss 0.45200388 - samples/sec: 71.94 - lr: 0.100000\n",
      "2020-10-22 15:37:46,728 epoch 27 - iter 108/368 - loss 0.42712629 - samples/sec: 72.60 - lr: 0.100000\n",
      "2020-10-22 15:38:03,062 epoch 27 - iter 144/368 - loss 0.42170933 - samples/sec: 71.93 - lr: 0.100000\n",
      "2020-10-22 15:38:19,159 epoch 27 - iter 180/368 - loss 0.42419396 - samples/sec: 72.93 - lr: 0.100000\n",
      "2020-10-22 15:38:35,501 epoch 27 - iter 216/368 - loss 0.42256011 - samples/sec: 71.92 - lr: 0.100000\n",
      "2020-10-22 15:38:51,711 epoch 27 - iter 252/368 - loss 0.41867265 - samples/sec: 72.43 - lr: 0.100000\n",
      "2020-10-22 15:39:07,925 epoch 27 - iter 288/368 - loss 0.42377453 - samples/sec: 72.40 - lr: 0.100000\n",
      "2020-10-22 15:39:24,193 epoch 27 - iter 324/368 - loss 0.42505871 - samples/sec: 72.16 - lr: 0.100000\n",
      "2020-10-22 15:39:40,502 epoch 27 - iter 360/368 - loss 0.42409889 - samples/sec: 70.94 - lr: 0.100000\n",
      "2020-10-22 15:39:44,304 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 15:39:44,305 EPOCH 27 done: loss 0.4232 - lr 0.1000000\n",
      "2020-10-22 15:40:31,691 DEV : loss 0.4688448905944824 - score 0.8159\n",
      "2020-10-22 15:40:33,587 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 15:40:33,588 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 15:40:50,354 epoch 28 - iter 36/368 - loss 0.39013833 - samples/sec: 70.87 - lr: 0.100000\n",
      "2020-10-22 15:41:06,701 epoch 28 - iter 72/368 - loss 0.39058495 - samples/sec: 71.83 - lr: 0.100000\n",
      "2020-10-22 15:41:22,834 epoch 28 - iter 108/368 - loss 0.40404310 - samples/sec: 71.71 - lr: 0.100000\n",
      "2020-10-22 15:41:39,115 epoch 28 - iter 144/368 - loss 0.40667537 - samples/sec: 72.16 - lr: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 15:41:55,560 epoch 28 - iter 180/368 - loss 0.41090741 - samples/sec: 71.43 - lr: 0.100000\n",
      "2020-10-22 15:42:11,967 epoch 28 - iter 216/368 - loss 0.40672961 - samples/sec: 71.55 - lr: 0.100000\n",
      "2020-10-22 15:42:28,310 epoch 28 - iter 252/368 - loss 0.41314283 - samples/sec: 71.87 - lr: 0.100000\n",
      "2020-10-22 15:42:44,670 epoch 28 - iter 288/368 - loss 0.41700177 - samples/sec: 71.77 - lr: 0.100000\n",
      "2020-10-22 15:43:01,148 epoch 28 - iter 324/368 - loss 0.41971990 - samples/sec: 71.25 - lr: 0.100000\n",
      "2020-10-22 15:43:17,377 epoch 28 - iter 360/368 - loss 0.42008202 - samples/sec: 71.28 - lr: 0.100000\n",
      "2020-10-22 15:43:21,187 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 15:43:21,188 EPOCH 28 done: loss 0.4210 - lr 0.1000000\n",
      "2020-10-22 15:44:08,112 DEV : loss 0.5684040784835815 - score 0.7783\n",
      "2020-10-22 15:44:09,978 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 15:44:09,979 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 15:44:26,782 epoch 29 - iter 36/368 - loss 0.39600689 - samples/sec: 70.73 - lr: 0.100000\n",
      "2020-10-22 15:44:42,941 epoch 29 - iter 72/368 - loss 0.40183697 - samples/sec: 72.70 - lr: 0.100000\n",
      "2020-10-22 15:44:59,417 epoch 29 - iter 108/368 - loss 0.41762711 - samples/sec: 71.26 - lr: 0.100000\n",
      "2020-10-22 15:45:16,006 epoch 29 - iter 144/368 - loss 0.41483652 - samples/sec: 70.79 - lr: 0.100000\n",
      "2020-10-22 15:45:32,661 epoch 29 - iter 180/368 - loss 0.41611397 - samples/sec: 70.50 - lr: 0.100000\n",
      "2020-10-22 15:45:49,267 epoch 29 - iter 216/368 - loss 0.42146147 - samples/sec: 70.70 - lr: 0.100000\n",
      "2020-10-22 15:46:05,468 epoch 29 - iter 252/368 - loss 0.42153607 - samples/sec: 71.36 - lr: 0.100000\n",
      "2020-10-22 15:46:21,745 epoch 29 - iter 288/368 - loss 0.42400735 - samples/sec: 72.17 - lr: 0.100000\n",
      "2020-10-22 15:46:38,085 epoch 29 - iter 324/368 - loss 0.42610786 - samples/sec: 70.78 - lr: 0.100000\n",
      "2020-10-22 15:46:54,434 epoch 29 - iter 360/368 - loss 0.42712131 - samples/sec: 71.84 - lr: 0.100000\n",
      "2020-10-22 15:46:57,822 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 15:46:57,823 EPOCH 29 done: loss 0.4269 - lr 0.1000000\n",
      "2020-10-22 15:47:45,489 DEV : loss 0.46973565220832825 - score 0.8149\n",
      "2020-10-22 15:47:47,370 BAD EPOCHS (no improvement): 5\n",
      "2020-10-22 15:47:47,371 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 15:48:04,237 epoch 30 - iter 36/368 - loss 0.38274394 - samples/sec: 70.45 - lr: 0.100000\n",
      "2020-10-22 15:48:20,751 epoch 30 - iter 72/368 - loss 0.40716625 - samples/sec: 71.08 - lr: 0.100000\n",
      "2020-10-22 15:48:37,394 epoch 30 - iter 108/368 - loss 0.40490685 - samples/sec: 70.54 - lr: 0.100000\n",
      "2020-10-22 15:48:53,691 epoch 30 - iter 144/368 - loss 0.41385181 - samples/sec: 71.00 - lr: 0.100000\n",
      "2020-10-22 15:49:10,255 epoch 30 - iter 180/368 - loss 0.40603459 - samples/sec: 70.89 - lr: 0.100000\n",
      "2020-10-22 15:49:26,804 epoch 30 - iter 216/368 - loss 0.40515621 - samples/sec: 70.94 - lr: 0.100000\n",
      "2020-10-22 15:49:43,441 epoch 30 - iter 252/368 - loss 0.40631086 - samples/sec: 70.57 - lr: 0.100000\n",
      "2020-10-22 15:49:59,686 epoch 30 - iter 288/368 - loss 0.41195287 - samples/sec: 71.19 - lr: 0.100000\n",
      "2020-10-22 15:50:16,224 epoch 30 - iter 324/368 - loss 0.41410314 - samples/sec: 69.93 - lr: 0.100000\n",
      "2020-10-22 15:50:32,495 epoch 30 - iter 360/368 - loss 0.41912829 - samples/sec: 72.10 - lr: 0.100000\n",
      "2020-10-22 15:50:35,801 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 15:50:35,802 EPOCH 30 done: loss 0.4197 - lr 0.1000000\n",
      "2020-10-22 15:51:23,329 DEV : loss 0.44143563508987427 - score 0.8149\n",
      "Epoch    30: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2020-10-22 15:51:25,198 BAD EPOCHS (no improvement): 6\n",
      "2020-10-22 15:51:25,199 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 15:51:42,240 epoch 31 - iter 36/368 - loss 0.41316726 - samples/sec: 69.47 - lr: 0.050000\n",
      "2020-10-22 15:51:58,901 epoch 31 - iter 72/368 - loss 0.38869465 - samples/sec: 70.51 - lr: 0.050000\n",
      "2020-10-22 15:52:14,738 epoch 31 - iter 108/368 - loss 0.40894869 - samples/sec: 73.02 - lr: 0.050000\n",
      "2020-10-22 15:52:31,379 epoch 31 - iter 144/368 - loss 0.40142941 - samples/sec: 69.49 - lr: 0.050000\n",
      "2020-10-22 15:52:48,014 epoch 31 - iter 180/368 - loss 0.38777694 - samples/sec: 70.54 - lr: 0.050000\n",
      "2020-10-22 15:53:04,437 epoch 31 - iter 216/368 - loss 0.38582384 - samples/sec: 70.41 - lr: 0.050000\n",
      "2020-10-22 15:53:20,883 epoch 31 - iter 252/368 - loss 0.38529073 - samples/sec: 71.37 - lr: 0.050000\n",
      "2020-10-22 15:53:37,259 epoch 31 - iter 288/368 - loss 0.38044782 - samples/sec: 71.73 - lr: 0.050000\n",
      "2020-10-22 15:53:53,720 epoch 31 - iter 324/368 - loss 0.38345603 - samples/sec: 71.29 - lr: 0.050000\n",
      "2020-10-22 15:54:10,395 epoch 31 - iter 360/368 - loss 0.38047241 - samples/sec: 69.35 - lr: 0.050000\n",
      "2020-10-22 15:54:13,840 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 15:54:13,840 EPOCH 31 done: loss 0.3793 - lr 0.0500000\n",
      "2020-10-22 15:55:00,846 DEV : loss 0.4213426113128662 - score 0.831\n",
      "2020-10-22 15:55:02,728 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 15:55:03,428 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 15:55:20,081 epoch 32 - iter 36/368 - loss 0.40740439 - samples/sec: 70.16 - lr: 0.050000\n",
      "2020-10-22 15:55:36,771 epoch 32 - iter 72/368 - loss 0.37488625 - samples/sec: 70.36 - lr: 0.050000\n",
      "2020-10-22 15:55:53,481 epoch 32 - iter 108/368 - loss 0.35667713 - samples/sec: 70.28 - lr: 0.050000\n",
      "2020-10-22 15:56:09,655 epoch 32 - iter 144/368 - loss 0.35580394 - samples/sec: 72.61 - lr: 0.050000\n",
      "2020-10-22 15:56:25,809 epoch 32 - iter 180/368 - loss 0.35891346 - samples/sec: 72.78 - lr: 0.050000\n",
      "2020-10-22 15:56:42,144 epoch 32 - iter 216/368 - loss 0.35380235 - samples/sec: 70.82 - lr: 0.050000\n",
      "2020-10-22 15:56:58,600 epoch 32 - iter 252/368 - loss 0.35500627 - samples/sec: 71.39 - lr: 0.050000\n",
      "2020-10-22 15:57:14,900 epoch 32 - iter 288/368 - loss 0.35953084 - samples/sec: 72.04 - lr: 0.050000\n",
      "2020-10-22 15:57:31,128 epoch 32 - iter 324/368 - loss 0.36336788 - samples/sec: 72.34 - lr: 0.050000\n",
      "2020-10-22 15:57:47,800 epoch 32 - iter 360/368 - loss 0.36413129 - samples/sec: 70.45 - lr: 0.050000\n",
      "2020-10-22 15:57:51,308 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 15:57:51,308 EPOCH 32 done: loss 0.3628 - lr 0.0500000\n",
      "2020-10-22 15:58:38,640 DEV : loss 0.433952271938324 - score 0.8274\n",
      "2020-10-22 15:58:40,775 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 15:58:40,776 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 15:58:57,529 epoch 33 - iter 36/368 - loss 0.35123155 - samples/sec: 70.81 - lr: 0.050000\n",
      "2020-10-22 15:59:13,516 epoch 33 - iter 72/368 - loss 0.34957883 - samples/sec: 72.37 - lr: 0.050000\n",
      "2020-10-22 15:59:29,968 epoch 33 - iter 108/368 - loss 0.34951301 - samples/sec: 71.44 - lr: 0.050000\n",
      "2020-10-22 15:59:46,513 epoch 33 - iter 144/368 - loss 0.34382753 - samples/sec: 70.90 - lr: 0.050000\n",
      "2020-10-22 16:00:02,823 epoch 33 - iter 180/368 - loss 0.34009767 - samples/sec: 70.89 - lr: 0.050000\n",
      "2020-10-22 16:00:19,495 epoch 33 - iter 216/368 - loss 0.33879374 - samples/sec: 70.47 - lr: 0.050000\n",
      "2020-10-22 16:00:35,956 epoch 33 - iter 252/368 - loss 0.34514250 - samples/sec: 70.26 - lr: 0.050000\n",
      "2020-10-22 16:00:52,367 epoch 33 - iter 288/368 - loss 0.34034306 - samples/sec: 71.59 - lr: 0.050000\n",
      "2020-10-22 16:01:08,799 epoch 33 - iter 324/368 - loss 0.34423009 - samples/sec: 71.46 - lr: 0.050000\n",
      "2020-10-22 16:01:25,036 epoch 33 - iter 360/368 - loss 0.34699328 - samples/sec: 71.25 - lr: 0.050000\n",
      "2020-10-22 16:01:28,700 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 16:01:28,700 EPOCH 33 done: loss 0.3474 - lr 0.0500000\n",
      "2020-10-22 16:02:16,093 DEV : loss 0.42231789231300354 - score 0.8287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 16:02:17,971 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 16:02:17,972 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 16:02:34,973 epoch 34 - iter 36/368 - loss 0.39096973 - samples/sec: 69.92 - lr: 0.050000\n",
      "2020-10-22 16:02:51,733 epoch 34 - iter 72/368 - loss 0.36852365 - samples/sec: 70.07 - lr: 0.050000\n",
      "2020-10-22 16:03:07,814 epoch 34 - iter 108/368 - loss 0.35721548 - samples/sec: 71.95 - lr: 0.050000\n",
      "2020-10-22 16:03:24,098 epoch 34 - iter 144/368 - loss 0.35346020 - samples/sec: 71.03 - lr: 0.050000\n",
      "2020-10-22 16:03:40,503 epoch 34 - iter 180/368 - loss 0.35324210 - samples/sec: 71.54 - lr: 0.050000\n",
      "2020-10-22 16:03:56,979 epoch 34 - iter 216/368 - loss 0.34984069 - samples/sec: 71.28 - lr: 0.050000\n",
      "2020-10-22 16:04:13,262 epoch 34 - iter 252/368 - loss 0.34956528 - samples/sec: 72.05 - lr: 0.050000\n",
      "2020-10-22 16:04:29,989 epoch 34 - iter 288/368 - loss 0.34862567 - samples/sec: 70.21 - lr: 0.050000\n",
      "2020-10-22 16:04:46,919 epoch 34 - iter 324/368 - loss 0.34507294 - samples/sec: 69.25 - lr: 0.050000\n",
      "2020-10-22 16:05:03,546 epoch 34 - iter 360/368 - loss 0.34383679 - samples/sec: 69.55 - lr: 0.050000\n",
      "2020-10-22 16:05:06,965 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 16:05:06,965 EPOCH 34 done: loss 0.3448 - lr 0.0500000\n",
      "2020-10-22 16:05:54,905 DEV : loss 0.4243922829627991 - score 0.8272\n",
      "2020-10-22 16:05:56,802 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 16:05:56,803 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 16:06:13,883 epoch 35 - iter 36/368 - loss 0.32433545 - samples/sec: 69.57 - lr: 0.050000\n",
      "2020-10-22 16:06:30,608 epoch 35 - iter 72/368 - loss 0.32499874 - samples/sec: 69.19 - lr: 0.050000\n",
      "2020-10-22 16:06:47,051 epoch 35 - iter 108/368 - loss 0.31871494 - samples/sec: 71.39 - lr: 0.050000\n",
      "2020-10-22 16:07:03,538 epoch 35 - iter 144/368 - loss 0.32504603 - samples/sec: 71.22 - lr: 0.050000\n",
      "2020-10-22 16:07:20,008 epoch 35 - iter 180/368 - loss 0.32665066 - samples/sec: 71.34 - lr: 0.050000\n",
      "2020-10-22 16:07:36,593 epoch 35 - iter 216/368 - loss 0.32652462 - samples/sec: 70.73 - lr: 0.050000\n",
      "2020-10-22 16:07:52,928 epoch 35 - iter 252/368 - loss 0.32802331 - samples/sec: 70.80 - lr: 0.050000\n",
      "2020-10-22 16:08:09,089 epoch 35 - iter 288/368 - loss 0.33526278 - samples/sec: 72.73 - lr: 0.050000\n",
      "2020-10-22 16:08:25,368 epoch 35 - iter 324/368 - loss 0.33483668 - samples/sec: 72.07 - lr: 0.050000\n",
      "2020-10-22 16:08:41,809 epoch 35 - iter 360/368 - loss 0.33724095 - samples/sec: 71.49 - lr: 0.050000\n",
      "2020-10-22 16:08:45,336 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 16:08:45,336 EPOCH 35 done: loss 0.3375 - lr 0.0500000\n",
      "2020-10-22 16:09:32,578 DEV : loss 0.4145326316356659 - score 0.8348\n",
      "2020-10-22 16:09:34,449 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 16:09:35,150 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 16:09:51,878 epoch 36 - iter 36/368 - loss 0.29380652 - samples/sec: 69.81 - lr: 0.050000\n",
      "2020-10-22 16:10:08,402 epoch 36 - iter 72/368 - loss 0.31869221 - samples/sec: 71.06 - lr: 0.050000\n",
      "2020-10-22 16:10:24,955 epoch 36 - iter 108/368 - loss 0.31450465 - samples/sec: 69.90 - lr: 0.050000\n",
      "2020-10-22 16:10:41,722 epoch 36 - iter 144/368 - loss 0.31209219 - samples/sec: 70.06 - lr: 0.050000\n",
      "2020-10-22 16:10:58,064 epoch 36 - iter 180/368 - loss 0.32247493 - samples/sec: 70.80 - lr: 0.050000\n",
      "2020-10-22 16:11:14,636 epoch 36 - iter 216/368 - loss 0.32414495 - samples/sec: 70.83 - lr: 0.050000\n",
      "2020-10-22 16:11:31,470 epoch 36 - iter 252/368 - loss 0.32386266 - samples/sec: 69.80 - lr: 0.050000\n",
      "2020-10-22 16:11:47,823 epoch 36 - iter 288/368 - loss 0.32477760 - samples/sec: 71.81 - lr: 0.050000\n",
      "2020-10-22 16:12:04,361 epoch 36 - iter 324/368 - loss 0.32751012 - samples/sec: 70.97 - lr: 0.050000\n",
      "2020-10-22 16:12:20,868 epoch 36 - iter 360/368 - loss 0.32871649 - samples/sec: 71.15 - lr: 0.050000\n",
      "2020-10-22 16:12:24,259 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 16:12:24,260 EPOCH 36 done: loss 0.3296 - lr 0.0500000\n",
      "2020-10-22 16:13:11,831 DEV : loss 0.41224217414855957 - score 0.8379\n",
      "2020-10-22 16:13:13,707 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 16:13:14,408 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 16:13:31,537 epoch 37 - iter 36/368 - loss 0.35136630 - samples/sec: 69.41 - lr: 0.050000\n",
      "2020-10-22 16:13:48,218 epoch 37 - iter 72/368 - loss 0.34984006 - samples/sec: 70.34 - lr: 0.050000\n",
      "2020-10-22 16:14:04,831 epoch 37 - iter 108/368 - loss 0.33690339 - samples/sec: 70.74 - lr: 0.050000\n",
      "2020-10-22 16:14:21,406 epoch 37 - iter 144/368 - loss 0.33711794 - samples/sec: 70.84 - lr: 0.050000\n",
      "2020-10-22 16:14:37,634 epoch 37 - iter 180/368 - loss 0.33459962 - samples/sec: 72.36 - lr: 0.050000\n",
      "2020-10-22 16:14:53,694 epoch 37 - iter 216/368 - loss 0.32469375 - samples/sec: 72.04 - lr: 0.050000\n",
      "2020-10-22 16:15:10,289 epoch 37 - iter 252/368 - loss 0.32751796 - samples/sec: 70.78 - lr: 0.050000\n",
      "2020-10-22 16:15:26,839 epoch 37 - iter 288/368 - loss 0.32835315 - samples/sec: 70.96 - lr: 0.050000\n",
      "2020-10-22 16:15:43,108 epoch 37 - iter 324/368 - loss 0.32866220 - samples/sec: 72.16 - lr: 0.050000\n",
      "2020-10-22 16:15:59,594 epoch 37 - iter 360/368 - loss 0.33027729 - samples/sec: 71.22 - lr: 0.050000\n",
      "2020-10-22 16:16:03,007 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 16:16:03,008 EPOCH 37 done: loss 0.3316 - lr 0.0500000\n",
      "2020-10-22 16:16:50,524 DEV : loss 0.41470786929130554 - score 0.8343\n",
      "2020-10-22 16:16:52,663 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 16:16:52,664 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 16:17:09,230 epoch 38 - iter 36/368 - loss 0.31628213 - samples/sec: 70.45 - lr: 0.050000\n",
      "2020-10-22 16:17:25,946 epoch 38 - iter 72/368 - loss 0.32647211 - samples/sec: 70.32 - lr: 0.050000\n",
      "2020-10-22 16:17:42,418 epoch 38 - iter 108/368 - loss 0.32219480 - samples/sec: 71.29 - lr: 0.050000\n",
      "2020-10-22 16:17:58,859 epoch 38 - iter 144/368 - loss 0.32572861 - samples/sec: 71.49 - lr: 0.050000\n",
      "2020-10-22 16:18:15,646 epoch 38 - iter 180/368 - loss 0.32666675 - samples/sec: 69.95 - lr: 0.050000\n",
      "2020-10-22 16:18:32,017 epoch 38 - iter 216/368 - loss 0.32727829 - samples/sec: 71.72 - lr: 0.050000\n",
      "2020-10-22 16:18:48,457 epoch 38 - iter 252/368 - loss 0.32952874 - samples/sec: 71.47 - lr: 0.050000\n",
      "2020-10-22 16:19:04,570 epoch 38 - iter 288/368 - loss 0.32685581 - samples/sec: 71.81 - lr: 0.050000\n",
      "2020-10-22 16:19:21,155 epoch 38 - iter 324/368 - loss 0.33161562 - samples/sec: 70.76 - lr: 0.050000\n",
      "2020-10-22 16:19:37,632 epoch 38 - iter 360/368 - loss 0.32862718 - samples/sec: 71.22 - lr: 0.050000\n",
      "2020-10-22 16:19:41,091 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 16:19:41,092 EPOCH 38 done: loss 0.3284 - lr 0.0500000\n",
      "2020-10-22 16:20:29,185 DEV : loss 0.4222954511642456 - score 0.8289\n",
      "2020-10-22 16:20:31,111 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 16:20:31,112 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 16:20:48,116 epoch 39 - iter 36/368 - loss 0.32520978 - samples/sec: 69.81 - lr: 0.050000\n",
      "2020-10-22 16:21:04,519 epoch 39 - iter 72/368 - loss 0.31403161 - samples/sec: 70.53 - lr: 0.050000\n",
      "2020-10-22 16:21:20,836 epoch 39 - iter 108/368 - loss 0.31276375 - samples/sec: 71.96 - lr: 0.050000\n",
      "2020-10-22 16:21:37,234 epoch 39 - iter 144/368 - loss 0.30975846 - samples/sec: 71.64 - lr: 0.050000\n",
      "2020-10-22 16:21:53,722 epoch 39 - iter 180/368 - loss 0.31536744 - samples/sec: 71.25 - lr: 0.050000\n",
      "2020-10-22 16:22:10,355 epoch 39 - iter 216/368 - loss 0.31505727 - samples/sec: 70.59 - lr: 0.050000\n",
      "2020-10-22 16:22:26,833 epoch 39 - iter 252/368 - loss 0.31572780 - samples/sec: 71.24 - lr: 0.050000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 16:22:43,349 epoch 39 - iter 288/368 - loss 0.31412578 - samples/sec: 71.11 - lr: 0.050000\n",
      "2020-10-22 16:22:59,541 epoch 39 - iter 324/368 - loss 0.31595787 - samples/sec: 71.45 - lr: 0.050000\n",
      "2020-10-22 16:23:16,067 epoch 39 - iter 360/368 - loss 0.31840097 - samples/sec: 71.05 - lr: 0.050000\n",
      "2020-10-22 16:23:19,486 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 16:23:19,487 EPOCH 39 done: loss 0.3169 - lr 0.0500000\n",
      "2020-10-22 16:24:07,634 DEV : loss 0.4162510633468628 - score 0.8374\n",
      "2020-10-22 16:24:09,562 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 16:24:09,562 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 16:24:26,174 epoch 40 - iter 36/368 - loss 0.34334941 - samples/sec: 71.58 - lr: 0.050000\n",
      "2020-10-22 16:24:42,397 epoch 40 - iter 72/368 - loss 0.32011413 - samples/sec: 71.32 - lr: 0.050000\n",
      "2020-10-22 16:24:58,834 epoch 40 - iter 108/368 - loss 0.32321184 - samples/sec: 71.46 - lr: 0.050000\n",
      "2020-10-22 16:25:15,306 epoch 40 - iter 144/368 - loss 0.32040909 - samples/sec: 71.29 - lr: 0.050000\n",
      "2020-10-22 16:25:31,951 epoch 40 - iter 180/368 - loss 0.31852214 - samples/sec: 70.50 - lr: 0.050000\n",
      "2020-10-22 16:25:48,652 epoch 40 - iter 216/368 - loss 0.31483191 - samples/sec: 69.24 - lr: 0.050000\n",
      "2020-10-22 16:26:05,367 epoch 40 - iter 252/368 - loss 0.31132080 - samples/sec: 70.21 - lr: 0.050000\n",
      "2020-10-22 16:26:21,826 epoch 40 - iter 288/368 - loss 0.31586095 - samples/sec: 70.27 - lr: 0.050000\n",
      "2020-10-22 16:26:38,533 epoch 40 - iter 324/368 - loss 0.31306244 - samples/sec: 70.25 - lr: 0.050000\n",
      "2020-10-22 16:26:55,125 epoch 40 - iter 360/368 - loss 0.31389284 - samples/sec: 70.78 - lr: 0.050000\n",
      "2020-10-22 16:26:58,596 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 16:26:58,597 EPOCH 40 done: loss 0.3128 - lr 0.0500000\n",
      "2020-10-22 16:27:45,610 DEV : loss 0.43183767795562744 - score 0.8282\n",
      "2020-10-22 16:27:47,496 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 16:27:47,497 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 16:28:04,413 epoch 41 - iter 36/368 - loss 0.28946104 - samples/sec: 70.33 - lr: 0.050000\n",
      "2020-10-22 16:28:20,727 epoch 41 - iter 72/368 - loss 0.30491744 - samples/sec: 70.93 - lr: 0.050000\n",
      "2020-10-22 16:28:37,117 epoch 41 - iter 108/368 - loss 0.30639720 - samples/sec: 71.63 - lr: 0.050000\n",
      "2020-10-22 16:28:53,470 epoch 41 - iter 144/368 - loss 0.30706459 - samples/sec: 70.73 - lr: 0.050000\n",
      "2020-10-22 16:29:09,540 epoch 41 - iter 180/368 - loss 0.30697192 - samples/sec: 73.03 - lr: 0.050000\n",
      "2020-10-22 16:29:26,045 epoch 41 - iter 216/368 - loss 0.31225042 - samples/sec: 71.17 - lr: 0.050000\n",
      "2020-10-22 16:29:42,250 epoch 41 - iter 252/368 - loss 0.31152800 - samples/sec: 71.39 - lr: 0.050000\n",
      "2020-10-22 16:29:58,677 epoch 41 - iter 288/368 - loss 0.31571441 - samples/sec: 71.49 - lr: 0.050000\n",
      "2020-10-22 16:30:15,147 epoch 41 - iter 324/368 - loss 0.31522071 - samples/sec: 71.30 - lr: 0.050000\n",
      "2020-10-22 16:30:31,791 epoch 41 - iter 360/368 - loss 0.31669004 - samples/sec: 69.52 - lr: 0.050000\n",
      "2020-10-22 16:30:35,296 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 16:30:35,296 EPOCH 41 done: loss 0.3148 - lr 0.0500000\n",
      "2020-10-22 16:31:22,369 DEV : loss 0.44246193766593933 - score 0.8256\n",
      "2020-10-22 16:31:24,493 BAD EPOCHS (no improvement): 5\n",
      "2020-10-22 16:31:24,502 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 16:31:41,087 epoch 42 - iter 36/368 - loss 0.30896965 - samples/sec: 70.44 - lr: 0.050000\n",
      "2020-10-22 16:31:57,516 epoch 42 - iter 72/368 - loss 0.32299342 - samples/sec: 71.52 - lr: 0.050000\n",
      "2020-10-22 16:32:14,031 epoch 42 - iter 108/368 - loss 0.32014816 - samples/sec: 71.13 - lr: 0.050000\n",
      "2020-10-22 16:32:30,383 epoch 42 - iter 144/368 - loss 0.31094905 - samples/sec: 71.73 - lr: 0.050000\n",
      "2020-10-22 16:32:46,684 epoch 42 - iter 180/368 - loss 0.30694314 - samples/sec: 72.08 - lr: 0.050000\n",
      "2020-10-22 16:33:03,113 epoch 42 - iter 216/368 - loss 0.31052404 - samples/sec: 71.48 - lr: 0.050000\n",
      "2020-10-22 16:33:19,709 epoch 42 - iter 252/368 - loss 0.31095543 - samples/sec: 70.71 - lr: 0.050000\n",
      "2020-10-22 16:33:36,464 epoch 42 - iter 288/368 - loss 0.31048997 - samples/sec: 70.11 - lr: 0.050000\n",
      "2020-10-22 16:33:53,104 epoch 42 - iter 324/368 - loss 0.31109521 - samples/sec: 70.49 - lr: 0.050000\n",
      "2020-10-22 16:34:09,438 epoch 42 - iter 360/368 - loss 0.30916897 - samples/sec: 71.90 - lr: 0.050000\n",
      "2020-10-22 16:34:13,008 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 16:34:13,009 EPOCH 42 done: loss 0.3078 - lr 0.0500000\n",
      "2020-10-22 16:35:00,447 DEV : loss 0.43531885743141174 - score 0.8264\n",
      "Epoch    42: reducing learning rate of group 0 to 2.5000e-02.\n",
      "2020-10-22 16:35:02,326 BAD EPOCHS (no improvement): 6\n",
      "2020-10-22 16:35:02,327 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 16:35:19,069 epoch 43 - iter 36/368 - loss 0.31158005 - samples/sec: 70.97 - lr: 0.025000\n",
      "2020-10-22 16:35:35,535 epoch 43 - iter 72/368 - loss 0.28263965 - samples/sec: 70.24 - lr: 0.025000\n",
      "2020-10-22 16:35:51,896 epoch 43 - iter 108/368 - loss 0.27888706 - samples/sec: 71.81 - lr: 0.025000\n",
      "2020-10-22 16:36:08,413 epoch 43 - iter 144/368 - loss 0.28900179 - samples/sec: 71.12 - lr: 0.025000\n",
      "2020-10-22 16:36:24,497 epoch 43 - iter 180/368 - loss 0.29513398 - samples/sec: 71.90 - lr: 0.025000\n",
      "2020-10-22 16:36:41,234 epoch 43 - iter 216/368 - loss 0.29506634 - samples/sec: 70.11 - lr: 0.025000\n",
      "2020-10-22 16:36:57,914 epoch 43 - iter 252/368 - loss 0.29585477 - samples/sec: 70.44 - lr: 0.025000\n",
      "2020-10-22 16:37:14,512 epoch 43 - iter 288/368 - loss 0.29522462 - samples/sec: 70.70 - lr: 0.025000\n",
      "2020-10-22 16:37:31,371 epoch 43 - iter 324/368 - loss 0.30095940 - samples/sec: 69.65 - lr: 0.025000\n",
      "2020-10-22 16:37:48,253 epoch 43 - iter 360/368 - loss 0.29876717 - samples/sec: 69.48 - lr: 0.025000\n",
      "2020-10-22 16:37:51,563 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 16:37:51,563 EPOCH 43 done: loss 0.2986 - lr 0.0250000\n",
      "2020-10-22 16:38:39,311 DEV : loss 0.39765802025794983 - score 0.8415\n",
      "2020-10-22 16:38:41,471 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 16:38:42,178 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 16:38:59,133 epoch 44 - iter 36/368 - loss 0.26166808 - samples/sec: 70.03 - lr: 0.025000\n",
      "2020-10-22 16:39:15,256 epoch 44 - iter 72/368 - loss 0.27766052 - samples/sec: 71.78 - lr: 0.025000\n",
      "2020-10-22 16:39:32,046 epoch 44 - iter 108/368 - loss 0.28573638 - samples/sec: 69.92 - lr: 0.025000\n",
      "2020-10-22 16:39:48,436 epoch 44 - iter 144/368 - loss 0.28215824 - samples/sec: 71.71 - lr: 0.025000\n",
      "2020-10-22 16:40:04,758 epoch 44 - iter 180/368 - loss 0.28305901 - samples/sec: 71.91 - lr: 0.025000\n",
      "2020-10-22 16:40:21,321 epoch 44 - iter 216/368 - loss 0.28140481 - samples/sec: 70.90 - lr: 0.025000\n",
      "2020-10-22 16:40:37,760 epoch 44 - iter 252/368 - loss 0.27859373 - samples/sec: 70.38 - lr: 0.025000\n",
      "2020-10-22 16:40:54,240 epoch 44 - iter 288/368 - loss 0.27814211 - samples/sec: 71.27 - lr: 0.025000\n",
      "2020-10-22 16:41:10,837 epoch 44 - iter 324/368 - loss 0.27783869 - samples/sec: 70.76 - lr: 0.025000\n",
      "2020-10-22 16:41:27,205 epoch 44 - iter 360/368 - loss 0.27870470 - samples/sec: 70.68 - lr: 0.025000\n",
      "2020-10-22 16:41:30,895 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 16:41:30,896 EPOCH 44 done: loss 0.2784 - lr 0.0250000\n",
      "2020-10-22 16:42:18,166 DEV : loss 0.4131954312324524 - score 0.8369\n",
      "2020-10-22 16:42:20,051 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 16:42:20,052 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 16:42:36,903 epoch 45 - iter 36/368 - loss 0.27175897 - samples/sec: 70.53 - lr: 0.025000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 16:42:53,412 epoch 45 - iter 72/368 - loss 0.26322208 - samples/sec: 71.18 - lr: 0.025000\n",
      "2020-10-22 16:43:09,747 epoch 45 - iter 108/368 - loss 0.27214624 - samples/sec: 71.96 - lr: 0.025000\n",
      "2020-10-22 16:43:26,260 epoch 45 - iter 144/368 - loss 0.27711702 - samples/sec: 71.12 - lr: 0.025000\n",
      "2020-10-22 16:43:42,549 epoch 45 - iter 180/368 - loss 0.27812835 - samples/sec: 71.02 - lr: 0.025000\n",
      "2020-10-22 16:43:59,051 epoch 45 - iter 216/368 - loss 0.27919007 - samples/sec: 71.15 - lr: 0.025000\n",
      "2020-10-22 16:44:15,497 epoch 45 - iter 252/368 - loss 0.27770449 - samples/sec: 71.38 - lr: 0.025000\n",
      "2020-10-22 16:44:32,098 epoch 45 - iter 288/368 - loss 0.27876284 - samples/sec: 70.76 - lr: 0.025000\n",
      "2020-10-22 16:44:48,714 epoch 45 - iter 324/368 - loss 0.27566485 - samples/sec: 70.73 - lr: 0.025000\n",
      "2020-10-22 16:45:05,252 epoch 45 - iter 360/368 - loss 0.27688193 - samples/sec: 71.05 - lr: 0.025000\n",
      "2020-10-22 16:45:08,852 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 16:45:08,853 EPOCH 45 done: loss 0.2755 - lr 0.0250000\n",
      "2020-10-22 16:45:56,834 DEV : loss 0.40824374556541443 - score 0.8376\n",
      "2020-10-22 16:45:58,751 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 16:45:58,752 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 16:46:15,713 epoch 46 - iter 36/368 - loss 0.27481235 - samples/sec: 68.82 - lr: 0.025000\n",
      "2020-10-22 16:46:32,008 epoch 46 - iter 72/368 - loss 0.27499976 - samples/sec: 72.10 - lr: 0.025000\n",
      "2020-10-22 16:46:48,563 epoch 46 - iter 108/368 - loss 0.27913628 - samples/sec: 70.92 - lr: 0.025000\n",
      "2020-10-22 16:47:04,936 epoch 46 - iter 144/368 - loss 0.27052158 - samples/sec: 71.75 - lr: 0.025000\n",
      "2020-10-22 16:47:21,314 epoch 46 - iter 180/368 - loss 0.27212405 - samples/sec: 70.60 - lr: 0.025000\n",
      "2020-10-22 16:47:37,876 epoch 46 - iter 216/368 - loss 0.27572400 - samples/sec: 70.92 - lr: 0.025000\n",
      "2020-10-22 16:47:54,547 epoch 46 - iter 252/368 - loss 0.27434752 - samples/sec: 70.42 - lr: 0.025000\n",
      "2020-10-22 16:48:11,111 epoch 46 - iter 288/368 - loss 0.27356588 - samples/sec: 70.88 - lr: 0.025000\n",
      "2020-10-22 16:48:27,863 epoch 46 - iter 324/368 - loss 0.27305007 - samples/sec: 69.04 - lr: 0.025000\n",
      "2020-10-22 16:48:44,375 epoch 46 - iter 360/368 - loss 0.27076202 - samples/sec: 71.10 - lr: 0.025000\n",
      "2020-10-22 16:48:47,930 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 16:48:47,931 EPOCH 46 done: loss 0.2714 - lr 0.0250000\n",
      "2020-10-22 16:49:35,645 DEV : loss 0.41943594813346863 - score 0.8356\n",
      "2020-10-22 16:49:37,524 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 16:49:37,524 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 16:49:54,330 epoch 47 - iter 36/368 - loss 0.28022890 - samples/sec: 70.73 - lr: 0.025000\n",
      "2020-10-22 16:50:10,973 epoch 47 - iter 72/368 - loss 0.27047288 - samples/sec: 69.47 - lr: 0.025000\n",
      "2020-10-22 16:50:27,581 epoch 47 - iter 108/368 - loss 0.27071022 - samples/sec: 70.65 - lr: 0.025000\n",
      "2020-10-22 16:50:44,242 epoch 47 - iter 144/368 - loss 0.27149214 - samples/sec: 70.57 - lr: 0.025000\n",
      "2020-10-22 16:51:00,692 epoch 47 - iter 180/368 - loss 0.26364276 - samples/sec: 70.30 - lr: 0.025000\n",
      "2020-10-22 16:51:17,255 epoch 47 - iter 216/368 - loss 0.25873716 - samples/sec: 70.83 - lr: 0.025000\n",
      "2020-10-22 16:51:33,781 epoch 47 - iter 252/368 - loss 0.25977124 - samples/sec: 71.03 - lr: 0.025000\n",
      "2020-10-22 16:51:50,302 epoch 47 - iter 288/368 - loss 0.26074973 - samples/sec: 71.13 - lr: 0.025000\n",
      "2020-10-22 16:52:06,727 epoch 47 - iter 324/368 - loss 0.26049386 - samples/sec: 71.41 - lr: 0.025000\n",
      "2020-10-22 16:52:23,405 epoch 47 - iter 360/368 - loss 0.26216276 - samples/sec: 70.41 - lr: 0.025000\n",
      "2020-10-22 16:52:26,846 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 16:52:26,846 EPOCH 47 done: loss 0.2618 - lr 0.0250000\n",
      "2020-10-22 16:53:14,207 DEV : loss 0.401189386844635 - score 0.8417\n",
      "2020-10-22 16:53:16,070 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 16:53:16,772 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 16:53:33,443 epoch 48 - iter 36/368 - loss 0.27143925 - samples/sec: 71.38 - lr: 0.025000\n",
      "2020-10-22 16:53:49,759 epoch 48 - iter 72/368 - loss 0.27599565 - samples/sec: 71.96 - lr: 0.025000\n",
      "2020-10-22 16:54:06,515 epoch 48 - iter 108/368 - loss 0.26700322 - samples/sec: 70.11 - lr: 0.025000\n",
      "2020-10-22 16:54:22,530 epoch 48 - iter 144/368 - loss 0.26186791 - samples/sec: 72.22 - lr: 0.025000\n",
      "2020-10-22 16:54:39,043 epoch 48 - iter 180/368 - loss 0.25756716 - samples/sec: 71.07 - lr: 0.025000\n",
      "2020-10-22 16:54:55,414 epoch 48 - iter 216/368 - loss 0.26219343 - samples/sec: 70.63 - lr: 0.025000\n",
      "2020-10-22 16:55:11,642 epoch 48 - iter 252/368 - loss 0.26628318 - samples/sec: 72.34 - lr: 0.025000\n",
      "2020-10-22 16:55:28,140 epoch 48 - iter 288/368 - loss 0.26583464 - samples/sec: 71.15 - lr: 0.025000\n",
      "2020-10-22 16:55:44,517 epoch 48 - iter 324/368 - loss 0.26656390 - samples/sec: 71.75 - lr: 0.025000\n",
      "2020-10-22 16:56:00,921 epoch 48 - iter 360/368 - loss 0.26597846 - samples/sec: 71.59 - lr: 0.025000\n",
      "2020-10-22 16:56:04,302 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 16:56:04,302 EPOCH 48 done: loss 0.2669 - lr 0.0250000\n",
      "2020-10-22 16:56:51,639 DEV : loss 0.4054614007472992 - score 0.8392\n",
      "2020-10-22 16:56:53,749 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 16:56:53,750 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 16:57:10,444 epoch 49 - iter 36/368 - loss 0.27882348 - samples/sec: 69.93 - lr: 0.025000\n",
      "2020-10-22 16:57:26,962 epoch 49 - iter 72/368 - loss 0.25943679 - samples/sec: 71.04 - lr: 0.025000\n",
      "2020-10-22 16:57:43,147 epoch 49 - iter 108/368 - loss 0.26756809 - samples/sec: 71.50 - lr: 0.025000\n",
      "2020-10-22 16:57:59,865 epoch 49 - iter 144/368 - loss 0.26055410 - samples/sec: 70.22 - lr: 0.025000\n",
      "2020-10-22 16:58:16,422 epoch 49 - iter 180/368 - loss 0.26382644 - samples/sec: 70.89 - lr: 0.025000\n",
      "2020-10-22 16:58:33,020 epoch 49 - iter 216/368 - loss 0.26320499 - samples/sec: 70.72 - lr: 0.025000\n",
      "2020-10-22 16:58:49,941 epoch 49 - iter 252/368 - loss 0.26364044 - samples/sec: 69.42 - lr: 0.025000\n",
      "2020-10-22 16:59:06,365 epoch 49 - iter 288/368 - loss 0.26487499 - samples/sec: 71.49 - lr: 0.025000\n",
      "2020-10-22 16:59:22,848 epoch 49 - iter 324/368 - loss 0.26407075 - samples/sec: 70.17 - lr: 0.025000\n",
      "2020-10-22 16:59:39,228 epoch 49 - iter 360/368 - loss 0.26549845 - samples/sec: 71.65 - lr: 0.025000\n",
      "2020-10-22 16:59:42,605 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 16:59:42,606 EPOCH 49 done: loss 0.2652 - lr 0.0250000\n",
      "2020-10-22 17:00:30,331 DEV : loss 0.4098110795021057 - score 0.841\n",
      "2020-10-22 17:00:32,211 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 17:00:32,212 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 17:00:49,329 epoch 50 - iter 36/368 - loss 0.24815595 - samples/sec: 69.28 - lr: 0.025000\n",
      "2020-10-22 17:01:06,127 epoch 50 - iter 72/368 - loss 0.25359201 - samples/sec: 69.87 - lr: 0.025000\n",
      "2020-10-22 17:01:22,391 epoch 50 - iter 108/368 - loss 0.25588718 - samples/sec: 71.14 - lr: 0.025000\n",
      "2020-10-22 17:01:39,014 epoch 50 - iter 144/368 - loss 0.25881701 - samples/sec: 70.69 - lr: 0.025000\n",
      "2020-10-22 17:01:55,540 epoch 50 - iter 180/368 - loss 0.26091183 - samples/sec: 71.06 - lr: 0.025000\n",
      "2020-10-22 17:02:12,160 epoch 50 - iter 216/368 - loss 0.26171029 - samples/sec: 70.71 - lr: 0.025000\n",
      "2020-10-22 17:02:28,686 epoch 50 - iter 252/368 - loss 0.25758757 - samples/sec: 71.09 - lr: 0.025000\n",
      "2020-10-22 17:02:45,023 epoch 50 - iter 288/368 - loss 0.25765922 - samples/sec: 71.88 - lr: 0.025000\n",
      "2020-10-22 17:03:01,462 epoch 50 - iter 324/368 - loss 0.26075098 - samples/sec: 70.38 - lr: 0.025000\n",
      "2020-10-22 17:03:17,981 epoch 50 - iter 360/368 - loss 0.26464691 - samples/sec: 71.09 - lr: 0.025000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 17:03:21,480 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 17:03:21,481 EPOCH 50 done: loss 0.2633 - lr 0.0250000\n",
      "2020-10-22 17:04:08,941 DEV : loss 0.4068930447101593 - score 0.8433\n",
      "2020-10-22 17:04:10,841 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 17:04:11,543 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 17:04:28,437 epoch 51 - iter 36/368 - loss 0.25183717 - samples/sec: 69.10 - lr: 0.025000\n",
      "2020-10-22 17:04:45,103 epoch 51 - iter 72/368 - loss 0.23683839 - samples/sec: 70.43 - lr: 0.025000\n",
      "2020-10-22 17:05:01,650 epoch 51 - iter 108/368 - loss 0.24111759 - samples/sec: 70.89 - lr: 0.025000\n",
      "2020-10-22 17:05:18,145 epoch 51 - iter 144/368 - loss 0.24490976 - samples/sec: 71.18 - lr: 0.025000\n",
      "2020-10-22 17:05:34,792 epoch 51 - iter 180/368 - loss 0.24088971 - samples/sec: 70.57 - lr: 0.025000\n",
      "2020-10-22 17:05:51,464 epoch 51 - iter 216/368 - loss 0.24668739 - samples/sec: 70.45 - lr: 0.025000\n",
      "2020-10-22 17:06:07,696 epoch 51 - iter 252/368 - loss 0.24944778 - samples/sec: 71.28 - lr: 0.025000\n",
      "2020-10-22 17:06:24,317 epoch 51 - iter 288/368 - loss 0.25211375 - samples/sec: 70.62 - lr: 0.025000\n",
      "2020-10-22 17:06:40,753 epoch 51 - iter 324/368 - loss 0.25245657 - samples/sec: 71.44 - lr: 0.025000\n",
      "2020-10-22 17:06:57,226 epoch 51 - iter 360/368 - loss 0.25397753 - samples/sec: 71.33 - lr: 0.025000\n",
      "2020-10-22 17:07:00,651 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 17:07:00,651 EPOCH 51 done: loss 0.2546 - lr 0.0250000\n",
      "2020-10-22 17:07:47,857 DEV : loss 0.40686240792274475 - score 0.8381\n",
      "2020-10-22 17:07:49,749 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 17:07:49,750 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 17:08:06,384 epoch 52 - iter 36/368 - loss 0.25922171 - samples/sec: 71.49 - lr: 0.025000\n",
      "2020-10-22 17:08:22,927 epoch 52 - iter 72/368 - loss 0.25464361 - samples/sec: 70.97 - lr: 0.025000\n",
      "2020-10-22 17:08:39,334 epoch 52 - iter 108/368 - loss 0.26401700 - samples/sec: 71.59 - lr: 0.025000\n",
      "2020-10-22 17:08:55,775 epoch 52 - iter 144/368 - loss 0.26178554 - samples/sec: 71.40 - lr: 0.025000\n",
      "2020-10-22 17:09:11,776 epoch 52 - iter 180/368 - loss 0.26016457 - samples/sec: 72.29 - lr: 0.025000\n",
      "2020-10-22 17:09:27,900 epoch 52 - iter 216/368 - loss 0.25562715 - samples/sec: 72.83 - lr: 0.025000\n",
      "2020-10-22 17:09:44,329 epoch 52 - iter 252/368 - loss 0.24950884 - samples/sec: 71.50 - lr: 0.025000\n",
      "2020-10-22 17:10:00,939 epoch 52 - iter 288/368 - loss 0.25388596 - samples/sec: 70.70 - lr: 0.025000\n",
      "2020-10-22 17:10:17,259 epoch 52 - iter 324/368 - loss 0.25388090 - samples/sec: 72.03 - lr: 0.025000\n",
      "2020-10-22 17:10:33,741 epoch 52 - iter 360/368 - loss 0.25140200 - samples/sec: 71.21 - lr: 0.025000\n",
      "2020-10-22 17:10:37,327 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 17:10:37,327 EPOCH 52 done: loss 0.2520 - lr 0.0250000\n",
      "2020-10-22 17:11:24,621 DEV : loss 0.40585434436798096 - score 0.8384\n",
      "2020-10-22 17:11:26,502 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 17:11:26,503 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 17:11:43,533 epoch 53 - iter 36/368 - loss 0.24190267 - samples/sec: 69.61 - lr: 0.025000\n",
      "2020-10-22 17:12:00,278 epoch 53 - iter 72/368 - loss 0.23190979 - samples/sec: 70.06 - lr: 0.025000\n",
      "2020-10-22 17:12:16,616 epoch 53 - iter 108/368 - loss 0.24091599 - samples/sec: 70.81 - lr: 0.025000\n",
      "2020-10-22 17:12:33,147 epoch 53 - iter 144/368 - loss 0.24445986 - samples/sec: 71.01 - lr: 0.025000\n",
      "2020-10-22 17:12:49,775 epoch 53 - iter 180/368 - loss 0.25090987 - samples/sec: 70.57 - lr: 0.025000\n",
      "2020-10-22 17:13:06,770 epoch 53 - iter 216/368 - loss 0.24862986 - samples/sec: 69.10 - lr: 0.025000\n",
      "2020-10-22 17:13:23,254 epoch 53 - iter 252/368 - loss 0.24618905 - samples/sec: 71.20 - lr: 0.025000\n",
      "2020-10-22 17:13:39,773 epoch 53 - iter 288/368 - loss 0.24387054 - samples/sec: 71.14 - lr: 0.025000\n",
      "2020-10-22 17:13:56,260 epoch 53 - iter 324/368 - loss 0.24961550 - samples/sec: 71.18 - lr: 0.025000\n",
      "2020-10-22 17:14:13,065 epoch 53 - iter 360/368 - loss 0.24789910 - samples/sec: 69.90 - lr: 0.025000\n",
      "2020-10-22 17:14:16,464 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 17:14:16,465 EPOCH 53 done: loss 0.2474 - lr 0.0250000\n",
      "2020-10-22 17:15:04,658 DEV : loss 0.4016282856464386 - score 0.8458\n",
      "2020-10-22 17:15:06,548 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 17:15:07,252 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 17:15:23,700 epoch 54 - iter 36/368 - loss 0.25394715 - samples/sec: 72.24 - lr: 0.025000\n",
      "2020-10-22 17:15:40,218 epoch 54 - iter 72/368 - loss 0.25444018 - samples/sec: 71.13 - lr: 0.025000\n",
      "2020-10-22 17:15:56,824 epoch 54 - iter 108/368 - loss 0.25124253 - samples/sec: 70.67 - lr: 0.025000\n",
      "2020-10-22 17:16:12,943 epoch 54 - iter 144/368 - loss 0.25203793 - samples/sec: 71.73 - lr: 0.025000\n",
      "2020-10-22 17:16:29,543 epoch 54 - iter 180/368 - loss 0.25063524 - samples/sec: 70.76 - lr: 0.025000\n",
      "2020-10-22 17:16:46,016 epoch 54 - iter 216/368 - loss 0.24820427 - samples/sec: 71.26 - lr: 0.025000\n",
      "2020-10-22 17:17:02,484 epoch 54 - iter 252/368 - loss 0.24509058 - samples/sec: 71.20 - lr: 0.025000\n",
      "2020-10-22 17:17:19,041 epoch 54 - iter 288/368 - loss 0.24442120 - samples/sec: 70.99 - lr: 0.025000\n",
      "2020-10-22 17:17:35,541 epoch 54 - iter 324/368 - loss 0.24541003 - samples/sec: 71.13 - lr: 0.025000\n",
      "2020-10-22 17:17:52,239 epoch 54 - iter 360/368 - loss 0.24535818 - samples/sec: 70.37 - lr: 0.025000\n",
      "2020-10-22 17:17:55,641 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 17:17:55,641 EPOCH 54 done: loss 0.2447 - lr 0.0250000\n",
      "2020-10-22 17:18:43,367 DEV : loss 0.4057975113391876 - score 0.8438\n",
      "2020-10-22 17:18:45,284 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 17:18:45,284 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 17:19:02,713 epoch 55 - iter 36/368 - loss 0.25942861 - samples/sec: 68.06 - lr: 0.025000\n",
      "2020-10-22 17:19:19,477 epoch 55 - iter 72/368 - loss 0.25654768 - samples/sec: 69.02 - lr: 0.025000\n",
      "2020-10-22 17:19:36,900 epoch 55 - iter 108/368 - loss 0.24973579 - samples/sec: 67.35 - lr: 0.025000\n",
      "2020-10-22 17:19:54,044 epoch 55 - iter 144/368 - loss 0.24479224 - samples/sec: 68.50 - lr: 0.025000\n",
      "2020-10-22 17:20:11,267 epoch 55 - iter 180/368 - loss 0.24580188 - samples/sec: 68.15 - lr: 0.025000\n",
      "2020-10-22 17:20:27,962 epoch 55 - iter 216/368 - loss 0.24482327 - samples/sec: 70.32 - lr: 0.025000\n",
      "2020-10-22 17:20:44,850 epoch 55 - iter 252/368 - loss 0.24573296 - samples/sec: 69.49 - lr: 0.025000\n",
      "2020-10-22 17:21:02,144 epoch 55 - iter 288/368 - loss 0.24617063 - samples/sec: 67.90 - lr: 0.025000\n",
      "2020-10-22 17:21:18,863 epoch 55 - iter 324/368 - loss 0.24450287 - samples/sec: 70.21 - lr: 0.025000\n",
      "2020-10-22 17:21:35,277 epoch 55 - iter 360/368 - loss 0.24268682 - samples/sec: 70.51 - lr: 0.025000\n",
      "2020-10-22 17:21:39,099 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 17:21:39,099 EPOCH 55 done: loss 0.2438 - lr 0.0250000\n",
      "2020-10-22 17:22:27,801 DEV : loss 0.39909347891807556 - score 0.8433\n",
      "2020-10-22 17:22:29,736 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 17:22:29,737 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 17:22:46,818 epoch 56 - iter 36/368 - loss 0.22451679 - samples/sec: 69.77 - lr: 0.025000\n",
      "2020-10-22 17:23:03,438 epoch 56 - iter 72/368 - loss 0.23929596 - samples/sec: 70.63 - lr: 0.025000\n",
      "2020-10-22 17:23:20,457 epoch 56 - iter 108/368 - loss 0.24342245 - samples/sec: 68.89 - lr: 0.025000\n",
      "2020-10-22 17:23:37,296 epoch 56 - iter 144/368 - loss 0.23458629 - samples/sec: 69.75 - lr: 0.025000\n",
      "2020-10-22 17:23:53,568 epoch 56 - iter 180/368 - loss 0.23517098 - samples/sec: 71.10 - lr: 0.025000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 17:24:10,026 epoch 56 - iter 216/368 - loss 0.23087817 - samples/sec: 71.36 - lr: 0.025000\n",
      "2020-10-22 17:24:26,460 epoch 56 - iter 252/368 - loss 0.23433180 - samples/sec: 70.39 - lr: 0.025000\n",
      "2020-10-22 17:24:43,274 epoch 56 - iter 288/368 - loss 0.23352501 - samples/sec: 69.86 - lr: 0.025000\n",
      "2020-10-22 17:25:00,140 epoch 56 - iter 324/368 - loss 0.23737051 - samples/sec: 69.57 - lr: 0.025000\n",
      "2020-10-22 17:25:17,433 epoch 56 - iter 360/368 - loss 0.23993103 - samples/sec: 67.96 - lr: 0.025000\n",
      "2020-10-22 17:25:21,005 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 17:25:21,006 EPOCH 56 done: loss 0.2392 - lr 0.0250000\n",
      "2020-10-22 17:26:09,582 DEV : loss 0.42097073793411255 - score 0.8422\n",
      "2020-10-22 17:26:11,488 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 17:26:11,488 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 17:26:28,859 epoch 57 - iter 36/368 - loss 0.22178361 - samples/sec: 68.40 - lr: 0.025000\n",
      "2020-10-22 17:26:45,549 epoch 57 - iter 72/368 - loss 0.22296768 - samples/sec: 69.32 - lr: 0.025000\n",
      "2020-10-22 17:27:02,266 epoch 57 - iter 108/368 - loss 0.22794660 - samples/sec: 69.23 - lr: 0.025000\n",
      "2020-10-22 17:27:19,054 epoch 57 - iter 144/368 - loss 0.23171657 - samples/sec: 69.92 - lr: 0.025000\n",
      "2020-10-22 17:27:35,906 epoch 57 - iter 180/368 - loss 0.23214556 - samples/sec: 69.67 - lr: 0.025000\n",
      "2020-10-22 17:27:52,786 epoch 57 - iter 216/368 - loss 0.23591954 - samples/sec: 69.54 - lr: 0.025000\n",
      "2020-10-22 17:28:09,610 epoch 57 - iter 252/368 - loss 0.23934184 - samples/sec: 69.74 - lr: 0.025000\n",
      "2020-10-22 17:28:25,955 epoch 57 - iter 288/368 - loss 0.24209523 - samples/sec: 71.90 - lr: 0.025000\n",
      "2020-10-22 17:28:42,797 epoch 57 - iter 324/368 - loss 0.24132294 - samples/sec: 69.70 - lr: 0.025000\n",
      "2020-10-22 17:28:59,430 epoch 57 - iter 360/368 - loss 0.24079654 - samples/sec: 70.59 - lr: 0.025000\n",
      "2020-10-22 17:29:02,982 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 17:29:02,982 EPOCH 57 done: loss 0.2409 - lr 0.0250000\n",
      "2020-10-22 17:29:51,181 DEV : loss 0.39546912908554077 - score 0.8456\n",
      "2020-10-22 17:29:53,083 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 17:29:53,084 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 17:30:09,790 epoch 58 - iter 36/368 - loss 0.26682905 - samples/sec: 71.22 - lr: 0.025000\n",
      "2020-10-22 17:30:26,745 epoch 58 - iter 72/368 - loss 0.24745368 - samples/sec: 69.32 - lr: 0.025000\n",
      "2020-10-22 17:30:43,647 epoch 58 - iter 108/368 - loss 0.23840939 - samples/sec: 69.50 - lr: 0.025000\n",
      "2020-10-22 17:31:00,449 epoch 58 - iter 144/368 - loss 0.24109145 - samples/sec: 69.91 - lr: 0.025000\n",
      "2020-10-22 17:31:17,418 epoch 58 - iter 180/368 - loss 0.23999236 - samples/sec: 69.21 - lr: 0.025000\n",
      "2020-10-22 17:31:34,360 epoch 58 - iter 216/368 - loss 0.23763619 - samples/sec: 69.26 - lr: 0.025000\n",
      "2020-10-22 17:31:51,224 epoch 58 - iter 252/368 - loss 0.24008735 - samples/sec: 69.63 - lr: 0.025000\n",
      "2020-10-22 17:32:07,958 epoch 58 - iter 288/368 - loss 0.23954315 - samples/sec: 70.15 - lr: 0.025000\n",
      "2020-10-22 17:32:24,902 epoch 58 - iter 324/368 - loss 0.24019267 - samples/sec: 68.25 - lr: 0.025000\n",
      "2020-10-22 17:32:41,962 epoch 58 - iter 360/368 - loss 0.23809404 - samples/sec: 68.84 - lr: 0.025000\n",
      "2020-10-22 17:32:45,828 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 17:32:45,828 EPOCH 58 done: loss 0.2384 - lr 0.0250000\n",
      "2020-10-22 17:33:34,475 DEV : loss 0.40738871693611145 - score 0.8481\n",
      "2020-10-22 17:33:36,379 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 17:33:37,091 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 17:33:54,340 epoch 59 - iter 36/368 - loss 0.24313393 - samples/sec: 68.94 - lr: 0.025000\n",
      "2020-10-22 17:34:11,374 epoch 59 - iter 72/368 - loss 0.23249025 - samples/sec: 68.95 - lr: 0.025000\n",
      "2020-10-22 17:34:28,189 epoch 59 - iter 108/368 - loss 0.22957188 - samples/sec: 69.78 - lr: 0.025000\n",
      "2020-10-22 17:34:45,861 epoch 59 - iter 144/368 - loss 0.22861453 - samples/sec: 66.36 - lr: 0.025000\n",
      "2020-10-22 17:35:03,148 epoch 59 - iter 180/368 - loss 0.22971472 - samples/sec: 67.86 - lr: 0.025000\n",
      "2020-10-22 17:35:25,813 epoch 59 - iter 216/368 - loss 0.22905825 - samples/sec: 51.89 - lr: 0.025000\n",
      "2020-10-22 17:35:48,194 epoch 59 - iter 252/368 - loss 0.23193393 - samples/sec: 51.80 - lr: 0.025000\n",
      "2020-10-22 17:36:06,822 epoch 59 - iter 288/368 - loss 0.23105321 - samples/sec: 63.24 - lr: 0.025000\n",
      "2020-10-22 17:36:23,765 epoch 59 - iter 324/368 - loss 0.22893649 - samples/sec: 69.36 - lr: 0.025000\n",
      "2020-10-22 17:36:42,653 epoch 59 - iter 360/368 - loss 0.22970266 - samples/sec: 61.34 - lr: 0.025000\n",
      "2020-10-22 17:36:47,415 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 17:36:47,416 EPOCH 59 done: loss 0.2293 - lr 0.0250000\n",
      "2020-10-22 17:37:46,715 DEV : loss 0.41387879848480225 - score 0.8463\n",
      "2020-10-22 17:37:48,699 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 17:37:48,700 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 17:38:07,787 epoch 60 - iter 36/368 - loss 0.23541096 - samples/sec: 62.08 - lr: 0.025000\n",
      "2020-10-22 17:38:30,507 epoch 60 - iter 72/368 - loss 0.23538554 - samples/sec: 51.77 - lr: 0.025000\n",
      "2020-10-22 17:38:52,419 epoch 60 - iter 108/368 - loss 0.23440283 - samples/sec: 52.85 - lr: 0.025000\n",
      "2020-10-22 17:39:12,739 epoch 60 - iter 144/368 - loss 0.22787566 - samples/sec: 57.97 - lr: 0.025000\n",
      "2020-10-22 17:39:30,366 epoch 60 - iter 180/368 - loss 0.23006406 - samples/sec: 66.58 - lr: 0.025000\n",
      "2020-10-22 17:39:47,641 epoch 60 - iter 216/368 - loss 0.22899413 - samples/sec: 67.96 - lr: 0.025000\n",
      "2020-10-22 17:40:04,979 epoch 60 - iter 252/368 - loss 0.22827646 - samples/sec: 67.69 - lr: 0.025000\n",
      "2020-10-22 17:40:22,158 epoch 60 - iter 288/368 - loss 0.22674689 - samples/sec: 68.31 - lr: 0.025000\n",
      "2020-10-22 17:40:39,118 epoch 60 - iter 324/368 - loss 0.22972797 - samples/sec: 69.21 - lr: 0.025000\n",
      "2020-10-22 17:40:56,130 epoch 60 - iter 360/368 - loss 0.22818294 - samples/sec: 68.00 - lr: 0.025000\n",
      "2020-10-22 17:40:59,641 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 17:40:59,642 EPOCH 60 done: loss 0.2280 - lr 0.0250000\n",
      "2020-10-22 17:41:47,494 DEV : loss 0.4143044948577881 - score 0.8479\n",
      "2020-10-22 17:41:49,381 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 17:41:49,381 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 17:42:06,264 epoch 61 - iter 36/368 - loss 0.22205421 - samples/sec: 70.44 - lr: 0.025000\n",
      "2020-10-22 17:42:23,136 epoch 61 - iter 72/368 - loss 0.22161190 - samples/sec: 68.57 - lr: 0.025000\n",
      "2020-10-22 17:42:40,533 epoch 61 - iter 108/368 - loss 0.22274723 - samples/sec: 67.49 - lr: 0.025000\n",
      "2020-10-22 17:42:57,706 epoch 61 - iter 144/368 - loss 0.22719909 - samples/sec: 68.31 - lr: 0.025000\n",
      "2020-10-22 17:43:15,034 epoch 61 - iter 180/368 - loss 0.22785874 - samples/sec: 67.82 - lr: 0.025000\n",
      "2020-10-22 17:43:31,927 epoch 61 - iter 216/368 - loss 0.22710706 - samples/sec: 69.48 - lr: 0.025000\n",
      "2020-10-22 17:43:48,972 epoch 61 - iter 252/368 - loss 0.22831276 - samples/sec: 68.90 - lr: 0.025000\n",
      "2020-10-22 17:44:06,150 epoch 61 - iter 288/368 - loss 0.22971987 - samples/sec: 68.30 - lr: 0.025000\n",
      "2020-10-22 17:44:22,794 epoch 61 - iter 324/368 - loss 0.23090208 - samples/sec: 69.51 - lr: 0.025000\n",
      "2020-10-22 17:44:39,491 epoch 61 - iter 360/368 - loss 0.22950744 - samples/sec: 70.32 - lr: 0.025000\n",
      "2020-10-22 17:44:43,048 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 17:44:43,048 EPOCH 61 done: loss 0.2307 - lr 0.0250000\n",
      "2020-10-22 17:45:32,298 DEV : loss 0.4026189148426056 - score 0.8453\n",
      "2020-10-22 17:45:34,210 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 17:45:34,211 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 17:45:51,628 epoch 62 - iter 36/368 - loss 0.20883210 - samples/sec: 67.07 - lr: 0.025000\n",
      "2020-10-22 17:46:08,270 epoch 62 - iter 72/368 - loss 0.21965398 - samples/sec: 69.55 - lr: 0.025000\n",
      "2020-10-22 17:46:24,980 epoch 62 - iter 108/368 - loss 0.22604893 - samples/sec: 70.26 - lr: 0.025000\n",
      "2020-10-22 17:46:41,456 epoch 62 - iter 144/368 - loss 0.22163407 - samples/sec: 70.21 - lr: 0.025000\n",
      "2020-10-22 17:46:58,521 epoch 62 - iter 180/368 - loss 0.21434570 - samples/sec: 67.79 - lr: 0.025000\n",
      "2020-10-22 17:47:15,293 epoch 62 - iter 216/368 - loss 0.21645800 - samples/sec: 69.94 - lr: 0.025000\n",
      "2020-10-22 17:47:32,254 epoch 62 - iter 252/368 - loss 0.21566939 - samples/sec: 68.20 - lr: 0.025000\n",
      "2020-10-22 17:47:49,079 epoch 62 - iter 288/368 - loss 0.21943863 - samples/sec: 69.79 - lr: 0.025000\n",
      "2020-10-22 17:48:06,130 epoch 62 - iter 324/368 - loss 0.21985597 - samples/sec: 68.82 - lr: 0.025000\n",
      "2020-10-22 17:48:22,861 epoch 62 - iter 360/368 - loss 0.22152737 - samples/sec: 69.13 - lr: 0.025000\n",
      "2020-10-22 17:48:26,319 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 17:48:26,320 EPOCH 62 done: loss 0.2213 - lr 0.0250000\n",
      "2020-10-22 17:49:15,449 DEV : loss 0.4055662155151367 - score 0.8458\n",
      "2020-10-22 17:49:17,365 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 17:49:17,366 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 17:49:34,963 epoch 63 - iter 36/368 - loss 0.19390896 - samples/sec: 67.55 - lr: 0.025000\n",
      "2020-10-22 17:49:52,032 epoch 63 - iter 72/368 - loss 0.20707461 - samples/sec: 68.81 - lr: 0.025000\n",
      "2020-10-22 17:50:09,181 epoch 63 - iter 108/368 - loss 0.21131366 - samples/sec: 67.46 - lr: 0.025000\n",
      "2020-10-22 17:50:26,138 epoch 63 - iter 144/368 - loss 0.21441795 - samples/sec: 69.21 - lr: 0.025000\n",
      "2020-10-22 17:50:42,691 epoch 63 - iter 180/368 - loss 0.21112453 - samples/sec: 70.91 - lr: 0.025000\n",
      "2020-10-22 17:51:00,048 epoch 63 - iter 216/368 - loss 0.21088876 - samples/sec: 66.61 - lr: 0.025000\n",
      "2020-10-22 17:51:16,992 epoch 63 - iter 252/368 - loss 0.21302816 - samples/sec: 68.26 - lr: 0.025000\n",
      "2020-10-22 17:51:34,456 epoch 63 - iter 288/368 - loss 0.21543750 - samples/sec: 67.20 - lr: 0.025000\n",
      "2020-10-22 17:51:51,772 epoch 63 - iter 324/368 - loss 0.21691219 - samples/sec: 66.84 - lr: 0.025000\n",
      "2020-10-22 17:52:09,038 epoch 63 - iter 360/368 - loss 0.21738559 - samples/sec: 67.98 - lr: 0.025000\n",
      "2020-10-22 17:52:12,721 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 17:52:12,722 EPOCH 63 done: loss 0.2164 - lr 0.0250000\n",
      "2020-10-22 17:53:02,064 DEV : loss 0.4120483994483948 - score 0.8502\n",
      "2020-10-22 17:53:04,000 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 17:53:04,725 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 17:53:21,973 epoch 64 - iter 36/368 - loss 0.18474919 - samples/sec: 68.91 - lr: 0.025000\n",
      "2020-10-22 17:53:39,366 epoch 64 - iter 72/368 - loss 0.20703451 - samples/sec: 67.48 - lr: 0.025000\n",
      "2020-10-22 17:53:56,855 epoch 64 - iter 108/368 - loss 0.20279843 - samples/sec: 67.05 - lr: 0.025000\n",
      "2020-10-22 17:54:13,654 epoch 64 - iter 144/368 - loss 0.20900583 - samples/sec: 69.89 - lr: 0.025000\n",
      "2020-10-22 17:54:30,510 epoch 64 - iter 180/368 - loss 0.21741619 - samples/sec: 69.69 - lr: 0.025000\n",
      "2020-10-22 17:54:47,410 epoch 64 - iter 216/368 - loss 0.21574215 - samples/sec: 69.44 - lr: 0.025000\n",
      "2020-10-22 17:55:04,093 epoch 64 - iter 252/368 - loss 0.21451254 - samples/sec: 70.34 - lr: 0.025000\n",
      "2020-10-22 17:55:21,366 epoch 64 - iter 288/368 - loss 0.21756706 - samples/sec: 67.93 - lr: 0.025000\n",
      "2020-10-22 17:55:38,358 epoch 64 - iter 324/368 - loss 0.22010123 - samples/sec: 68.08 - lr: 0.025000\n",
      "2020-10-22 17:55:55,682 epoch 64 - iter 360/368 - loss 0.22096144 - samples/sec: 67.76 - lr: 0.025000\n",
      "2020-10-22 17:55:59,279 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 17:55:59,279 EPOCH 64 done: loss 0.2202 - lr 0.0250000\n",
      "2020-10-22 17:56:49,079 DEV : loss 0.4129878282546997 - score 0.8514\n",
      "2020-10-22 17:56:50,986 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 17:56:51,709 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 17:57:09,130 epoch 65 - iter 36/368 - loss 0.20914969 - samples/sec: 68.10 - lr: 0.025000\n",
      "2020-10-22 17:57:26,480 epoch 65 - iter 72/368 - loss 0.20570252 - samples/sec: 67.64 - lr: 0.025000\n",
      "2020-10-22 17:57:43,462 epoch 65 - iter 108/368 - loss 0.20125384 - samples/sec: 68.12 - lr: 0.025000\n",
      "2020-10-22 17:58:00,608 epoch 65 - iter 144/368 - loss 0.20566990 - samples/sec: 68.46 - lr: 0.025000\n",
      "2020-10-22 17:58:17,397 epoch 65 - iter 180/368 - loss 0.21043243 - samples/sec: 69.91 - lr: 0.025000\n",
      "2020-10-22 17:58:33,881 epoch 65 - iter 216/368 - loss 0.21043141 - samples/sec: 71.25 - lr: 0.025000\n",
      "2020-10-22 17:58:50,411 epoch 65 - iter 252/368 - loss 0.20992698 - samples/sec: 71.03 - lr: 0.025000\n",
      "2020-10-22 17:59:07,181 epoch 65 - iter 288/368 - loss 0.21044053 - samples/sec: 69.98 - lr: 0.025000\n",
      "2020-10-22 17:59:24,717 epoch 65 - iter 324/368 - loss 0.21145116 - samples/sec: 66.92 - lr: 0.025000\n",
      "2020-10-22 17:59:41,355 epoch 65 - iter 360/368 - loss 0.21259350 - samples/sec: 69.51 - lr: 0.025000\n",
      "2020-10-22 17:59:45,296 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 17:59:45,296 EPOCH 65 done: loss 0.2134 - lr 0.0250000\n",
      "2020-10-22 18:00:34,751 DEV : loss 0.3997349441051483 - score 0.8486\n",
      "2020-10-22 18:00:36,687 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 18:00:36,688 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 18:00:53,646 epoch 66 - iter 36/368 - loss 0.20483964 - samples/sec: 70.09 - lr: 0.025000\n",
      "2020-10-22 18:01:09,974 epoch 66 - iter 72/368 - loss 0.20934126 - samples/sec: 71.92 - lr: 0.025000\n",
      "2020-10-22 18:01:26,534 epoch 66 - iter 108/368 - loss 0.20075324 - samples/sec: 69.85 - lr: 0.025000\n",
      "2020-10-22 18:01:43,563 epoch 66 - iter 144/368 - loss 0.20500973 - samples/sec: 68.90 - lr: 0.025000\n",
      "2020-10-22 18:02:00,178 epoch 66 - iter 180/368 - loss 0.20021127 - samples/sec: 70.66 - lr: 0.025000\n",
      "2020-10-22 18:02:16,372 epoch 66 - iter 216/368 - loss 0.20603247 - samples/sec: 71.44 - lr: 0.025000\n",
      "2020-10-22 18:02:33,342 epoch 66 - iter 252/368 - loss 0.20609392 - samples/sec: 68.18 - lr: 0.025000\n",
      "2020-10-22 18:02:50,283 epoch 66 - iter 288/368 - loss 0.20387158 - samples/sec: 69.31 - lr: 0.025000\n",
      "2020-10-22 18:03:07,341 epoch 66 - iter 324/368 - loss 0.20446498 - samples/sec: 68.81 - lr: 0.025000\n",
      "2020-10-22 18:03:24,243 epoch 66 - iter 360/368 - loss 0.20628468 - samples/sec: 69.46 - lr: 0.025000\n",
      "2020-10-22 18:03:27,715 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 18:03:27,715 EPOCH 66 done: loss 0.2062 - lr 0.0250000\n",
      "2020-10-22 18:04:16,460 DEV : loss 0.3976660370826721 - score 0.8443\n",
      "2020-10-22 18:04:18,356 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 18:04:18,357 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 18:04:35,815 epoch 67 - iter 36/368 - loss 0.21867020 - samples/sec: 67.96 - lr: 0.025000\n",
      "2020-10-22 18:04:52,537 epoch 67 - iter 72/368 - loss 0.21982740 - samples/sec: 69.18 - lr: 0.025000\n",
      "2020-10-22 18:05:09,610 epoch 67 - iter 108/368 - loss 0.22487753 - samples/sec: 68.75 - lr: 0.025000\n",
      "2020-10-22 18:05:26,828 epoch 67 - iter 144/368 - loss 0.22243387 - samples/sec: 68.10 - lr: 0.025000\n",
      "2020-10-22 18:05:43,767 epoch 67 - iter 180/368 - loss 0.22085236 - samples/sec: 69.23 - lr: 0.025000\n",
      "2020-10-22 18:06:00,786 epoch 67 - iter 216/368 - loss 0.21627762 - samples/sec: 68.97 - lr: 0.025000\n",
      "2020-10-22 18:06:18,120 epoch 67 - iter 252/368 - loss 0.21350210 - samples/sec: 67.67 - lr: 0.025000\n",
      "2020-10-22 18:06:34,873 epoch 67 - iter 288/368 - loss 0.21621862 - samples/sec: 69.04 - lr: 0.025000\n",
      "2020-10-22 18:06:51,705 epoch 67 - iter 324/368 - loss 0.21449373 - samples/sec: 69.73 - lr: 0.025000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 18:07:08,211 epoch 67 - iter 360/368 - loss 0.21173068 - samples/sec: 71.10 - lr: 0.025000\n",
      "2020-10-22 18:07:11,571 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 18:07:11,572 EPOCH 67 done: loss 0.2113 - lr 0.0250000\n",
      "2020-10-22 18:08:00,530 DEV : loss 0.41175931692123413 - score 0.843\n",
      "2020-10-22 18:08:02,451 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 18:08:02,452 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 18:08:19,683 epoch 68 - iter 36/368 - loss 0.20770690 - samples/sec: 68.96 - lr: 0.025000\n",
      "2020-10-22 18:08:36,691 epoch 68 - iter 72/368 - loss 0.21077614 - samples/sec: 69.02 - lr: 0.025000\n",
      "2020-10-22 18:08:53,723 epoch 68 - iter 108/368 - loss 0.20838435 - samples/sec: 68.90 - lr: 0.025000\n",
      "2020-10-22 18:09:11,123 epoch 68 - iter 144/368 - loss 0.20627320 - samples/sec: 67.52 - lr: 0.025000\n",
      "2020-10-22 18:09:28,541 epoch 68 - iter 180/368 - loss 0.20631264 - samples/sec: 67.33 - lr: 0.025000\n",
      "2020-10-22 18:09:45,910 epoch 68 - iter 216/368 - loss 0.20760613 - samples/sec: 67.57 - lr: 0.025000\n",
      "2020-10-22 18:10:03,118 epoch 68 - iter 252/368 - loss 0.20629632 - samples/sec: 68.21 - lr: 0.025000\n",
      "2020-10-22 18:10:20,143 epoch 68 - iter 288/368 - loss 0.20465597 - samples/sec: 67.99 - lr: 0.025000\n",
      "2020-10-22 18:10:37,748 epoch 68 - iter 324/368 - loss 0.20707653 - samples/sec: 66.67 - lr: 0.025000\n",
      "2020-10-22 18:10:54,808 epoch 68 - iter 360/368 - loss 0.20737545 - samples/sec: 67.76 - lr: 0.025000\n",
      "2020-10-22 18:10:58,560 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 18:10:58,561 EPOCH 68 done: loss 0.2067 - lr 0.0250000\n",
      "2020-10-22 18:11:47,037 DEV : loss 0.4105680584907532 - score 0.8445\n",
      "2020-10-22 18:11:48,950 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 18:11:48,951 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 18:12:06,381 epoch 69 - iter 36/368 - loss 0.19263798 - samples/sec: 67.01 - lr: 0.025000\n",
      "2020-10-22 18:12:23,338 epoch 69 - iter 72/368 - loss 0.18848161 - samples/sec: 69.22 - lr: 0.025000\n",
      "2020-10-22 18:12:40,276 epoch 69 - iter 108/368 - loss 0.19412494 - samples/sec: 68.27 - lr: 0.025000\n",
      "2020-10-22 18:12:56,843 epoch 69 - iter 144/368 - loss 0.19379960 - samples/sec: 69.82 - lr: 0.025000\n",
      "2020-10-22 18:13:13,671 epoch 69 - iter 180/368 - loss 0.19300387 - samples/sec: 69.74 - lr: 0.025000\n",
      "2020-10-22 18:13:30,371 epoch 69 - iter 216/368 - loss 0.19629617 - samples/sec: 70.33 - lr: 0.025000\n",
      "2020-10-22 18:13:47,114 epoch 69 - iter 252/368 - loss 0.19825760 - samples/sec: 69.08 - lr: 0.025000\n",
      "2020-10-22 18:14:03,810 epoch 69 - iter 288/368 - loss 0.20016482 - samples/sec: 70.30 - lr: 0.025000\n",
      "2020-10-22 18:14:20,478 epoch 69 - iter 324/368 - loss 0.20113314 - samples/sec: 70.46 - lr: 0.025000\n",
      "2020-10-22 18:14:36,884 epoch 69 - iter 360/368 - loss 0.20005443 - samples/sec: 71.61 - lr: 0.025000\n",
      "2020-10-22 18:14:40,440 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 18:14:40,440 EPOCH 69 done: loss 0.1994 - lr 0.0250000\n",
      "2020-10-22 18:15:29,226 DEV : loss 0.4048095941543579 - score 0.8497\n",
      "2020-10-22 18:15:31,125 BAD EPOCHS (no improvement): 5\n",
      "2020-10-22 18:15:31,126 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 18:15:48,604 epoch 70 - iter 36/368 - loss 0.19797899 - samples/sec: 66.80 - lr: 0.025000\n",
      "2020-10-22 18:16:05,890 epoch 70 - iter 72/368 - loss 0.20265822 - samples/sec: 67.88 - lr: 0.025000\n",
      "2020-10-22 18:16:23,123 epoch 70 - iter 108/368 - loss 0.20744402 - samples/sec: 68.16 - lr: 0.025000\n",
      "2020-10-22 18:16:39,831 epoch 70 - iter 144/368 - loss 0.20781992 - samples/sec: 70.28 - lr: 0.025000\n",
      "2020-10-22 18:16:56,483 epoch 70 - iter 180/368 - loss 0.20726403 - samples/sec: 70.49 - lr: 0.025000\n",
      "2020-10-22 18:17:13,298 epoch 70 - iter 216/368 - loss 0.20668510 - samples/sec: 69.83 - lr: 0.025000\n",
      "2020-10-22 18:17:30,149 epoch 70 - iter 252/368 - loss 0.20723965 - samples/sec: 69.78 - lr: 0.025000\n",
      "2020-10-22 18:17:47,155 epoch 70 - iter 288/368 - loss 0.20497553 - samples/sec: 68.00 - lr: 0.025000\n",
      "2020-10-22 18:18:04,164 epoch 70 - iter 324/368 - loss 0.20755235 - samples/sec: 67.99 - lr: 0.025000\n",
      "2020-10-22 18:18:20,912 epoch 70 - iter 360/368 - loss 0.20679792 - samples/sec: 70.09 - lr: 0.025000\n",
      "2020-10-22 18:18:24,640 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 18:18:24,641 EPOCH 70 done: loss 0.2072 - lr 0.0250000\n",
      "2020-10-22 18:19:13,615 DEV : loss 0.4143088459968567 - score 0.8512\n",
      "Epoch    70: reducing learning rate of group 0 to 1.2500e-02.\n",
      "2020-10-22 18:19:15,515 BAD EPOCHS (no improvement): 6\n",
      "2020-10-22 18:19:15,516 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 18:19:33,255 epoch 71 - iter 36/368 - loss 0.19695760 - samples/sec: 66.94 - lr: 0.012500\n",
      "2020-10-22 18:19:50,027 epoch 71 - iter 72/368 - loss 0.18959277 - samples/sec: 69.97 - lr: 0.012500\n",
      "2020-10-22 18:20:06,980 epoch 71 - iter 108/368 - loss 0.19939132 - samples/sec: 69.18 - lr: 0.012500\n",
      "2020-10-22 18:20:23,868 epoch 71 - iter 144/368 - loss 0.19376447 - samples/sec: 69.57 - lr: 0.012500\n",
      "2020-10-22 18:20:40,876 epoch 71 - iter 180/368 - loss 0.19397832 - samples/sec: 67.97 - lr: 0.012500\n",
      "2020-10-22 18:20:57,767 epoch 71 - iter 216/368 - loss 0.19571395 - samples/sec: 69.43 - lr: 0.012500\n",
      "2020-10-22 18:21:14,653 epoch 71 - iter 252/368 - loss 0.19246457 - samples/sec: 68.50 - lr: 0.012500\n",
      "2020-10-22 18:21:31,897 epoch 71 - iter 288/368 - loss 0.19248399 - samples/sec: 68.13 - lr: 0.012500\n",
      "2020-10-22 18:21:48,939 epoch 71 - iter 324/368 - loss 0.19406607 - samples/sec: 68.89 - lr: 0.012500\n",
      "2020-10-22 18:22:06,225 epoch 71 - iter 360/368 - loss 0.19463675 - samples/sec: 66.92 - lr: 0.012500\n",
      "2020-10-22 18:22:09,822 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 18:22:09,822 EPOCH 71 done: loss 0.1941 - lr 0.0125000\n",
      "2020-10-22 18:22:59,140 DEV : loss 0.4081110656261444 - score 0.8502\n",
      "2020-10-22 18:23:01,112 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 18:23:01,113 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 18:23:18,436 epoch 72 - iter 36/368 - loss 0.20240327 - samples/sec: 68.62 - lr: 0.012500\n",
      "2020-10-22 18:23:35,968 epoch 72 - iter 72/368 - loss 0.19216974 - samples/sec: 66.93 - lr: 0.012500\n",
      "2020-10-22 18:23:52,976 epoch 72 - iter 108/368 - loss 0.18739429 - samples/sec: 69.04 - lr: 0.012500\n",
      "2020-10-22 18:24:10,230 epoch 72 - iter 144/368 - loss 0.18591734 - samples/sec: 68.12 - lr: 0.012500\n",
      "2020-10-22 18:24:27,213 epoch 72 - iter 180/368 - loss 0.18690782 - samples/sec: 69.07 - lr: 0.012500\n",
      "2020-10-22 18:24:44,509 epoch 72 - iter 216/368 - loss 0.18267224 - samples/sec: 66.88 - lr: 0.012500\n",
      "2020-10-22 18:25:01,463 epoch 72 - iter 252/368 - loss 0.18700157 - samples/sec: 69.20 - lr: 0.012500\n",
      "2020-10-22 18:25:18,366 epoch 72 - iter 288/368 - loss 0.18502944 - samples/sec: 68.44 - lr: 0.012500\n",
      "2020-10-22 18:25:35,683 epoch 72 - iter 324/368 - loss 0.18888661 - samples/sec: 67.77 - lr: 0.012500\n",
      "2020-10-22 18:25:52,701 epoch 72 - iter 360/368 - loss 0.18792180 - samples/sec: 68.95 - lr: 0.012500\n",
      "2020-10-22 18:25:56,528 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 18:25:56,528 EPOCH 72 done: loss 0.1897 - lr 0.0125000\n",
      "2020-10-22 18:26:45,604 DEV : loss 0.417693167924881 - score 0.8491\n",
      "2020-10-22 18:26:47,547 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 18:26:47,548 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 18:27:05,184 epoch 73 - iter 36/368 - loss 0.20354937 - samples/sec: 67.44 - lr: 0.012500\n",
      "2020-10-22 18:27:27,678 epoch 73 - iter 72/368 - loss 0.20887475 - samples/sec: 52.31 - lr: 0.012500\n",
      "2020-10-22 18:27:50,514 epoch 73 - iter 108/368 - loss 0.19766173 - samples/sec: 51.46 - lr: 0.012500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 18:28:12,164 epoch 73 - iter 144/368 - loss 0.19067199 - samples/sec: 54.38 - lr: 0.012500\n",
      "2020-10-22 18:28:29,820 epoch 73 - iter 180/368 - loss 0.19144834 - samples/sec: 66.50 - lr: 0.012500\n",
      "2020-10-22 18:28:47,289 epoch 73 - iter 216/368 - loss 0.18932441 - samples/sec: 67.29 - lr: 0.012500\n",
      "2020-10-22 18:29:04,697 epoch 73 - iter 252/368 - loss 0.19458806 - samples/sec: 67.38 - lr: 0.012500\n",
      "2020-10-22 18:29:22,140 epoch 73 - iter 288/368 - loss 0.19646669 - samples/sec: 66.30 - lr: 0.012500\n",
      "2020-10-22 18:29:38,837 epoch 73 - iter 324/368 - loss 0.19240940 - samples/sec: 70.31 - lr: 0.012500\n",
      "2020-10-22 18:29:55,242 epoch 73 - iter 360/368 - loss 0.19217938 - samples/sec: 70.49 - lr: 0.012500\n",
      "2020-10-22 18:29:58,955 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 18:29:58,955 EPOCH 73 done: loss 0.1918 - lr 0.0125000\n",
      "2020-10-22 18:30:46,731 DEV : loss 0.40996217727661133 - score 0.8517\n",
      "2020-10-22 18:30:48,606 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 18:30:49,314 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 18:31:06,341 epoch 74 - iter 36/368 - loss 0.15778557 - samples/sec: 69.76 - lr: 0.012500\n",
      "2020-10-22 18:31:23,017 epoch 74 - iter 72/368 - loss 0.17639042 - samples/sec: 70.42 - lr: 0.012500\n",
      "2020-10-22 18:31:40,031 epoch 74 - iter 108/368 - loss 0.17898571 - samples/sec: 68.98 - lr: 0.012500\n",
      "2020-10-22 18:31:56,275 epoch 74 - iter 144/368 - loss 0.18282647 - samples/sec: 71.21 - lr: 0.012500\n",
      "2020-10-22 18:32:12,673 epoch 74 - iter 180/368 - loss 0.18399077 - samples/sec: 71.66 - lr: 0.012500\n",
      "2020-10-22 18:32:29,139 epoch 74 - iter 216/368 - loss 0.18356196 - samples/sec: 71.34 - lr: 0.012500\n",
      "2020-10-22 18:32:45,713 epoch 74 - iter 252/368 - loss 0.18810792 - samples/sec: 70.79 - lr: 0.012500\n",
      "2020-10-22 18:33:02,260 epoch 74 - iter 288/368 - loss 0.18893114 - samples/sec: 70.96 - lr: 0.012500\n",
      "2020-10-22 18:33:18,814 epoch 74 - iter 324/368 - loss 0.18979475 - samples/sec: 70.87 - lr: 0.012500\n",
      "2020-10-22 18:33:35,556 epoch 74 - iter 360/368 - loss 0.18821887 - samples/sec: 70.16 - lr: 0.012500\n",
      "2020-10-22 18:33:39,078 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 18:33:39,079 EPOCH 74 done: loss 0.1900 - lr 0.0125000\n",
      "2020-10-22 18:34:26,904 DEV : loss 0.4109233319759369 - score 0.8517\n",
      "2020-10-22 18:34:28,807 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 18:34:28,808 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 18:34:45,742 epoch 75 - iter 36/368 - loss 0.17068455 - samples/sec: 70.28 - lr: 0.012500\n",
      "2020-10-22 18:35:02,158 epoch 75 - iter 72/368 - loss 0.15715134 - samples/sec: 71.54 - lr: 0.012500\n",
      "2020-10-22 18:35:18,868 epoch 75 - iter 108/368 - loss 0.16361987 - samples/sec: 70.27 - lr: 0.012500\n",
      "2020-10-22 18:35:35,331 epoch 75 - iter 144/368 - loss 0.16797529 - samples/sec: 71.32 - lr: 0.012500\n",
      "2020-10-22 18:35:51,743 epoch 75 - iter 180/368 - loss 0.17085315 - samples/sec: 71.61 - lr: 0.012500\n",
      "2020-10-22 18:36:08,287 epoch 75 - iter 216/368 - loss 0.17613257 - samples/sec: 70.95 - lr: 0.012500\n",
      "2020-10-22 18:36:24,914 epoch 75 - iter 252/368 - loss 0.17840681 - samples/sec: 69.57 - lr: 0.012500\n",
      "2020-10-22 18:36:41,494 epoch 75 - iter 288/368 - loss 0.17970758 - samples/sec: 70.82 - lr: 0.012500\n",
      "2020-10-22 18:36:58,193 epoch 75 - iter 324/368 - loss 0.17937230 - samples/sec: 70.24 - lr: 0.012500\n",
      "2020-10-22 18:37:14,686 epoch 75 - iter 360/368 - loss 0.18332106 - samples/sec: 71.23 - lr: 0.012500\n",
      "2020-10-22 18:37:18,205 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 18:37:18,205 EPOCH 75 done: loss 0.1830 - lr 0.0125000\n",
      "2020-10-22 18:38:06,169 DEV : loss 0.4129912257194519 - score 0.8497\n",
      "2020-10-22 18:38:08,042 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 18:38:08,043 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 18:38:24,894 epoch 76 - iter 36/368 - loss 0.16234090 - samples/sec: 70.62 - lr: 0.012500\n",
      "2020-10-22 18:38:41,188 epoch 76 - iter 72/368 - loss 0.16384009 - samples/sec: 72.03 - lr: 0.012500\n",
      "2020-10-22 18:38:57,379 epoch 76 - iter 108/368 - loss 0.16325234 - samples/sec: 72.54 - lr: 0.012500\n",
      "2020-10-22 18:39:13,945 epoch 76 - iter 144/368 - loss 0.16660600 - samples/sec: 70.92 - lr: 0.012500\n",
      "2020-10-22 18:39:30,220 epoch 76 - iter 180/368 - loss 0.17101093 - samples/sec: 72.13 - lr: 0.012500\n",
      "2020-10-22 18:39:46,736 epoch 76 - iter 216/368 - loss 0.17229653 - samples/sec: 71.11 - lr: 0.012500\n",
      "2020-10-22 18:40:03,216 epoch 76 - iter 252/368 - loss 0.17520930 - samples/sec: 70.20 - lr: 0.012500\n",
      "2020-10-22 18:40:20,021 epoch 76 - iter 288/368 - loss 0.17435464 - samples/sec: 69.85 - lr: 0.012500\n",
      "2020-10-22 18:40:36,710 epoch 76 - iter 324/368 - loss 0.17508838 - samples/sec: 70.36 - lr: 0.012500\n",
      "2020-10-22 18:40:53,379 epoch 76 - iter 360/368 - loss 0.17641692 - samples/sec: 70.43 - lr: 0.012500\n",
      "2020-10-22 18:40:56,870 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 18:40:56,870 EPOCH 76 done: loss 0.1769 - lr 0.0125000\n",
      "2020-10-22 18:41:45,013 DEV : loss 0.4151964485645294 - score 0.8502\n",
      "2020-10-22 18:41:46,938 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 18:41:46,939 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 18:42:03,394 epoch 77 - iter 36/368 - loss 0.16057052 - samples/sec: 72.17 - lr: 0.012500\n",
      "2020-10-22 18:42:20,220 epoch 77 - iter 72/368 - loss 0.16443508 - samples/sec: 68.74 - lr: 0.012500\n",
      "2020-10-22 18:42:36,772 epoch 77 - iter 108/368 - loss 0.16248391 - samples/sec: 69.87 - lr: 0.012500\n",
      "2020-10-22 18:42:53,214 epoch 77 - iter 144/368 - loss 0.17207546 - samples/sec: 71.39 - lr: 0.012500\n",
      "2020-10-22 18:43:09,546 epoch 77 - iter 180/368 - loss 0.17321290 - samples/sec: 71.88 - lr: 0.012500\n",
      "2020-10-22 18:43:26,112 epoch 77 - iter 216/368 - loss 0.17333342 - samples/sec: 70.82 - lr: 0.012500\n",
      "2020-10-22 18:43:42,507 epoch 77 - iter 252/368 - loss 0.17439866 - samples/sec: 71.69 - lr: 0.012500\n",
      "2020-10-22 18:43:58,751 epoch 77 - iter 288/368 - loss 0.17924117 - samples/sec: 72.31 - lr: 0.012500\n",
      "2020-10-22 18:44:15,108 epoch 77 - iter 324/368 - loss 0.18024220 - samples/sec: 71.80 - lr: 0.012500\n",
      "2020-10-22 18:44:31,790 epoch 77 - iter 360/368 - loss 0.18030118 - samples/sec: 70.35 - lr: 0.012500\n",
      "2020-10-22 18:44:35,215 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 18:44:35,215 EPOCH 77 done: loss 0.1805 - lr 0.0125000\n",
      "2020-10-22 18:45:22,239 DEV : loss 0.4083593487739563 - score 0.8499\n",
      "2020-10-22 18:45:24,131 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 18:45:24,132 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 18:45:40,815 epoch 78 - iter 36/368 - loss 0.17206430 - samples/sec: 71.41 - lr: 0.012500\n",
      "2020-10-22 18:45:57,634 epoch 78 - iter 72/368 - loss 0.16398948 - samples/sec: 68.79 - lr: 0.012500\n",
      "2020-10-22 18:46:14,100 epoch 78 - iter 108/368 - loss 0.16932542 - samples/sec: 71.34 - lr: 0.012500\n",
      "2020-10-22 18:46:30,495 epoch 78 - iter 144/368 - loss 0.16230584 - samples/sec: 71.61 - lr: 0.012500\n",
      "2020-10-22 18:46:47,022 epoch 78 - iter 180/368 - loss 0.16981911 - samples/sec: 69.99 - lr: 0.012500\n",
      "2020-10-22 18:47:03,846 epoch 78 - iter 216/368 - loss 0.17285586 - samples/sec: 69.80 - lr: 0.012500\n",
      "2020-10-22 18:47:20,295 epoch 78 - iter 252/368 - loss 0.17501254 - samples/sec: 71.41 - lr: 0.012500\n",
      "2020-10-22 18:47:36,842 epoch 78 - iter 288/368 - loss 0.17552146 - samples/sec: 70.95 - lr: 0.012500\n",
      "2020-10-22 18:47:53,344 epoch 78 - iter 324/368 - loss 0.17575966 - samples/sec: 71.12 - lr: 0.012500\n",
      "2020-10-22 18:48:09,708 epoch 78 - iter 360/368 - loss 0.17535524 - samples/sec: 70.69 - lr: 0.012500\n",
      "2020-10-22 18:48:13,181 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 18:48:13,181 EPOCH 78 done: loss 0.1750 - lr 0.0125000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 18:49:00,437 DEV : loss 0.4110707640647888 - score 0.8481\n",
      "2020-10-22 18:49:02,303 BAD EPOCHS (no improvement): 5\n",
      "2020-10-22 18:49:02,304 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 18:49:19,196 epoch 79 - iter 36/368 - loss 0.19623629 - samples/sec: 70.38 - lr: 0.012500\n",
      "2020-10-22 18:49:35,545 epoch 79 - iter 72/368 - loss 0.19466855 - samples/sec: 71.83 - lr: 0.012500\n",
      "2020-10-22 18:49:52,132 epoch 79 - iter 108/368 - loss 0.18450918 - samples/sec: 70.78 - lr: 0.012500\n",
      "2020-10-22 18:50:08,512 epoch 79 - iter 144/368 - loss 0.18651052 - samples/sec: 71.69 - lr: 0.012500\n",
      "2020-10-22 18:50:25,021 epoch 79 - iter 180/368 - loss 0.18074880 - samples/sec: 71.17 - lr: 0.012500\n",
      "2020-10-22 18:50:41,207 epoch 79 - iter 216/368 - loss 0.18359526 - samples/sec: 72.53 - lr: 0.012500\n",
      "2020-10-22 18:50:57,477 epoch 79 - iter 252/368 - loss 0.18273030 - samples/sec: 71.14 - lr: 0.012500\n",
      "2020-10-22 18:51:13,709 epoch 79 - iter 288/368 - loss 0.18057866 - samples/sec: 72.31 - lr: 0.012500\n",
      "2020-10-22 18:51:29,987 epoch 79 - iter 324/368 - loss 0.17878632 - samples/sec: 72.16 - lr: 0.012500\n",
      "2020-10-22 18:51:46,046 epoch 79 - iter 360/368 - loss 0.17768979 - samples/sec: 73.17 - lr: 0.012500\n",
      "2020-10-22 18:51:49,544 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 18:51:49,544 EPOCH 79 done: loss 0.1764 - lr 0.0125000\n",
      "2020-10-22 18:52:37,613 DEV : loss 0.4189637005329132 - score 0.8504\n",
      "Epoch    79: reducing learning rate of group 0 to 6.2500e-03.\n",
      "2020-10-22 18:52:39,521 BAD EPOCHS (no improvement): 6\n",
      "2020-10-22 18:52:39,522 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 18:52:55,765 epoch 80 - iter 36/368 - loss 0.16702723 - samples/sec: 71.84 - lr: 0.006250\n",
      "2020-10-22 18:53:12,172 epoch 80 - iter 72/368 - loss 0.18308921 - samples/sec: 71.69 - lr: 0.006250\n",
      "2020-10-22 18:53:28,550 epoch 80 - iter 108/368 - loss 0.17960644 - samples/sec: 71.70 - lr: 0.006250\n",
      "2020-10-22 18:53:44,970 epoch 80 - iter 144/368 - loss 0.17201966 - samples/sec: 71.50 - lr: 0.006250\n",
      "2020-10-22 18:54:01,568 epoch 80 - iter 180/368 - loss 0.17192315 - samples/sec: 70.74 - lr: 0.006250\n",
      "2020-10-22 18:54:18,013 epoch 80 - iter 216/368 - loss 0.17266394 - samples/sec: 70.33 - lr: 0.006250\n",
      "2020-10-22 18:54:34,600 epoch 80 - iter 252/368 - loss 0.16951642 - samples/sec: 70.78 - lr: 0.006250\n",
      "2020-10-22 18:54:51,336 epoch 80 - iter 288/368 - loss 0.17044623 - samples/sec: 70.17 - lr: 0.006250\n",
      "2020-10-22 18:55:07,521 epoch 80 - iter 324/368 - loss 0.17347700 - samples/sec: 71.51 - lr: 0.006250\n",
      "2020-10-22 18:55:24,184 epoch 80 - iter 360/368 - loss 0.17296377 - samples/sec: 70.50 - lr: 0.006250\n",
      "2020-10-22 18:55:27,737 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 18:55:27,737 EPOCH 80 done: loss 0.1739 - lr 0.0062500\n",
      "2020-10-22 18:56:15,535 DEV : loss 0.41911759972572327 - score 0.8494\n",
      "2020-10-22 18:56:17,437 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 18:56:17,438 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 18:56:34,158 epoch 81 - iter 36/368 - loss 0.16349057 - samples/sec: 69.89 - lr: 0.006250\n",
      "2020-10-22 18:56:50,534 epoch 81 - iter 72/368 - loss 0.18151547 - samples/sec: 71.70 - lr: 0.006250\n",
      "2020-10-22 18:57:06,881 epoch 81 - iter 108/368 - loss 0.17324494 - samples/sec: 70.77 - lr: 0.006250\n",
      "2020-10-22 18:57:23,644 epoch 81 - iter 144/368 - loss 0.17447613 - samples/sec: 70.02 - lr: 0.006250\n",
      "2020-10-22 18:57:39,992 epoch 81 - iter 180/368 - loss 0.17365956 - samples/sec: 71.86 - lr: 0.006250\n",
      "2020-10-22 18:57:56,481 epoch 81 - iter 216/368 - loss 0.16938875 - samples/sec: 71.23 - lr: 0.006250\n",
      "2020-10-22 18:58:12,996 epoch 81 - iter 252/368 - loss 0.16641410 - samples/sec: 71.08 - lr: 0.006250\n",
      "2020-10-22 18:58:29,345 epoch 81 - iter 288/368 - loss 0.17016909 - samples/sec: 71.80 - lr: 0.006250\n",
      "2020-10-22 18:58:45,661 epoch 81 - iter 324/368 - loss 0.17177070 - samples/sec: 70.89 - lr: 0.006250\n",
      "2020-10-22 18:59:01,887 epoch 81 - iter 360/368 - loss 0.17273502 - samples/sec: 72.32 - lr: 0.006250\n",
      "2020-10-22 18:59:05,397 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 18:59:05,397 EPOCH 81 done: loss 0.1737 - lr 0.0062500\n",
      "2020-10-22 18:59:53,011 DEV : loss 0.41747888922691345 - score 0.8509\n",
      "2020-10-22 18:59:54,882 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 18:59:54,882 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 19:00:11,659 epoch 82 - iter 36/368 - loss 0.15441373 - samples/sec: 70.95 - lr: 0.006250\n",
      "2020-10-22 19:00:28,165 epoch 82 - iter 72/368 - loss 0.16986219 - samples/sec: 71.09 - lr: 0.006250\n",
      "2020-10-22 19:00:44,487 epoch 82 - iter 108/368 - loss 0.17425097 - samples/sec: 71.94 - lr: 0.006250\n",
      "2020-10-22 19:01:00,821 epoch 82 - iter 144/368 - loss 0.17650829 - samples/sec: 71.90 - lr: 0.006250\n",
      "2020-10-22 19:01:16,804 epoch 82 - iter 180/368 - loss 0.17529957 - samples/sec: 72.37 - lr: 0.006250\n",
      "2020-10-22 19:01:33,009 epoch 82 - iter 216/368 - loss 0.17054098 - samples/sec: 72.52 - lr: 0.006250\n",
      "2020-10-22 19:01:49,183 epoch 82 - iter 252/368 - loss 0.17173816 - samples/sec: 72.58 - lr: 0.006250\n",
      "2020-10-22 19:02:06,253 epoch 82 - iter 288/368 - loss 0.17534098 - samples/sec: 68.86 - lr: 0.006250\n",
      "2020-10-22 19:02:23,824 epoch 82 - iter 324/368 - loss 0.17361439 - samples/sec: 66.74 - lr: 0.006250\n",
      "2020-10-22 19:02:40,731 epoch 82 - iter 360/368 - loss 0.17363489 - samples/sec: 69.44 - lr: 0.006250\n",
      "2020-10-22 19:02:44,220 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 19:02:44,220 EPOCH 82 done: loss 0.1738 - lr 0.0062500\n",
      "2020-10-22 19:03:33,229 DEV : loss 0.42080599069595337 - score 0.8486\n",
      "2020-10-22 19:03:35,169 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 19:03:35,170 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 19:03:53,024 epoch 83 - iter 36/368 - loss 0.17301588 - samples/sec: 66.86 - lr: 0.006250\n",
      "2020-10-22 19:04:10,268 epoch 83 - iter 72/368 - loss 0.17630416 - samples/sec: 68.06 - lr: 0.006250\n",
      "2020-10-22 19:04:27,166 epoch 83 - iter 108/368 - loss 0.16989309 - samples/sec: 69.48 - lr: 0.006250\n",
      "2020-10-22 19:04:44,132 epoch 83 - iter 144/368 - loss 0.16985772 - samples/sec: 69.23 - lr: 0.006250\n",
      "2020-10-22 19:05:01,907 epoch 83 - iter 180/368 - loss 0.16768818 - samples/sec: 66.00 - lr: 0.006250\n",
      "2020-10-22 19:05:18,472 epoch 83 - iter 216/368 - loss 0.17027264 - samples/sec: 69.84 - lr: 0.006250\n",
      "2020-10-22 19:05:35,749 epoch 83 - iter 252/368 - loss 0.16914190 - samples/sec: 67.96 - lr: 0.006250\n",
      "2020-10-22 19:05:52,742 epoch 83 - iter 288/368 - loss 0.16694829 - samples/sec: 69.05 - lr: 0.006250\n",
      "2020-10-22 19:06:09,737 epoch 83 - iter 324/368 - loss 0.16636853 - samples/sec: 69.14 - lr: 0.006250\n",
      "2020-10-22 19:06:26,733 epoch 83 - iter 360/368 - loss 0.16832063 - samples/sec: 69.05 - lr: 0.006250\n",
      "2020-10-22 19:06:30,191 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 19:06:30,192 EPOCH 83 done: loss 0.1692 - lr 0.0062500\n",
      "2020-10-22 19:07:18,632 DEV : loss 0.4183289408683777 - score 0.8525\n",
      "2020-10-22 19:07:20,531 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 19:07:21,240 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 19:07:38,730 epoch 84 - iter 36/368 - loss 0.15176410 - samples/sec: 67.94 - lr: 0.006250\n",
      "2020-10-22 19:07:55,655 epoch 84 - iter 72/368 - loss 0.14996838 - samples/sec: 69.32 - lr: 0.006250\n",
      "2020-10-22 19:08:12,701 epoch 84 - iter 108/368 - loss 0.15692364 - samples/sec: 67.83 - lr: 0.006250\n",
      "2020-10-22 19:08:29,843 epoch 84 - iter 144/368 - loss 0.16561737 - samples/sec: 68.45 - lr: 0.006250\n",
      "2020-10-22 19:08:46,682 epoch 84 - iter 180/368 - loss 0.16759840 - samples/sec: 69.76 - lr: 0.006250\n",
      "2020-10-22 19:09:03,594 epoch 84 - iter 216/368 - loss 0.16510411 - samples/sec: 68.37 - lr: 0.006250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 19:09:20,209 epoch 84 - iter 252/368 - loss 0.16530717 - samples/sec: 70.60 - lr: 0.006250\n",
      "2020-10-22 19:09:36,658 epoch 84 - iter 288/368 - loss 0.16759835 - samples/sec: 70.31 - lr: 0.006250\n",
      "2020-10-22 19:09:53,462 epoch 84 - iter 324/368 - loss 0.16789974 - samples/sec: 69.86 - lr: 0.006250\n",
      "2020-10-22 19:10:10,106 epoch 84 - iter 360/368 - loss 0.16967078 - samples/sec: 70.57 - lr: 0.006250\n",
      "2020-10-22 19:10:13,586 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 19:10:13,587 EPOCH 84 done: loss 0.1691 - lr 0.0062500\n",
      "2020-10-22 19:11:01,952 DEV : loss 0.4179345369338989 - score 0.8509\n",
      "2020-10-22 19:11:03,839 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 19:11:03,840 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 19:11:21,967 epoch 85 - iter 36/368 - loss 0.16621961 - samples/sec: 65.43 - lr: 0.006250\n",
      "2020-10-22 19:11:39,272 epoch 85 - iter 72/368 - loss 0.16476280 - samples/sec: 66.85 - lr: 0.006250\n",
      "2020-10-22 19:11:57,266 epoch 85 - iter 108/368 - loss 0.16933302 - samples/sec: 65.23 - lr: 0.006250\n",
      "2020-10-22 19:12:15,332 epoch 85 - iter 144/368 - loss 0.16712738 - samples/sec: 65.09 - lr: 0.006250\n",
      "2020-10-22 19:12:32,703 epoch 85 - iter 180/368 - loss 0.16754296 - samples/sec: 67.55 - lr: 0.006250\n",
      "2020-10-22 19:12:49,452 epoch 85 - iter 216/368 - loss 0.16652483 - samples/sec: 70.10 - lr: 0.006250\n",
      "2020-10-22 19:13:06,989 epoch 85 - iter 252/368 - loss 0.16572600 - samples/sec: 67.02 - lr: 0.006250\n",
      "2020-10-22 19:13:24,364 epoch 85 - iter 288/368 - loss 0.16448135 - samples/sec: 67.54 - lr: 0.006250\n",
      "2020-10-22 19:13:41,321 epoch 85 - iter 324/368 - loss 0.16606077 - samples/sec: 69.21 - lr: 0.006250\n",
      "2020-10-22 19:13:58,077 epoch 85 - iter 360/368 - loss 0.16561776 - samples/sec: 69.04 - lr: 0.006250\n",
      "2020-10-22 19:14:01,917 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 19:14:01,918 EPOCH 85 done: loss 0.1659 - lr 0.0062500\n",
      "2020-10-22 19:14:50,226 DEV : loss 0.4154578447341919 - score 0.8553\n",
      "2020-10-22 19:14:52,150 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 19:14:52,869 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 19:15:10,014 epoch 86 - iter 36/368 - loss 0.19030286 - samples/sec: 69.41 - lr: 0.006250\n",
      "2020-10-22 19:15:26,959 epoch 86 - iter 72/368 - loss 0.17172882 - samples/sec: 69.30 - lr: 0.006250\n",
      "2020-10-22 19:15:43,939 epoch 86 - iter 108/368 - loss 0.17018140 - samples/sec: 69.14 - lr: 0.006250\n",
      "2020-10-22 19:16:00,470 epoch 86 - iter 144/368 - loss 0.17177350 - samples/sec: 71.07 - lr: 0.006250\n",
      "2020-10-22 19:16:16,950 epoch 86 - iter 180/368 - loss 0.17643715 - samples/sec: 71.27 - lr: 0.006250\n",
      "2020-10-22 19:16:33,629 epoch 86 - iter 216/368 - loss 0.17303466 - samples/sec: 70.38 - lr: 0.006250\n",
      "2020-10-22 19:16:50,838 epoch 86 - iter 252/368 - loss 0.17029367 - samples/sec: 68.20 - lr: 0.006250\n",
      "2020-10-22 19:17:07,626 epoch 86 - iter 288/368 - loss 0.16844031 - samples/sec: 68.89 - lr: 0.006250\n",
      "2020-10-22 19:17:24,246 epoch 86 - iter 324/368 - loss 0.16911293 - samples/sec: 70.59 - lr: 0.006250\n",
      "2020-10-22 19:17:41,323 epoch 86 - iter 360/368 - loss 0.16899004 - samples/sec: 67.73 - lr: 0.006250\n",
      "2020-10-22 19:17:44,908 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 19:17:44,909 EPOCH 86 done: loss 0.1693 - lr 0.0062500\n",
      "2020-10-22 19:18:33,894 DEV : loss 0.4165736436843872 - score 0.8512\n",
      "2020-10-22 19:18:35,818 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 19:18:35,820 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 19:18:53,682 epoch 87 - iter 36/368 - loss 0.13856646 - samples/sec: 66.42 - lr: 0.006250\n",
      "2020-10-22 19:19:10,725 epoch 87 - iter 72/368 - loss 0.16573191 - samples/sec: 68.88 - lr: 0.006250\n",
      "2020-10-22 19:19:27,879 epoch 87 - iter 108/368 - loss 0.16996240 - samples/sec: 68.43 - lr: 0.006250\n",
      "2020-10-22 19:19:45,238 epoch 87 - iter 144/368 - loss 0.17217656 - samples/sec: 66.65 - lr: 0.006250\n",
      "2020-10-22 19:20:02,049 epoch 87 - iter 180/368 - loss 0.17298652 - samples/sec: 69.87 - lr: 0.006250\n",
      "2020-10-22 19:20:18,789 epoch 87 - iter 216/368 - loss 0.17411494 - samples/sec: 69.12 - lr: 0.006250\n",
      "2020-10-22 19:20:35,825 epoch 87 - iter 252/368 - loss 0.17491893 - samples/sec: 68.88 - lr: 0.006250\n",
      "2020-10-22 19:20:52,645 epoch 87 - iter 288/368 - loss 0.17377399 - samples/sec: 69.78 - lr: 0.006250\n",
      "2020-10-22 19:21:09,309 epoch 87 - iter 324/368 - loss 0.17692482 - samples/sec: 70.51 - lr: 0.006250\n",
      "2020-10-22 19:21:26,099 epoch 87 - iter 360/368 - loss 0.17472771 - samples/sec: 69.89 - lr: 0.006250\n",
      "2020-10-22 19:21:29,494 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 19:21:29,495 EPOCH 87 done: loss 0.1747 - lr 0.0062500\n",
      "2020-10-22 19:22:18,763 DEV : loss 0.4126582443714142 - score 0.852\n",
      "2020-10-22 19:22:20,687 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 19:22:20,688 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 19:22:38,256 epoch 88 - iter 36/368 - loss 0.16171259 - samples/sec: 67.59 - lr: 0.006250\n",
      "2020-10-22 19:22:55,162 epoch 88 - iter 72/368 - loss 0.16125694 - samples/sec: 69.42 - lr: 0.006250\n",
      "2020-10-22 19:23:11,863 epoch 88 - iter 108/368 - loss 0.16481223 - samples/sec: 70.34 - lr: 0.006250\n",
      "2020-10-22 19:23:29,063 epoch 88 - iter 144/368 - loss 0.16707881 - samples/sec: 67.22 - lr: 0.006250\n",
      "2020-10-22 19:23:45,766 epoch 88 - iter 180/368 - loss 0.16472011 - samples/sec: 69.23 - lr: 0.006250\n",
      "2020-10-22 19:24:02,465 epoch 88 - iter 216/368 - loss 0.16256806 - samples/sec: 70.32 - lr: 0.006250\n",
      "2020-10-22 19:24:19,486 epoch 88 - iter 252/368 - loss 0.16270247 - samples/sec: 68.91 - lr: 0.006250\n",
      "2020-10-22 19:24:36,446 epoch 88 - iter 288/368 - loss 0.15967985 - samples/sec: 69.25 - lr: 0.006250\n",
      "2020-10-22 19:24:53,357 epoch 88 - iter 324/368 - loss 0.16098540 - samples/sec: 69.39 - lr: 0.006250\n",
      "2020-10-22 19:25:10,126 epoch 88 - iter 360/368 - loss 0.16338554 - samples/sec: 70.03 - lr: 0.006250\n",
      "2020-10-22 19:25:13,542 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 19:25:13,542 EPOCH 88 done: loss 0.1642 - lr 0.0062500\n",
      "2020-10-22 19:26:02,065 DEV : loss 0.41781190037727356 - score 0.8525\n",
      "2020-10-22 19:26:04,210 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 19:26:04,211 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 19:26:21,707 epoch 89 - iter 36/368 - loss 0.16312322 - samples/sec: 66.81 - lr: 0.006250\n",
      "2020-10-22 19:26:38,497 epoch 89 - iter 72/368 - loss 0.15735247 - samples/sec: 70.13 - lr: 0.006250\n",
      "2020-10-22 19:26:55,220 epoch 89 - iter 108/368 - loss 0.15962171 - samples/sec: 70.18 - lr: 0.006250\n",
      "2020-10-22 19:27:12,371 epoch 89 - iter 144/368 - loss 0.16788738 - samples/sec: 68.49 - lr: 0.006250\n",
      "2020-10-22 19:27:29,018 epoch 89 - iter 180/368 - loss 0.16560315 - samples/sec: 70.55 - lr: 0.006250\n",
      "2020-10-22 19:27:45,903 epoch 89 - iter 216/368 - loss 0.16158368 - samples/sec: 68.51 - lr: 0.006250\n",
      "2020-10-22 19:28:03,315 epoch 89 - iter 252/368 - loss 0.16243186 - samples/sec: 67.40 - lr: 0.006250\n",
      "2020-10-22 19:28:19,913 epoch 89 - iter 288/368 - loss 0.16233665 - samples/sec: 69.69 - lr: 0.006250\n",
      "2020-10-22 19:28:36,621 epoch 89 - iter 324/368 - loss 0.16369198 - samples/sec: 70.27 - lr: 0.006250\n",
      "2020-10-22 19:28:53,635 epoch 89 - iter 360/368 - loss 0.16704062 - samples/sec: 68.95 - lr: 0.006250\n",
      "2020-10-22 19:28:57,126 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 19:28:57,127 EPOCH 89 done: loss 0.1671 - lr 0.0062500\n",
      "2020-10-22 19:29:45,599 DEV : loss 0.41568782925605774 - score 0.8545\n",
      "2020-10-22 19:29:47,743 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 19:29:47,743 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 19:30:04,573 epoch 90 - iter 36/368 - loss 0.17884844 - samples/sec: 69.44 - lr: 0.006250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 19:30:21,446 epoch 90 - iter 72/368 - loss 0.16681880 - samples/sec: 69.64 - lr: 0.006250\n",
      "2020-10-22 19:30:38,370 epoch 90 - iter 108/368 - loss 0.16281888 - samples/sec: 69.38 - lr: 0.006250\n",
      "2020-10-22 19:30:55,595 epoch 90 - iter 144/368 - loss 0.16076260 - samples/sec: 68.28 - lr: 0.006250\n",
      "2020-10-22 19:31:12,321 epoch 90 - iter 180/368 - loss 0.16241432 - samples/sec: 70.20 - lr: 0.006250\n",
      "2020-10-22 19:31:29,399 epoch 90 - iter 216/368 - loss 0.16308607 - samples/sec: 68.74 - lr: 0.006250\n",
      "2020-10-22 19:31:46,346 epoch 90 - iter 252/368 - loss 0.16367439 - samples/sec: 68.27 - lr: 0.006250\n",
      "2020-10-22 19:32:03,206 epoch 90 - iter 288/368 - loss 0.16312379 - samples/sec: 69.63 - lr: 0.006250\n",
      "2020-10-22 19:32:20,130 epoch 90 - iter 324/368 - loss 0.16469129 - samples/sec: 69.39 - lr: 0.006250\n",
      "2020-10-22 19:32:36,852 epoch 90 - iter 360/368 - loss 0.16539362 - samples/sec: 69.18 - lr: 0.006250\n",
      "2020-10-22 19:32:40,642 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 19:32:40,643 EPOCH 90 done: loss 0.1645 - lr 0.0062500\n",
      "2020-10-22 19:33:29,533 DEV : loss 0.4171310067176819 - score 0.8566\n",
      "2020-10-22 19:33:31,447 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 19:33:32,160 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 19:33:49,067 epoch 91 - iter 36/368 - loss 0.14682793 - samples/sec: 70.33 - lr: 0.006250\n",
      "2020-10-22 19:34:05,917 epoch 91 - iter 72/368 - loss 0.14540502 - samples/sec: 69.68 - lr: 0.006250\n",
      "2020-10-22 19:34:22,839 epoch 91 - iter 108/368 - loss 0.15809348 - samples/sec: 69.38 - lr: 0.006250\n",
      "2020-10-22 19:34:39,710 epoch 91 - iter 144/368 - loss 0.15877025 - samples/sec: 69.61 - lr: 0.006250\n",
      "2020-10-22 19:34:56,370 epoch 91 - iter 180/368 - loss 0.15636633 - samples/sec: 70.47 - lr: 0.006250\n",
      "2020-10-22 19:35:13,286 epoch 91 - iter 216/368 - loss 0.15873918 - samples/sec: 69.37 - lr: 0.006250\n",
      "2020-10-22 19:35:30,039 epoch 91 - iter 252/368 - loss 0.16105023 - samples/sec: 70.17 - lr: 0.006250\n",
      "2020-10-22 19:35:47,410 epoch 91 - iter 288/368 - loss 0.16053029 - samples/sec: 67.56 - lr: 0.006250\n",
      "2020-10-22 19:36:04,076 epoch 91 - iter 324/368 - loss 0.16316604 - samples/sec: 69.42 - lr: 0.006250\n",
      "2020-10-22 19:36:21,271 epoch 91 - iter 360/368 - loss 0.16507566 - samples/sec: 68.25 - lr: 0.006250\n",
      "2020-10-22 19:36:24,822 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 19:36:24,822 EPOCH 91 done: loss 0.1642 - lr 0.0062500\n",
      "2020-10-22 19:37:14,019 DEV : loss 0.4126613140106201 - score 0.8543\n",
      "2020-10-22 19:37:15,927 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 19:37:15,928 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 19:37:33,318 epoch 92 - iter 36/368 - loss 0.13996472 - samples/sec: 68.33 - lr: 0.006250\n",
      "2020-10-22 19:37:50,601 epoch 92 - iter 72/368 - loss 0.15154237 - samples/sec: 68.04 - lr: 0.006250\n",
      "2020-10-22 19:38:07,403 epoch 92 - iter 108/368 - loss 0.16063558 - samples/sec: 68.83 - lr: 0.006250\n",
      "2020-10-22 19:38:24,096 epoch 92 - iter 144/368 - loss 0.16461716 - samples/sec: 69.31 - lr: 0.006250\n",
      "2020-10-22 19:38:40,928 epoch 92 - iter 180/368 - loss 0.16639609 - samples/sec: 68.70 - lr: 0.006250\n",
      "2020-10-22 19:38:57,825 epoch 92 - iter 216/368 - loss 0.16627270 - samples/sec: 69.53 - lr: 0.006250\n",
      "2020-10-22 19:39:14,666 epoch 92 - iter 252/368 - loss 0.16285498 - samples/sec: 69.65 - lr: 0.006250\n",
      "2020-10-22 19:39:31,500 epoch 92 - iter 288/368 - loss 0.16459525 - samples/sec: 69.75 - lr: 0.006250\n",
      "2020-10-22 19:39:48,377 epoch 92 - iter 324/368 - loss 0.16257210 - samples/sec: 69.51 - lr: 0.006250\n",
      "2020-10-22 19:40:05,414 epoch 92 - iter 360/368 - loss 0.16281571 - samples/sec: 68.94 - lr: 0.006250\n",
      "2020-10-22 19:40:08,914 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 19:40:08,915 EPOCH 92 done: loss 0.1636 - lr 0.0062500\n",
      "2020-10-22 19:40:56,989 DEV : loss 0.41894659399986267 - score 0.8507\n",
      "2020-10-22 19:40:58,898 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 19:40:58,899 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 19:41:16,285 epoch 93 - iter 36/368 - loss 0.16228149 - samples/sec: 67.18 - lr: 0.006250\n",
      "2020-10-22 19:41:33,208 epoch 93 - iter 72/368 - loss 0.17005641 - samples/sec: 68.34 - lr: 0.006250\n",
      "2020-10-22 19:41:50,109 epoch 93 - iter 108/368 - loss 0.16636207 - samples/sec: 69.44 - lr: 0.006250\n",
      "2020-10-22 19:42:06,934 epoch 93 - iter 144/368 - loss 0.15915906 - samples/sec: 68.78 - lr: 0.006250\n",
      "2020-10-22 19:42:23,865 epoch 93 - iter 180/368 - loss 0.15776065 - samples/sec: 69.37 - lr: 0.006250\n",
      "2020-10-22 19:42:40,604 epoch 93 - iter 216/368 - loss 0.15539361 - samples/sec: 70.17 - lr: 0.006250\n",
      "2020-10-22 19:42:57,550 epoch 93 - iter 252/368 - loss 0.15741423 - samples/sec: 69.27 - lr: 0.006250\n",
      "2020-10-22 19:43:14,121 epoch 93 - iter 288/368 - loss 0.15674900 - samples/sec: 70.90 - lr: 0.006250\n",
      "2020-10-22 19:43:30,774 epoch 93 - iter 324/368 - loss 0.15438854 - samples/sec: 70.49 - lr: 0.006250\n",
      "2020-10-22 19:43:47,585 epoch 93 - iter 360/368 - loss 0.15670676 - samples/sec: 69.83 - lr: 0.006250\n",
      "2020-10-22 19:43:51,190 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 19:43:51,191 EPOCH 93 done: loss 0.1570 - lr 0.0062500\n",
      "2020-10-22 19:44:39,126 DEV : loss 0.42125290632247925 - score 0.8532\n",
      "2020-10-22 19:44:41,016 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 19:44:41,017 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 19:44:58,556 epoch 94 - iter 36/368 - loss 0.14076827 - samples/sec: 67.77 - lr: 0.006250\n",
      "2020-10-22 19:45:15,337 epoch 94 - iter 72/368 - loss 0.15151357 - samples/sec: 69.92 - lr: 0.006250\n",
      "2020-10-22 19:45:32,014 epoch 94 - iter 108/368 - loss 0.16471012 - samples/sec: 70.43 - lr: 0.006250\n",
      "2020-10-22 19:45:48,846 epoch 94 - iter 144/368 - loss 0.16473784 - samples/sec: 69.76 - lr: 0.006250\n",
      "2020-10-22 19:46:05,366 epoch 94 - iter 180/368 - loss 0.16584671 - samples/sec: 70.02 - lr: 0.006250\n",
      "2020-10-22 19:46:22,492 epoch 94 - iter 216/368 - loss 0.16541815 - samples/sec: 68.60 - lr: 0.006250\n",
      "2020-10-22 19:46:39,332 epoch 94 - iter 252/368 - loss 0.16092350 - samples/sec: 69.81 - lr: 0.006250\n",
      "2020-10-22 19:46:57,351 epoch 94 - iter 288/368 - loss 0.16001584 - samples/sec: 65.14 - lr: 0.006250\n",
      "2020-10-22 19:47:14,324 epoch 94 - iter 324/368 - loss 0.16029432 - samples/sec: 69.17 - lr: 0.006250\n",
      "2020-10-22 19:47:31,027 epoch 94 - iter 360/368 - loss 0.16024485 - samples/sec: 69.25 - lr: 0.006250\n",
      "2020-10-22 19:47:34,471 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 19:47:34,472 EPOCH 94 done: loss 0.1593 - lr 0.0062500\n",
      "2020-10-22 19:48:22,990 DEV : loss 0.41888412833213806 - score 0.8525\n",
      "2020-10-22 19:48:24,893 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 19:48:24,894 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 19:48:42,207 epoch 95 - iter 36/368 - loss 0.18403356 - samples/sec: 67.49 - lr: 0.006250\n",
      "2020-10-22 19:48:59,872 epoch 95 - iter 72/368 - loss 0.17846229 - samples/sec: 66.42 - lr: 0.006250\n",
      "2020-10-22 19:49:17,454 epoch 95 - iter 108/368 - loss 0.16632409 - samples/sec: 66.75 - lr: 0.006250\n",
      "2020-10-22 19:49:34,846 epoch 95 - iter 144/368 - loss 0.16640278 - samples/sec: 67.48 - lr: 0.006250\n",
      "2020-10-22 19:49:52,188 epoch 95 - iter 180/368 - loss 0.16951551 - samples/sec: 67.67 - lr: 0.006250\n",
      "2020-10-22 19:50:09,242 epoch 95 - iter 216/368 - loss 0.16933016 - samples/sec: 68.85 - lr: 0.006250\n",
      "2020-10-22 19:50:26,245 epoch 95 - iter 252/368 - loss 0.17052436 - samples/sec: 68.99 - lr: 0.006250\n",
      "2020-10-22 19:50:43,614 epoch 95 - iter 288/368 - loss 0.17001866 - samples/sec: 67.60 - lr: 0.006250\n",
      "2020-10-22 19:51:00,413 epoch 95 - iter 324/368 - loss 0.17054699 - samples/sec: 69.88 - lr: 0.006250\n",
      "2020-10-22 19:51:17,173 epoch 95 - iter 360/368 - loss 0.16902006 - samples/sec: 69.01 - lr: 0.006250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 19:51:20,972 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 19:51:20,973 EPOCH 95 done: loss 0.1708 - lr 0.0062500\n",
      "2020-10-22 19:52:10,549 DEV : loss 0.4162958562374115 - score 0.8512\n",
      "2020-10-22 19:52:12,479 BAD EPOCHS (no improvement): 5\n",
      "2020-10-22 19:52:12,479 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 19:52:29,724 epoch 96 - iter 36/368 - loss 0.15119970 - samples/sec: 68.84 - lr: 0.006250\n",
      "2020-10-22 19:52:47,091 epoch 96 - iter 72/368 - loss 0.14604399 - samples/sec: 66.61 - lr: 0.006250\n",
      "2020-10-22 19:53:03,906 epoch 96 - iter 108/368 - loss 0.15411143 - samples/sec: 68.80 - lr: 0.006250\n",
      "2020-10-22 19:53:20,752 epoch 96 - iter 144/368 - loss 0.15791249 - samples/sec: 69.70 - lr: 0.006250\n",
      "2020-10-22 19:53:37,776 epoch 96 - iter 180/368 - loss 0.16081407 - samples/sec: 68.94 - lr: 0.006250\n",
      "2020-10-22 19:53:54,296 epoch 96 - iter 216/368 - loss 0.15812282 - samples/sec: 71.10 - lr: 0.006250\n",
      "2020-10-22 19:54:10,762 epoch 96 - iter 252/368 - loss 0.15657982 - samples/sec: 70.25 - lr: 0.006250\n",
      "2020-10-22 19:54:27,333 epoch 96 - iter 288/368 - loss 0.15698948 - samples/sec: 70.85 - lr: 0.006250\n",
      "2020-10-22 19:54:43,857 epoch 96 - iter 324/368 - loss 0.15779266 - samples/sec: 71.08 - lr: 0.006250\n",
      "2020-10-22 19:55:00,482 epoch 96 - iter 360/368 - loss 0.15815294 - samples/sec: 70.59 - lr: 0.006250\n",
      "2020-10-22 19:55:04,036 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 19:55:04,036 EPOCH 96 done: loss 0.1587 - lr 0.0062500\n",
      "2020-10-22 19:55:52,583 DEV : loss 0.4173387587070465 - score 0.852\n",
      "Epoch    96: reducing learning rate of group 0 to 3.1250e-03.\n",
      "2020-10-22 19:55:54,470 BAD EPOCHS (no improvement): 6\n",
      "2020-10-22 19:55:54,471 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 19:56:11,477 epoch 97 - iter 36/368 - loss 0.12178026 - samples/sec: 69.78 - lr: 0.003125\n",
      "2020-10-22 19:56:27,606 epoch 97 - iter 72/368 - loss 0.14585844 - samples/sec: 71.71 - lr: 0.003125\n",
      "2020-10-22 19:56:44,171 epoch 97 - iter 108/368 - loss 0.15119622 - samples/sec: 70.90 - lr: 0.003125\n",
      "2020-10-22 19:57:00,650 epoch 97 - iter 144/368 - loss 0.15832390 - samples/sec: 71.24 - lr: 0.003125\n",
      "2020-10-22 19:57:17,445 epoch 97 - iter 180/368 - loss 0.16106314 - samples/sec: 69.88 - lr: 0.003125\n",
      "2020-10-22 19:57:34,181 epoch 97 - iter 216/368 - loss 0.15850662 - samples/sec: 70.16 - lr: 0.003125\n",
      "2020-10-22 19:57:50,622 epoch 97 - iter 252/368 - loss 0.16225736 - samples/sec: 71.41 - lr: 0.003125\n",
      "2020-10-22 19:58:07,052 epoch 97 - iter 288/368 - loss 0.15825668 - samples/sec: 71.45 - lr: 0.003125\n",
      "2020-10-22 19:58:23,437 epoch 97 - iter 324/368 - loss 0.15988030 - samples/sec: 71.67 - lr: 0.003125\n",
      "2020-10-22 19:58:40,460 epoch 97 - iter 360/368 - loss 0.16045755 - samples/sec: 69.05 - lr: 0.003125\n",
      "2020-10-22 19:58:43,980 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 19:58:43,981 EPOCH 97 done: loss 0.1599 - lr 0.0031250\n",
      "2020-10-22 19:59:32,221 DEV : loss 0.41755199432373047 - score 0.8517\n",
      "2020-10-22 19:59:34,137 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 19:59:34,137 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 19:59:51,375 epoch 98 - iter 36/368 - loss 0.15772987 - samples/sec: 67.74 - lr: 0.003125\n",
      "2020-10-22 20:00:07,881 epoch 98 - iter 72/368 - loss 0.16251608 - samples/sec: 70.08 - lr: 0.003125\n",
      "2020-10-22 20:00:24,978 epoch 98 - iter 108/368 - loss 0.15877009 - samples/sec: 68.67 - lr: 0.003125\n",
      "2020-10-22 20:00:41,855 epoch 98 - iter 144/368 - loss 0.15972365 - samples/sec: 69.59 - lr: 0.003125\n",
      "2020-10-22 20:00:58,790 epoch 98 - iter 180/368 - loss 0.15776062 - samples/sec: 69.40 - lr: 0.003125\n",
      "2020-10-22 20:01:15,822 epoch 98 - iter 216/368 - loss 0.15757436 - samples/sec: 68.94 - lr: 0.003125\n",
      "2020-10-22 20:01:32,784 epoch 98 - iter 252/368 - loss 0.15751030 - samples/sec: 69.18 - lr: 0.003125\n",
      "2020-10-22 20:01:49,782 epoch 98 - iter 288/368 - loss 0.15806814 - samples/sec: 69.07 - lr: 0.003125\n",
      "2020-10-22 20:02:06,349 epoch 98 - iter 324/368 - loss 0.15728465 - samples/sec: 70.91 - lr: 0.003125\n",
      "2020-10-22 20:02:22,886 epoch 98 - iter 360/368 - loss 0.15581996 - samples/sec: 69.95 - lr: 0.003125\n",
      "2020-10-22 20:02:26,727 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 20:02:26,728 EPOCH 98 done: loss 0.1564 - lr 0.0031250\n",
      "2020-10-22 20:03:14,972 DEV : loss 0.4208509027957916 - score 0.8509\n",
      "2020-10-22 20:03:16,890 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 20:03:16,891 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 20:03:33,922 epoch 99 - iter 36/368 - loss 0.16275435 - samples/sec: 69.88 - lr: 0.003125\n",
      "2020-10-22 20:03:50,698 epoch 99 - iter 72/368 - loss 0.16077131 - samples/sec: 69.97 - lr: 0.003125\n",
      "2020-10-22 20:04:07,268 epoch 99 - iter 108/368 - loss 0.15050610 - samples/sec: 69.77 - lr: 0.003125\n",
      "2020-10-22 20:04:23,649 epoch 99 - iter 144/368 - loss 0.15199277 - samples/sec: 70.58 - lr: 0.003125\n",
      "2020-10-22 20:04:40,392 epoch 99 - iter 180/368 - loss 0.14642858 - samples/sec: 70.07 - lr: 0.003125\n",
      "2020-10-22 20:04:56,795 epoch 99 - iter 216/368 - loss 0.15083012 - samples/sec: 71.65 - lr: 0.003125\n",
      "2020-10-22 20:05:13,352 epoch 99 - iter 252/368 - loss 0.15126667 - samples/sec: 70.92 - lr: 0.003125\n",
      "2020-10-22 20:05:30,238 epoch 99 - iter 288/368 - loss 0.15085575 - samples/sec: 69.53 - lr: 0.003125\n",
      "2020-10-22 20:05:47,075 epoch 99 - iter 324/368 - loss 0.15463335 - samples/sec: 68.74 - lr: 0.003125\n",
      "2020-10-22 20:06:03,918 epoch 99 - iter 360/368 - loss 0.15295655 - samples/sec: 69.73 - lr: 0.003125\n",
      "2020-10-22 20:06:07,677 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 20:06:07,678 EPOCH 99 done: loss 0.1520 - lr 0.0031250\n",
      "2020-10-22 20:06:55,891 DEV : loss 0.42034921050071716 - score 0.8517\n",
      "2020-10-22 20:06:57,794 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 20:06:57,795 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 20:07:15,053 epoch 100 - iter 36/368 - loss 0.16418718 - samples/sec: 68.89 - lr: 0.003125\n",
      "2020-10-22 20:07:31,497 epoch 100 - iter 72/368 - loss 0.15221680 - samples/sec: 71.42 - lr: 0.003125\n",
      "2020-10-22 20:07:47,913 epoch 100 - iter 108/368 - loss 0.16410237 - samples/sec: 70.47 - lr: 0.003125\n",
      "2020-10-22 20:08:04,691 epoch 100 - iter 144/368 - loss 0.15909385 - samples/sec: 70.02 - lr: 0.003125\n",
      "2020-10-22 20:08:21,455 epoch 100 - iter 180/368 - loss 0.15855219 - samples/sec: 69.00 - lr: 0.003125\n",
      "2020-10-22 20:08:37,923 epoch 100 - iter 216/368 - loss 0.15530682 - samples/sec: 71.33 - lr: 0.003125\n",
      "2020-10-22 20:08:54,519 epoch 100 - iter 252/368 - loss 0.15607734 - samples/sec: 70.74 - lr: 0.003125\n",
      "2020-10-22 20:09:11,334 epoch 100 - iter 288/368 - loss 0.15645193 - samples/sec: 69.90 - lr: 0.003125\n",
      "2020-10-22 20:09:27,856 epoch 100 - iter 324/368 - loss 0.15642197 - samples/sec: 71.04 - lr: 0.003125\n",
      "2020-10-22 20:09:44,977 epoch 100 - iter 360/368 - loss 0.15774767 - samples/sec: 68.56 - lr: 0.003125\n",
      "2020-10-22 20:09:48,566 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 20:09:48,566 EPOCH 100 done: loss 0.1575 - lr 0.0031250\n",
      "2020-10-22 20:10:36,897 DEV : loss 0.4215196669101715 - score 0.8514\n",
      "2020-10-22 20:10:38,803 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 20:10:38,804 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 20:10:55,841 epoch 101 - iter 36/368 - loss 0.14092950 - samples/sec: 68.56 - lr: 0.003125\n",
      "2020-10-22 20:11:12,598 epoch 101 - iter 72/368 - loss 0.14951389 - samples/sec: 70.03 - lr: 0.003125\n",
      "2020-10-22 20:11:29,334 epoch 101 - iter 108/368 - loss 0.16261554 - samples/sec: 70.11 - lr: 0.003125\n",
      "2020-10-22 20:11:46,491 epoch 101 - iter 144/368 - loss 0.16512567 - samples/sec: 68.41 - lr: 0.003125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 20:12:03,219 epoch 101 - iter 180/368 - loss 0.16398447 - samples/sec: 70.18 - lr: 0.003125\n",
      "2020-10-22 20:12:19,919 epoch 101 - iter 216/368 - loss 0.16046408 - samples/sec: 70.27 - lr: 0.003125\n",
      "2020-10-22 20:12:36,773 epoch 101 - iter 252/368 - loss 0.15932449 - samples/sec: 69.66 - lr: 0.003125\n",
      "2020-10-22 20:12:53,658 epoch 101 - iter 288/368 - loss 0.15720434 - samples/sec: 69.54 - lr: 0.003125\n",
      "2020-10-22 20:13:10,379 epoch 101 - iter 324/368 - loss 0.15816732 - samples/sec: 70.21 - lr: 0.003125\n",
      "2020-10-22 20:13:27,016 epoch 101 - iter 360/368 - loss 0.15858108 - samples/sec: 69.58 - lr: 0.003125\n",
      "2020-10-22 20:13:30,955 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 20:13:30,955 EPOCH 101 done: loss 0.1578 - lr 0.0031250\n",
      "2020-10-22 20:14:19,590 DEV : loss 0.41956210136413574 - score 0.8527\n",
      "2020-10-22 20:14:21,493 BAD EPOCHS (no improvement): 5\n",
      "2020-10-22 20:14:21,493 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 20:14:38,310 epoch 102 - iter 36/368 - loss 0.14164378 - samples/sec: 70.79 - lr: 0.003125\n",
      "2020-10-22 20:14:55,245 epoch 102 - iter 72/368 - loss 0.15813188 - samples/sec: 69.36 - lr: 0.003125\n",
      "2020-10-22 20:15:11,922 epoch 102 - iter 108/368 - loss 0.15408231 - samples/sec: 69.38 - lr: 0.003125\n",
      "2020-10-22 20:15:28,395 epoch 102 - iter 144/368 - loss 0.15702222 - samples/sec: 71.27 - lr: 0.003125\n",
      "2020-10-22 20:15:44,648 epoch 102 - iter 180/368 - loss 0.16130924 - samples/sec: 71.18 - lr: 0.003125\n",
      "2020-10-22 20:16:01,256 epoch 102 - iter 216/368 - loss 0.16070006 - samples/sec: 70.71 - lr: 0.003125\n",
      "2020-10-22 20:16:18,082 epoch 102 - iter 252/368 - loss 0.15544095 - samples/sec: 69.78 - lr: 0.003125\n",
      "2020-10-22 20:16:35,237 epoch 102 - iter 288/368 - loss 0.15555692 - samples/sec: 68.41 - lr: 0.003125\n",
      "2020-10-22 20:16:52,163 epoch 102 - iter 324/368 - loss 0.15527867 - samples/sec: 69.37 - lr: 0.003125\n",
      "2020-10-22 20:17:08,871 epoch 102 - iter 360/368 - loss 0.15625050 - samples/sec: 70.25 - lr: 0.003125\n",
      "2020-10-22 20:17:12,306 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 20:17:12,307 EPOCH 102 done: loss 0.1569 - lr 0.0031250\n",
      "2020-10-22 20:17:59,757 DEV : loss 0.41928642988204956 - score 0.855\n",
      "Epoch   102: reducing learning rate of group 0 to 1.5625e-03.\n",
      "2020-10-22 20:18:01,640 BAD EPOCHS (no improvement): 6\n",
      "2020-10-22 20:18:01,641 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 20:18:18,459 epoch 103 - iter 36/368 - loss 0.15623267 - samples/sec: 70.73 - lr: 0.001563\n",
      "2020-10-22 20:18:34,988 epoch 103 - iter 72/368 - loss 0.15321303 - samples/sec: 71.07 - lr: 0.001563\n",
      "2020-10-22 20:18:51,509 epoch 103 - iter 108/368 - loss 0.15551119 - samples/sec: 71.13 - lr: 0.001563\n",
      "2020-10-22 20:19:08,314 epoch 103 - iter 144/368 - loss 0.15275372 - samples/sec: 69.87 - lr: 0.001563\n",
      "2020-10-22 20:19:25,063 epoch 103 - iter 180/368 - loss 0.15387816 - samples/sec: 69.08 - lr: 0.001563\n",
      "2020-10-22 20:19:41,848 epoch 103 - iter 216/368 - loss 0.15428529 - samples/sec: 68.91 - lr: 0.001563\n",
      "2020-10-22 20:19:58,631 epoch 103 - iter 252/368 - loss 0.15348570 - samples/sec: 69.96 - lr: 0.001563\n",
      "2020-10-22 20:20:15,062 epoch 103 - iter 288/368 - loss 0.15317440 - samples/sec: 71.45 - lr: 0.001563\n",
      "2020-10-22 20:20:31,949 epoch 103 - iter 324/368 - loss 0.15400605 - samples/sec: 69.53 - lr: 0.001563\n",
      "2020-10-22 20:20:48,978 epoch 103 - iter 360/368 - loss 0.15384646 - samples/sec: 69.01 - lr: 0.001563\n",
      "2020-10-22 20:20:52,428 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 20:20:52,428 EPOCH 103 done: loss 0.1530 - lr 0.0015625\n",
      "2020-10-22 20:21:40,254 DEV : loss 0.4168274700641632 - score 0.8548\n",
      "2020-10-22 20:21:42,395 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 20:21:42,396 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 20:21:58,833 epoch 104 - iter 36/368 - loss 0.17775436 - samples/sec: 71.07 - lr: 0.001563\n",
      "2020-10-22 20:22:15,047 epoch 104 - iter 72/368 - loss 0.15840643 - samples/sec: 72.53 - lr: 0.001563\n",
      "2020-10-22 20:22:31,665 epoch 104 - iter 108/368 - loss 0.15370809 - samples/sec: 70.61 - lr: 0.001563\n",
      "2020-10-22 20:22:48,127 epoch 104 - iter 144/368 - loss 0.15601454 - samples/sec: 71.29 - lr: 0.001563\n",
      "2020-10-22 20:23:04,729 epoch 104 - iter 180/368 - loss 0.15406534 - samples/sec: 70.75 - lr: 0.001563\n",
      "2020-10-22 20:23:21,631 epoch 104 - iter 216/368 - loss 0.15458754 - samples/sec: 69.52 - lr: 0.001563\n",
      "2020-10-22 20:23:38,858 epoch 104 - iter 252/368 - loss 0.15460281 - samples/sec: 68.16 - lr: 0.001563\n",
      "2020-10-22 20:23:55,905 epoch 104 - iter 288/368 - loss 0.15244533 - samples/sec: 67.85 - lr: 0.001563\n",
      "2020-10-22 20:24:12,783 epoch 104 - iter 324/368 - loss 0.15209347 - samples/sec: 69.56 - lr: 0.001563\n",
      "2020-10-22 20:24:29,676 epoch 104 - iter 360/368 - loss 0.15464509 - samples/sec: 69.52 - lr: 0.001563\n",
      "2020-10-22 20:24:33,174 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 20:24:33,175 EPOCH 104 done: loss 0.1546 - lr 0.0015625\n",
      "2020-10-22 20:25:21,079 DEV : loss 0.41926971077919006 - score 0.8545\n",
      "2020-10-22 20:25:23,000 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 20:25:23,001 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 20:25:39,850 epoch 105 - iter 36/368 - loss 0.17795292 - samples/sec: 70.62 - lr: 0.001563\n",
      "2020-10-22 20:25:56,691 epoch 105 - iter 72/368 - loss 0.15893883 - samples/sec: 68.66 - lr: 0.001563\n",
      "2020-10-22 20:26:13,421 epoch 105 - iter 108/368 - loss 0.15697194 - samples/sec: 70.16 - lr: 0.001563\n",
      "2020-10-22 20:26:30,077 epoch 105 - iter 144/368 - loss 0.15275190 - samples/sec: 70.51 - lr: 0.001563\n",
      "2020-10-22 20:26:46,867 epoch 105 - iter 180/368 - loss 0.15267542 - samples/sec: 69.92 - lr: 0.001563\n",
      "2020-10-22 20:27:03,298 epoch 105 - iter 216/368 - loss 0.14996578 - samples/sec: 70.42 - lr: 0.001563\n",
      "2020-10-22 20:27:19,735 epoch 105 - iter 252/368 - loss 0.15332272 - samples/sec: 71.46 - lr: 0.001563\n",
      "2020-10-22 20:27:36,608 epoch 105 - iter 288/368 - loss 0.15542049 - samples/sec: 69.61 - lr: 0.001563\n",
      "2020-10-22 20:27:53,678 epoch 105 - iter 324/368 - loss 0.15374104 - samples/sec: 68.80 - lr: 0.001563\n",
      "2020-10-22 20:28:10,268 epoch 105 - iter 360/368 - loss 0.15219312 - samples/sec: 70.76 - lr: 0.001563\n",
      "2020-10-22 20:28:13,666 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 20:28:13,667 EPOCH 105 done: loss 0.1531 - lr 0.0015625\n",
      "2020-10-22 20:29:02,165 DEV : loss 0.41993001103401184 - score 0.854\n",
      "2020-10-22 20:29:04,096 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 20:29:04,097 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 20:29:21,328 epoch 106 - iter 36/368 - loss 0.15651988 - samples/sec: 68.96 - lr: 0.001563\n",
      "2020-10-22 20:29:38,265 epoch 106 - iter 72/368 - loss 0.14512511 - samples/sec: 69.35 - lr: 0.001563\n",
      "2020-10-22 20:29:55,332 epoch 106 - iter 108/368 - loss 0.14376968 - samples/sec: 68.74 - lr: 0.001563\n",
      "2020-10-22 20:30:12,343 epoch 106 - iter 144/368 - loss 0.14837400 - samples/sec: 68.99 - lr: 0.001563\n",
      "2020-10-22 20:30:29,190 epoch 106 - iter 180/368 - loss 0.14993910 - samples/sec: 68.64 - lr: 0.001563\n",
      "2020-10-22 20:30:46,228 epoch 106 - iter 216/368 - loss 0.14830438 - samples/sec: 68.90 - lr: 0.001563\n",
      "2020-10-22 20:31:03,105 epoch 106 - iter 252/368 - loss 0.14728567 - samples/sec: 69.51 - lr: 0.001563\n",
      "2020-10-22 20:31:19,650 epoch 106 - iter 288/368 - loss 0.14869780 - samples/sec: 71.01 - lr: 0.001563\n",
      "2020-10-22 20:31:36,369 epoch 106 - iter 324/368 - loss 0.15082631 - samples/sec: 70.21 - lr: 0.001563\n",
      "2020-10-22 20:31:53,077 epoch 106 - iter 360/368 - loss 0.14939740 - samples/sec: 69.21 - lr: 0.001563\n",
      "2020-10-22 20:31:56,909 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 20:31:56,910 EPOCH 106 done: loss 0.1497 - lr 0.0015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 20:32:44,971 DEV : loss 0.4204995036125183 - score 0.8537\n",
      "2020-10-22 20:32:46,860 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 20:32:46,860 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 20:33:03,822 epoch 107 - iter 36/368 - loss 0.15842249 - samples/sec: 70.19 - lr: 0.001563\n",
      "2020-10-22 20:33:20,275 epoch 107 - iter 72/368 - loss 0.15417178 - samples/sec: 71.40 - lr: 0.001563\n",
      "2020-10-22 20:33:36,650 epoch 107 - iter 108/368 - loss 0.15052047 - samples/sec: 71.69 - lr: 0.001563\n",
      "2020-10-22 20:33:53,246 epoch 107 - iter 144/368 - loss 0.14782753 - samples/sec: 70.73 - lr: 0.001563\n",
      "2020-10-22 20:34:09,723 epoch 107 - iter 180/368 - loss 0.14994712 - samples/sec: 70.21 - lr: 0.001563\n",
      "2020-10-22 20:34:26,792 epoch 107 - iter 216/368 - loss 0.15163033 - samples/sec: 68.79 - lr: 0.001563\n",
      "2020-10-22 20:34:43,803 epoch 107 - iter 252/368 - loss 0.15213532 - samples/sec: 69.02 - lr: 0.001563\n",
      "2020-10-22 20:35:02,295 epoch 107 - iter 288/368 - loss 0.15286930 - samples/sec: 62.56 - lr: 0.001563\n",
      "2020-10-22 20:35:19,315 epoch 107 - iter 324/368 - loss 0.15524627 - samples/sec: 67.96 - lr: 0.001563\n",
      "2020-10-22 20:35:36,365 epoch 107 - iter 360/368 - loss 0.15445076 - samples/sec: 68.93 - lr: 0.001563\n",
      "2020-10-22 20:35:39,887 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 20:35:39,888 EPOCH 107 done: loss 0.1544 - lr 0.0015625\n",
      "2020-10-22 20:36:28,805 DEV : loss 0.41934439539909363 - score 0.853\n",
      "2020-10-22 20:36:30,696 BAD EPOCHS (no improvement): 5\n",
      "2020-10-22 20:36:30,697 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 20:36:48,071 epoch 108 - iter 36/368 - loss 0.15429868 - samples/sec: 68.65 - lr: 0.001563\n",
      "2020-10-22 20:37:04,525 epoch 108 - iter 72/368 - loss 0.15343977 - samples/sec: 71.40 - lr: 0.001563\n",
      "2020-10-22 20:37:21,601 epoch 108 - iter 108/368 - loss 0.14265933 - samples/sec: 68.74 - lr: 0.001563\n",
      "2020-10-22 20:37:38,585 epoch 108 - iter 144/368 - loss 0.14776114 - samples/sec: 69.09 - lr: 0.001563\n",
      "2020-10-22 20:37:55,665 epoch 108 - iter 180/368 - loss 0.14760282 - samples/sec: 68.76 - lr: 0.001563\n",
      "2020-10-22 20:38:12,344 epoch 108 - iter 216/368 - loss 0.14872806 - samples/sec: 70.39 - lr: 0.001563\n",
      "2020-10-22 20:38:29,126 epoch 108 - iter 252/368 - loss 0.14623936 - samples/sec: 69.99 - lr: 0.001563\n",
      "2020-10-22 20:38:46,178 epoch 108 - iter 288/368 - loss 0.14678653 - samples/sec: 68.85 - lr: 0.001563\n",
      "2020-10-22 20:39:02,443 epoch 108 - iter 324/368 - loss 0.14584390 - samples/sec: 71.12 - lr: 0.001563\n",
      "2020-10-22 20:39:19,614 epoch 108 - iter 360/368 - loss 0.14762692 - samples/sec: 68.32 - lr: 0.001563\n",
      "2020-10-22 20:39:23,248 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 20:39:23,248 EPOCH 108 done: loss 0.1481 - lr 0.0015625\n",
      "2020-10-22 20:40:13,105 DEV : loss 0.4204815626144409 - score 0.8537\n",
      "Epoch   108: reducing learning rate of group 0 to 7.8125e-04.\n",
      "2020-10-22 20:40:14,987 BAD EPOCHS (no improvement): 6\n",
      "2020-10-22 20:40:14,987 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 20:40:32,428 epoch 109 - iter 36/368 - loss 0.16001972 - samples/sec: 66.90 - lr: 0.000781\n",
      "2020-10-22 20:40:50,228 epoch 109 - iter 72/368 - loss 0.14193952 - samples/sec: 65.95 - lr: 0.000781\n",
      "2020-10-22 20:41:07,210 epoch 109 - iter 108/368 - loss 0.14029084 - samples/sec: 69.16 - lr: 0.000781\n",
      "2020-10-22 20:41:24,036 epoch 109 - iter 144/368 - loss 0.13846199 - samples/sec: 68.76 - lr: 0.000781\n",
      "2020-10-22 20:41:41,423 epoch 109 - iter 180/368 - loss 0.13887565 - samples/sec: 67.51 - lr: 0.000781\n",
      "2020-10-22 20:41:59,660 epoch 109 - iter 216/368 - loss 0.14108159 - samples/sec: 64.35 - lr: 0.000781\n",
      "2020-10-22 20:42:16,770 epoch 109 - iter 252/368 - loss 0.14495361 - samples/sec: 68.61 - lr: 0.000781\n",
      "2020-10-22 20:42:33,934 epoch 109 - iter 288/368 - loss 0.14566276 - samples/sec: 68.28 - lr: 0.000781\n",
      "2020-10-22 20:42:51,364 epoch 109 - iter 324/368 - loss 0.14712237 - samples/sec: 67.37 - lr: 0.000781\n",
      "2020-10-22 20:43:08,019 epoch 109 - iter 360/368 - loss 0.14659251 - samples/sec: 70.49 - lr: 0.000781\n",
      "2020-10-22 20:43:11,539 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 20:43:11,540 EPOCH 109 done: loss 0.1463 - lr 0.0007813\n",
      "2020-10-22 20:44:00,172 DEV : loss 0.4215811491012573 - score 0.854\n",
      "2020-10-22 20:44:02,336 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 20:44:02,337 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 20:44:19,269 epoch 110 - iter 36/368 - loss 0.13926100 - samples/sec: 69.08 - lr: 0.000781\n",
      "2020-10-22 20:44:36,194 epoch 110 - iter 72/368 - loss 0.14052827 - samples/sec: 69.45 - lr: 0.000781\n",
      "2020-10-22 20:44:53,098 epoch 110 - iter 108/368 - loss 0.14361696 - samples/sec: 69.48 - lr: 0.000781\n",
      "2020-10-22 20:45:10,678 epoch 110 - iter 144/368 - loss 0.14377814 - samples/sec: 66.77 - lr: 0.000781\n",
      "2020-10-22 20:45:28,295 epoch 110 - iter 180/368 - loss 0.14406088 - samples/sec: 66.62 - lr: 0.000781\n",
      "2020-10-22 20:45:44,769 epoch 110 - iter 216/368 - loss 0.14722738 - samples/sec: 70.23 - lr: 0.000781\n",
      "2020-10-22 20:46:01,095 epoch 110 - iter 252/368 - loss 0.14802511 - samples/sec: 71.92 - lr: 0.000781\n",
      "2020-10-22 20:46:17,949 epoch 110 - iter 288/368 - loss 0.14783973 - samples/sec: 69.71 - lr: 0.000781\n",
      "2020-10-22 20:46:34,352 epoch 110 - iter 324/368 - loss 0.14839451 - samples/sec: 70.49 - lr: 0.000781\n",
      "2020-10-22 20:46:51,157 epoch 110 - iter 360/368 - loss 0.14989359 - samples/sec: 69.83 - lr: 0.000781\n",
      "2020-10-22 20:46:54,957 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 20:46:54,958 EPOCH 110 done: loss 0.1507 - lr 0.0007813\n",
      "2020-10-22 20:47:43,605 DEV : loss 0.42161455750465393 - score 0.854\n",
      "2020-10-22 20:47:45,507 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 20:47:45,508 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 20:48:02,620 epoch 111 - iter 36/368 - loss 0.13981737 - samples/sec: 69.42 - lr: 0.000781\n",
      "2020-10-22 20:48:19,523 epoch 111 - iter 72/368 - loss 0.14062287 - samples/sec: 69.41 - lr: 0.000781\n",
      "2020-10-22 20:48:36,446 epoch 111 - iter 108/368 - loss 0.14353351 - samples/sec: 69.34 - lr: 0.000781\n",
      "2020-10-22 20:48:53,583 epoch 111 - iter 144/368 - loss 0.14545859 - samples/sec: 68.50 - lr: 0.000781\n",
      "2020-10-22 20:49:10,150 epoch 111 - iter 180/368 - loss 0.14896115 - samples/sec: 69.79 - lr: 0.000781\n",
      "2020-10-22 20:49:26,813 epoch 111 - iter 216/368 - loss 0.15086579 - samples/sec: 70.41 - lr: 0.000781\n",
      "2020-10-22 20:49:43,846 epoch 111 - iter 252/368 - loss 0.14933779 - samples/sec: 67.89 - lr: 0.000781\n",
      "2020-10-22 20:50:00,838 epoch 111 - iter 288/368 - loss 0.14980152 - samples/sec: 69.13 - lr: 0.000781\n",
      "2020-10-22 20:50:17,898 epoch 111 - iter 324/368 - loss 0.14992042 - samples/sec: 68.82 - lr: 0.000781\n",
      "2020-10-22 20:50:34,931 epoch 111 - iter 360/368 - loss 0.14944123 - samples/sec: 68.93 - lr: 0.000781\n",
      "2020-10-22 20:50:38,943 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 20:50:38,944 EPOCH 111 done: loss 0.1502 - lr 0.0007813\n",
      "2020-10-22 20:51:26,962 DEV : loss 0.4204862713813782 - score 0.8535\n",
      "2020-10-22 20:51:28,887 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 20:51:28,888 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 20:51:46,231 epoch 112 - iter 36/368 - loss 0.13766654 - samples/sec: 68.62 - lr: 0.000781\n",
      "2020-10-22 20:52:03,246 epoch 112 - iter 72/368 - loss 0.14836817 - samples/sec: 68.02 - lr: 0.000781\n",
      "2020-10-22 20:52:20,356 epoch 112 - iter 108/368 - loss 0.15180469 - samples/sec: 68.55 - lr: 0.000781\n",
      "2020-10-22 20:52:37,355 epoch 112 - iter 144/368 - loss 0.15024804 - samples/sec: 69.04 - lr: 0.000781\n",
      "2020-10-22 20:52:54,098 epoch 112 - iter 180/368 - loss 0.14391674 - samples/sec: 69.11 - lr: 0.000781\n",
      "2020-10-22 20:53:10,927 epoch 112 - iter 216/368 - loss 0.14320810 - samples/sec: 68.73 - lr: 0.000781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 20:53:28,006 epoch 112 - iter 252/368 - loss 0.14145082 - samples/sec: 68.73 - lr: 0.000781\n",
      "2020-10-22 20:53:44,692 epoch 112 - iter 288/368 - loss 0.14796462 - samples/sec: 70.40 - lr: 0.000781\n",
      "2020-10-22 20:54:01,488 epoch 112 - iter 324/368 - loss 0.15068915 - samples/sec: 69.86 - lr: 0.000781\n",
      "2020-10-22 20:54:18,526 epoch 112 - iter 360/368 - loss 0.15049402 - samples/sec: 67.88 - lr: 0.000781\n",
      "2020-10-22 20:54:22,067 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 20:54:22,068 EPOCH 112 done: loss 0.1499 - lr 0.0007813\n",
      "2020-10-22 20:55:11,263 DEV : loss 0.42142152786254883 - score 0.8527\n",
      "2020-10-22 20:55:13,181 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 20:55:13,182 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 20:55:30,759 epoch 113 - iter 36/368 - loss 0.19185520 - samples/sec: 67.43 - lr: 0.000781\n",
      "2020-10-22 20:55:47,602 epoch 113 - iter 72/368 - loss 0.17239038 - samples/sec: 69.76 - lr: 0.000781\n",
      "2020-10-22 20:56:04,837 epoch 113 - iter 108/368 - loss 0.16900795 - samples/sec: 68.03 - lr: 0.000781\n",
      "2020-10-22 20:56:22,285 epoch 113 - iter 144/368 - loss 0.15985810 - samples/sec: 66.30 - lr: 0.000781\n",
      "2020-10-22 20:56:39,473 epoch 113 - iter 180/368 - loss 0.15687920 - samples/sec: 68.32 - lr: 0.000781\n",
      "2020-10-22 20:56:57,063 epoch 113 - iter 216/368 - loss 0.15552764 - samples/sec: 66.72 - lr: 0.000781\n",
      "2020-10-22 20:57:14,071 epoch 113 - iter 252/368 - loss 0.15737604 - samples/sec: 68.98 - lr: 0.000781\n",
      "2020-10-22 20:57:31,305 epoch 113 - iter 288/368 - loss 0.15557097 - samples/sec: 68.06 - lr: 0.000781\n",
      "2020-10-22 20:57:48,569 epoch 113 - iter 324/368 - loss 0.15447921 - samples/sec: 68.06 - lr: 0.000781\n",
      "2020-10-22 20:58:05,673 epoch 113 - iter 360/368 - loss 0.15288349 - samples/sec: 68.62 - lr: 0.000781\n",
      "2020-10-22 20:58:09,429 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 20:58:09,430 EPOCH 113 done: loss 0.1529 - lr 0.0007813\n",
      "2020-10-22 20:58:57,976 DEV : loss 0.419534832239151 - score 0.8535\n",
      "2020-10-22 20:58:59,899 BAD EPOCHS (no improvement): 5\n",
      "2020-10-22 20:58:59,900 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 20:59:17,386 epoch 114 - iter 36/368 - loss 0.15325742 - samples/sec: 67.98 - lr: 0.000781\n",
      "2020-10-22 20:59:34,599 epoch 114 - iter 72/368 - loss 0.14226327 - samples/sec: 68.29 - lr: 0.000781\n",
      "2020-10-22 20:59:51,791 epoch 114 - iter 108/368 - loss 0.14627246 - samples/sec: 67.27 - lr: 0.000781\n",
      "2020-10-22 21:00:08,968 epoch 114 - iter 144/368 - loss 0.14272133 - samples/sec: 68.31 - lr: 0.000781\n",
      "2020-10-22 21:00:26,244 epoch 114 - iter 180/368 - loss 0.14363745 - samples/sec: 66.99 - lr: 0.000781\n",
      "2020-10-22 21:00:43,676 epoch 114 - iter 216/368 - loss 0.14614148 - samples/sec: 67.40 - lr: 0.000781\n",
      "2020-10-22 21:01:00,961 epoch 114 - iter 252/368 - loss 0.14694446 - samples/sec: 67.92 - lr: 0.000781\n",
      "2020-10-22 21:01:17,943 epoch 114 - iter 288/368 - loss 0.14865264 - samples/sec: 69.13 - lr: 0.000781\n",
      "2020-10-22 21:01:34,615 epoch 114 - iter 324/368 - loss 0.14765668 - samples/sec: 70.44 - lr: 0.000781\n",
      "2020-10-22 21:01:51,596 epoch 114 - iter 360/368 - loss 0.14945873 - samples/sec: 69.13 - lr: 0.000781\n",
      "2020-10-22 21:01:55,158 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 21:01:55,159 EPOCH 114 done: loss 0.1495 - lr 0.0007813\n",
      "2020-10-22 21:02:43,361 DEV : loss 0.42072010040283203 - score 0.8527\n",
      "Epoch   114: reducing learning rate of group 0 to 3.9063e-04.\n",
      "2020-10-22 21:02:45,261 BAD EPOCHS (no improvement): 6\n",
      "2020-10-22 21:02:45,262 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 21:03:02,813 epoch 115 - iter 36/368 - loss 0.15699944 - samples/sec: 66.53 - lr: 0.000391\n",
      "2020-10-22 21:03:19,135 epoch 115 - iter 72/368 - loss 0.14767116 - samples/sec: 71.94 - lr: 0.000391\n",
      "2020-10-22 21:03:36,704 epoch 115 - iter 108/368 - loss 0.14844276 - samples/sec: 66.83 - lr: 0.000391\n",
      "2020-10-22 21:03:53,705 epoch 115 - iter 144/368 - loss 0.15230303 - samples/sec: 68.06 - lr: 0.000391\n",
      "2020-10-22 21:04:10,611 epoch 115 - iter 180/368 - loss 0.15678583 - samples/sec: 69.56 - lr: 0.000391\n",
      "2020-10-22 21:04:27,838 epoch 115 - iter 216/368 - loss 0.15798519 - samples/sec: 68.11 - lr: 0.000391\n",
      "2020-10-22 21:04:45,539 epoch 115 - iter 252/368 - loss 0.15772634 - samples/sec: 66.27 - lr: 0.000391\n",
      "2020-10-22 21:05:03,080 epoch 115 - iter 288/368 - loss 0.15615889 - samples/sec: 66.97 - lr: 0.000391\n",
      "2020-10-22 21:05:20,016 epoch 115 - iter 324/368 - loss 0.15455876 - samples/sec: 69.28 - lr: 0.000391\n",
      "2020-10-22 21:05:36,406 epoch 115 - iter 360/368 - loss 0.15295636 - samples/sec: 71.66 - lr: 0.000391\n",
      "2020-10-22 21:05:39,784 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 21:05:39,785 EPOCH 115 done: loss 0.1531 - lr 0.0003906\n",
      "2020-10-22 21:06:28,552 DEV : loss 0.4206778109073639 - score 0.8532\n",
      "2020-10-22 21:06:30,464 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 21:06:30,465 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 21:06:47,936 epoch 116 - iter 36/368 - loss 0.12784072 - samples/sec: 68.08 - lr: 0.000391\n",
      "2020-10-22 21:07:05,141 epoch 116 - iter 72/368 - loss 0.12696376 - samples/sec: 68.30 - lr: 0.000391\n",
      "2020-10-22 21:07:22,553 epoch 116 - iter 108/368 - loss 0.13752727 - samples/sec: 67.40 - lr: 0.000391\n",
      "2020-10-22 21:07:39,718 epoch 116 - iter 144/368 - loss 0.14174956 - samples/sec: 68.38 - lr: 0.000391\n",
      "2020-10-22 21:07:56,631 epoch 116 - iter 180/368 - loss 0.14481957 - samples/sec: 68.41 - lr: 0.000391\n",
      "2020-10-22 21:08:13,864 epoch 116 - iter 216/368 - loss 0.14836061 - samples/sec: 68.09 - lr: 0.000391\n",
      "2020-10-22 21:08:30,382 epoch 116 - iter 252/368 - loss 0.15055256 - samples/sec: 70.06 - lr: 0.000391\n",
      "2020-10-22 21:08:47,529 epoch 116 - iter 288/368 - loss 0.14994310 - samples/sec: 68.44 - lr: 0.000391\n",
      "2020-10-22 21:09:04,794 epoch 116 - iter 324/368 - loss 0.15206585 - samples/sec: 67.99 - lr: 0.000391\n",
      "2020-10-22 21:09:22,057 epoch 116 - iter 360/368 - loss 0.15038704 - samples/sec: 66.97 - lr: 0.000391\n",
      "2020-10-22 21:09:25,419 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 21:09:25,419 EPOCH 116 done: loss 0.1515 - lr 0.0003906\n",
      "2020-10-22 21:10:14,446 DEV : loss 0.4207124412059784 - score 0.8525\n",
      "2020-10-22 21:10:16,598 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 21:10:16,599 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 21:10:33,388 epoch 117 - iter 36/368 - loss 0.15043491 - samples/sec: 70.74 - lr: 0.000391\n",
      "2020-10-22 21:10:50,163 epoch 117 - iter 72/368 - loss 0.14851832 - samples/sec: 68.95 - lr: 0.000391\n",
      "2020-10-22 21:11:06,905 epoch 117 - iter 108/368 - loss 0.14424919 - samples/sec: 69.12 - lr: 0.000391\n",
      "2020-10-22 21:11:23,944 epoch 117 - iter 144/368 - loss 0.14963942 - samples/sec: 68.93 - lr: 0.000391\n",
      "2020-10-22 21:11:40,760 epoch 117 - iter 180/368 - loss 0.14996101 - samples/sec: 69.75 - lr: 0.000391\n",
      "2020-10-22 21:11:57,018 epoch 117 - iter 216/368 - loss 0.15036668 - samples/sec: 72.25 - lr: 0.000391\n",
      "2020-10-22 21:12:13,896 epoch 117 - iter 252/368 - loss 0.15240577 - samples/sec: 68.53 - lr: 0.000391\n",
      "2020-10-22 21:12:30,800 epoch 117 - iter 288/368 - loss 0.14917345 - samples/sec: 69.43 - lr: 0.000391\n",
      "2020-10-22 21:12:47,857 epoch 117 - iter 324/368 - loss 0.14793295 - samples/sec: 68.84 - lr: 0.000391\n",
      "2020-10-22 21:13:04,524 epoch 117 - iter 360/368 - loss 0.14829343 - samples/sec: 70.47 - lr: 0.000391\n",
      "2020-10-22 21:13:08,064 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 21:13:08,065 EPOCH 117 done: loss 0.1488 - lr 0.0003906\n",
      "2020-10-22 21:13:56,901 DEV : loss 0.4210531413555145 - score 0.8527\n",
      "2020-10-22 21:13:58,785 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 21:13:58,786 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 21:14:15,675 epoch 118 - iter 36/368 - loss 0.15156224 - samples/sec: 70.50 - lr: 0.000391\n",
      "2020-10-22 21:14:32,902 epoch 118 - iter 72/368 - loss 0.14646500 - samples/sec: 67.12 - lr: 0.000391\n",
      "2020-10-22 21:14:50,330 epoch 118 - iter 108/368 - loss 0.14566728 - samples/sec: 67.39 - lr: 0.000391\n",
      "2020-10-22 21:15:07,331 epoch 118 - iter 144/368 - loss 0.14783675 - samples/sec: 68.00 - lr: 0.000391\n",
      "2020-10-22 21:15:24,697 epoch 118 - iter 180/368 - loss 0.15149259 - samples/sec: 67.55 - lr: 0.000391\n",
      "2020-10-22 21:15:41,564 epoch 118 - iter 216/368 - loss 0.14889265 - samples/sec: 68.59 - lr: 0.000391\n",
      "2020-10-22 21:15:58,650 epoch 118 - iter 252/368 - loss 0.14959316 - samples/sec: 68.65 - lr: 0.000391\n",
      "2020-10-22 21:16:15,602 epoch 118 - iter 288/368 - loss 0.14834335 - samples/sec: 68.23 - lr: 0.000391\n",
      "2020-10-22 21:16:32,556 epoch 118 - iter 324/368 - loss 0.14866673 - samples/sec: 69.23 - lr: 0.000391\n",
      "2020-10-22 21:16:48,999 epoch 118 - iter 360/368 - loss 0.15060692 - samples/sec: 70.34 - lr: 0.000391\n",
      "2020-10-22 21:16:52,927 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 21:16:52,927 EPOCH 118 done: loss 0.1502 - lr 0.0003906\n",
      "2020-10-22 21:17:42,069 DEV : loss 0.4213979244232178 - score 0.8522\n",
      "2020-10-22 21:17:43,957 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 21:17:43,958 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 21:18:01,485 epoch 119 - iter 36/368 - loss 0.15718345 - samples/sec: 67.82 - lr: 0.000391\n",
      "2020-10-22 21:18:18,552 epoch 119 - iter 72/368 - loss 0.15666754 - samples/sec: 68.80 - lr: 0.000391\n",
      "2020-10-22 21:18:35,308 epoch 119 - iter 108/368 - loss 0.16789090 - samples/sec: 70.05 - lr: 0.000391\n",
      "2020-10-22 21:18:52,330 epoch 119 - iter 144/368 - loss 0.15909574 - samples/sec: 68.98 - lr: 0.000391\n",
      "2020-10-22 21:19:09,263 epoch 119 - iter 180/368 - loss 0.16102908 - samples/sec: 69.29 - lr: 0.000391\n",
      "2020-10-22 21:19:26,528 epoch 119 - iter 216/368 - loss 0.15966939 - samples/sec: 68.03 - lr: 0.000391\n",
      "2020-10-22 21:19:42,777 epoch 119 - iter 252/368 - loss 0.15830685 - samples/sec: 71.20 - lr: 0.000391\n",
      "2020-10-22 21:19:59,818 epoch 119 - iter 288/368 - loss 0.15839041 - samples/sec: 67.88 - lr: 0.000391\n",
      "2020-10-22 21:20:16,616 epoch 119 - iter 324/368 - loss 0.15781858 - samples/sec: 69.89 - lr: 0.000391\n",
      "2020-10-22 21:20:32,956 epoch 119 - iter 360/368 - loss 0.15816872 - samples/sec: 70.77 - lr: 0.000391\n",
      "2020-10-22 21:20:36,594 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 21:20:36,595 EPOCH 119 done: loss 0.1578 - lr 0.0003906\n",
      "2020-10-22 21:21:24,585 DEV : loss 0.42112210392951965 - score 0.8522\n",
      "2020-10-22 21:21:26,462 BAD EPOCHS (no improvement): 5\n",
      "2020-10-22 21:21:26,463 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 21:21:43,705 epoch 120 - iter 36/368 - loss 0.14588869 - samples/sec: 68.92 - lr: 0.000391\n",
      "2020-10-22 21:22:01,167 epoch 120 - iter 72/368 - loss 0.13702311 - samples/sec: 67.25 - lr: 0.000391\n",
      "2020-10-22 21:22:18,904 epoch 120 - iter 108/368 - loss 0.14444263 - samples/sec: 66.14 - lr: 0.000391\n",
      "2020-10-22 21:22:35,787 epoch 120 - iter 144/368 - loss 0.14378975 - samples/sec: 68.53 - lr: 0.000391\n",
      "2020-10-22 21:22:53,083 epoch 120 - iter 180/368 - loss 0.14342555 - samples/sec: 67.84 - lr: 0.000391\n",
      "2020-10-22 21:23:10,638 epoch 120 - iter 216/368 - loss 0.14421643 - samples/sec: 66.90 - lr: 0.000391\n",
      "2020-10-22 21:23:28,078 epoch 120 - iter 252/368 - loss 0.14627957 - samples/sec: 67.31 - lr: 0.000391\n",
      "2020-10-22 21:23:44,934 epoch 120 - iter 288/368 - loss 0.14764232 - samples/sec: 69.59 - lr: 0.000391\n",
      "2020-10-22 21:24:01,973 epoch 120 - iter 324/368 - loss 0.14543052 - samples/sec: 68.89 - lr: 0.000391\n",
      "2020-10-22 21:24:18,301 epoch 120 - iter 360/368 - loss 0.14886271 - samples/sec: 70.84 - lr: 0.000391\n",
      "2020-10-22 21:24:22,135 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 21:24:22,135 EPOCH 120 done: loss 0.1499 - lr 0.0003906\n",
      "2020-10-22 21:25:10,853 DEV : loss 0.42072081565856934 - score 0.8517\n",
      "Epoch   120: reducing learning rate of group 0 to 1.9531e-04.\n",
      "2020-10-22 21:25:12,794 BAD EPOCHS (no improvement): 6\n",
      "2020-10-22 21:25:12,795 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 21:25:29,770 epoch 121 - iter 36/368 - loss 0.14495148 - samples/sec: 69.99 - lr: 0.000195\n",
      "2020-10-22 21:25:46,471 epoch 121 - iter 72/368 - loss 0.14652584 - samples/sec: 70.33 - lr: 0.000195\n",
      "2020-10-22 21:26:02,636 epoch 121 - iter 108/368 - loss 0.14781034 - samples/sec: 71.59 - lr: 0.000195\n",
      "2020-10-22 21:26:18,869 epoch 121 - iter 144/368 - loss 0.15055647 - samples/sec: 72.34 - lr: 0.000195\n",
      "2020-10-22 21:26:35,484 epoch 121 - iter 180/368 - loss 0.15080908 - samples/sec: 70.62 - lr: 0.000195\n",
      "2020-10-22 21:26:52,244 epoch 121 - iter 216/368 - loss 0.14820588 - samples/sec: 69.00 - lr: 0.000195\n",
      "2020-10-22 21:27:09,235 epoch 121 - iter 252/368 - loss 0.14710432 - samples/sec: 69.08 - lr: 0.000195\n",
      "2020-10-22 21:27:25,775 epoch 121 - iter 288/368 - loss 0.15075042 - samples/sec: 69.94 - lr: 0.000195\n",
      "2020-10-22 21:27:42,370 epoch 121 - iter 324/368 - loss 0.15016002 - samples/sec: 69.70 - lr: 0.000195\n",
      "2020-10-22 21:27:58,929 epoch 121 - iter 360/368 - loss 0.15060516 - samples/sec: 70.86 - lr: 0.000195\n",
      "2020-10-22 21:28:02,367 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 21:28:02,368 EPOCH 121 done: loss 0.1508 - lr 0.0001953\n",
      "2020-10-22 21:28:49,566 DEV : loss 0.42097553610801697 - score 0.8522\n",
      "2020-10-22 21:28:51,438 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 21:28:51,438 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 21:29:08,599 epoch 122 - iter 36/368 - loss 0.16558499 - samples/sec: 69.23 - lr: 0.000195\n",
      "2020-10-22 21:29:25,359 epoch 122 - iter 72/368 - loss 0.16250595 - samples/sec: 70.03 - lr: 0.000195\n",
      "2020-10-22 21:29:42,150 epoch 122 - iter 108/368 - loss 0.15845570 - samples/sec: 69.94 - lr: 0.000195\n",
      "2020-10-22 21:29:58,695 epoch 122 - iter 144/368 - loss 0.15629488 - samples/sec: 69.95 - lr: 0.000195\n",
      "2020-10-22 21:30:15,934 epoch 122 - iter 180/368 - loss 0.15514111 - samples/sec: 68.11 - lr: 0.000195\n",
      "2020-10-22 21:30:32,680 epoch 122 - iter 216/368 - loss 0.15383326 - samples/sec: 70.17 - lr: 0.000195\n",
      "2020-10-22 21:30:49,381 epoch 122 - iter 252/368 - loss 0.15305650 - samples/sec: 70.26 - lr: 0.000195\n",
      "2020-10-22 21:31:05,808 epoch 122 - iter 288/368 - loss 0.14857657 - samples/sec: 71.52 - lr: 0.000195\n",
      "2020-10-22 21:31:22,147 epoch 122 - iter 324/368 - loss 0.15083408 - samples/sec: 71.87 - lr: 0.000195\n",
      "2020-10-22 21:31:38,638 epoch 122 - iter 360/368 - loss 0.14787090 - samples/sec: 70.14 - lr: 0.000195\n",
      "2020-10-22 21:31:42,367 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 21:31:42,368 EPOCH 122 done: loss 0.1476 - lr 0.0001953\n",
      "2020-10-22 21:32:31,040 DEV : loss 0.4209207594394684 - score 0.8525\n",
      "2020-10-22 21:32:32,960 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 21:32:32,961 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 21:32:49,904 epoch 123 - iter 36/368 - loss 0.16297062 - samples/sec: 70.16 - lr: 0.000195\n",
      "2020-10-22 21:33:06,749 epoch 123 - iter 72/368 - loss 0.14732006 - samples/sec: 69.72 - lr: 0.000195\n",
      "2020-10-22 21:33:23,249 epoch 123 - iter 108/368 - loss 0.14166800 - samples/sec: 71.15 - lr: 0.000195\n",
      "2020-10-22 21:33:40,597 epoch 123 - iter 144/368 - loss 0.13860500 - samples/sec: 67.64 - lr: 0.000195\n",
      "2020-10-22 21:33:57,420 epoch 123 - iter 180/368 - loss 0.13931190 - samples/sec: 69.78 - lr: 0.000195\n",
      "2020-10-22 21:34:14,899 epoch 123 - iter 216/368 - loss 0.14337301 - samples/sec: 67.08 - lr: 0.000195\n",
      "2020-10-22 21:34:31,669 epoch 123 - iter 252/368 - loss 0.14479332 - samples/sec: 70.03 - lr: 0.000195\n",
      "2020-10-22 21:34:48,076 epoch 123 - iter 288/368 - loss 0.14570577 - samples/sec: 70.48 - lr: 0.000195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 21:35:04,860 epoch 123 - iter 324/368 - loss 0.14747788 - samples/sec: 69.92 - lr: 0.000195\n",
      "2020-10-22 21:35:21,868 epoch 123 - iter 360/368 - loss 0.14739360 - samples/sec: 69.00 - lr: 0.000195\n",
      "2020-10-22 21:35:25,607 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 21:35:25,607 EPOCH 123 done: loss 0.1474 - lr 0.0001953\n",
      "2020-10-22 21:36:15,522 DEV : loss 0.4210428297519684 - score 0.8522\n",
      "2020-10-22 21:36:17,402 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 21:36:17,403 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 21:36:34,464 epoch 124 - iter 36/368 - loss 0.15370604 - samples/sec: 68.48 - lr: 0.000195\n",
      "2020-10-22 21:36:51,411 epoch 124 - iter 72/368 - loss 0.14630944 - samples/sec: 69.23 - lr: 0.000195\n",
      "2020-10-22 21:37:07,873 epoch 124 - iter 108/368 - loss 0.14446120 - samples/sec: 70.28 - lr: 0.000195\n",
      "2020-10-22 21:37:24,555 epoch 124 - iter 144/368 - loss 0.14308352 - samples/sec: 69.36 - lr: 0.000195\n",
      "2020-10-22 21:37:41,209 epoch 124 - iter 180/368 - loss 0.14505701 - samples/sec: 70.52 - lr: 0.000195\n",
      "2020-10-22 21:37:58,120 epoch 124 - iter 216/368 - loss 0.14726724 - samples/sec: 69.46 - lr: 0.000195\n",
      "2020-10-22 21:38:15,092 epoch 124 - iter 252/368 - loss 0.14897382 - samples/sec: 69.17 - lr: 0.000195\n",
      "2020-10-22 21:38:32,268 epoch 124 - iter 288/368 - loss 0.14898619 - samples/sec: 68.29 - lr: 0.000195\n",
      "2020-10-22 21:38:49,341 epoch 124 - iter 324/368 - loss 0.14922060 - samples/sec: 68.72 - lr: 0.000195\n",
      "2020-10-22 21:39:05,749 epoch 124 - iter 360/368 - loss 0.14885077 - samples/sec: 70.50 - lr: 0.000195\n",
      "2020-10-22 21:39:09,686 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 21:39:09,686 EPOCH 124 done: loss 0.1490 - lr 0.0001953\n",
      "2020-10-22 21:39:57,414 DEV : loss 0.4210475981235504 - score 0.8522\n",
      "2020-10-22 21:39:59,330 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 21:39:59,331 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 21:40:16,404 epoch 125 - iter 36/368 - loss 0.13820248 - samples/sec: 69.62 - lr: 0.000195\n",
      "2020-10-22 21:40:33,108 epoch 125 - iter 72/368 - loss 0.14271327 - samples/sec: 70.30 - lr: 0.000195\n",
      "2020-10-22 21:40:49,639 epoch 125 - iter 108/368 - loss 0.14011073 - samples/sec: 71.03 - lr: 0.000195\n",
      "2020-10-22 21:41:06,288 epoch 125 - iter 144/368 - loss 0.13936044 - samples/sec: 70.53 - lr: 0.000195\n",
      "2020-10-22 21:41:22,496 epoch 125 - iter 180/368 - loss 0.14425134 - samples/sec: 71.34 - lr: 0.000195\n",
      "2020-10-22 21:41:38,982 epoch 125 - iter 216/368 - loss 0.14534308 - samples/sec: 71.21 - lr: 0.000195\n",
      "2020-10-22 21:41:55,489 epoch 125 - iter 252/368 - loss 0.14876667 - samples/sec: 71.06 - lr: 0.000195\n",
      "2020-10-22 21:42:12,210 epoch 125 - iter 288/368 - loss 0.14898731 - samples/sec: 70.22 - lr: 0.000195\n",
      "2020-10-22 21:42:28,726 epoch 125 - iter 324/368 - loss 0.14808979 - samples/sec: 71.12 - lr: 0.000195\n",
      "2020-10-22 21:42:45,482 epoch 125 - iter 360/368 - loss 0.14985180 - samples/sec: 70.05 - lr: 0.000195\n",
      "2020-10-22 21:42:49,054 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 21:42:49,054 EPOCH 125 done: loss 0.1499 - lr 0.0001953\n",
      "2020-10-22 21:43:36,442 DEV : loss 0.4212711751461029 - score 0.852\n",
      "2020-10-22 21:43:38,319 BAD EPOCHS (no improvement): 5\n",
      "2020-10-22 21:43:38,319 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 21:43:54,968 epoch 126 - iter 36/368 - loss 0.14070800 - samples/sec: 71.38 - lr: 0.000195\n",
      "2020-10-22 21:44:11,384 epoch 126 - iter 72/368 - loss 0.14248131 - samples/sec: 71.58 - lr: 0.000195\n",
      "2020-10-22 21:44:27,717 epoch 126 - iter 108/368 - loss 0.14389604 - samples/sec: 70.85 - lr: 0.000195\n",
      "2020-10-22 21:44:43,768 epoch 126 - iter 144/368 - loss 0.14291800 - samples/sec: 72.09 - lr: 0.000195\n",
      "2020-10-22 21:45:00,273 epoch 126 - iter 180/368 - loss 0.14612529 - samples/sec: 71.15 - lr: 0.000195\n",
      "2020-10-22 21:45:16,910 epoch 126 - iter 216/368 - loss 0.14619580 - samples/sec: 69.54 - lr: 0.000195\n",
      "2020-10-22 21:45:33,738 epoch 126 - iter 252/368 - loss 0.14786125 - samples/sec: 69.75 - lr: 0.000195\n",
      "2020-10-22 21:45:50,345 epoch 126 - iter 288/368 - loss 0.14818232 - samples/sec: 70.69 - lr: 0.000195\n",
      "2020-10-22 21:46:06,813 epoch 126 - iter 324/368 - loss 0.14901260 - samples/sec: 71.34 - lr: 0.000195\n",
      "2020-10-22 21:46:23,288 epoch 126 - iter 360/368 - loss 0.15065876 - samples/sec: 71.22 - lr: 0.000195\n",
      "2020-10-22 21:46:26,735 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 21:46:26,735 EPOCH 126 done: loss 0.1499 - lr 0.0001953\n",
      "2020-10-22 21:47:15,566 DEV : loss 0.4210350811481476 - score 0.8532\n",
      "Epoch   126: reducing learning rate of group 0 to 9.7656e-05.\n",
      "2020-10-22 21:47:17,510 BAD EPOCHS (no improvement): 6\n",
      "2020-10-22 21:47:17,511 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 21:47:17,511 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 21:47:17,512 learning rate too small - quitting training!\n",
      "2020-10-22 21:47:17,512 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 21:47:18,149 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 21:47:18,150 Testing using best model ...\n",
      "2020-10-22 21:47:18,150 loading file classifiers/spooky_authorship_classifier_bert/best-model.pt\n",
      "2020-10-22 21:48:04,997 \t0.8495\n",
      "2020-10-22 21:48:04,998 \n",
      "Results:\n",
      "- F-score (micro) 0.8495\n",
      "- F-score (macro) 0.8502\n",
      "- Accuracy 0.8495\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         EAP     0.8260    0.8674    0.8462      1554\n",
      "         MWS     0.8426    0.8405    0.8415      1210\n",
      "         HPL     0.8932    0.8345    0.8628      1142\n",
      "\n",
      "   micro avg     0.8495    0.8495    0.8495      3906\n",
      "   macro avg     0.8539    0.8475    0.8502      3906\n",
      "weighted avg     0.8508    0.8495    0.8496      3906\n",
      " samples avg     0.8495    0.8495    0.8495      3906\n",
      "\n",
      "2020-10-22 21:48:04,999 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.8495,\n",
       " 'dev_score_history': [0.7223,\n",
       "  0.7195,\n",
       "  0.7901,\n",
       "  0.7735,\n",
       "  0.6891,\n",
       "  0.7216,\n",
       "  0.7972,\n",
       "  0.7919,\n",
       "  0.7921,\n",
       "  0.8052,\n",
       "  0.7786,\n",
       "  0.8052,\n",
       "  0.7763,\n",
       "  0.8141,\n",
       "  0.8151,\n",
       "  0.8082,\n",
       "  0.81,\n",
       "  0.7435,\n",
       "  0.8141,\n",
       "  0.8133,\n",
       "  0.8167,\n",
       "  0.8062,\n",
       "  0.7837,\n",
       "  0.8251,\n",
       "  0.8192,\n",
       "  0.8172,\n",
       "  0.8159,\n",
       "  0.7783,\n",
       "  0.8149,\n",
       "  0.8149,\n",
       "  0.831,\n",
       "  0.8274,\n",
       "  0.8287,\n",
       "  0.8272,\n",
       "  0.8348,\n",
       "  0.8379,\n",
       "  0.8343,\n",
       "  0.8289,\n",
       "  0.8374,\n",
       "  0.8282,\n",
       "  0.8256,\n",
       "  0.8264,\n",
       "  0.8415,\n",
       "  0.8369,\n",
       "  0.8376,\n",
       "  0.8356,\n",
       "  0.8417,\n",
       "  0.8392,\n",
       "  0.841,\n",
       "  0.8433,\n",
       "  0.8381,\n",
       "  0.8384,\n",
       "  0.8458,\n",
       "  0.8438,\n",
       "  0.8433,\n",
       "  0.8422,\n",
       "  0.8456,\n",
       "  0.8481,\n",
       "  0.8463,\n",
       "  0.8479,\n",
       "  0.8453,\n",
       "  0.8458,\n",
       "  0.8502,\n",
       "  0.8514,\n",
       "  0.8486,\n",
       "  0.8443,\n",
       "  0.843,\n",
       "  0.8445,\n",
       "  0.8497,\n",
       "  0.8512,\n",
       "  0.8502,\n",
       "  0.8491,\n",
       "  0.8517,\n",
       "  0.8517,\n",
       "  0.8497,\n",
       "  0.8502,\n",
       "  0.8499,\n",
       "  0.8481,\n",
       "  0.8504,\n",
       "  0.8494,\n",
       "  0.8509,\n",
       "  0.8486,\n",
       "  0.8525,\n",
       "  0.8509,\n",
       "  0.8553,\n",
       "  0.8512,\n",
       "  0.852,\n",
       "  0.8525,\n",
       "  0.8545,\n",
       "  0.8566,\n",
       "  0.8543,\n",
       "  0.8507,\n",
       "  0.8532,\n",
       "  0.8525,\n",
       "  0.8512,\n",
       "  0.852,\n",
       "  0.8517,\n",
       "  0.8509,\n",
       "  0.8517,\n",
       "  0.8514,\n",
       "  0.8527,\n",
       "  0.855,\n",
       "  0.8548,\n",
       "  0.8545,\n",
       "  0.854,\n",
       "  0.8537,\n",
       "  0.853,\n",
       "  0.8537,\n",
       "  0.854,\n",
       "  0.854,\n",
       "  0.8535,\n",
       "  0.8527,\n",
       "  0.8535,\n",
       "  0.8527,\n",
       "  0.8532,\n",
       "  0.8525,\n",
       "  0.8527,\n",
       "  0.8522,\n",
       "  0.8522,\n",
       "  0.8517,\n",
       "  0.8522,\n",
       "  0.8525,\n",
       "  0.8522,\n",
       "  0.8522,\n",
       "  0.852,\n",
       "  0.8532],\n",
       " 'train_loss_history': [0.9221288626608641,\n",
       "  0.6762128520109083,\n",
       "  0.6227032427230607,\n",
       "  0.6143173089493876,\n",
       "  0.5797769209451001,\n",
       "  0.5498665407623934,\n",
       "  0.5353674827467488,\n",
       "  0.5220256383004396,\n",
       "  0.5232547600146221,\n",
       "  0.521961851571889,\n",
       "  0.491778617684284,\n",
       "  0.507887444195702,\n",
       "  0.5137121680638065,\n",
       "  0.4907715085529439,\n",
       "  0.4866491354111096,\n",
       "  0.4673603196911838,\n",
       "  0.4713178634967493,\n",
       "  0.4664309352393384,\n",
       "  0.4692636963142001,\n",
       "  0.46114310174775514,\n",
       "  0.46313554311738064,\n",
       "  0.4553046302424501,\n",
       "  0.4462656011076077,\n",
       "  0.43682284993322,\n",
       "  0.4342943548589297,\n",
       "  0.43292649867741956,\n",
       "  0.423239024983638,\n",
       "  0.4209564518304947,\n",
       "  0.4268859260432098,\n",
       "  0.4197348470232733,\n",
       "  0.3793288698703375,\n",
       "  0.36277264449745417,\n",
       "  0.34743503203777515,\n",
       "  0.3448286234482151,\n",
       "  0.3375432355045948,\n",
       "  0.32964268903774413,\n",
       "  0.3315911705241255,\n",
       "  0.3283538179796027,\n",
       "  0.3169361830527044,\n",
       "  0.3127635909426633,\n",
       "  0.31476203253006807,\n",
       "  0.30784869922891905,\n",
       "  0.29855792904677597,\n",
       "  0.27838869673280936,\n",
       "  0.27546380163656303,\n",
       "  0.2713640925737665,\n",
       "  0.26175735998169886,\n",
       "  0.2668867954964061,\n",
       "  0.26519304088762274,\n",
       "  0.2633332485211608,\n",
       "  0.25456305204526236,\n",
       "  0.2520312407843607,\n",
       "  0.24741236905000455,\n",
       "  0.24470964885499005,\n",
       "  0.2437908384574415,\n",
       "  0.23920834560514145,\n",
       "  0.24089650618438813,\n",
       "  0.2384287329674091,\n",
       "  0.22930319940306895,\n",
       "  0.22798342066412064,\n",
       "  0.23066266651427292,\n",
       "  0.22125413203004585,\n",
       "  0.2164322939630517,\n",
       "  0.22022304531065343,\n",
       "  0.2133720566559097,\n",
       "  0.20615488666352694,\n",
       "  0.2113443387510336,\n",
       "  0.20674863297229065,\n",
       "  0.19936806531926698,\n",
       "  0.20723050764923834,\n",
       "  0.19412868577258094,\n",
       "  0.1896884191285252,\n",
       "  0.1917816160256853,\n",
       "  0.19000854036952977,\n",
       "  0.1830419735254153,\n",
       "  0.1768689669020798,\n",
       "  0.18045978496134604,\n",
       "  0.1750424829888684,\n",
       "  0.1764278568064227,\n",
       "  0.173913313065777,\n",
       "  0.1737051134949307,\n",
       "  0.17384840766190673,\n",
       "  0.1691585326941846,\n",
       "  0.16911400980113642,\n",
       "  0.1658925599489442,\n",
       "  0.16925994325783508,\n",
       "  0.1747383422764909,\n",
       "  0.16423969473133027,\n",
       "  0.16711975734316462,\n",
       "  0.16449979052919408,\n",
       "  0.1641933165855058,\n",
       "  0.1635808122202592,\n",
       "  0.1570426326437408,\n",
       "  0.15929172676228714,\n",
       "  0.1708024895152725,\n",
       "  0.15867712909011575,\n",
       "  0.15992125448183683,\n",
       "  0.1564323208294809,\n",
       "  0.15204530793530663,\n",
       "  0.1575472723216871,\n",
       "  0.15775763950533356,\n",
       "  0.15687236127079182,\n",
       "  0.15295755904061598,\n",
       "  0.15463416470700633,\n",
       "  0.15311386355239412,\n",
       "  0.1496738592547405,\n",
       "  0.15439945694727256,\n",
       "  0.14807093508906014,\n",
       "  0.14634676716978784,\n",
       "  0.1506952165281805,\n",
       "  0.15017271143606986,\n",
       "  0.14992287989361616,\n",
       "  0.15293046920914607,\n",
       "  0.14952069294193518,\n",
       "  0.1531239057126779,\n",
       "  0.15150947318635072,\n",
       "  0.14878400834277272,\n",
       "  0.15016625418186025,\n",
       "  0.15778339068587546,\n",
       "  0.1499458722815768,\n",
       "  0.15078237823099302,\n",
       "  0.14762264701193603,\n",
       "  0.14736105271351888,\n",
       "  0.14895645170421948,\n",
       "  0.14986746884001742,\n",
       "  0.1498500751382064],\n",
       " 'dev_loss_history': [0.642713189125061,\n",
       "  0.6609243154525757,\n",
       "  0.5206485986709595,\n",
       "  0.5330621600151062,\n",
       "  0.7465242147445679,\n",
       "  0.6956577897071838,\n",
       "  0.49316585063934326,\n",
       "  0.5060697197914124,\n",
       "  0.5005537867546082,\n",
       "  0.4742196798324585,\n",
       "  0.5237590074539185,\n",
       "  0.4762105643749237,\n",
       "  0.5889406204223633,\n",
       "  0.4652252495288849,\n",
       "  0.4493841230869293,\n",
       "  0.4751187562942505,\n",
       "  0.46244534850120544,\n",
       "  0.6470394134521484,\n",
       "  0.4592461884021759,\n",
       "  0.45337456464767456,\n",
       "  0.44286391139030457,\n",
       "  0.47379186749458313,\n",
       "  0.5050782561302185,\n",
       "  0.44784843921661377,\n",
       "  0.4581835865974426,\n",
       "  0.46119850873947144,\n",
       "  0.4688448905944824,\n",
       "  0.5684040784835815,\n",
       "  0.46973565220832825,\n",
       "  0.44143563508987427,\n",
       "  0.4213426113128662,\n",
       "  0.433952271938324,\n",
       "  0.42231789231300354,\n",
       "  0.4243922829627991,\n",
       "  0.4145326316356659,\n",
       "  0.41224217414855957,\n",
       "  0.41470786929130554,\n",
       "  0.4222954511642456,\n",
       "  0.4162510633468628,\n",
       "  0.43183767795562744,\n",
       "  0.44246193766593933,\n",
       "  0.43531885743141174,\n",
       "  0.39765802025794983,\n",
       "  0.4131954312324524,\n",
       "  0.40824374556541443,\n",
       "  0.41943594813346863,\n",
       "  0.401189386844635,\n",
       "  0.4054614007472992,\n",
       "  0.4098110795021057,\n",
       "  0.4068930447101593,\n",
       "  0.40686240792274475,\n",
       "  0.40585434436798096,\n",
       "  0.4016282856464386,\n",
       "  0.4057975113391876,\n",
       "  0.39909347891807556,\n",
       "  0.42097073793411255,\n",
       "  0.39546912908554077,\n",
       "  0.40738871693611145,\n",
       "  0.41387879848480225,\n",
       "  0.4143044948577881,\n",
       "  0.4026189148426056,\n",
       "  0.4055662155151367,\n",
       "  0.4120483994483948,\n",
       "  0.4129878282546997,\n",
       "  0.3997349441051483,\n",
       "  0.3976660370826721,\n",
       "  0.41175931692123413,\n",
       "  0.4105680584907532,\n",
       "  0.4048095941543579,\n",
       "  0.4143088459968567,\n",
       "  0.4081110656261444,\n",
       "  0.417693167924881,\n",
       "  0.40996217727661133,\n",
       "  0.4109233319759369,\n",
       "  0.4129912257194519,\n",
       "  0.4151964485645294,\n",
       "  0.4083593487739563,\n",
       "  0.4110707640647888,\n",
       "  0.4189637005329132,\n",
       "  0.41911759972572327,\n",
       "  0.41747888922691345,\n",
       "  0.42080599069595337,\n",
       "  0.4183289408683777,\n",
       "  0.4179345369338989,\n",
       "  0.4154578447341919,\n",
       "  0.4165736436843872,\n",
       "  0.4126582443714142,\n",
       "  0.41781190037727356,\n",
       "  0.41568782925605774,\n",
       "  0.4171310067176819,\n",
       "  0.4126613140106201,\n",
       "  0.41894659399986267,\n",
       "  0.42125290632247925,\n",
       "  0.41888412833213806,\n",
       "  0.4162958562374115,\n",
       "  0.4173387587070465,\n",
       "  0.41755199432373047,\n",
       "  0.4208509027957916,\n",
       "  0.42034921050071716,\n",
       "  0.4215196669101715,\n",
       "  0.41956210136413574,\n",
       "  0.41928642988204956,\n",
       "  0.4168274700641632,\n",
       "  0.41926971077919006,\n",
       "  0.41993001103401184,\n",
       "  0.4204995036125183,\n",
       "  0.41934439539909363,\n",
       "  0.4204815626144409,\n",
       "  0.4215811491012573,\n",
       "  0.42161455750465393,\n",
       "  0.4204862713813782,\n",
       "  0.42142152786254883,\n",
       "  0.419534832239151,\n",
       "  0.42072010040283203,\n",
       "  0.4206778109073639,\n",
       "  0.4207124412059784,\n",
       "  0.4210531413555145,\n",
       "  0.4213979244232178,\n",
       "  0.42112210392951965,\n",
       "  0.42072081565856934,\n",
       "  0.42097553610801697,\n",
       "  0.4209207594394684,\n",
       "  0.4210428297519684,\n",
       "  0.4210475981235504,\n",
       "  0.4212711751461029,\n",
       "  0.4210350811481476]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "word_embeddings = [TransformerWordEmbeddings('bert-base-uncased')]\n",
    "\n",
    "# 4. initialize document embedding by passing list of word embeddings\n",
    "# Can choose between many RNN types (GRU by default, to change use rnn_type parameter)\n",
    "document_embeddings = DocumentRNNEmbeddings(word_embeddings, hidden_size=256)\n",
    "\n",
    "# 5. create the text classifier\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)\n",
    "\n",
    "# 6. initialize the text classifier trainer\n",
    "trainer = ModelTrainer(classifier, corpus)\n",
    "\n",
    "# 7. start the training\n",
    "trainer.train('classifiers/spooky_authorship_classifier_bert',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              anneal_factor=0.5,\n",
    "              patience=5,\n",
    "              max_epochs=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 01:59:06,967 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 01:59:06,969 Model: \"TextClassifier(\n",
      "  (document_embeddings): TransformerDocumentEmbeddings(\n",
      "    (model): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=768, out_features=3, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 01:59:06,969 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 01:59:06,969 Corpus: \"Corpus: 11762 train + 3911 dev + 3906 test sentences\"\n",
      "2020-10-22 01:59:06,970 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 01:59:06,970 Parameters:\n",
      "2020-10-22 01:59:06,970  - learning_rate: \"3e-05\"\n",
      "2020-10-22 01:59:06,971  - mini_batch_size: \"1\"\n",
      "2020-10-22 01:59:06,971  - patience: \"3\"\n",
      "2020-10-22 01:59:06,971  - anneal_factor: \"0.5\"\n",
      "2020-10-22 01:59:06,972  - max_epochs: \"50\"\n",
      "2020-10-22 01:59:06,972  - shuffle: \"True\"\n",
      "2020-10-22 01:59:06,973  - train_with_dev: \"False\"\n",
      "2020-10-22 01:59:06,973  - batch_growth_annealing: \"False\"\n",
      "2020-10-22 01:59:06,973 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 01:59:06,974 Model training base path: \"classifiers/spooky_authorship_classifier_transformer\"\n",
      "2020-10-22 01:59:06,974 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 01:59:06,974 Device: cuda:0\n",
      "2020-10-22 01:59:06,975 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 01:59:06,975 Embeddings storage mode: cpu\n",
      "2020-10-22 01:59:06,978 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 02:00:12,179 epoch 1 - iter 1176/11762 - loss 1.20558335 - samples/sec: 18.11 - lr: 0.000030\n",
      "2020-10-22 02:01:14,809 epoch 1 - iter 2352/11762 - loss 1.06406443 - samples/sec: 18.83 - lr: 0.000030\n",
      "2020-10-22 02:02:37,093 epoch 1 - iter 3528/11762 - loss 1.02343317 - samples/sec: 14.33 - lr: 0.000030\n",
      "2020-10-22 02:04:29,014 epoch 1 - iter 4704/11762 - loss 0.96919416 - samples/sec: 10.53 - lr: 0.000030\n",
      "2020-10-22 02:06:21,921 epoch 1 - iter 5880/11762 - loss 0.93205917 - samples/sec: 10.44 - lr: 0.000030\n",
      "2020-10-22 02:08:14,804 epoch 1 - iter 7056/11762 - loss 0.90838669 - samples/sec: 10.44 - lr: 0.000030\n",
      "2020-10-22 02:10:08,194 epoch 1 - iter 8232/11762 - loss 0.88795958 - samples/sec: 10.39 - lr: 0.000030\n",
      "2020-10-22 02:12:00,590 epoch 1 - iter 9408/11762 - loss 0.87452408 - samples/sec: 10.48 - lr: 0.000030\n",
      "2020-10-22 02:13:53,545 epoch 1 - iter 10584/11762 - loss 0.86029372 - samples/sec: 10.43 - lr: 0.000030\n",
      "2020-10-22 02:15:45,830 epoch 1 - iter 11760/11762 - loss 0.84762393 - samples/sec: 10.49 - lr: 0.000030\n",
      "2020-10-22 02:15:46,055 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 02:15:46,056 EPOCH 1 done: loss 0.8475 - lr 0.0000300\n",
      "2020-10-22 02:16:45,381 DEV : loss 0.6951817274093628 - score 0.8251\n",
      "2020-10-22 02:16:47,385 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 02:16:47,946 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 02:18:38,753 epoch 2 - iter 1176/11762 - loss 0.43340297 - samples/sec: 10.64 - lr: 0.000030\n",
      "2020-10-22 02:20:28,969 epoch 2 - iter 2352/11762 - loss 0.43651616 - samples/sec: 10.69 - lr: 0.000030\n",
      "2020-10-22 02:22:19,290 epoch 2 - iter 3528/11762 - loss 0.43828423 - samples/sec: 10.68 - lr: 0.000030\n",
      "2020-10-22 02:24:08,592 epoch 2 - iter 4704/11762 - loss 0.44512735 - samples/sec: 10.78 - lr: 0.000030\n",
      "2020-10-22 02:25:57,864 epoch 2 - iter 5880/11762 - loss 0.42987514 - samples/sec: 10.78 - lr: 0.000030\n",
      "2020-10-22 02:27:47,052 epoch 2 - iter 7056/11762 - loss 0.43277370 - samples/sec: 10.79 - lr: 0.000030\n",
      "2020-10-22 02:29:36,130 epoch 2 - iter 8232/11762 - loss 0.42934547 - samples/sec: 10.80 - lr: 0.000030\n",
      "2020-10-22 02:31:25,637 epoch 2 - iter 9408/11762 - loss 0.42972688 - samples/sec: 10.76 - lr: 0.000030\n",
      "2020-10-22 02:33:14,708 epoch 2 - iter 10584/11762 - loss 0.42994615 - samples/sec: 10.80 - lr: 0.000030\n",
      "2020-10-22 02:35:04,203 epoch 2 - iter 11760/11762 - loss 0.43296759 - samples/sec: 10.76 - lr: 0.000030\n",
      "2020-10-22 02:35:04,418 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 02:35:04,418 EPOCH 2 done: loss 0.4329 - lr 0.0000300\n",
      "2020-10-22 02:36:03,027 DEV : loss 0.9179255962371826 - score 0.8417\n",
      "2020-10-22 02:36:05,017 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 02:36:05,636 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 02:37:54,401 epoch 3 - iter 1176/11762 - loss 0.25005779 - samples/sec: 10.84 - lr: 0.000030\n",
      "2020-10-22 02:39:29,832 epoch 3 - iter 2352/11762 - loss 0.25753153 - samples/sec: 12.35 - lr: 0.000030\n",
      "2020-10-22 02:40:33,270 epoch 3 - iter 3528/11762 - loss 0.25395747 - samples/sec: 18.59 - lr: 0.000030\n",
      "2020-10-22 02:41:35,558 epoch 3 - iter 4704/11762 - loss 0.26265974 - samples/sec: 18.94 - lr: 0.000030\n",
      "2020-10-22 02:42:38,328 epoch 3 - iter 5880/11762 - loss 0.27476414 - samples/sec: 18.79 - lr: 0.000030\n",
      "2020-10-22 02:43:40,634 epoch 3 - iter 7056/11762 - loss 0.27630911 - samples/sec: 18.93 - lr: 0.000030\n",
      "2020-10-22 02:44:43,148 epoch 3 - iter 8232/11762 - loss 0.28116176 - samples/sec: 18.87 - lr: 0.000030\n",
      "2020-10-22 02:45:45,674 epoch 3 - iter 9408/11762 - loss 0.27657752 - samples/sec: 18.87 - lr: 0.000030\n",
      "2020-10-22 02:46:47,042 epoch 3 - iter 10584/11762 - loss 0.28025796 - samples/sec: 19.22 - lr: 0.000030\n",
      "2020-10-22 02:47:47,782 epoch 3 - iter 11760/11762 - loss 0.28705236 - samples/sec: 19.42 - lr: 0.000030\n",
      "2020-10-22 02:47:47,915 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 02:47:47,916 EPOCH 3 done: loss 0.2870 - lr 0.0000300\n",
      "2020-10-22 02:48:18,626 DEV : loss 0.6853742003440857 - score 0.8468\n",
      "2020-10-22 02:48:20,578 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-22 02:48:21,185 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 02:49:21,204 epoch 4 - iter 1176/11762 - loss 0.15762467 - samples/sec: 19.67 - lr: 0.000030\n",
      "2020-10-22 02:50:21,239 epoch 4 - iter 2352/11762 - loss 0.15688688 - samples/sec: 19.64 - lr: 0.000030\n",
      "2020-10-22 02:51:21,329 epoch 4 - iter 3528/11762 - loss 0.16399506 - samples/sec: 19.63 - lr: 0.000030\n",
      "2020-10-22 02:52:22,125 epoch 4 - iter 4704/11762 - loss 0.17187213 - samples/sec: 19.40 - lr: 0.000030\n",
      "2020-10-22 02:53:22,373 epoch 4 - iter 5880/11762 - loss 0.17923837 - samples/sec: 19.61 - lr: 0.000030\n",
      "2020-10-22 02:54:22,738 epoch 4 - iter 7056/11762 - loss 0.18303892 - samples/sec: 19.54 - lr: 0.000030\n",
      "2020-10-22 02:55:23,426 epoch 4 - iter 8232/11762 - loss 0.18772752 - samples/sec: 19.43 - lr: 0.000030\n",
      "2020-10-22 02:56:24,306 epoch 4 - iter 9408/11762 - loss 0.19394891 - samples/sec: 19.37 - lr: 0.000030\n",
      "2020-10-22 02:57:24,340 epoch 4 - iter 10584/11762 - loss 0.19444702 - samples/sec: 19.65 - lr: 0.000030\n",
      "2020-10-22 02:58:24,583 epoch 4 - iter 11760/11762 - loss 0.20391082 - samples/sec: 19.58 - lr: 0.000030\n",
      "2020-10-22 02:58:24,720 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 02:58:24,721 EPOCH 4 done: loss 0.2039 - lr 0.0000300\n",
      "2020-10-22 02:58:55,540 DEV : loss 0.9877879619598389 - score 0.8397\n",
      "2020-10-22 02:58:57,444 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 02:58:57,445 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 02:59:58,088 epoch 5 - iter 1176/11762 - loss 0.11445975 - samples/sec: 19.47 - lr: 0.000030\n",
      "2020-10-22 03:00:58,930 epoch 5 - iter 2352/11762 - loss 0.16060550 - samples/sec: 19.38 - lr: 0.000030\n",
      "2020-10-22 03:01:59,398 epoch 5 - iter 3528/11762 - loss 0.15442908 - samples/sec: 19.51 - lr: 0.000030\n",
      "2020-10-22 03:03:00,004 epoch 5 - iter 4704/11762 - loss 0.15921293 - samples/sec: 19.46 - lr: 0.000030\n",
      "2020-10-22 03:04:00,389 epoch 5 - iter 5880/11762 - loss 0.15654858 - samples/sec: 19.53 - lr: 0.000030\n",
      "2020-10-22 03:05:00,644 epoch 5 - iter 7056/11762 - loss 0.15229694 - samples/sec: 19.57 - lr: 0.000030\n",
      "2020-10-22 03:06:01,129 epoch 5 - iter 8232/11762 - loss 0.15566222 - samples/sec: 19.50 - lr: 0.000030\n",
      "2020-10-22 03:07:01,910 epoch 5 - iter 9408/11762 - loss 0.15885510 - samples/sec: 19.40 - lr: 0.000030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 03:08:01,902 epoch 5 - iter 10584/11762 - loss 0.16065545 - samples/sec: 19.66 - lr: 0.000030\n",
      "2020-10-22 03:09:03,078 epoch 5 - iter 11760/11762 - loss 0.16426696 - samples/sec: 19.28 - lr: 0.000030\n",
      "2020-10-22 03:09:03,214 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 03:09:03,215 EPOCH 5 done: loss 0.1643 - lr 0.0000300\n",
      "2020-10-22 03:09:33,793 DEV : loss 1.2200660705566406 - score 0.8312\n",
      "2020-10-22 03:09:35,671 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 03:09:35,672 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 03:10:37,064 epoch 6 - iter 1176/11762 - loss 0.13672677 - samples/sec: 19.23 - lr: 0.000030\n",
      "2020-10-22 03:11:38,217 epoch 6 - iter 2352/11762 - loss 0.13037400 - samples/sec: 19.29 - lr: 0.000030\n",
      "2020-10-22 03:12:38,929 epoch 6 - iter 3528/11762 - loss 0.12928274 - samples/sec: 19.43 - lr: 0.000030\n",
      "2020-10-22 03:13:39,718 epoch 6 - iter 4704/11762 - loss 0.15582719 - samples/sec: 19.40 - lr: 0.000030\n",
      "2020-10-22 03:14:39,042 epoch 6 - iter 5880/11762 - loss 0.17216468 - samples/sec: 19.88 - lr: 0.000030\n",
      "2020-10-22 03:15:38,817 epoch 6 - iter 7056/11762 - loss 0.18027250 - samples/sec: 19.73 - lr: 0.000030\n",
      "2020-10-22 03:16:39,407 epoch 6 - iter 8232/11762 - loss 0.17688568 - samples/sec: 19.47 - lr: 0.000030\n",
      "2020-10-22 03:17:40,310 epoch 6 - iter 9408/11762 - loss 0.18110700 - samples/sec: 19.36 - lr: 0.000030\n",
      "2020-10-22 03:18:41,013 epoch 6 - iter 10584/11762 - loss 0.17958544 - samples/sec: 19.43 - lr: 0.000030\n",
      "2020-10-22 03:19:41,712 epoch 6 - iter 11760/11762 - loss 0.17637333 - samples/sec: 19.43 - lr: 0.000030\n",
      "2020-10-22 03:19:41,849 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 03:19:41,849 EPOCH 6 done: loss 0.1763 - lr 0.0000300\n",
      "2020-10-22 03:20:12,657 DEV : loss 1.2726454734802246 - score 0.8146\n",
      "2020-10-22 03:20:14,533 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 03:20:14,533 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 03:21:15,621 epoch 7 - iter 1176/11762 - loss 0.13758437 - samples/sec: 19.33 - lr: 0.000030\n",
      "2020-10-22 03:22:14,914 epoch 7 - iter 2352/11762 - loss 0.12801700 - samples/sec: 19.89 - lr: 0.000030\n",
      "2020-10-22 03:23:15,074 epoch 7 - iter 3528/11762 - loss 0.11925135 - samples/sec: 19.60 - lr: 0.000030\n",
      "2020-10-22 03:24:15,786 epoch 7 - iter 4704/11762 - loss 0.14009709 - samples/sec: 19.42 - lr: 0.000030\n",
      "2020-10-22 03:25:16,626 epoch 7 - iter 5880/11762 - loss 0.18802500 - samples/sec: 19.38 - lr: 0.000030\n",
      "2020-10-22 03:26:16,591 epoch 7 - iter 7056/11762 - loss 0.20443505 - samples/sec: 19.67 - lr: 0.000030\n",
      "2020-10-22 03:27:17,896 epoch 7 - iter 8232/11762 - loss 0.23819998 - samples/sec: 19.24 - lr: 0.000030\n",
      "2020-10-22 03:28:19,433 epoch 7 - iter 9408/11762 - loss 0.24391488 - samples/sec: 19.17 - lr: 0.000030\n",
      "2020-10-22 03:29:20,135 epoch 7 - iter 10584/11762 - loss 0.28946603 - samples/sec: 19.43 - lr: 0.000030\n",
      "2020-10-22 03:30:21,762 epoch 7 - iter 11760/11762 - loss 0.31586878 - samples/sec: 19.14 - lr: 0.000030\n",
      "2020-10-22 03:30:21,899 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 03:30:21,900 EPOCH 7 done: loss 0.3158 - lr 0.0000300\n",
      "2020-10-22 03:30:52,334 DEV : loss 1.0422911643981934 - score 0.7366\n",
      "Epoch     7: reducing learning rate of group 0 to 1.5000e-05.\n",
      "2020-10-22 03:30:54,219 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 03:30:54,220 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 03:31:55,845 epoch 8 - iter 1176/11762 - loss 1.02143030 - samples/sec: 19.16 - lr: 0.000015\n",
      "2020-10-22 03:32:59,177 epoch 8 - iter 2352/11762 - loss 1.08186021 - samples/sec: 18.62 - lr: 0.000015\n",
      "2020-10-22 03:34:00,368 epoch 8 - iter 3528/11762 - loss 1.00830081 - samples/sec: 19.27 - lr: 0.000015\n",
      "2020-10-22 03:35:01,385 epoch 8 - iter 4704/11762 - loss 0.88803505 - samples/sec: 19.32 - lr: 0.000015\n",
      "2020-10-22 03:36:03,921 epoch 8 - iter 5880/11762 - loss 0.88008456 - samples/sec: 18.86 - lr: 0.000015\n",
      "2020-10-22 03:37:05,905 epoch 8 - iter 7056/11762 - loss 0.88382258 - samples/sec: 19.02 - lr: 0.000015\n",
      "2020-10-22 03:38:07,899 epoch 8 - iter 8232/11762 - loss 0.83017309 - samples/sec: 19.02 - lr: 0.000015\n",
      "2020-10-22 03:39:08,377 epoch 8 - iter 9408/11762 - loss 0.76665324 - samples/sec: 19.50 - lr: 0.000015\n",
      "2020-10-22 03:40:09,203 epoch 8 - iter 10584/11762 - loss 0.72098053 - samples/sec: 19.39 - lr: 0.000015\n",
      "2020-10-22 03:41:10,206 epoch 8 - iter 11760/11762 - loss 0.69589822 - samples/sec: 19.34 - lr: 0.000015\n",
      "2020-10-22 03:41:10,339 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 03:41:10,339 EPOCH 8 done: loss 0.6961 - lr 0.0000150\n",
      "2020-10-22 03:41:40,999 DEV : loss 1.0451858043670654 - score 0.7977\n",
      "2020-10-22 03:41:42,895 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 03:41:42,896 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 03:42:43,627 epoch 9 - iter 1176/11762 - loss 0.32432029 - samples/sec: 19.44 - lr: 0.000015\n",
      "2020-10-22 03:43:44,623 epoch 9 - iter 2352/11762 - loss 0.34115175 - samples/sec: 19.33 - lr: 0.000015\n",
      "2020-10-22 03:44:45,286 epoch 9 - iter 3528/11762 - loss 0.34530437 - samples/sec: 19.47 - lr: 0.000015\n",
      "2020-10-22 03:45:46,088 epoch 9 - iter 4704/11762 - loss 0.36532210 - samples/sec: 19.39 - lr: 0.000015\n",
      "2020-10-22 03:46:47,687 epoch 9 - iter 5880/11762 - loss 0.37788022 - samples/sec: 19.15 - lr: 0.000015\n",
      "2020-10-22 03:47:49,276 epoch 9 - iter 7056/11762 - loss 0.39652324 - samples/sec: 19.15 - lr: 0.000015\n",
      "2020-10-22 03:48:50,334 epoch 9 - iter 8232/11762 - loss 0.40395984 - samples/sec: 19.32 - lr: 0.000015\n",
      "2020-10-22 03:49:52,090 epoch 9 - iter 9408/11762 - loss 0.42211382 - samples/sec: 19.10 - lr: 0.000015\n",
      "2020-10-22 03:50:52,332 epoch 9 - iter 10584/11762 - loss 0.42369811 - samples/sec: 19.58 - lr: 0.000015\n",
      "2020-10-22 03:51:53,041 epoch 9 - iter 11760/11762 - loss 0.43328549 - samples/sec: 19.44 - lr: 0.000015\n",
      "2020-10-22 03:51:53,171 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 03:51:53,171 EPOCH 9 done: loss 0.4332 - lr 0.0000150\n",
      "2020-10-22 03:52:23,723 DEV : loss 1.0180667638778687 - score 0.7635\n",
      "2020-10-22 03:52:25,605 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 03:52:25,606 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 03:53:26,087 epoch 10 - iter 1176/11762 - loss 0.36189311 - samples/sec: 19.52 - lr: 0.000015\n",
      "2020-10-22 03:54:26,732 epoch 10 - iter 2352/11762 - loss 0.39406682 - samples/sec: 19.45 - lr: 0.000015\n",
      "2020-10-22 03:55:27,664 epoch 10 - iter 3528/11762 - loss 0.48587557 - samples/sec: 19.35 - lr: 0.000015\n",
      "2020-10-22 03:56:27,144 epoch 10 - iter 4704/11762 - loss 0.53885075 - samples/sec: 19.83 - lr: 0.000015\n",
      "2020-10-22 03:57:26,778 epoch 10 - iter 5880/11762 - loss 0.53160068 - samples/sec: 19.78 - lr: 0.000015\n",
      "2020-10-22 03:58:27,674 epoch 10 - iter 7056/11762 - loss 0.52578212 - samples/sec: 19.36 - lr: 0.000015\n",
      "2020-10-22 03:59:28,543 epoch 10 - iter 8232/11762 - loss 0.51794924 - samples/sec: 19.38 - lr: 0.000015\n",
      "2020-10-22 04:00:29,323 epoch 10 - iter 9408/11762 - loss 0.49575008 - samples/sec: 19.40 - lr: 0.000015\n",
      "2020-10-22 04:01:30,774 epoch 10 - iter 10584/11762 - loss 0.51021734 - samples/sec: 19.19 - lr: 0.000015\n",
      "2020-10-22 04:02:32,416 epoch 10 - iter 11760/11762 - loss 0.50723264 - samples/sec: 19.14 - lr: 0.000015\n",
      "2020-10-22 04:02:32,579 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 04:02:32,581 EPOCH 10 done: loss 0.5080 - lr 0.0000150\n",
      "2020-10-22 04:03:03,307 DEV : loss 2.696859836578369 - score 0.5285\n",
      "2020-10-22 04:03:05,181 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 04:03:05,181 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 04:04:05,773 epoch 11 - iter 1176/11762 - loss 0.59006358 - samples/sec: 19.49 - lr: 0.000015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 04:05:06,359 epoch 11 - iter 2352/11762 - loss 0.48739608 - samples/sec: 19.49 - lr: 0.000015\n",
      "2020-10-22 04:06:07,073 epoch 11 - iter 3528/11762 - loss 0.45137204 - samples/sec: 19.42 - lr: 0.000015\n",
      "2020-10-22 04:07:07,693 epoch 11 - iter 4704/11762 - loss 0.43779539 - samples/sec: 19.46 - lr: 0.000015\n",
      "2020-10-22 04:08:08,821 epoch 11 - iter 5880/11762 - loss 0.48126263 - samples/sec: 19.29 - lr: 0.000015\n",
      "2020-10-22 04:09:09,987 epoch 11 - iter 7056/11762 - loss 0.49364693 - samples/sec: 19.28 - lr: 0.000015\n",
      "2020-10-22 04:10:11,475 epoch 11 - iter 8232/11762 - loss 0.52547924 - samples/sec: 19.18 - lr: 0.000015\n",
      "2020-10-22 04:11:12,445 epoch 11 - iter 9408/11762 - loss 0.57372096 - samples/sec: 19.35 - lr: 0.000015\n",
      "2020-10-22 04:12:16,188 epoch 11 - iter 10584/11762 - loss 0.61729554 - samples/sec: 18.50 - lr: 0.000015\n",
      "2020-10-22 04:13:18,869 epoch 11 - iter 11760/11762 - loss 0.65836284 - samples/sec: 18.82 - lr: 0.000015\n",
      "2020-10-22 04:13:19,013 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 04:13:19,014 EPOCH 11 done: loss 0.6583 - lr 0.0000150\n",
      "2020-10-22 04:13:49,581 DEV : loss 1.2079285383224487 - score 0.4017\n",
      "Epoch    11: reducing learning rate of group 0 to 7.5000e-06.\n",
      "2020-10-22 04:13:51,457 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 04:13:51,458 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 04:14:55,130 epoch 12 - iter 1176/11762 - loss 1.15193302 - samples/sec: 18.54 - lr: 0.000008\n",
      "2020-10-22 04:15:58,159 epoch 12 - iter 2352/11762 - loss 1.14083927 - samples/sec: 18.71 - lr: 0.000008\n",
      "2020-10-22 04:16:59,810 epoch 12 - iter 3528/11762 - loss 1.05617711 - samples/sec: 19.12 - lr: 0.000008\n",
      "2020-10-22 04:18:01,545 epoch 12 - iter 4704/11762 - loss 0.97340739 - samples/sec: 19.11 - lr: 0.000008\n",
      "2020-10-22 04:19:03,101 epoch 12 - iter 5880/11762 - loss 0.88217306 - samples/sec: 19.17 - lr: 0.000008\n",
      "2020-10-22 04:20:03,695 epoch 12 - iter 7056/11762 - loss 0.84526825 - samples/sec: 19.46 - lr: 0.000008\n",
      "2020-10-22 04:21:04,496 epoch 12 - iter 8232/11762 - loss 0.79754189 - samples/sec: 19.40 - lr: 0.000008\n",
      "2020-10-22 04:22:05,894 epoch 12 - iter 9408/11762 - loss 0.75859120 - samples/sec: 19.21 - lr: 0.000008\n",
      "2020-10-22 04:23:05,342 epoch 12 - iter 10584/11762 - loss 0.72511374 - samples/sec: 19.84 - lr: 0.000008\n",
      "2020-10-22 04:24:06,438 epoch 12 - iter 11760/11762 - loss 0.71371155 - samples/sec: 19.30 - lr: 0.000008\n",
      "2020-10-22 04:24:06,574 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 04:24:06,575 EPOCH 12 done: loss 0.7136 - lr 0.0000075\n",
      "2020-10-22 04:24:37,415 DEV : loss 1.0325223207473755 - score 0.7891\n",
      "2020-10-22 04:24:39,307 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 04:24:39,308 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 04:25:40,221 epoch 13 - iter 1176/11762 - loss 0.45396768 - samples/sec: 19.38 - lr: 0.000008\n",
      "2020-10-22 04:26:41,116 epoch 13 - iter 2352/11762 - loss 0.38883847 - samples/sec: 19.36 - lr: 0.000008\n",
      "2020-10-22 04:27:42,135 epoch 13 - iter 3528/11762 - loss 0.37035363 - samples/sec: 19.33 - lr: 0.000008\n",
      "2020-10-22 04:28:42,963 epoch 13 - iter 4704/11762 - loss 0.36118961 - samples/sec: 19.39 - lr: 0.000008\n",
      "2020-10-22 04:29:43,943 epoch 13 - iter 5880/11762 - loss 0.34955877 - samples/sec: 19.34 - lr: 0.000008\n",
      "2020-10-22 04:30:42,511 epoch 13 - iter 7056/11762 - loss 0.35482842 - samples/sec: 20.14 - lr: 0.000008\n",
      "2020-10-22 04:31:42,158 epoch 13 - iter 8232/11762 - loss 0.35573669 - samples/sec: 19.78 - lr: 0.000008\n",
      "2020-10-22 04:32:42,998 epoch 13 - iter 9408/11762 - loss 0.35560119 - samples/sec: 19.39 - lr: 0.000008\n",
      "2020-10-22 04:33:44,625 epoch 13 - iter 10584/11762 - loss 0.37461589 - samples/sec: 19.14 - lr: 0.000008\n",
      "2020-10-22 04:34:46,102 epoch 13 - iter 11760/11762 - loss 0.39389711 - samples/sec: 19.18 - lr: 0.000008\n",
      "2020-10-22 04:34:46,239 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 04:34:46,240 EPOCH 13 done: loss 0.3938 - lr 0.0000075\n",
      "2020-10-22 04:35:17,138 DEV : loss 0.9829927086830139 - score 0.7233\n",
      "2020-10-22 04:35:19,060 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 04:35:19,061 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 04:36:19,862 epoch 14 - iter 1176/11762 - loss 0.35136445 - samples/sec: 19.42 - lr: 0.000008\n",
      "2020-10-22 04:37:20,708 epoch 14 - iter 2352/11762 - loss 0.38209727 - samples/sec: 19.39 - lr: 0.000008\n",
      "2020-10-22 04:38:21,864 epoch 14 - iter 3528/11762 - loss 0.36189826 - samples/sec: 19.28 - lr: 0.000008\n",
      "2020-10-22 04:39:22,727 epoch 14 - iter 4704/11762 - loss 0.35179232 - samples/sec: 19.38 - lr: 0.000008\n",
      "2020-10-22 04:40:23,587 epoch 14 - iter 5880/11762 - loss 0.33609433 - samples/sec: 19.38 - lr: 0.000008\n",
      "2020-10-22 04:41:22,948 epoch 14 - iter 7056/11762 - loss 0.33057147 - samples/sec: 19.88 - lr: 0.000008\n",
      "2020-10-22 04:42:23,839 epoch 14 - iter 8232/11762 - loss 0.32016164 - samples/sec: 19.37 - lr: 0.000008\n",
      "2020-10-22 04:43:24,798 epoch 14 - iter 9408/11762 - loss 0.33849022 - samples/sec: 19.35 - lr: 0.000008\n",
      "2020-10-22 04:44:24,443 epoch 14 - iter 10584/11762 - loss 0.34642739 - samples/sec: 19.77 - lr: 0.000008\n",
      "2020-10-22 04:45:24,989 epoch 14 - iter 11760/11762 - loss 0.34315038 - samples/sec: 19.48 - lr: 0.000008\n",
      "2020-10-22 04:45:25,121 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 04:45:25,122 EPOCH 14 done: loss 0.3431 - lr 0.0000075\n",
      "2020-10-22 04:45:55,744 DEV : loss 1.1076633930206299 - score 0.8006\n",
      "2020-10-22 04:45:57,688 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 04:45:57,689 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 04:46:58,099 epoch 15 - iter 1176/11762 - loss 0.31089935 - samples/sec: 19.55 - lr: 0.000008\n",
      "2020-10-22 04:47:59,634 epoch 15 - iter 2352/11762 - loss 0.32740503 - samples/sec: 19.16 - lr: 0.000008\n",
      "2020-10-22 04:49:00,230 epoch 15 - iter 3528/11762 - loss 0.32762469 - samples/sec: 19.46 - lr: 0.000008\n",
      "2020-10-22 04:50:01,241 epoch 15 - iter 4704/11762 - loss 0.30814502 - samples/sec: 19.33 - lr: 0.000008\n",
      "2020-10-22 04:51:01,786 epoch 15 - iter 5880/11762 - loss 0.32384482 - samples/sec: 19.48 - lr: 0.000008\n",
      "2020-10-22 04:52:02,126 epoch 15 - iter 7056/11762 - loss 0.31802418 - samples/sec: 19.55 - lr: 0.000008\n",
      "2020-10-22 04:53:03,714 epoch 15 - iter 8232/11762 - loss 0.31451597 - samples/sec: 19.15 - lr: 0.000008\n",
      "2020-10-22 04:54:04,638 epoch 15 - iter 9408/11762 - loss 0.31623337 - samples/sec: 19.36 - lr: 0.000008\n",
      "2020-10-22 04:55:05,521 epoch 15 - iter 10584/11762 - loss 0.30347722 - samples/sec: 19.37 - lr: 0.000008\n",
      "2020-10-22 04:56:06,066 epoch 15 - iter 11760/11762 - loss 0.30173555 - samples/sec: 19.48 - lr: 0.000008\n",
      "2020-10-22 04:56:06,201 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 04:56:06,202 EPOCH 15 done: loss 0.3017 - lr 0.0000075\n",
      "2020-10-22 04:56:36,919 DEV : loss 1.0377002954483032 - score 0.8105\n",
      "Epoch    15: reducing learning rate of group 0 to 3.7500e-06.\n",
      "2020-10-22 04:56:38,868 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 04:56:38,868 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 04:57:37,953 epoch 16 - iter 1176/11762 - loss 0.23082745 - samples/sec: 19.99 - lr: 0.000004\n",
      "2020-10-22 04:58:37,567 epoch 16 - iter 2352/11762 - loss 0.19740640 - samples/sec: 19.78 - lr: 0.000004\n",
      "2020-10-22 04:59:36,864 epoch 16 - iter 3528/11762 - loss 0.23359370 - samples/sec: 19.89 - lr: 0.000004\n",
      "2020-10-22 05:00:36,741 epoch 16 - iter 4704/11762 - loss 0.21437202 - samples/sec: 19.70 - lr: 0.000004\n",
      "2020-10-22 05:01:36,361 epoch 16 - iter 5880/11762 - loss 0.20462154 - samples/sec: 19.78 - lr: 0.000004\n",
      "2020-10-22 05:02:36,670 epoch 16 - iter 7056/11762 - loss 0.22207791 - samples/sec: 19.56 - lr: 0.000004\n",
      "2020-10-22 05:03:38,098 epoch 16 - iter 8232/11762 - loss 0.23431724 - samples/sec: 19.20 - lr: 0.000004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 05:04:38,705 epoch 16 - iter 9408/11762 - loss 0.24334196 - samples/sec: 19.45 - lr: 0.000004\n",
      "2020-10-22 05:05:37,681 epoch 16 - iter 10584/11762 - loss 0.24516871 - samples/sec: 20.00 - lr: 0.000004\n",
      "2020-10-22 05:06:38,146 epoch 16 - iter 11760/11762 - loss 0.24826148 - samples/sec: 19.51 - lr: 0.000004\n",
      "2020-10-22 05:06:38,285 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 05:06:38,286 EPOCH 16 done: loss 0.2482 - lr 0.0000038\n",
      "2020-10-22 05:07:09,102 DEV : loss 1.1977378129959106 - score 0.7934\n",
      "2020-10-22 05:07:11,084 BAD EPOCHS (no improvement): 1\n",
      "2020-10-22 05:07:11,085 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 05:08:11,359 epoch 17 - iter 1176/11762 - loss 0.13938726 - samples/sec: 19.58 - lr: 0.000004\n",
      "2020-10-22 05:09:12,185 epoch 17 - iter 2352/11762 - loss 0.19535208 - samples/sec: 19.39 - lr: 0.000004\n",
      "2020-10-22 05:10:13,258 epoch 17 - iter 3528/11762 - loss 0.21069472 - samples/sec: 19.31 - lr: 0.000004\n",
      "2020-10-22 05:11:14,477 epoch 17 - iter 4704/11762 - loss 0.21345498 - samples/sec: 19.27 - lr: 0.000004\n",
      "2020-10-22 05:12:15,470 epoch 17 - iter 5880/11762 - loss 0.21113896 - samples/sec: 19.34 - lr: 0.000004\n",
      "2020-10-22 05:13:16,109 epoch 17 - iter 7056/11762 - loss 0.20308715 - samples/sec: 19.46 - lr: 0.000004\n",
      "2020-10-22 05:14:17,212 epoch 17 - iter 8232/11762 - loss 0.20479080 - samples/sec: 19.30 - lr: 0.000004\n",
      "2020-10-22 05:15:18,221 epoch 17 - iter 9408/11762 - loss 0.20054610 - samples/sec: 19.33 - lr: 0.000004\n",
      "2020-10-22 05:16:19,100 epoch 17 - iter 10584/11762 - loss 0.20713009 - samples/sec: 19.37 - lr: 0.000004\n",
      "2020-10-22 05:17:19,820 epoch 17 - iter 11760/11762 - loss 0.20480918 - samples/sec: 19.42 - lr: 0.000004\n",
      "2020-10-22 05:17:19,942 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 05:17:19,943 EPOCH 17 done: loss 0.2048 - lr 0.0000038\n",
      "2020-10-22 05:17:50,635 DEV : loss 1.116486668586731 - score 0.8131\n",
      "2020-10-22 05:17:52,589 BAD EPOCHS (no improvement): 2\n",
      "2020-10-22 05:17:52,590 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 05:18:52,938 epoch 18 - iter 1176/11762 - loss 0.15816194 - samples/sec: 19.57 - lr: 0.000004\n",
      "2020-10-22 05:19:52,782 epoch 18 - iter 2352/11762 - loss 0.17265870 - samples/sec: 19.71 - lr: 0.000004\n",
      "2020-10-22 05:20:52,848 epoch 18 - iter 3528/11762 - loss 0.17754756 - samples/sec: 19.63 - lr: 0.000004\n",
      "2020-10-22 05:21:52,119 epoch 18 - iter 4704/11762 - loss 0.17244840 - samples/sec: 19.90 - lr: 0.000004\n",
      "2020-10-22 05:22:51,545 epoch 18 - iter 5880/11762 - loss 0.16271888 - samples/sec: 19.85 - lr: 0.000004\n",
      "2020-10-22 05:23:51,986 epoch 18 - iter 7056/11762 - loss 0.15593086 - samples/sec: 19.51 - lr: 0.000004\n",
      "2020-10-22 05:24:51,998 epoch 18 - iter 8232/11762 - loss 0.15587948 - samples/sec: 19.65 - lr: 0.000004\n",
      "2020-10-22 05:25:51,863 epoch 18 - iter 9408/11762 - loss 0.15746025 - samples/sec: 19.70 - lr: 0.000004\n",
      "2020-10-22 05:26:51,455 epoch 18 - iter 10584/11762 - loss 0.15597928 - samples/sec: 19.79 - lr: 0.000004\n",
      "2020-10-22 05:27:50,560 epoch 18 - iter 11760/11762 - loss 0.15668673 - samples/sec: 19.95 - lr: 0.000004\n",
      "2020-10-22 05:27:50,687 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 05:27:50,688 EPOCH 18 done: loss 0.1567 - lr 0.0000038\n",
      "2020-10-22 05:28:21,579 DEV : loss 1.378648042678833 - score 0.8018\n",
      "2020-10-22 05:28:23,551 BAD EPOCHS (no improvement): 3\n",
      "2020-10-22 05:28:23,552 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 05:29:22,146 epoch 19 - iter 1176/11762 - loss 0.16726081 - samples/sec: 20.15 - lr: 0.000004\n",
      "2020-10-22 05:30:23,194 epoch 19 - iter 2352/11762 - loss 0.12958541 - samples/sec: 19.32 - lr: 0.000004\n",
      "2020-10-22 05:31:23,749 epoch 19 - iter 3528/11762 - loss 0.13957196 - samples/sec: 19.48 - lr: 0.000004\n",
      "2020-10-22 05:32:23,560 epoch 19 - iter 4704/11762 - loss 0.14467890 - samples/sec: 19.72 - lr: 0.000004\n",
      "2020-10-22 05:33:24,499 epoch 19 - iter 5880/11762 - loss 0.14656845 - samples/sec: 19.36 - lr: 0.000004\n",
      "2020-10-22 05:34:25,276 epoch 19 - iter 7056/11762 - loss 0.14129932 - samples/sec: 19.40 - lr: 0.000004\n",
      "2020-10-22 05:35:22,906 epoch 19 - iter 8232/11762 - loss 0.13669157 - samples/sec: 20.47 - lr: 0.000004\n",
      "2020-10-22 05:36:22,538 epoch 19 - iter 9408/11762 - loss 0.13659218 - samples/sec: 19.78 - lr: 0.000004\n",
      "2020-10-22 05:37:22,981 epoch 19 - iter 10584/11762 - loss 0.13262396 - samples/sec: 19.52 - lr: 0.000004\n",
      "2020-10-22 05:38:23,429 epoch 19 - iter 11760/11762 - loss 0.12915679 - samples/sec: 19.52 - lr: 0.000004\n",
      "2020-10-22 05:38:23,572 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 05:38:23,573 EPOCH 19 done: loss 0.1291 - lr 0.0000038\n",
      "2020-10-22 05:38:54,493 DEV : loss 1.2106409072875977 - score 0.822\n",
      "Epoch    19: reducing learning rate of group 0 to 1.8750e-06.\n",
      "2020-10-22 05:38:56,422 BAD EPOCHS (no improvement): 4\n",
      "2020-10-22 05:38:56,423 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 05:38:56,423 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 05:38:56,424 learning rate too small - quitting training!\n",
      "2020-10-22 05:38:56,424 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 05:38:56,965 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 05:38:56,966 Testing using best model ...\n",
      "2020-10-22 05:38:56,967 loading file classifiers/spooky_authorship_classifier_transformer/best-model.pt\n",
      "2020-10-22 05:39:28,012 \t0.8469\n",
      "2020-10-22 05:39:28,013 \n",
      "Results:\n",
      "- F-score (micro) 0.8469\n",
      "- F-score (macro) 0.847\n",
      "- Accuracy 0.8469\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         EAP     0.8265    0.8674    0.8465      1554\n",
      "         MWS     0.8651    0.8000    0.8313      1210\n",
      "         HPL     0.8581    0.8687    0.8634      1142\n",
      "\n",
      "   micro avg     0.8469    0.8469    0.8469      3906\n",
      "   macro avg     0.8499    0.8454    0.8470      3906\n",
      "weighted avg     0.8477    0.8469    0.8467      3906\n",
      " samples avg     0.8469    0.8469    0.8469      3906\n",
      "\n",
      "2020-10-22 05:39:28,013 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.8469,\n",
       " 'dev_score_history': [0.8251,\n",
       "  0.8417,\n",
       "  0.8468,\n",
       "  0.8397,\n",
       "  0.8312,\n",
       "  0.8146,\n",
       "  0.7366,\n",
       "  0.7977,\n",
       "  0.7635,\n",
       "  0.5285,\n",
       "  0.4017,\n",
       "  0.7891,\n",
       "  0.7233,\n",
       "  0.8006,\n",
       "  0.8105,\n",
       "  0.7934,\n",
       "  0.8131,\n",
       "  0.8018,\n",
       "  0.822],\n",
       " 'train_loss_history': [0.8474903985428051,\n",
       "  0.4328962669024286,\n",
       "  0.2870155546113206,\n",
       "  0.20389938118258502,\n",
       "  0.1642565741552335,\n",
       "  0.17634345009699567,\n",
       "  0.31582380232078633,\n",
       "  0.6961090544328526,\n",
       "  0.43322091353308045,\n",
       "  0.5079981821086628,\n",
       "  0.658336912656301,\n",
       "  0.7135963585032439,\n",
       "  0.39383146148178166,\n",
       "  0.34309273786842465,\n",
       "  0.30168497799569527,\n",
       "  0.24822078653878338,\n",
       "  0.20477457962662532,\n",
       "  0.1566602155592032,\n",
       "  0.12913906098645614],\n",
       " 'dev_loss_history': [0.6951817274093628,\n",
       "  0.9179255962371826,\n",
       "  0.6853742003440857,\n",
       "  0.9877879619598389,\n",
       "  1.2200660705566406,\n",
       "  1.2726454734802246,\n",
       "  1.0422911643981934,\n",
       "  1.0451858043670654,\n",
       "  1.0180667638778687,\n",
       "  2.696859836578369,\n",
       "  1.2079285383224487,\n",
       "  1.0325223207473755,\n",
       "  0.9829927086830139,\n",
       "  1.1076633930206299,\n",
       "  1.0377002954483032,\n",
       "  1.1977378129959106,\n",
       "  1.116486668586731,\n",
       "  1.378648042678833,\n",
       "  1.2106409072875977]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "document_embeddings = TransformerDocumentEmbeddings('bert-base-uncased', fine_tune=True)\n",
    "\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)\n",
    "\n",
    "trainer = ModelTrainer(classifier, corpus, optimizer=Adam)\n",
    "\n",
    "trainer.train('classifiers/spooky_authorship_classifier_transformer',\n",
    "              learning_rate=3e-5, # use very small learning rate\n",
    "              mini_batch_size=1,\n",
    "              mini_batch_chunk_size=4, # optionally set this if transformer is too much for your machine\n",
    "              max_epochs=50, # terminate after 5 epochs\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
