{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import chardet\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from tqdm import tqdm_notebook, tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spooky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id22965</td>\n",
       "      <td>A youth passed in solitude, my best years spen...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>id19322</td>\n",
       "      <td>I knew that you could not say to yourself 'ste...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19574</th>\n",
       "      <td>id17718</td>\n",
       "      <td>I could have fancied, while I looked at it, th...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19575</th>\n",
       "      <td>id08973</td>\n",
       "      <td>The lids clenched themselves together as if in...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19576</th>\n",
       "      <td>id05267</td>\n",
       "      <td>Mais il faut agir that is to say, a Frenchman ...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19577</th>\n",
       "      <td>id17513</td>\n",
       "      <td>For an item of news like this, it strikes us i...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19578</th>\n",
       "      <td>id00393</td>\n",
       "      <td>He laid a gnarled claw on my shoulder, and it ...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11762 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text author\n",
       "2      id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3      id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4      id12958  Finding nothing else, not even gold, the Super...    HPL\n",
       "5      id22965  A youth passed in solitude, my best years spen...    MWS\n",
       "8      id19322  I knew that you could not say to yourself 'ste...    EAP\n",
       "...        ...                                                ...    ...\n",
       "19574  id17718  I could have fancied, while I looked at it, th...    EAP\n",
       "19575  id08973  The lids clenched themselves together as if in...    EAP\n",
       "19576  id05267  Mais il faut agir that is to say, a Frenchman ...    EAP\n",
       "19577  id17513  For an item of news like this, it strikes us i...    EAP\n",
       "19578  id00393  He laid a gnarled claw on my shoulder, and it ...    HPL\n",
       "\n",
       "[11762 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './dataset/Spooky Author Identification/split/'\n",
    "\n",
    "df_train = pd.read_csv(path+'train.csv', delimiter=',', index_col= 0, encoding='utf-8') \n",
    "df_test = pd.read_csv(path+'test.csv', delimiter=',', index_col= 0, encoding='utf-8') \n",
    "df_dev = pd.read_csv(path+'dev.csv', delimiter=',', index_col= 0, encoding='utf-8') \n",
    "df_total = pd.read_csv(path+'total.csv', delimiter=',', index_col= 0, encoding='utf-8') \n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = df_total['id'].values.tolist()\n",
    "text_list = df_total['text'].values.tolist()\n",
    "author_list = df_total['author'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 02:01:51,642 loading file /home/joey/.flair/models/en-pos-ontonotes-v0.5.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-5ef82793719b>:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for text in tqdm_notebook(text_list):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e62d4503164416f9580393d18e74884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19579.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tagger = SequenceTagger.load('pos')\n",
    "flair_pos_sentences = []\n",
    "for text in tqdm_notebook(text_list):\n",
    "    sentence = Sentence(text)    \n",
    "    tagger.predict(sentence)\n",
    "    tagged_sentence = sentence.to_tagged_string()\n",
    "    flair_pos_sentences.append(tagged_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total['flair raw'] = flair_pos_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-39-e686cea8fd54>:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for text in tqdm_notebook(text_list):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c5caebf56d4510b46297f723b4efd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19579.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nltk_pos_sentences = []\n",
    "for text in tqdm_notebook(text_list):\n",
    "    sentence = Sentence(text)\n",
    "    tokens = []\n",
    "    for token in sentence:\n",
    "        tokens.append(token.__dict__['text'])\n",
    "    tagged_sentence = nltk.pos_tag(tokens)\n",
    "    nltk_pos_sentences.append(tagged_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total['nltk raw'] = nltk_pos_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMMDecode:\n",
    "    \n",
    "    def __init__(self, model_path = \"hmmmodel.txt\"):\n",
    "        \n",
    "        self.model_path = model_path\n",
    "        # variables to keep possible tags and words\n",
    "        self.possible_tags = set()\n",
    "        self.possible_words = set()\n",
    "        \n",
    "        # variable to keep possible tags count\n",
    "        self.possible_tags_count = dict()\n",
    "        \n",
    "        # variables to keep the probabilities\n",
    "        self.emission_probabilities = dict()\n",
    "        self.transition_probabilities = dict()\n",
    "\n",
    "        with open(self.model_path) as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                var_array = line.split(\" \")\n",
    "                if var_array[0] == \"em\":\n",
    "                    self.emission_probabilities[var_array[1]] = float(var_array[2].strip())\n",
    "                    word_tag = var_array[1]\n",
    "                    word = word_tag.rsplit(\"/\")[0]\n",
    "                    self.possible_words.add(word)\n",
    "        \n",
    "                elif var_array[0] == \"tr\":\n",
    "                    self.transition_probabilities[var_array[1]] = float(var_array[2].strip())\n",
    "        \n",
    "                elif var_array[0] == \"tg\":\n",
    "                    self.possible_tags.add(var_array[1].strip())\n",
    "                    self.possible_tags_count[var_array[1]] = int(var_array[2].strip())\n",
    "        return\n",
    "        \n",
    "    def smooth_probabilities(self, word, prev_tag, cur_tag):\n",
    "        \n",
    "        if (prev_tag + \"/\" + cur_tag) not in self.transition_probabilities:\n",
    "            tr_prob = 1 / float(len(self.possible_tags) + self.possible_tags_count[prev_tag])\n",
    "        else:\n",
    "            tr_prob = self.transition_probabilities[prev_tag + \"/\" + cur_tag]\n",
    "        \n",
    "        if word not in self.possible_words:\n",
    "            em_prob = 1\n",
    "        elif (word + \"/\" + cur_tag) not in self.emission_probabilities:\n",
    "            em_prob = 0\n",
    "        else:\n",
    "            em_prob = self.emission_probabilities[word + \"/\" + cur_tag]\n",
    "            \n",
    "        return em_prob, tr_prob\n",
    "    \n",
    "    def viterbi_algorithm(self, sentence):\n",
    "        best_edge = dict()\n",
    "        best_score = dict()\n",
    "        words = sentence.split(\" \")\n",
    "        words = [word.strip() for word in words]\n",
    "       \n",
    "        for tag in self.possible_tags:\n",
    "            em_prob, tr_prob = self.smooth_probabilities(words[0], \"<s>\", tag)\n",
    "            best_score[(words[0], tag, 0)] = em_prob * tr_prob\n",
    "            best_edge[(words[0], tag, 0)] = \"<s>\"\n",
    "\n",
    "        for i in range(1, len(words)):\n",
    "            for cur_tag in self.possible_tags:\n",
    "                temp_score = 0\n",
    "                if (words[i] in self.possible_words) and ((words[i] + \"/\" + cur_tag) not in self.emission_probabilities):\n",
    "                    best_score[(words[i], cur_tag, i)] = temp_score\n",
    "                else:\n",
    "                    for prev_tag in self.possible_tags:\n",
    "                        em_prob, tr_prob = self.smooth_probabilities(words[i], prev_tag, cur_tag)\n",
    "                        score = best_score[(words[i-1], prev_tag, i-1)] * em_prob * tr_prob\n",
    "                        best_score[(words[i], cur_tag, i)] = temp_score\n",
    "                        \n",
    "                        if score > temp_score:\n",
    "                            temp_score = score\n",
    "                            best_score[(words[i], cur_tag, i)] = score\n",
    "                            best_edge[(words[i], cur_tag, i)] = prev_tag\n",
    "        score = 0\n",
    "        best_tag = None\n",
    "        tagged_sentence = []\n",
    "        nth_word = words[-1]\n",
    "        words_length = len(words) - 1\n",
    "        for tag in self.possible_tags:\n",
    "            if best_score[(nth_word, tag, words_length)] > score:\n",
    "                score = best_score[(nth_word, tag, words_length)]\n",
    "                best_tag = tag\n",
    "        tagged_sentence.append((nth_word, best_tag))\n",
    "        \n",
    "        for i in range(len(words) - 2, -1, -1):\n",
    "            try:\n",
    "                tagged_sentence.append((words[i], best_edge[(words[i+1], best_tag, i+1)]))\n",
    "                best_tag = best_edge[(words[i+1], best_tag, i+1)]\n",
    "            except:\n",
    "                tagged_sentence.append((words[i], 'UNK'))\n",
    "                best_tag = 'UNK'\n",
    "        return tagged_sentence\n",
    "    \n",
    "    def tag_sentence(self, sentence, file_object):\n",
    "        tagged_sentence = self.viterbi_algorithm(sentence)\n",
    "        tagged_sentence = tagged_sentence[::-1]\n",
    "        \n",
    "        lnth = len(tagged_sentence)\n",
    "        for i, word_tag in enumerate(tagged_sentence):\n",
    "            word = word_tag[0]\n",
    "            tag = word_tag[1]\n",
    "            file_object.write(word + \"/\" + tag)\n",
    "            if i != lnth - 1:\n",
    "                file_object.write(\" \")\n",
    "        \n",
    "        file_object.write(\"\\n\")\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def run(self, infile, outfile):\n",
    "        try:\n",
    "            file_object = open(outfile, \"w\")\n",
    "            with open(infile) as file:\n",
    "                sentences = file.readlines()\n",
    "                for i, sentence in enumerate(sentences):\n",
    "                    self.tag_sentence(sentence, file_object)\n",
    "            \n",
    "            file_object.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "    \n",
    "        return\n",
    "    def predict(self, sentence):\n",
    "        tagged_sentence = self.viterbi_algorithm(sentence)\n",
    "        tagged_sentence = tagged_sentence[::-1]\n",
    "        return tagged_sentence\n",
    "    \n",
    "model_path = './github/HMM-POS-Tagger/hmmmodel.txt'\n",
    "hmm_decode_object = HMMDecode(model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-9a16f3fcf26a>:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for text in tqdm_notebook(text_list):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b5f78b5fc7041269ddb22e0c76c7719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19579.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hmm_pos_sentences = []\n",
    "for text in tqdm_notebook(text_list):\n",
    "    tagged_sentence = hmm_decode_object.predict(text)\n",
    "    hmm_pos_sentences.append(tagged_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total['hmm raw'] = hmm_pos_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>flair POS</th>\n",
       "      <th>nltk POS</th>\n",
       "      <th>hmm POS</th>\n",
       "      <th>flair raw</th>\n",
       "      <th>nltk raw</th>\n",
       "      <th>hmm raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>This &lt;DT&gt; process &lt;NN&gt; , &lt;,&gt; however &lt;RB&gt; , &lt;,...</td>\n",
       "      <td>[(This, DT), (process, NN), (,, ,), (however, ...</td>\n",
       "      <td>[('This', 'DT'), ('process,', 'JJ'), ('however...</td>\n",
       "      <td>This &lt;DT&gt; process &lt;NN&gt; , &lt;,&gt; however &lt;RB&gt; , &lt;,...</td>\n",
       "      <td>[(This, DT), (process, NN), (,, ,), (however, ...</td>\n",
       "      <td>[('This', 'DT'), ('process,', 'JJ'), ('however...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>It &lt;PRP&gt; never &lt;RB&gt; once &lt;RB&gt; occurred &lt;VBD&gt; t...</td>\n",
       "      <td>[(It, PRP), (never, RB), (once, RB), (occurred...</td>\n",
       "      <td>[('It', 'PRP'), ('never', 'RB'), ('once', 'RB'...</td>\n",
       "      <td>It &lt;PRP&gt; never &lt;RB&gt; once &lt;RB&gt; occurred &lt;VBD&gt; t...</td>\n",
       "      <td>[(It, PRP), (never, RB), (once, RB), (occurred...</td>\n",
       "      <td>[('It', 'PRP'), ('never', 'RB'), ('once', 'RB'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>In &lt;IN&gt; his &lt;PRP$&gt; left &lt;JJ&gt; hand &lt;NN&gt; was &lt;VB...</td>\n",
       "      <td>[(In, IN), (his, PRP$), (left, JJ), (hand, NN)...</td>\n",
       "      <td>[('In', 'IN'), ('his', 'PRP$'), ('left', 'JJ')...</td>\n",
       "      <td>In &lt;IN&gt; his &lt;PRP$&gt; left &lt;JJ&gt; hand &lt;NN&gt; was &lt;VB...</td>\n",
       "      <td>[(In, IN), (his, PRP$), (left, JJ), (hand, NN)...</td>\n",
       "      <td>[('In', 'IN'), ('his', 'PRP$'), ('left', 'JJ')...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>How &lt;WRB&gt; lovely &lt;JJ&gt; is &lt;VBZ&gt; spring &lt;NN&gt; As ...</td>\n",
       "      <td>[(How, WRB), (lovely, RB), (is, VBZ), (spring,...</td>\n",
       "      <td>[('How', 'WRB'), ('lovely', 'JJ'), ('is', 'VBZ...</td>\n",
       "      <td>How &lt;WRB&gt; lovely &lt;JJ&gt; is &lt;VBZ&gt; spring &lt;NN&gt; As ...</td>\n",
       "      <td>[(How, WRB), (lovely, RB), (is, VBZ), (spring,...</td>\n",
       "      <td>[('How', 'WRB'), ('lovely', 'JJ'), ('is', 'VBZ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>Finding &lt;VBG&gt; nothing &lt;NN&gt; else &lt;RB&gt; , &lt;,&gt; not...</td>\n",
       "      <td>[(Finding, VBG), (nothing, NN), (else, RB), (,...</td>\n",
       "      <td>[('Finding', 'VBG'), ('nothing', 'NN'), ('else...</td>\n",
       "      <td>Finding &lt;VBG&gt; nothing &lt;NN&gt; else &lt;RB&gt; , &lt;,&gt; not...</td>\n",
       "      <td>[(Finding, VBG), (nothing, NN), (else, RB), (,...</td>\n",
       "      <td>[('Finding', 'VBG'), ('nothing', 'NN'), ('else...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19574</th>\n",
       "      <td>id17718</td>\n",
       "      <td>I could have fancied, while I looked at it, th...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>I &lt;PRP&gt; could &lt;MD&gt; have &lt;VB&gt; fancied &lt;VBN&gt; , &lt;...</td>\n",
       "      <td>[(I, PRP), (could, MD), (have, VB), (fancied, ...</td>\n",
       "      <td>[('I', 'PRP'), ('could', 'MD'), ('have', 'VB')...</td>\n",
       "      <td>I &lt;PRP&gt; could &lt;MD&gt; have &lt;VB&gt; fancied &lt;VBN&gt; , &lt;...</td>\n",
       "      <td>[(I, PRP), (could, MD), (have, VB), (fancied, ...</td>\n",
       "      <td>[('I', 'PRP'), ('could', 'MD'), ('have', 'VB')...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19575</th>\n",
       "      <td>id08973</td>\n",
       "      <td>The lids clenched themselves together as if in...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>The &lt;DT&gt; lids &lt;NNS&gt; clenched &lt;VBD&gt; themselves ...</td>\n",
       "      <td>[(The, DT), (lids, NNS), (clenched, VBD), (the...</td>\n",
       "      <td>[('The', 'DT'), ('lids', 'NN'), ('clenched', '...</td>\n",
       "      <td>The &lt;DT&gt; lids &lt;NNS&gt; clenched &lt;VBD&gt; themselves ...</td>\n",
       "      <td>[(The, DT), (lids, NNS), (clenched, VBD), (the...</td>\n",
       "      <td>[('The', 'DT'), ('lids', 'NN'), ('clenched', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19576</th>\n",
       "      <td>id05267</td>\n",
       "      <td>Mais il faut agir that is to say, a Frenchman ...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>Mais &lt;FW&gt; il &lt;FW&gt; faut &lt;FW&gt; agir &lt;FW&gt; that &lt;DT...</td>\n",
       "      <td>[(Mais, NNP), (il, NN), (faut, NN), (agir, NN)...</td>\n",
       "      <td>[('Mais', 'DT'), ('il', 'NN'), ('faut', '.'), ...</td>\n",
       "      <td>Mais &lt;FW&gt; il &lt;FW&gt; faut &lt;FW&gt; agir &lt;FW&gt; that &lt;DT...</td>\n",
       "      <td>[(Mais, NNP), (il, NN), (faut, NN), (agir, NN)...</td>\n",
       "      <td>[('Mais', 'DT'), ('il', 'NN'), ('faut', '.'), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19577</th>\n",
       "      <td>id17513</td>\n",
       "      <td>For an item of news like this, it strikes us i...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>For &lt;IN&gt; an &lt;DT&gt; item &lt;NN&gt; of &lt;IN&gt; news &lt;NN&gt; l...</td>\n",
       "      <td>[(For, IN), (an, DT), (item, NN), (of, IN), (n...</td>\n",
       "      <td>[('For', 'IN'), ('an', 'DT'), ('item', 'NN'), ...</td>\n",
       "      <td>For &lt;IN&gt; an &lt;DT&gt; item &lt;NN&gt; of &lt;IN&gt; news &lt;NN&gt; l...</td>\n",
       "      <td>[(For, IN), (an, DT), (item, NN), (of, IN), (n...</td>\n",
       "      <td>[('For', 'IN'), ('an', 'DT'), ('item', 'NN'), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19578</th>\n",
       "      <td>id00393</td>\n",
       "      <td>He laid a gnarled claw on my shoulder, and it ...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>He &lt;PRP&gt; laid &lt;VBD&gt; a &lt;DT&gt; gnarled &lt;JJ&gt; claw &lt;...</td>\n",
       "      <td>[(He, PRP), (laid, VBD), (a, DT), (gnarled, JJ...</td>\n",
       "      <td>[('He', 'PRP'), ('laid', 'VBD'), ('a', 'DT'), ...</td>\n",
       "      <td>He &lt;PRP&gt; laid &lt;VBD&gt; a &lt;DT&gt; gnarled &lt;JJ&gt; claw &lt;...</td>\n",
       "      <td>[(He, PRP), (laid, VBD), (a, DT), (gnarled, JJ...</td>\n",
       "      <td>[('He', 'PRP'), ('laid', 'VBD'), ('a', 'DT'), ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19579 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text author  \\\n",
       "0      id26305  This process, however, afforded me no means of...    EAP   \n",
       "1      id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "2      id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "3      id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "4      id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "...        ...                                                ...    ...   \n",
       "19574  id17718  I could have fancied, while I looked at it, th...    EAP   \n",
       "19575  id08973  The lids clenched themselves together as if in...    EAP   \n",
       "19576  id05267  Mais il faut agir that is to say, a Frenchman ...    EAP   \n",
       "19577  id17513  For an item of news like this, it strikes us i...    EAP   \n",
       "19578  id00393  He laid a gnarled claw on my shoulder, and it ...    HPL   \n",
       "\n",
       "                                               flair POS  \\\n",
       "0      This <DT> process <NN> , <,> however <RB> , <,...   \n",
       "1      It <PRP> never <RB> once <RB> occurred <VBD> t...   \n",
       "2      In <IN> his <PRP$> left <JJ> hand <NN> was <VB...   \n",
       "3      How <WRB> lovely <JJ> is <VBZ> spring <NN> As ...   \n",
       "4      Finding <VBG> nothing <NN> else <RB> , <,> not...   \n",
       "...                                                  ...   \n",
       "19574  I <PRP> could <MD> have <VB> fancied <VBN> , <...   \n",
       "19575  The <DT> lids <NNS> clenched <VBD> themselves ...   \n",
       "19576  Mais <FW> il <FW> faut <FW> agir <FW> that <DT...   \n",
       "19577  For <IN> an <DT> item <NN> of <IN> news <NN> l...   \n",
       "19578  He <PRP> laid <VBD> a <DT> gnarled <JJ> claw <...   \n",
       "\n",
       "                                                nltk POS  \\\n",
       "0      [(This, DT), (process, NN), (,, ,), (however, ...   \n",
       "1      [(It, PRP), (never, RB), (once, RB), (occurred...   \n",
       "2      [(In, IN), (his, PRP$), (left, JJ), (hand, NN)...   \n",
       "3      [(How, WRB), (lovely, RB), (is, VBZ), (spring,...   \n",
       "4      [(Finding, VBG), (nothing, NN), (else, RB), (,...   \n",
       "...                                                  ...   \n",
       "19574  [(I, PRP), (could, MD), (have, VB), (fancied, ...   \n",
       "19575  [(The, DT), (lids, NNS), (clenched, VBD), (the...   \n",
       "19576  [(Mais, NNP), (il, NN), (faut, NN), (agir, NN)...   \n",
       "19577  [(For, IN), (an, DT), (item, NN), (of, IN), (n...   \n",
       "19578  [(He, PRP), (laid, VBD), (a, DT), (gnarled, JJ...   \n",
       "\n",
       "                                                 hmm POS  \\\n",
       "0      [('This', 'DT'), ('process,', 'JJ'), ('however...   \n",
       "1      [('It', 'PRP'), ('never', 'RB'), ('once', 'RB'...   \n",
       "2      [('In', 'IN'), ('his', 'PRP$'), ('left', 'JJ')...   \n",
       "3      [('How', 'WRB'), ('lovely', 'JJ'), ('is', 'VBZ...   \n",
       "4      [('Finding', 'VBG'), ('nothing', 'NN'), ('else...   \n",
       "...                                                  ...   \n",
       "19574  [('I', 'PRP'), ('could', 'MD'), ('have', 'VB')...   \n",
       "19575  [('The', 'DT'), ('lids', 'NN'), ('clenched', '...   \n",
       "19576  [('Mais', 'DT'), ('il', 'NN'), ('faut', '.'), ...   \n",
       "19577  [('For', 'IN'), ('an', 'DT'), ('item', 'NN'), ...   \n",
       "19578  [('He', 'PRP'), ('laid', 'VBD'), ('a', 'DT'), ...   \n",
       "\n",
       "                                               flair raw  \\\n",
       "0      This <DT> process <NN> , <,> however <RB> , <,...   \n",
       "1      It <PRP> never <RB> once <RB> occurred <VBD> t...   \n",
       "2      In <IN> his <PRP$> left <JJ> hand <NN> was <VB...   \n",
       "3      How <WRB> lovely <JJ> is <VBZ> spring <NN> As ...   \n",
       "4      Finding <VBG> nothing <NN> else <RB> , <,> not...   \n",
       "...                                                  ...   \n",
       "19574  I <PRP> could <MD> have <VB> fancied <VBN> , <...   \n",
       "19575  The <DT> lids <NNS> clenched <VBD> themselves ...   \n",
       "19576  Mais <FW> il <FW> faut <FW> agir <FW> that <DT...   \n",
       "19577  For <IN> an <DT> item <NN> of <IN> news <NN> l...   \n",
       "19578  He <PRP> laid <VBD> a <DT> gnarled <JJ> claw <...   \n",
       "\n",
       "                                                nltk raw  \\\n",
       "0      [(This, DT), (process, NN), (,, ,), (however, ...   \n",
       "1      [(It, PRP), (never, RB), (once, RB), (occurred...   \n",
       "2      [(In, IN), (his, PRP$), (left, JJ), (hand, NN)...   \n",
       "3      [(How, WRB), (lovely, RB), (is, VBZ), (spring,...   \n",
       "4      [(Finding, VBG), (nothing, NN), (else, RB), (,...   \n",
       "...                                                  ...   \n",
       "19574  [(I, PRP), (could, MD), (have, VB), (fancied, ...   \n",
       "19575  [(The, DT), (lids, NNS), (clenched, VBD), (the...   \n",
       "19576  [(Mais, NNP), (il, NN), (faut, NN), (agir, NN)...   \n",
       "19577  [(For, IN), (an, DT), (item, NN), (of, IN), (n...   \n",
       "19578  [(He, PRP), (laid, VBD), (a, DT), (gnarled, JJ...   \n",
       "\n",
       "                                                 hmm raw  \n",
       "0      [('This', 'DT'), ('process,', 'JJ'), ('however...  \n",
       "1      [('It', 'PRP'), ('never', 'RB'), ('once', 'RB'...  \n",
       "2      [('In', 'IN'), ('his', 'PRP$'), ('left', 'JJ')...  \n",
       "3      [('How', 'WRB'), ('lovely', 'JJ'), ('is', 'VBZ...  \n",
       "4      [('Finding', 'VBG'), ('nothing', 'NN'), ('else...  \n",
       "...                                                  ...  \n",
       "19574  [('I', 'PRP'), ('could', 'MD'), ('have', 'VB')...  \n",
       "19575  [('The', 'DT'), ('lids', 'NN'), ('clenched', '...  \n",
       "19576  [('Mais', 'DT'), ('il', 'NN'), ('faut', '.'), ...  \n",
       "19577  [('For', 'IN'), ('an', 'DT'), ('item', 'NN'), ...  \n",
       "19578  [('He', 'PRP'), ('laid', 'VBD'), ('a', 'DT'), ...  \n",
       "\n",
       "[19579 rows x 9 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flair_raw = df_total['flair raw'].values.tolist()\n",
    "nltk_raw = df_total['nltk raw'].values.tolist()\n",
    "hmm_raw = df_total['hmm raw'].values.tolist()\n",
    "df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "re_tag = re.compile(r'\\<(.*?)\\>')\n",
    "flair_POS = []\n",
    "for string in flair_raw:\n",
    "    tags = re_tag.findall(string)\n",
    "    flair_POS.append(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_POS = []\n",
    "for lst in nltk_raw:\n",
    "    temp_lst = []\n",
    "    for tup in lst:\n",
    "        temp_lst.append(tup[1])\n",
    "    nltk_POS.append(temp_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_POS = []\n",
    "for lst in hmm_raw:\n",
    "    temp_lst = []\n",
    "    for tup in lst:\n",
    "        temp_lst.append(tup[1])\n",
    "    hmm_POS.append(temp_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total['flair POS'] = flair_POS\n",
    "df_total['nltk POS'] = nltk_POS\n",
    "df_total['hmm POS'] = hmm_POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>flair POS</th>\n",
       "      <th>nltk POS</th>\n",
       "      <th>hmm POS</th>\n",
       "      <th>flair raw</th>\n",
       "      <th>nltk raw</th>\n",
       "      <th>hmm raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[DT, NN, ,, RB, ,, VBD, PRP, DT, NN, IN, VBG, ...</td>\n",
       "      <td>[DT, NN, ,, RB, ,, VBD, PRP, DT, NNS, IN, VBG,...</td>\n",
       "      <td>[DT, JJ, NN, IN, PRP, DT, NNS, IN, IN, DT, NN,...</td>\n",
       "      <td>This &lt;DT&gt; process &lt;NN&gt; , &lt;,&gt; however &lt;RB&gt; , &lt;,...</td>\n",
       "      <td>[(This, DT), (process, NN), (,, ,), (however, ...</td>\n",
       "      <td>[('This', 'DT'), ('process,', 'JJ'), ('however...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[PRP, RB, RB, VBD, IN, PRP, IN, DT, NN, MD, VB...</td>\n",
       "      <td>[PRP, RB, RB, VBD, TO, PRP, IN, DT, NN, MD, VB...</td>\n",
       "      <td>[PRP, RB, RB, VBN, IN, PRP, IN, DT, NN, MD, VB...</td>\n",
       "      <td>It &lt;PRP&gt; never &lt;RB&gt; once &lt;RB&gt; occurred &lt;VBD&gt; t...</td>\n",
       "      <td>[(It, PRP), (never, RB), (once, RB), (occurred...</td>\n",
       "      <td>[('It', 'PRP'), ('never', 'RB'), ('once', 'RB'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[IN, PRP$, JJ, NN, VBD, DT, JJ, NN, NN, ,, IN,...</td>\n",
       "      <td>[IN, PRP$, JJ, NN, VBD, DT, JJ, NN, NN, ,, IN,...</td>\n",
       "      <td>[IN, PRP$, JJ, NN, VBD, DT, NN, ., '', IN, NN,...</td>\n",
       "      <td>In &lt;IN&gt; his &lt;PRP$&gt; left &lt;JJ&gt; hand &lt;NN&gt; was &lt;VB...</td>\n",
       "      <td>[(In, IN), (his, PRP$), (left, JJ), (hand, NN)...</td>\n",
       "      <td>[('In', 'IN'), ('his', 'PRP$'), ('left', 'JJ')...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>[WRB, JJ, VBZ, NN, IN, PRP, VBD, IN, NNP, NNP,...</td>\n",
       "      <td>[WRB, RB, VBZ, JJ, IN, PRP, VBD, IN, NNP, NNP,...</td>\n",
       "      <td>[WRB, JJ, VBZ, NN, IN, PRP, VBD, IN, NNP, NNP,...</td>\n",
       "      <td>How &lt;WRB&gt; lovely &lt;JJ&gt; is &lt;VBZ&gt; spring &lt;NN&gt; As ...</td>\n",
       "      <td>[(How, WRB), (lovely, RB), (is, VBZ), (spring,...</td>\n",
       "      <td>[('How', 'WRB'), ('lovely', 'JJ'), ('is', 'VBZ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[VBG, NN, RB, ,, RB, RB, NN, ,, DT, NNP, VBD, ...</td>\n",
       "      <td>[VBG, NN, RB, ,, RB, RB, NN, ,, DT, NNP, VBD, ...</td>\n",
       "      <td>[VBG, NN, VBZ, RB, RB, IN, DT, NN, VBD, PRP$, ...</td>\n",
       "      <td>Finding &lt;VBG&gt; nothing &lt;NN&gt; else &lt;RB&gt; , &lt;,&gt; not...</td>\n",
       "      <td>[(Finding, VBG), (nothing, NN), (else, RB), (,...</td>\n",
       "      <td>[('Finding', 'VBG'), ('nothing', 'NN'), ('else...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19574</th>\n",
       "      <td>id17718</td>\n",
       "      <td>I could have fancied, while I looked at it, th...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[PRP, MD, VB, VBN, ,, IN, PRP, VBD, IN, PRP, ,...</td>\n",
       "      <td>[PRP, MD, VB, VBN, ,, IN, PRP, VBD, IN, PRP, ,...</td>\n",
       "      <td>[PRP, MD, VB, VBN, IN, PRP, VBD, IN, NN, IN, D...</td>\n",
       "      <td>I &lt;PRP&gt; could &lt;MD&gt; have &lt;VB&gt; fancied &lt;VBN&gt; , &lt;...</td>\n",
       "      <td>[(I, PRP), (could, MD), (have, VB), (fancied, ...</td>\n",
       "      <td>[('I', 'PRP'), ('could', 'MD'), ('have', 'VB')...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19575</th>\n",
       "      <td>id08973</td>\n",
       "      <td>The lids clenched themselves together as if in...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[DT, NNS, VBD, PRP, RB, IN, IN, IN, DT, NN, .]</td>\n",
       "      <td>[DT, NNS, VBD, PRP, RB, IN, IN, IN, DT, NN, .]</td>\n",
       "      <td>[DT, NN, IN, PRP, RB, RB, IN, IN, DT, NN]</td>\n",
       "      <td>The &lt;DT&gt; lids &lt;NNS&gt; clenched &lt;VBD&gt; themselves ...</td>\n",
       "      <td>[(The, DT), (lids, NNS), (clenched, VBD), (the...</td>\n",
       "      <td>[('The', 'DT'), ('lids', 'NN'), ('clenched', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19576</th>\n",
       "      <td>id05267</td>\n",
       "      <td>Mais il faut agir that is to say, a Frenchman ...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[FW, FW, FW, FW, DT, VBZ, TO, VB, ,, DT, NNP, ...</td>\n",
       "      <td>[NNP, NN, NN, NN, WDT, VBZ, TO, VB, ,, DT, NNP...</td>\n",
       "      <td>[DT, NN, ., '', WDT, VBZ, TO, VB, DT, NN, RB, ...</td>\n",
       "      <td>Mais &lt;FW&gt; il &lt;FW&gt; faut &lt;FW&gt; agir &lt;FW&gt; that &lt;DT...</td>\n",
       "      <td>[(Mais, NNP), (il, NN), (faut, NN), (agir, NN)...</td>\n",
       "      <td>[('Mais', 'DT'), ('il', 'NN'), ('faut', '.'), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19577</th>\n",
       "      <td>id17513</td>\n",
       "      <td>For an item of news like this, it strikes us i...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[IN, DT, NN, IN, NN, IN, DT, ,, PRP, VBZ, PRP,...</td>\n",
       "      <td>[IN, DT, NN, IN, NN, IN, DT, ,, PRP, VBZ, PRP,...</td>\n",
       "      <td>[IN, DT, NN, IN, NN, IN, IN, PRP, VBP, PRP, PR...</td>\n",
       "      <td>For &lt;IN&gt; an &lt;DT&gt; item &lt;NN&gt; of &lt;IN&gt; news &lt;NN&gt; l...</td>\n",
       "      <td>[(For, IN), (an, DT), (item, NN), (of, IN), (n...</td>\n",
       "      <td>[('For', 'IN'), ('an', 'DT'), ('item', 'NN'), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19578</th>\n",
       "      <td>id00393</td>\n",
       "      <td>He laid a gnarled claw on my shoulder, and it ...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[PRP, VBD, DT, JJ, NN, IN, PRP$, NN, ,, CC, PR...</td>\n",
       "      <td>[PRP, VBD, DT, JJ, NN, IN, PRP$, NN, ,, CC, PR...</td>\n",
       "      <td>[PRP, VBD, DT, JJ, NN, IN, PRP$, NN, CC, PRP, ...</td>\n",
       "      <td>He &lt;PRP&gt; laid &lt;VBD&gt; a &lt;DT&gt; gnarled &lt;JJ&gt; claw &lt;...</td>\n",
       "      <td>[(He, PRP), (laid, VBD), (a, DT), (gnarled, JJ...</td>\n",
       "      <td>[('He', 'PRP'), ('laid', 'VBD'), ('a', 'DT'), ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19579 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text author  \\\n",
       "0      id26305  This process, however, afforded me no means of...    EAP   \n",
       "1      id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "2      id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "3      id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "4      id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "...        ...                                                ...    ...   \n",
       "19574  id17718  I could have fancied, while I looked at it, th...    EAP   \n",
       "19575  id08973  The lids clenched themselves together as if in...    EAP   \n",
       "19576  id05267  Mais il faut agir that is to say, a Frenchman ...    EAP   \n",
       "19577  id17513  For an item of news like this, it strikes us i...    EAP   \n",
       "19578  id00393  He laid a gnarled claw on my shoulder, and it ...    HPL   \n",
       "\n",
       "                                               flair POS  \\\n",
       "0      [DT, NN, ,, RB, ,, VBD, PRP, DT, NN, IN, VBG, ...   \n",
       "1      [PRP, RB, RB, VBD, IN, PRP, IN, DT, NN, MD, VB...   \n",
       "2      [IN, PRP$, JJ, NN, VBD, DT, JJ, NN, NN, ,, IN,...   \n",
       "3      [WRB, JJ, VBZ, NN, IN, PRP, VBD, IN, NNP, NNP,...   \n",
       "4      [VBG, NN, RB, ,, RB, RB, NN, ,, DT, NNP, VBD, ...   \n",
       "...                                                  ...   \n",
       "19574  [PRP, MD, VB, VBN, ,, IN, PRP, VBD, IN, PRP, ,...   \n",
       "19575     [DT, NNS, VBD, PRP, RB, IN, IN, IN, DT, NN, .]   \n",
       "19576  [FW, FW, FW, FW, DT, VBZ, TO, VB, ,, DT, NNP, ...   \n",
       "19577  [IN, DT, NN, IN, NN, IN, DT, ,, PRP, VBZ, PRP,...   \n",
       "19578  [PRP, VBD, DT, JJ, NN, IN, PRP$, NN, ,, CC, PR...   \n",
       "\n",
       "                                                nltk POS  \\\n",
       "0      [DT, NN, ,, RB, ,, VBD, PRP, DT, NNS, IN, VBG,...   \n",
       "1      [PRP, RB, RB, VBD, TO, PRP, IN, DT, NN, MD, VB...   \n",
       "2      [IN, PRP$, JJ, NN, VBD, DT, JJ, NN, NN, ,, IN,...   \n",
       "3      [WRB, RB, VBZ, JJ, IN, PRP, VBD, IN, NNP, NNP,...   \n",
       "4      [VBG, NN, RB, ,, RB, RB, NN, ,, DT, NNP, VBD, ...   \n",
       "...                                                  ...   \n",
       "19574  [PRP, MD, VB, VBN, ,, IN, PRP, VBD, IN, PRP, ,...   \n",
       "19575     [DT, NNS, VBD, PRP, RB, IN, IN, IN, DT, NN, .]   \n",
       "19576  [NNP, NN, NN, NN, WDT, VBZ, TO, VB, ,, DT, NNP...   \n",
       "19577  [IN, DT, NN, IN, NN, IN, DT, ,, PRP, VBZ, PRP,...   \n",
       "19578  [PRP, VBD, DT, JJ, NN, IN, PRP$, NN, ,, CC, PR...   \n",
       "\n",
       "                                                 hmm POS  \\\n",
       "0      [DT, JJ, NN, IN, PRP, DT, NNS, IN, IN, DT, NN,...   \n",
       "1      [PRP, RB, RB, VBN, IN, PRP, IN, DT, NN, MD, VB...   \n",
       "2      [IN, PRP$, JJ, NN, VBD, DT, NN, ., '', IN, NN,...   \n",
       "3      [WRB, JJ, VBZ, NN, IN, PRP, VBD, IN, NNP, NNP,...   \n",
       "4      [VBG, NN, VBZ, RB, RB, IN, DT, NN, VBD, PRP$, ...   \n",
       "...                                                  ...   \n",
       "19574  [PRP, MD, VB, VBN, IN, PRP, VBD, IN, NN, IN, D...   \n",
       "19575          [DT, NN, IN, PRP, RB, RB, IN, IN, DT, NN]   \n",
       "19576  [DT, NN, ., '', WDT, VBZ, TO, VB, DT, NN, RB, ...   \n",
       "19577  [IN, DT, NN, IN, NN, IN, IN, PRP, VBP, PRP, PR...   \n",
       "19578  [PRP, VBD, DT, JJ, NN, IN, PRP$, NN, CC, PRP, ...   \n",
       "\n",
       "                                               flair raw  \\\n",
       "0      This <DT> process <NN> , <,> however <RB> , <,...   \n",
       "1      It <PRP> never <RB> once <RB> occurred <VBD> t...   \n",
       "2      In <IN> his <PRP$> left <JJ> hand <NN> was <VB...   \n",
       "3      How <WRB> lovely <JJ> is <VBZ> spring <NN> As ...   \n",
       "4      Finding <VBG> nothing <NN> else <RB> , <,> not...   \n",
       "...                                                  ...   \n",
       "19574  I <PRP> could <MD> have <VB> fancied <VBN> , <...   \n",
       "19575  The <DT> lids <NNS> clenched <VBD> themselves ...   \n",
       "19576  Mais <FW> il <FW> faut <FW> agir <FW> that <DT...   \n",
       "19577  For <IN> an <DT> item <NN> of <IN> news <NN> l...   \n",
       "19578  He <PRP> laid <VBD> a <DT> gnarled <JJ> claw <...   \n",
       "\n",
       "                                                nltk raw  \\\n",
       "0      [(This, DT), (process, NN), (,, ,), (however, ...   \n",
       "1      [(It, PRP), (never, RB), (once, RB), (occurred...   \n",
       "2      [(In, IN), (his, PRP$), (left, JJ), (hand, NN)...   \n",
       "3      [(How, WRB), (lovely, RB), (is, VBZ), (spring,...   \n",
       "4      [(Finding, VBG), (nothing, NN), (else, RB), (,...   \n",
       "...                                                  ...   \n",
       "19574  [(I, PRP), (could, MD), (have, VB), (fancied, ...   \n",
       "19575  [(The, DT), (lids, NNS), (clenched, VBD), (the...   \n",
       "19576  [(Mais, NNP), (il, NN), (faut, NN), (agir, NN)...   \n",
       "19577  [(For, IN), (an, DT), (item, NN), (of, IN), (n...   \n",
       "19578  [(He, PRP), (laid, VBD), (a, DT), (gnarled, JJ...   \n",
       "\n",
       "                                                 hmm raw  \n",
       "0      [('This', 'DT'), ('process,', 'JJ'), ('however...  \n",
       "1      [('It', 'PRP'), ('never', 'RB'), ('once', 'RB'...  \n",
       "2      [('In', 'IN'), ('his', 'PRP$'), ('left', 'JJ')...  \n",
       "3      [('How', 'WRB'), ('lovely', 'JJ'), ('is', 'VBZ...  \n",
       "4      [('Finding', 'VBG'), ('nothing', 'NN'), ('else...  \n",
       "...                                                  ...  \n",
       "19574  [('I', 'PRP'), ('could', 'MD'), ('have', 'VB')...  \n",
       "19575  [('The', 'DT'), ('lids', 'NN'), ('clenched', '...  \n",
       "19576  [('Mais', 'DT'), ('il', 'NN'), ('faut', '.'), ...  \n",
       "19577  [('For', 'IN'), ('an', 'DT'), ('item', 'NN'), ...  \n",
       "19578  [('He', 'PRP'), ('laid', 'VBD'), ('a', 'DT'), ...  \n",
       "\n",
       "[19579 rows x 9 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.to_csv(path+'total_with_pos.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Victorian Era Authorship Attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './dataset/Victorian Era Authorship Attribution/split/'\n",
    "\n",
    "df_train = pd.read_csv(path+'train.csv', delimiter=',', index_col= 0, encoding='utf-8') \n",
    "df_test = pd.read_csv(path+'test.csv', delimiter=',', index_col= 0, encoding='utf-8') \n",
    "df_dev = pd.read_csv(path+'dev.csv', delimiter=',', index_col= 0, encoding='utf-8') \n",
    "df_total = pd.read_csv(path+'total.csv', delimiter=',', index_col= 0, encoding='utf-8') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_list = df_total[''].values.tolist()\n",
    "text_list = df_total['text'].values.tolist()\n",
    "author_list = df_total['author'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 10:15:31,994 loading file /home/joey/.flair/models/en-pos-ontonotes-v0.5.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-5ef82793719b>:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for text in tqdm_notebook(text_list):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a43e97d688f44a08b6145dcbfb130ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=53678.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-5ef82793719b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtagged_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tagged_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mflair_pos_sentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtagged_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, sentences, mini_batch_size, all_tag_prob, verbose, label_name, return_loss, embedding_storage_mode)\u001b[0m\n\u001b[1;32m    367\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m                 \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mreturn_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/flair/embeddings/token.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, sentences, static_embeddings)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/flair/embeddings/base.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0meverything_embedded\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_embeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_embeddings_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/flair/embeddings/token.py\u001b[0m in \u001b[0;36m_add_embeddings_internal\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;31m# get hidden states from language model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m             all_hidden_states_in_lm = self.lm.get_representation(\n\u001b[0m\u001b[1;32m    610\u001b[0m                 \u001b[0mtext_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_marker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_marker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchars_per_chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/flair/models/language_model.py\u001b[0m in \u001b[0;36mget_representation\u001b[0;34m(self, strings, start_marker, end_marker, chars_per_chunk)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0moutput_parts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/flair/models/language_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, ordered_sequence_lengths)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    577\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    578\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tagger = SequenceTagger.load('pos')\n",
    "flair_pos_sentences = []\n",
    "for text in tqdm_notebook(text_list):\n",
    "    sentence = Sentence(text)    \n",
    "    tagger.predict(sentence)\n",
    "    tagged_sentence = sentence.to_tagged_string()\n",
    "    flair_pos_sentences.append(tagged_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total['flair POS'] = flair_pos_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_pos_sentences = []\n",
    "for text in tqdm_notebook(text_list):\n",
    "    sentence = Sentence(text)\n",
    "    tokens = []\n",
    "    for token in sentence:\n",
    "        tokens.append(token.__dict__['text'])\n",
    "    tagged_sentence = nltk.pos_tag(tokens)\n",
    "    nltk_pos_sentences.append(tagged_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total['nltk POS'] = nltk_pos_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './github/HMM-POS-Tagger/hmmmodel.txt'\n",
    "hmm_decode_object = HMMDecode(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_pos_sentences = []\n",
    "for text in tqdm_notebook(text_list):\n",
    "    tagged_sentence = hmm_decode_object.predict(text)\n",
    "    hmm_pos_sentences.append(tagged_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total['hmm POS'] = hmm_pos_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.to_csv(path+'total_with_pos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = './dataset/Spooky Author Identification/split/'\n",
    "\n",
    "# df_train = pd.read_csv(path+'train.csv', delimiter=',', index_col= 0, encoding='utf-8') \n",
    "# df_test = pd.read_csv(path+'test.csv', delimiter=',', index_col= 0, encoding='utf-8') \n",
    "# df_dev = pd.read_csv(path+'dev.csv', delimiter=',', index_col= 0, encoding='utf-8') \n",
    "# df_total = pd.read_csv(path+'total.csv', delimiter=',', index_col= 0, encoding='utf-8') \n",
    "\n",
    "# df_train\n",
    "\n",
    "# id_list = df_total['id'].values.tolist()\n",
    "# text_list = df_total['text'].values.tolist()\n",
    "# author_list = df_total['author'].values.tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for text in text_list:\n",
    "#     sentence = Sentence(text_list[9])    \n",
    "#     tagger.predict(sentence)\n",
    "#     tagged_sentence = sentence.to_tagged_string()\n",
    "    \n",
    "#     break\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
