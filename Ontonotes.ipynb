{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flair\n",
    "import torch\n",
    "from flair.data import Corpus\n",
    "from flair.datasets import ColumnCorpus\n",
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, FlairEmbeddings\n",
    "from typing import List\n",
    "from flair.models import SequenceTagger\n",
    "from flair.trainers import ModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-02 23:56:21,875 Reading data from dataset/Ontonotes-conll-formatted\n",
      "2020-11-02 23:56:21,876 Train: dataset/Ontonotes-conll-formatted/train.english.v4_gold_conll\n",
      "2020-11-02 23:56:21,876 Dev: dataset/Ontonotes-conll-formatted/dev.english.v4_gold_conll\n",
      "2020-11-02 23:56:21,876 Test: dataset/Ontonotes-conll-formatted/test.english.v4_gold_conll\n"
     ]
    }
   ],
   "source": [
    "# 1. get the corpus\n",
    "corpus: Corpus = flair.datasets.ColumnCorpus('dataset/Ontonotes-conll-formatted/',\n",
    "                                             column_format={0: 'text', 1: 'pos', 2: 'upos'},)\n",
    "\n",
    "# 2. what tag do we want to predict?\n",
    "tag_type = 'pos'\n",
    "\n",
    "# 3. make the tag dictionary from the corpus\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "\n",
    "# initialize embeddings\n",
    "embedding_types: List[TokenEmbeddings] = [\n",
    "    WordEmbeddings('crawl'),\n",
    "    FlairEmbeddings('news-forward'),\n",
    "    FlairEmbeddings('news-backward'),\n",
    "]\n",
    "\n",
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-30 23:03:50,204 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-30 23:03:50,205 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings('crawl')\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.05, inplace=False)\n",
      "        (encoder): Embedding(300, 100)\n",
      "        (rnn): LSTM(100, 2048)\n",
      "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (list_embedding_2): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.05, inplace=False)\n",
      "        (encoder): Embedding(300, 100)\n",
      "        (rnn): LSTM(100, 2048)\n",
      "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=4396, out_features=4396, bias=True)\n",
      "  (rnn): LSTM(4396, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=28, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2020-10-30 23:03:50,205 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-30 23:03:50,205 Corpus: \"Corpus: 75188 train + 9604 dev + 9480 test sentences\"\n",
      "2020-10-30 23:03:50,206 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-30 23:03:50,206 Parameters:\n",
      "2020-10-30 23:03:50,206  - learning_rate: \"0.1\"\n",
      "2020-10-30 23:03:50,207  - mini_batch_size: \"32\"\n",
      "2020-10-30 23:03:50,207  - patience: \"3\"\n",
      "2020-10-30 23:03:50,207  - anneal_factor: \"0.5\"\n",
      "2020-10-30 23:03:50,208  - max_epochs: \"100\"\n",
      "2020-10-30 23:03:50,208  - shuffle: \"True\"\n",
      "2020-10-30 23:03:50,208  - train_with_dev: \"True\"\n",
      "2020-10-30 23:03:50,208  - batch_growth_annealing: \"False\"\n",
      "2020-10-30 23:03:50,209 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-30 23:03:50,209 Model training base path: \"models/taggers/ontonotes-pos\"\n",
      "2020-10-30 23:03:50,209 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-30 23:03:50,210 Device: cuda:0\n",
      "2020-10-30 23:03:50,210 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-30 23:03:50,210 Embeddings storage mode: none\n",
      "2020-10-30 23:03:50,213 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-30 23:07:00,521 epoch 1 - iter 265/2650 - loss 19.09905844 - samples/sec: 44.56 - lr: 0.100000\n",
      "2020-10-30 23:10:09,228 epoch 1 - iter 530/2650 - loss 13.62131010 - samples/sec: 44.94 - lr: 0.100000\n",
      "2020-10-30 23:13:26,245 epoch 1 - iter 795/2650 - loss 10.83545215 - samples/sec: 43.04 - lr: 0.100000\n",
      "2020-10-30 23:16:42,436 epoch 1 - iter 1060/2650 - loss 9.14086273 - samples/sec: 43.23 - lr: 0.100000\n",
      "2020-10-30 23:19:53,890 epoch 1 - iter 1325/2650 - loss 8.02292505 - samples/sec: 44.30 - lr: 0.100000\n",
      "2020-10-30 23:23:01,355 epoch 1 - iter 1590/2650 - loss 7.22809185 - samples/sec: 45.24 - lr: 0.100000\n",
      "2020-10-30 23:26:12,751 epoch 1 - iter 1855/2650 - loss 6.63031807 - samples/sec: 44.31 - lr: 0.100000\n",
      "2020-10-30 23:29:22,451 epoch 1 - iter 2120/2650 - loss 6.15313548 - samples/sec: 44.71 - lr: 0.100000\n",
      "2020-10-30 23:32:34,741 epoch 1 - iter 2385/2650 - loss 5.78028083 - samples/sec: 44.10 - lr: 0.100000\n",
      "2020-10-30 23:35:48,860 epoch 1 - iter 2650/2650 - loss 5.47532958 - samples/sec: 43.69 - lr: 0.100000\n",
      "2020-10-30 23:35:48,861 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-30 23:35:48,861 EPOCH 1 done: loss 5.4753 - lr 0.1000000\n",
      "2020-10-30 23:35:48,862 BAD EPOCHS (no improvement): 0\n",
      "2020-10-30 23:35:54,699 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-30 23:39:07,453 epoch 2 - iter 265/2650 - loss 2.73692470 - samples/sec: 44.00 - lr: 0.100000\n",
      "2020-10-30 23:42:20,612 epoch 2 - iter 530/2650 - loss 2.65829164 - samples/sec: 43.90 - lr: 0.100000\n",
      "2020-10-30 23:45:31,473 epoch 2 - iter 795/2650 - loss 2.61872671 - samples/sec: 44.43 - lr: 0.100000\n",
      "2020-10-30 23:48:41,580 epoch 2 - iter 1060/2650 - loss 2.60692467 - samples/sec: 44.61 - lr: 0.100000\n",
      "2020-10-30 23:51:53,496 epoch 2 - iter 1325/2650 - loss 2.60736108 - samples/sec: 44.19 - lr: 0.100000\n",
      "2020-10-30 23:54:59,180 epoch 2 - iter 1590/2650 - loss 2.58903785 - samples/sec: 45.67 - lr: 0.100000\n",
      "2020-10-30 23:58:11,336 epoch 2 - iter 1855/2650 - loss 2.59161309 - samples/sec: 44.13 - lr: 0.100000\n",
      "2020-10-31 00:01:24,216 epoch 2 - iter 2120/2650 - loss 2.58039064 - samples/sec: 43.97 - lr: 0.100000\n",
      "2020-10-31 00:04:33,676 epoch 2 - iter 2385/2650 - loss 2.57838149 - samples/sec: 44.76 - lr: 0.100000\n",
      "2020-10-31 00:07:51,022 epoch 2 - iter 2650/2650 - loss 2.56722703 - samples/sec: 42.97 - lr: 0.100000\n",
      "2020-10-31 00:07:51,023 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 00:07:51,023 EPOCH 2 done: loss 2.5672 - lr 0.1000000\n",
      "2020-10-31 00:07:51,024 BAD EPOCHS (no improvement): 0\n",
      "2020-10-31 00:07:56,907 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 00:11:10,618 epoch 3 - iter 265/2650 - loss 2.44434704 - samples/sec: 43.78 - lr: 0.100000\n",
      "2020-10-31 00:14:14,110 epoch 3 - iter 530/2650 - loss 2.44252043 - samples/sec: 46.22 - lr: 0.100000\n",
      "2020-10-31 00:17:27,320 epoch 3 - iter 795/2650 - loss 2.42499095 - samples/sec: 43.89 - lr: 0.100000\n",
      "2020-10-31 00:20:39,007 epoch 3 - iter 1060/2650 - loss 2.45024038 - samples/sec: 44.24 - lr: 0.100000\n",
      "2020-10-31 00:23:55,037 epoch 3 - iter 1325/2650 - loss 2.44890928 - samples/sec: 43.26 - lr: 0.100000\n",
      "2020-10-31 00:27:04,758 epoch 3 - iter 1590/2650 - loss 2.42892050 - samples/sec: 44.70 - lr: 0.100000\n",
      "2020-10-31 00:30:18,398 epoch 3 - iter 1855/2650 - loss 2.42675304 - samples/sec: 43.80 - lr: 0.100000\n",
      "2020-10-31 00:33:24,682 epoch 3 - iter 2120/2650 - loss 2.41890892 - samples/sec: 45.53 - lr: 0.100000\n",
      "2020-10-31 00:36:38,022 epoch 3 - iter 2385/2650 - loss 2.42626500 - samples/sec: 43.86 - lr: 0.100000\n",
      "2020-10-31 00:39:53,498 epoch 3 - iter 2650/2650 - loss 2.42680078 - samples/sec: 43.38 - lr: 0.100000\n",
      "2020-10-31 00:39:53,499 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 00:39:53,499 EPOCH 3 done: loss 2.4268 - lr 0.1000000\n",
      "2020-10-31 00:39:53,499 BAD EPOCHS (no improvement): 0\n",
      "2020-10-31 00:39:59,394 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 00:43:04,252 epoch 4 - iter 265/2650 - loss 2.37202320 - samples/sec: 45.88 - lr: 0.100000\n",
      "2020-10-31 00:46:11,080 epoch 4 - iter 530/2650 - loss 2.39501464 - samples/sec: 45.39 - lr: 0.100000\n",
      "2020-10-31 00:49:20,123 epoch 4 - iter 795/2650 - loss 2.40019269 - samples/sec: 44.86 - lr: 0.100000\n",
      "2020-10-31 00:52:36,781 epoch 4 - iter 1060/2650 - loss 2.39363103 - samples/sec: 43.12 - lr: 0.100000\n",
      "2020-10-31 00:55:48,634 epoch 4 - iter 1325/2650 - loss 2.39319208 - samples/sec: 44.20 - lr: 0.100000\n",
      "2020-10-31 00:59:02,553 epoch 4 - iter 1590/2650 - loss 2.38964202 - samples/sec: 43.73 - lr: 0.100000\n",
      "2020-10-31 01:02:17,233 epoch 4 - iter 1855/2650 - loss 2.38837412 - samples/sec: 43.56 - lr: 0.100000\n",
      "2020-10-31 01:05:28,006 epoch 4 - iter 2120/2650 - loss 2.39043158 - samples/sec: 44.45 - lr: 0.100000\n",
      "2020-10-31 01:08:47,598 epoch 4 - iter 2385/2650 - loss 2.39110248 - samples/sec: 42.49 - lr: 0.100000\n",
      "2020-10-31 01:11:55,357 epoch 4 - iter 2650/2650 - loss 2.39181594 - samples/sec: 45.17 - lr: 0.100000\n",
      "2020-10-31 01:11:55,358 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 01:11:55,358 EPOCH 4 done: loss 2.3918 - lr 0.1000000\n",
      "2020-10-31 01:11:55,358 BAD EPOCHS (no improvement): 0\n",
      "2020-10-31 01:12:01,257 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 01:15:08,771 epoch 5 - iter 265/2650 - loss 2.40593292 - samples/sec: 45.23 - lr: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-31 01:18:17,793 epoch 5 - iter 530/2650 - loss 2.35167194 - samples/sec: 44.87 - lr: 0.100000\n",
      "2020-10-31 01:21:28,802 epoch 5 - iter 795/2650 - loss 2.33863143 - samples/sec: 44.40 - lr: 0.100000\n",
      "2020-10-31 01:24:40,857 epoch 5 - iter 1060/2650 - loss 2.35425532 - samples/sec: 44.16 - lr: 0.100000\n",
      "2020-10-31 01:27:57,429 epoch 5 - iter 1325/2650 - loss 2.35761821 - samples/sec: 43.14 - lr: 0.100000\n",
      "2020-10-31 01:31:10,355 epoch 5 - iter 1590/2650 - loss 2.35989253 - samples/sec: 43.96 - lr: 0.100000\n",
      "2020-10-31 01:34:25,896 epoch 5 - iter 1855/2650 - loss 2.36756338 - samples/sec: 43.37 - lr: 0.100000\n",
      "2020-10-31 01:37:29,418 epoch 5 - iter 2120/2650 - loss 2.35625317 - samples/sec: 46.21 - lr: 0.100000\n",
      "2020-10-31 01:40:41,531 epoch 5 - iter 2385/2650 - loss 2.35640405 - samples/sec: 44.14 - lr: 0.100000\n",
      "2020-10-31 01:43:52,239 epoch 5 - iter 2650/2650 - loss 2.36594388 - samples/sec: 44.47 - lr: 0.100000\n",
      "2020-10-31 01:43:52,239 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 01:43:52,240 EPOCH 5 done: loss 2.3659 - lr 0.1000000\n",
      "2020-10-31 01:43:52,240 BAD EPOCHS (no improvement): 0\n",
      "2020-10-31 01:43:58,151 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 01:47:12,606 epoch 6 - iter 265/2650 - loss 2.34550326 - samples/sec: 43.61 - lr: 0.100000\n",
      "2020-10-31 01:50:20,672 epoch 6 - iter 530/2650 - loss 2.31827769 - samples/sec: 45.09 - lr: 0.100000\n",
      "2020-10-31 01:53:32,930 epoch 6 - iter 795/2650 - loss 2.31032008 - samples/sec: 44.11 - lr: 0.100000\n",
      "2020-10-31 01:56:42,352 epoch 6 - iter 1060/2650 - loss 2.32440718 - samples/sec: 44.77 - lr: 0.100000\n",
      "2020-10-31 01:59:51,607 epoch 6 - iter 1325/2650 - loss 2.32066645 - samples/sec: 44.81 - lr: 0.100000\n",
      "2020-10-31 02:03:06,811 epoch 6 - iter 1590/2650 - loss 2.32004656 - samples/sec: 43.44 - lr: 0.100000\n",
      "2020-10-31 02:06:20,176 epoch 6 - iter 1855/2650 - loss 2.32077715 - samples/sec: 43.86 - lr: 0.100000\n",
      "2020-10-31 02:09:32,871 epoch 6 - iter 2120/2650 - loss 2.33220985 - samples/sec: 44.01 - lr: 0.100000\n",
      "2020-10-31 02:12:43,642 epoch 6 - iter 2385/2650 - loss 2.33279345 - samples/sec: 44.45 - lr: 0.100000\n",
      "2020-10-31 02:15:53,925 epoch 6 - iter 2650/2650 - loss 2.33469185 - samples/sec: 44.57 - lr: 0.100000\n",
      "2020-10-31 02:15:53,926 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 02:15:53,926 EPOCH 6 done: loss 2.3347 - lr 0.1000000\n",
      "2020-10-31 02:15:53,927 BAD EPOCHS (no improvement): 0\n",
      "2020-10-31 02:15:59,847 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 02:19:09,685 epoch 7 - iter 265/2650 - loss 2.33137373 - samples/sec: 44.67 - lr: 0.100000\n",
      "2020-10-31 02:22:25,281 epoch 7 - iter 530/2650 - loss 2.32324527 - samples/sec: 43.36 - lr: 0.100000\n",
      "2020-10-31 02:25:40,273 epoch 7 - iter 795/2650 - loss 2.30934399 - samples/sec: 43.49 - lr: 0.100000\n",
      "2020-10-31 02:28:50,167 epoch 7 - iter 1060/2650 - loss 2.31096918 - samples/sec: 44.66 - lr: 0.100000\n",
      "2020-10-31 02:32:04,112 epoch 7 - iter 1325/2650 - loss 2.30995215 - samples/sec: 43.73 - lr: 0.100000\n",
      "2020-10-31 02:35:08,454 epoch 7 - iter 1590/2650 - loss 2.30836470 - samples/sec: 46.00 - lr: 0.100000\n",
      "2020-10-31 02:38:25,757 epoch 7 - iter 1855/2650 - loss 2.32071778 - samples/sec: 42.98 - lr: 0.100000\n",
      "2020-10-31 02:41:37,260 epoch 7 - iter 2120/2650 - loss 2.32381810 - samples/sec: 44.28 - lr: 0.100000\n",
      "2020-10-31 02:44:46,910 epoch 7 - iter 2385/2650 - loss 2.31819410 - samples/sec: 44.72 - lr: 0.100000\n",
      "2020-10-31 02:48:01,359 epoch 7 - iter 2650/2650 - loss 2.32550781 - samples/sec: 43.61 - lr: 0.100000\n",
      "2020-10-31 02:48:01,359 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 02:48:01,360 EPOCH 7 done: loss 2.3255 - lr 0.1000000\n",
      "2020-10-31 02:48:01,360 BAD EPOCHS (no improvement): 0\n",
      "2020-10-31 02:48:07,261 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 02:51:25,630 epoch 8 - iter 265/2650 - loss 2.36750222 - samples/sec: 42.75 - lr: 0.100000\n",
      "2020-10-31 02:54:31,254 epoch 8 - iter 530/2650 - loss 2.33087428 - samples/sec: 45.69 - lr: 0.100000\n",
      "2020-10-31 02:57:41,836 epoch 8 - iter 795/2650 - loss 2.32973780 - samples/sec: 44.50 - lr: 0.100000\n",
      "2020-10-31 03:00:54,092 epoch 8 - iter 1060/2650 - loss 2.33573156 - samples/sec: 44.11 - lr: 0.100000\n",
      "2020-10-31 03:04:07,006 epoch 8 - iter 1325/2650 - loss 2.34116915 - samples/sec: 43.96 - lr: 0.100000\n",
      "2020-10-31 03:07:15,178 epoch 8 - iter 1590/2650 - loss 2.34540957 - samples/sec: 45.07 - lr: 0.100000\n",
      "2020-10-31 03:10:25,201 epoch 8 - iter 1855/2650 - loss 2.33408037 - samples/sec: 44.63 - lr: 0.100000\n",
      "2020-10-31 03:13:38,251 epoch 8 - iter 2120/2650 - loss 2.32496675 - samples/sec: 43.93 - lr: 0.100000\n",
      "2020-10-31 03:16:54,475 epoch 8 - iter 2385/2650 - loss 2.33380237 - samples/sec: 43.22 - lr: 0.100000\n",
      "2020-10-31 03:20:06,123 epoch 8 - iter 2650/2650 - loss 2.33660483 - samples/sec: 44.25 - lr: 0.100000\n",
      "2020-10-31 03:20:06,124 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 03:20:06,124 EPOCH 8 done: loss 2.3366 - lr 0.1000000\n",
      "2020-10-31 03:20:06,125 BAD EPOCHS (no improvement): 1\n",
      "2020-10-31 03:20:12,143 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 03:23:19,616 epoch 9 - iter 265/2650 - loss 2.32258728 - samples/sec: 45.24 - lr: 0.100000\n",
      "2020-10-31 03:26:26,363 epoch 9 - iter 530/2650 - loss 2.32226876 - samples/sec: 45.41 - lr: 0.100000\n",
      "2020-10-31 03:29:35,324 epoch 9 - iter 795/2650 - loss 2.31933549 - samples/sec: 44.88 - lr: 0.100000\n",
      "2020-10-31 03:32:50,107 epoch 9 - iter 1060/2650 - loss 2.32499250 - samples/sec: 43.54 - lr: 0.100000\n",
      "2020-10-31 03:36:13,476 epoch 9 - iter 1325/2650 - loss 2.32772104 - samples/sec: 41.70 - lr: 0.100000\n",
      "2020-10-31 03:39:26,356 epoch 9 - iter 1590/2650 - loss 2.32322790 - samples/sec: 43.97 - lr: 0.100000\n",
      "2020-10-31 03:42:37,398 epoch 9 - iter 1855/2650 - loss 2.32075185 - samples/sec: 44.39 - lr: 0.100000\n",
      "2020-10-31 03:45:46,207 epoch 9 - iter 2120/2650 - loss 2.31105335 - samples/sec: 44.92 - lr: 0.100000\n",
      "2020-10-31 03:48:55,011 epoch 9 - iter 2385/2650 - loss 2.31194960 - samples/sec: 44.92 - lr: 0.100000\n",
      "2020-10-31 03:52:04,381 epoch 9 - iter 2650/2650 - loss 2.31573097 - samples/sec: 44.78 - lr: 0.100000\n",
      "2020-10-31 03:52:04,382 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 03:52:04,382 EPOCH 9 done: loss 2.3157 - lr 0.1000000\n",
      "2020-10-31 03:52:04,382 BAD EPOCHS (no improvement): 0\n",
      "2020-10-31 03:52:10,286 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 03:55:24,075 epoch 10 - iter 265/2650 - loss 2.29737189 - samples/sec: 43.76 - lr: 0.100000\n",
      "2020-10-31 03:58:30,332 epoch 10 - iter 530/2650 - loss 2.26716667 - samples/sec: 45.53 - lr: 0.100000\n",
      "2020-10-31 04:01:42,071 epoch 10 - iter 795/2650 - loss 2.29890683 - samples/sec: 44.23 - lr: 0.100000\n",
      "2020-10-31 04:04:50,572 epoch 10 - iter 1060/2650 - loss 2.27921062 - samples/sec: 44.99 - lr: 0.100000\n",
      "2020-10-31 04:08:11,075 epoch 10 - iter 1325/2650 - loss 2.29618006 - samples/sec: 42.30 - lr: 0.100000\n",
      "2020-10-31 04:11:21,601 epoch 10 - iter 1590/2650 - loss 2.29289283 - samples/sec: 44.51 - lr: 0.100000\n",
      "2020-10-31 04:14:32,175 epoch 10 - iter 1855/2650 - loss 2.29040017 - samples/sec: 44.50 - lr: 0.100000\n",
      "2020-10-31 04:17:42,851 epoch 10 - iter 2120/2650 - loss 2.29383146 - samples/sec: 44.48 - lr: 0.100000\n",
      "2020-10-31 04:20:53,711 epoch 10 - iter 2385/2650 - loss 2.28653088 - samples/sec: 44.43 - lr: 0.100000\n",
      "2020-10-31 04:24:00,796 epoch 10 - iter 2650/2650 - loss 2.29274647 - samples/sec: 45.33 - lr: 0.100000\n",
      "2020-10-31 04:24:00,797 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 04:24:00,797 EPOCH 10 done: loss 2.2927 - lr 0.1000000\n",
      "2020-10-31 04:24:00,797 BAD EPOCHS (no improvement): 0\n",
      "2020-10-31 04:24:06,825 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-31 04:27:19,537 epoch 11 - iter 265/2650 - loss 2.26305812 - samples/sec: 44.01 - lr: 0.100000\n",
      "2020-10-31 04:30:28,710 epoch 11 - iter 530/2650 - loss 2.27788934 - samples/sec: 44.83 - lr: 0.100000\n",
      "2020-10-31 04:33:39,076 epoch 11 - iter 795/2650 - loss 2.26249915 - samples/sec: 44.55 - lr: 0.100000\n",
      "2020-10-31 04:36:51,666 epoch 11 - iter 1060/2650 - loss 2.28012602 - samples/sec: 44.03 - lr: 0.100000\n",
      "2020-10-31 04:39:58,374 epoch 11 - iter 1325/2650 - loss 2.28141983 - samples/sec: 45.42 - lr: 0.100000\n",
      "2020-10-31 04:43:12,667 epoch 11 - iter 1590/2650 - loss 2.28381920 - samples/sec: 43.65 - lr: 0.100000\n",
      "2020-10-31 04:46:28,370 epoch 11 - iter 1855/2650 - loss 2.29653991 - samples/sec: 43.33 - lr: 0.100000\n",
      "2020-10-31 04:49:37,874 epoch 11 - iter 2120/2650 - loss 2.29520733 - samples/sec: 44.75 - lr: 0.100000\n",
      "2020-10-31 04:52:48,988 epoch 11 - iter 2385/2650 - loss 2.30810944 - samples/sec: 44.37 - lr: 0.100000\n",
      "2020-10-31 04:55:58,438 epoch 11 - iter 2650/2650 - loss 2.30928524 - samples/sec: 44.76 - lr: 0.100000\n",
      "2020-10-31 04:55:58,439 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 04:55:58,439 EPOCH 11 done: loss 2.3093 - lr 0.1000000\n",
      "2020-10-31 04:55:58,440 BAD EPOCHS (no improvement): 1\n",
      "2020-10-31 04:56:04,399 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 04:59:11,060 epoch 12 - iter 265/2650 - loss 2.36790797 - samples/sec: 45.43 - lr: 0.100000\n",
      "2020-10-31 05:02:19,718 epoch 12 - iter 530/2650 - loss 2.29611909 - samples/sec: 44.95 - lr: 0.100000\n",
      "2020-10-31 05:05:30,608 epoch 12 - iter 795/2650 - loss 2.28635934 - samples/sec: 44.43 - lr: 0.100000\n",
      "2020-10-31 05:08:45,342 epoch 12 - iter 1060/2650 - loss 2.28841932 - samples/sec: 43.55 - lr: 0.100000\n",
      "2020-10-31 05:11:57,271 epoch 12 - iter 1325/2650 - loss 2.29467378 - samples/sec: 44.19 - lr: 0.100000\n",
      "2020-10-31 05:15:08,447 epoch 12 - iter 1590/2650 - loss 2.30437510 - samples/sec: 44.36 - lr: 0.100000\n",
      "2020-10-31 05:18:18,808 epoch 12 - iter 1855/2650 - loss 2.30396518 - samples/sec: 44.55 - lr: 0.100000\n",
      "2020-10-31 05:21:33,213 epoch 12 - iter 2120/2650 - loss 2.30633493 - samples/sec: 43.62 - lr: 0.100000\n",
      "2020-10-31 05:24:48,548 epoch 12 - iter 2385/2650 - loss 2.30443048 - samples/sec: 43.42 - lr: 0.100000\n",
      "2020-10-31 05:27:58,679 epoch 12 - iter 2650/2650 - loss 2.30193036 - samples/sec: 44.60 - lr: 0.100000\n",
      "2020-10-31 05:27:58,680 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 05:27:58,681 EPOCH 12 done: loss 2.3019 - lr 0.1000000\n",
      "2020-10-31 05:27:58,681 BAD EPOCHS (no improvement): 2\n",
      "2020-10-31 05:28:04,636 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 05:31:18,998 epoch 13 - iter 265/2650 - loss 2.25761390 - samples/sec: 43.63 - lr: 0.100000\n",
      "2020-10-31 05:34:30,896 epoch 13 - iter 530/2650 - loss 2.30254449 - samples/sec: 44.19 - lr: 0.100000\n",
      "2020-10-31 05:37:43,437 epoch 13 - iter 795/2650 - loss 2.28531225 - samples/sec: 44.05 - lr: 0.100000\n",
      "2020-10-31 05:41:00,056 epoch 13 - iter 1060/2650 - loss 2.30490650 - samples/sec: 43.13 - lr: 0.100000\n",
      "2020-10-31 05:44:05,267 epoch 13 - iter 1325/2650 - loss 2.30163226 - samples/sec: 45.79 - lr: 0.100000\n",
      "2020-10-31 05:47:14,382 epoch 13 - iter 1590/2650 - loss 2.30058964 - samples/sec: 44.84 - lr: 0.100000\n",
      "2020-10-31 05:50:31,366 epoch 13 - iter 1855/2650 - loss 2.30190018 - samples/sec: 43.05 - lr: 0.100000\n",
      "2020-10-31 05:53:42,693 epoch 13 - iter 2120/2650 - loss 2.29784787 - samples/sec: 44.32 - lr: 0.100000\n",
      "2020-10-31 05:56:50,466 epoch 13 - iter 2385/2650 - loss 2.29633624 - samples/sec: 45.16 - lr: 0.100000\n",
      "2020-10-31 06:00:00,138 epoch 13 - iter 2650/2650 - loss 2.29693618 - samples/sec: 44.71 - lr: 0.100000\n",
      "2020-10-31 06:00:00,139 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 06:00:00,139 EPOCH 13 done: loss 2.2969 - lr 0.1000000\n",
      "2020-10-31 06:00:00,139 BAD EPOCHS (no improvement): 3\n",
      "2020-10-31 06:00:06,150 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 06:03:16,745 epoch 14 - iter 265/2650 - loss 2.31738871 - samples/sec: 44.50 - lr: 0.100000\n",
      "2020-10-31 06:06:26,545 epoch 14 - iter 530/2650 - loss 2.32801057 - samples/sec: 44.68 - lr: 0.100000\n",
      "2020-10-31 06:09:43,810 epoch 14 - iter 795/2650 - loss 2.34962274 - samples/sec: 42.99 - lr: 0.100000\n",
      "2020-10-31 06:12:54,869 epoch 14 - iter 1060/2650 - loss 2.34851674 - samples/sec: 44.39 - lr: 0.100000\n",
      "2020-10-31 06:16:10,062 epoch 14 - iter 1325/2650 - loss 2.34597371 - samples/sec: 43.45 - lr: 0.100000\n",
      "2020-10-31 06:19:20,614 epoch 14 - iter 1590/2650 - loss 2.32413006 - samples/sec: 44.51 - lr: 0.100000\n",
      "2020-10-31 06:22:34,489 epoch 14 - iter 1855/2650 - loss 2.31023343 - samples/sec: 43.74 - lr: 0.100000\n",
      "2020-10-31 06:25:43,142 epoch 14 - iter 2120/2650 - loss 2.29454551 - samples/sec: 44.95 - lr: 0.100000\n",
      "2020-10-31 06:28:49,003 epoch 14 - iter 2385/2650 - loss 2.29847101 - samples/sec: 45.63 - lr: 0.100000\n",
      "2020-10-31 06:31:57,842 epoch 14 - iter 2650/2650 - loss 2.28709129 - samples/sec: 44.91 - lr: 0.100000\n",
      "2020-10-31 06:31:57,842 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 06:31:57,843 EPOCH 14 done: loss 2.2871 - lr 0.1000000\n",
      "2020-10-31 06:31:57,843 BAD EPOCHS (no improvement): 0\n",
      "2020-10-31 06:32:03,740 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 06:35:11,094 epoch 15 - iter 265/2650 - loss 2.26005103 - samples/sec: 45.27 - lr: 0.100000\n",
      "2020-10-31 06:38:19,615 epoch 15 - iter 530/2650 - loss 2.25982636 - samples/sec: 44.98 - lr: 0.100000\n",
      "2020-10-31 06:41:33,579 epoch 15 - iter 795/2650 - loss 2.25133930 - samples/sec: 43.72 - lr: 0.100000\n",
      "2020-10-31 06:44:40,962 epoch 15 - iter 1060/2650 - loss 2.25025155 - samples/sec: 45.26 - lr: 0.100000\n",
      "2020-10-31 06:47:54,592 epoch 15 - iter 1325/2650 - loss 2.25650658 - samples/sec: 43.80 - lr: 0.100000\n",
      "2020-10-31 06:51:04,927 epoch 15 - iter 1590/2650 - loss 2.25635361 - samples/sec: 44.56 - lr: 0.100000\n",
      "2020-10-31 06:54:17,853 epoch 15 - iter 1855/2650 - loss 2.26120603 - samples/sec: 43.96 - lr: 0.100000\n",
      "2020-10-31 06:57:28,885 epoch 15 - iter 2120/2650 - loss 2.26214807 - samples/sec: 44.39 - lr: 0.100000\n",
      "2020-10-31 07:00:37,163 epoch 15 - iter 2385/2650 - loss 2.26641206 - samples/sec: 45.04 - lr: 0.100000\n",
      "2020-10-31 07:03:49,761 epoch 15 - iter 2650/2650 - loss 2.26567920 - samples/sec: 44.03 - lr: 0.100000\n",
      "2020-10-31 07:03:49,762 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 07:03:49,762 EPOCH 15 done: loss 2.2657 - lr 0.1000000\n",
      "2020-10-31 07:03:49,762 BAD EPOCHS (no improvement): 0\n",
      "2020-10-31 07:03:55,717 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 07:07:07,350 epoch 16 - iter 265/2650 - loss 2.36751134 - samples/sec: 44.25 - lr: 0.100000\n",
      "2020-10-31 07:10:26,182 epoch 16 - iter 530/2650 - loss 2.31617653 - samples/sec: 42.65 - lr: 0.100000\n",
      "2020-10-31 07:13:38,714 epoch 16 - iter 795/2650 - loss 2.31469644 - samples/sec: 44.05 - lr: 0.100000\n",
      "2020-10-31 07:16:44,061 epoch 16 - iter 1060/2650 - loss 2.28907219 - samples/sec: 45.76 - lr: 0.100000\n",
      "2020-10-31 07:19:55,093 epoch 16 - iter 1325/2650 - loss 2.28207238 - samples/sec: 44.39 - lr: 0.100000\n",
      "2020-10-31 07:23:04,641 epoch 16 - iter 1590/2650 - loss 2.28309062 - samples/sec: 44.74 - lr: 0.100000\n",
      "2020-10-31 07:26:12,671 epoch 16 - iter 1855/2650 - loss 2.27571589 - samples/sec: 45.10 - lr: 0.100000\n",
      "2020-10-31 07:29:29,508 epoch 16 - iter 2120/2650 - loss 2.28420415 - samples/sec: 43.08 - lr: 0.100000\n",
      "2020-10-31 07:32:40,198 epoch 16 - iter 2385/2650 - loss 2.28245829 - samples/sec: 44.47 - lr: 0.100000\n",
      "2020-10-31 07:35:52,658 epoch 16 - iter 2650/2650 - loss 2.28183910 - samples/sec: 44.06 - lr: 0.100000\n",
      "2020-10-31 07:35:52,659 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-31 07:35:52,659 EPOCH 16 done: loss 2.2818 - lr 0.1000000\n",
      "2020-10-31 07:35:52,659 BAD EPOCHS (no improvement): 1\n",
      "2020-10-31 07:35:58,514 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 07:39:14,177 epoch 17 - iter 265/2650 - loss 2.27007309 - samples/sec: 43.34 - lr: 0.100000\n",
      "2020-10-31 07:42:28,428 epoch 17 - iter 530/2650 - loss 2.30910558 - samples/sec: 43.66 - lr: 0.100000\n",
      "2020-10-31 07:45:36,090 epoch 17 - iter 795/2650 - loss 2.30589203 - samples/sec: 45.19 - lr: 0.100000\n",
      "2020-10-31 07:48:49,156 epoch 17 - iter 1060/2650 - loss 2.31545552 - samples/sec: 43.93 - lr: 0.100000\n",
      "2020-10-31 07:52:00,116 epoch 17 - iter 1325/2650 - loss 2.30370109 - samples/sec: 44.41 - lr: 0.100000\n",
      "2020-10-31 07:55:11,710 epoch 17 - iter 1590/2650 - loss 2.30119457 - samples/sec: 44.26 - lr: 0.100000\n",
      "2020-10-31 07:58:22,781 epoch 17 - iter 1855/2650 - loss 2.29584629 - samples/sec: 44.38 - lr: 0.100000\n",
      "2020-10-31 08:01:33,607 epoch 17 - iter 2120/2650 - loss 2.29189254 - samples/sec: 44.44 - lr: 0.100000\n",
      "2020-10-31 08:04:47,716 epoch 17 - iter 2385/2650 - loss 2.28705587 - samples/sec: 43.69 - lr: 0.100000\n",
      "2020-10-31 08:07:57,375 epoch 17 - iter 2650/2650 - loss 2.29717948 - samples/sec: 44.71 - lr: 0.100000\n",
      "2020-10-31 08:07:57,376 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 08:07:57,376 EPOCH 17 done: loss 2.2972 - lr 0.1000000\n",
      "2020-10-31 08:07:57,376 BAD EPOCHS (no improvement): 2\n",
      "2020-10-31 08:08:03,278 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 08:11:20,729 epoch 18 - iter 265/2650 - loss 2.26657923 - samples/sec: 42.95 - lr: 0.100000\n",
      "2020-10-31 08:14:36,133 epoch 18 - iter 530/2650 - loss 2.28264883 - samples/sec: 43.40 - lr: 0.100000\n",
      "2020-10-31 08:17:43,061 epoch 18 - iter 795/2650 - loss 2.27865075 - samples/sec: 45.37 - lr: 0.100000\n",
      "2020-10-31 08:20:53,195 epoch 18 - iter 1060/2650 - loss 2.28295836 - samples/sec: 44.60 - lr: 0.100000\n",
      "2020-10-31 08:24:06,240 epoch 18 - iter 1325/2650 - loss 2.27781455 - samples/sec: 43.93 - lr: 0.100000\n",
      "2020-10-31 08:27:23,254 epoch 18 - iter 1590/2650 - loss 2.27554568 - samples/sec: 43.05 - lr: 0.100000\n",
      "2020-10-31 08:30:30,925 epoch 18 - iter 1855/2650 - loss 2.27632781 - samples/sec: 45.19 - lr: 0.100000\n",
      "2020-10-31 08:33:41,516 epoch 18 - iter 2120/2650 - loss 2.27731321 - samples/sec: 44.50 - lr: 0.100000\n",
      "2020-10-31 08:36:51,758 epoch 18 - iter 2385/2650 - loss 2.27656486 - samples/sec: 44.58 - lr: 0.100000\n",
      "2020-10-31 08:39:57,823 epoch 18 - iter 2650/2650 - loss 2.27718151 - samples/sec: 45.58 - lr: 0.100000\n",
      "2020-10-31 08:39:57,824 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 08:39:57,824 EPOCH 18 done: loss 2.2772 - lr 0.1000000\n",
      "2020-10-31 08:39:57,825 BAD EPOCHS (no improvement): 3\n",
      "2020-10-31 08:40:03,680 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 08:43:23,151 epoch 19 - iter 265/2650 - loss 2.36209492 - samples/sec: 42.52 - lr: 0.100000\n",
      "2020-10-31 08:46:31,456 epoch 19 - iter 530/2650 - loss 2.31987442 - samples/sec: 45.04 - lr: 0.100000\n",
      "2020-10-31 08:49:47,953 epoch 19 - iter 795/2650 - loss 2.32136491 - samples/sec: 43.16 - lr: 0.100000\n",
      "2020-10-31 08:53:00,371 epoch 19 - iter 1060/2650 - loss 2.31143800 - samples/sec: 44.07 - lr: 0.100000\n",
      "2020-10-31 08:56:04,738 epoch 19 - iter 1325/2650 - loss 2.29607497 - samples/sec: 46.00 - lr: 0.100000\n",
      "2020-10-31 08:59:15,566 epoch 19 - iter 1590/2650 - loss 2.28731853 - samples/sec: 44.44 - lr: 0.100000\n",
      "2020-10-31 09:02:28,234 epoch 19 - iter 1855/2650 - loss 2.28366373 - samples/sec: 44.02 - lr: 0.100000\n",
      "2020-10-31 09:05:34,172 epoch 19 - iter 2120/2650 - loss 2.28984599 - samples/sec: 45.61 - lr: 0.100000\n",
      "2020-10-31 09:08:51,806 epoch 19 - iter 2385/2650 - loss 2.28572547 - samples/sec: 42.91 - lr: 0.100000\n",
      "2020-10-31 09:11:59,780 epoch 19 - iter 2650/2650 - loss 2.28070746 - samples/sec: 45.12 - lr: 0.100000\n",
      "2020-10-31 09:11:59,781 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 09:11:59,781 EPOCH 19 done: loss 2.2807 - lr 0.1000000\n",
      "Epoch    19: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2020-10-31 09:11:59,782 BAD EPOCHS (no improvement): 4\n",
      "2020-10-31 09:12:05,783 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 09:15:16,250 epoch 20 - iter 265/2650 - loss 1.53140531 - samples/sec: 44.53 - lr: 0.050000\n",
      "2020-10-31 09:18:29,547 epoch 20 - iter 530/2650 - loss 1.54211719 - samples/sec: 43.87 - lr: 0.050000\n",
      "2020-10-31 09:21:41,578 epoch 20 - iter 795/2650 - loss 1.52581649 - samples/sec: 44.16 - lr: 0.050000\n",
      "2020-10-31 09:24:54,380 epoch 20 - iter 1060/2650 - loss 1.51094487 - samples/sec: 43.99 - lr: 0.050000\n",
      "2020-10-31 09:28:10,140 epoch 20 - iter 1325/2650 - loss 1.51079921 - samples/sec: 43.32 - lr: 0.050000\n",
      "2020-10-31 09:31:23,543 epoch 20 - iter 1590/2650 - loss 1.50002344 - samples/sec: 43.85 - lr: 0.050000\n",
      "2020-10-31 09:34:33,772 epoch 20 - iter 1855/2650 - loss 1.50629232 - samples/sec: 44.58 - lr: 0.050000\n",
      "2020-10-31 09:37:45,657 epoch 20 - iter 2120/2650 - loss 1.50771849 - samples/sec: 44.20 - lr: 0.050000\n",
      "2020-10-31 09:41:01,099 epoch 20 - iter 2385/2650 - loss 1.50488738 - samples/sec: 43.39 - lr: 0.050000\n",
      "2020-10-31 09:44:01,261 epoch 20 - iter 2650/2650 - loss 1.50245426 - samples/sec: 47.07 - lr: 0.050000\n",
      "2020-10-31 09:44:01,262 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 09:44:01,262 EPOCH 20 done: loss 1.5025 - lr 0.0500000\n",
      "2020-10-31 09:44:01,263 BAD EPOCHS (no improvement): 0\n",
      "2020-10-31 09:44:07,185 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 09:47:18,997 epoch 21 - iter 265/2650 - loss 1.46996372 - samples/sec: 44.21 - lr: 0.050000\n",
      "2020-10-31 09:50:26,037 epoch 21 - iter 530/2650 - loss 1.49477372 - samples/sec: 45.34 - lr: 0.050000\n",
      "2020-10-31 09:53:37,641 epoch 21 - iter 795/2650 - loss 1.49702992 - samples/sec: 44.26 - lr: 0.050000\n",
      "2020-10-31 09:56:51,923 epoch 21 - iter 1060/2650 - loss 1.49334747 - samples/sec: 43.65 - lr: 0.050000\n",
      "2020-10-31 10:00:04,820 epoch 21 - iter 1325/2650 - loss 1.49131155 - samples/sec: 43.96 - lr: 0.050000\n",
      "2020-10-31 10:03:16,620 epoch 21 - iter 1590/2650 - loss 1.50328171 - samples/sec: 44.22 - lr: 0.050000\n",
      "2020-10-31 10:06:24,851 epoch 21 - iter 1855/2650 - loss 1.50571391 - samples/sec: 45.05 - lr: 0.050000\n",
      "2020-10-31 10:09:40,809 epoch 21 - iter 2120/2650 - loss 1.50239258 - samples/sec: 43.28 - lr: 0.050000\n",
      "2020-10-31 10:12:54,694 epoch 21 - iter 2385/2650 - loss 1.50023289 - samples/sec: 43.74 - lr: 0.050000\n",
      "2020-10-31 10:16:04,903 epoch 21 - iter 2650/2650 - loss 1.50063821 - samples/sec: 44.59 - lr: 0.050000\n",
      "2020-10-31 10:16:04,904 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 10:16:04,904 EPOCH 21 done: loss 1.5006 - lr 0.0500000\n",
      "2020-10-31 10:16:04,905 BAD EPOCHS (no improvement): 0\n",
      "2020-10-31 10:16:10,864 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 10:19:27,994 epoch 22 - iter 265/2650 - loss 1.50003371 - samples/sec: 43.02 - lr: 0.050000\n",
      "2020-10-31 10:22:33,608 epoch 22 - iter 530/2650 - loss 1.49359581 - samples/sec: 45.69 - lr: 0.050000\n",
      "2020-10-31 10:25:47,289 epoch 22 - iter 795/2650 - loss 1.49438444 - samples/sec: 43.79 - lr: 0.050000\n",
      "2020-10-31 10:29:06,457 epoch 22 - iter 1060/2650 - loss 1.50913118 - samples/sec: 42.58 - lr: 0.050000\n",
      "2020-10-31 10:32:20,324 epoch 22 - iter 1325/2650 - loss 1.50213325 - samples/sec: 43.74 - lr: 0.050000\n",
      "2020-10-31 10:35:25,611 epoch 22 - iter 1590/2650 - loss 1.49791569 - samples/sec: 45.77 - lr: 0.050000\n",
      "2020-10-31 10:38:38,440 epoch 22 - iter 1855/2650 - loss 1.50006188 - samples/sec: 43.98 - lr: 0.050000\n",
      "2020-10-31 10:41:46,354 epoch 22 - iter 2120/2650 - loss 1.50041052 - samples/sec: 45.13 - lr: 0.050000\n",
      "2020-10-31 10:44:52,225 epoch 22 - iter 2385/2650 - loss 1.49591713 - samples/sec: 45.63 - lr: 0.050000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-31 10:47:59,747 epoch 22 - iter 2650/2650 - loss 1.49423668 - samples/sec: 45.22 - lr: 0.050000\n",
      "2020-10-31 10:47:59,748 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 10:47:59,748 EPOCH 22 done: loss 1.4942 - lr 0.0500000\n",
      "2020-10-31 10:47:59,748 BAD EPOCHS (no improvement): 0\n",
      "2020-10-31 10:48:05,711 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 10:51:22,445 epoch 23 - iter 265/2650 - loss 1.51317963 - samples/sec: 43.11 - lr: 0.050000\n",
      "2020-10-31 10:54:33,920 epoch 23 - iter 530/2650 - loss 1.50244934 - samples/sec: 44.29 - lr: 0.050000\n",
      "2020-10-31 10:57:50,135 epoch 23 - iter 795/2650 - loss 1.49869032 - samples/sec: 43.22 - lr: 0.050000\n",
      "2020-10-31 11:00:58,325 epoch 23 - iter 1060/2650 - loss 1.50031695 - samples/sec: 45.06 - lr: 0.050000\n",
      "2020-10-31 11:04:12,196 epoch 23 - iter 1325/2650 - loss 1.50300252 - samples/sec: 43.74 - lr: 0.050000\n",
      "2020-10-31 11:07:19,566 epoch 23 - iter 1590/2650 - loss 1.50296023 - samples/sec: 45.26 - lr: 0.050000\n",
      "2020-10-31 11:10:32,170 epoch 23 - iter 1855/2650 - loss 1.50374309 - samples/sec: 44.03 - lr: 0.050000\n",
      "2020-10-31 11:13:40,609 epoch 23 - iter 2120/2650 - loss 1.50139439 - samples/sec: 45.00 - lr: 0.050000\n",
      "2020-10-31 11:16:49,897 epoch 23 - iter 2385/2650 - loss 1.50409280 - samples/sec: 44.80 - lr: 0.050000\n",
      "2020-10-31 11:20:00,327 epoch 23 - iter 2650/2650 - loss 1.50163423 - samples/sec: 44.53 - lr: 0.050000\n",
      "2020-10-31 11:20:00,328 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 11:20:00,328 EPOCH 23 done: loss 1.5016 - lr 0.0500000\n",
      "2020-10-31 11:20:00,328 BAD EPOCHS (no improvement): 1\n",
      "2020-10-31 11:20:06,215 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 11:23:17,241 epoch 24 - iter 265/2650 - loss 1.50239627 - samples/sec: 44.40 - lr: 0.050000\n",
      "2020-10-31 11:26:28,699 epoch 24 - iter 530/2650 - loss 1.50163472 - samples/sec: 44.29 - lr: 0.050000\n",
      "2020-10-31 11:29:41,649 epoch 24 - iter 795/2650 - loss 1.47821393 - samples/sec: 43.95 - lr: 0.050000\n",
      "2020-10-31 11:32:51,142 epoch 24 - iter 1060/2650 - loss 1.48597794 - samples/sec: 44.75 - lr: 0.050000\n",
      "2020-10-31 11:36:07,823 epoch 24 - iter 1325/2650 - loss 1.49285945 - samples/sec: 43.12 - lr: 0.050000\n",
      "2020-10-31 11:39:20,737 epoch 24 - iter 1590/2650 - loss 1.49497857 - samples/sec: 43.96 - lr: 0.050000\n",
      "2020-10-31 11:42:27,018 epoch 24 - iter 1855/2650 - loss 1.49561829 - samples/sec: 45.53 - lr: 0.050000\n",
      "2020-10-31 11:45:40,423 epoch 24 - iter 2120/2650 - loss 1.49101645 - samples/sec: 43.85 - lr: 0.050000\n",
      "2020-10-31 11:48:47,814 epoch 24 - iter 2385/2650 - loss 1.49168139 - samples/sec: 45.26 - lr: 0.050000\n",
      "2020-10-31 11:51:59,599 epoch 24 - iter 2650/2650 - loss 1.49193146 - samples/sec: 44.22 - lr: 0.050000\n",
      "2020-10-31 11:51:59,600 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 11:51:59,600 EPOCH 24 done: loss 1.4919 - lr 0.0500000\n",
      "2020-10-31 11:51:59,601 BAD EPOCHS (no improvement): 0\n",
      "2020-10-31 11:52:05,658 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 11:55:15,225 epoch 25 - iter 265/2650 - loss 1.45512838 - samples/sec: 44.74 - lr: 0.050000\n",
      "2020-10-31 11:58:24,408 epoch 25 - iter 530/2650 - loss 1.47142940 - samples/sec: 44.83 - lr: 0.050000\n",
      "2020-10-31 12:01:40,780 epoch 25 - iter 795/2650 - loss 1.48295114 - samples/sec: 43.19 - lr: 0.050000\n",
      "2020-10-31 12:04:53,153 epoch 25 - iter 1060/2650 - loss 1.47697372 - samples/sec: 44.08 - lr: 0.050000\n",
      "2020-10-31 12:08:08,945 epoch 25 - iter 1325/2650 - loss 1.48458861 - samples/sec: 43.31 - lr: 0.050000\n",
      "2020-10-31 12:11:22,658 epoch 25 - iter 1590/2650 - loss 1.48658789 - samples/sec: 43.78 - lr: 0.050000\n",
      "2020-10-31 12:14:28,796 epoch 25 - iter 1855/2650 - loss 1.48655608 - samples/sec: 45.56 - lr: 0.050000\n",
      "2020-10-31 12:17:45,137 epoch 25 - iter 2120/2650 - loss 1.48757635 - samples/sec: 43.19 - lr: 0.050000\n",
      "2020-10-31 12:20:54,050 epoch 25 - iter 2385/2650 - loss 1.48537971 - samples/sec: 44.89 - lr: 0.050000\n",
      "2020-10-31 12:24:03,787 epoch 25 - iter 2650/2650 - loss 1.48647747 - samples/sec: 44.70 - lr: 0.050000\n",
      "2020-10-31 12:24:03,788 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 12:24:03,788 EPOCH 25 done: loss 1.4865 - lr 0.0500000\n",
      "2020-10-31 12:24:03,789 BAD EPOCHS (no improvement): 0\n",
      "2020-10-31 12:24:09,684 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 12:27:17,067 epoch 26 - iter 265/2650 - loss 1.49758871 - samples/sec: 45.26 - lr: 0.050000\n",
      "2020-10-31 12:30:34,295 epoch 26 - iter 530/2650 - loss 1.47930905 - samples/sec: 43.00 - lr: 0.050000\n",
      "2020-10-31 12:33:41,334 epoch 26 - iter 795/2650 - loss 1.47727658 - samples/sec: 45.34 - lr: 0.050000\n",
      "2020-10-31 12:36:53,637 epoch 26 - iter 1060/2650 - loss 1.48320573 - samples/sec: 44.10 - lr: 0.050000\n",
      "2020-10-31 12:40:09,924 epoch 26 - iter 1325/2650 - loss 1.48676709 - samples/sec: 43.20 - lr: 0.050000\n",
      "2020-10-31 12:43:24,067 epoch 26 - iter 1590/2650 - loss 1.48390488 - samples/sec: 43.68 - lr: 0.050000\n",
      "2020-10-31 12:46:38,942 epoch 26 - iter 1855/2650 - loss 1.48397160 - samples/sec: 43.52 - lr: 0.050000\n",
      "2020-10-31 12:49:50,447 epoch 26 - iter 2120/2650 - loss 1.48567848 - samples/sec: 44.28 - lr: 0.050000\n",
      "2020-10-31 12:53:03,825 epoch 26 - iter 2385/2650 - loss 1.48889462 - samples/sec: 43.85 - lr: 0.050000\n",
      "2020-10-31 12:56:12,815 epoch 26 - iter 2650/2650 - loss 1.49400232 - samples/sec: 44.87 - lr: 0.050000\n",
      "2020-10-31 12:56:12,816 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 12:56:12,817 EPOCH 26 done: loss 1.4940 - lr 0.0500000\n",
      "2020-10-31 12:56:12,817 BAD EPOCHS (no improvement): 1\n",
      "2020-10-31 12:56:18,750 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 12:59:28,289 epoch 27 - iter 265/2650 - loss 1.50302248 - samples/sec: 44.74 - lr: 0.050000\n",
      "2020-10-31 13:02:41,693 epoch 27 - iter 530/2650 - loss 1.51478107 - samples/sec: 43.85 - lr: 0.050000\n",
      "2020-10-31 13:05:58,070 epoch 27 - iter 795/2650 - loss 1.50740385 - samples/sec: 43.18 - lr: 0.050000\n",
      "2020-10-31 13:09:12,106 epoch 27 - iter 1060/2650 - loss 1.50558977 - samples/sec: 43.71 - lr: 0.050000\n",
      "2020-10-31 13:12:22,021 epoch 27 - iter 1325/2650 - loss 1.49232361 - samples/sec: 44.65 - lr: 0.050000\n",
      "2020-10-31 13:15:32,451 epoch 27 - iter 1590/2650 - loss 1.49257692 - samples/sec: 44.53 - lr: 0.050000\n",
      "2020-10-31 13:18:44,238 epoch 27 - iter 1855/2650 - loss 1.48812406 - samples/sec: 44.22 - lr: 0.050000\n",
      "2020-10-31 13:21:51,170 epoch 27 - iter 2120/2650 - loss 1.48705523 - samples/sec: 45.37 - lr: 0.050000\n",
      "2020-10-31 13:25:03,843 epoch 27 - iter 2385/2650 - loss 1.48949986 - samples/sec: 44.02 - lr: 0.050000\n",
      "2020-10-31 13:28:16,342 epoch 27 - iter 2650/2650 - loss 1.48905603 - samples/sec: 44.06 - lr: 0.050000\n",
      "2020-10-31 13:28:16,343 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 13:28:16,343 EPOCH 27 done: loss 1.4891 - lr 0.0500000\n",
      "2020-10-31 13:28:16,344 BAD EPOCHS (no improvement): 2\n",
      "2020-10-31 13:28:22,301 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 13:31:38,568 epoch 28 - iter 265/2650 - loss 1.52456507 - samples/sec: 43.21 - lr: 0.050000\n",
      "2020-10-31 13:34:59,241 epoch 28 - iter 530/2650 - loss 1.51355372 - samples/sec: 42.26 - lr: 0.050000\n",
      "2020-10-31 13:38:11,883 epoch 28 - iter 795/2650 - loss 1.51623299 - samples/sec: 44.02 - lr: 0.050000\n",
      "2020-10-31 13:41:21,509 epoch 28 - iter 1060/2650 - loss 1.50919738 - samples/sec: 44.72 - lr: 0.050000\n",
      "2020-10-31 13:44:34,587 epoch 28 - iter 1325/2650 - loss 1.50306776 - samples/sec: 43.92 - lr: 0.050000\n",
      "2020-10-31 13:47:40,006 epoch 28 - iter 1590/2650 - loss 1.50172816 - samples/sec: 45.74 - lr: 0.050000\n",
      "2020-10-31 13:50:52,286 epoch 28 - iter 1855/2650 - loss 1.49766354 - samples/sec: 44.11 - lr: 0.050000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-31 13:54:00,812 epoch 28 - iter 2120/2650 - loss 1.49233444 - samples/sec: 44.98 - lr: 0.050000\n",
      "2020-10-31 13:57:13,517 epoch 28 - iter 2385/2650 - loss 1.49492994 - samples/sec: 44.01 - lr: 0.050000\n",
      "2020-10-31 14:00:25,715 epoch 28 - iter 2650/2650 - loss 1.49607755 - samples/sec: 44.12 - lr: 0.050000\n",
      "2020-10-31 14:00:25,716 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 14:00:25,717 EPOCH 28 done: loss 1.4961 - lr 0.0500000\n",
      "2020-10-31 14:00:25,717 BAD EPOCHS (no improvement): 3\n",
      "2020-10-31 14:00:31,620 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 14:03:44,242 epoch 29 - iter 265/2650 - loss 1.49367757 - samples/sec: 44.03 - lr: 0.050000\n",
      "2020-10-31 14:06:55,573 epoch 29 - iter 530/2650 - loss 1.51075876 - samples/sec: 44.32 - lr: 0.050000\n",
      "2020-10-31 14:10:03,376 epoch 29 - iter 795/2650 - loss 1.49596605 - samples/sec: 45.16 - lr: 0.050000\n",
      "2020-10-31 14:13:15,935 epoch 29 - iter 1060/2650 - loss 1.49253765 - samples/sec: 44.04 - lr: 0.050000\n",
      "2020-10-31 14:16:32,164 epoch 29 - iter 1325/2650 - loss 1.49563586 - samples/sec: 43.22 - lr: 0.050000\n",
      "2020-10-31 14:19:45,762 epoch 29 - iter 1590/2650 - loss 1.49881525 - samples/sec: 43.81 - lr: 0.050000\n",
      "2020-10-31 14:22:55,024 epoch 29 - iter 1855/2650 - loss 1.49970258 - samples/sec: 44.81 - lr: 0.050000\n",
      "2020-10-31 14:26:07,084 epoch 29 - iter 2120/2650 - loss 1.49534334 - samples/sec: 44.16 - lr: 0.050000\n",
      "2020-10-31 14:29:21,510 epoch 29 - iter 2385/2650 - loss 1.49426473 - samples/sec: 43.62 - lr: 0.050000\n",
      "2020-10-31 14:32:32,888 epoch 29 - iter 2650/2650 - loss 1.49101049 - samples/sec: 44.31 - lr: 0.050000\n",
      "2020-10-31 14:32:32,888 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 14:32:32,889 EPOCH 29 done: loss 1.4910 - lr 0.0500000\n",
      "Epoch    29: reducing learning rate of group 0 to 2.5000e-02.\n",
      "2020-10-31 14:32:32,889 BAD EPOCHS (no improvement): 4\n",
      "2020-10-31 14:32:38,870 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 14:35:55,490 epoch 30 - iter 265/2650 - loss 1.20939887 - samples/sec: 43.13 - lr: 0.025000\n",
      "2020-10-31 14:39:03,579 epoch 30 - iter 530/2650 - loss 1.21314923 - samples/sec: 45.09 - lr: 0.025000\n",
      "2020-10-31 14:42:09,448 epoch 30 - iter 795/2650 - loss 1.20134303 - samples/sec: 45.63 - lr: 0.025000\n",
      "2020-10-31 14:45:21,853 epoch 30 - iter 1060/2650 - loss 1.20279683 - samples/sec: 44.08 - lr: 0.025000\n",
      "2020-10-31 14:48:32,265 epoch 30 - iter 1325/2650 - loss 1.20258418 - samples/sec: 44.54 - lr: 0.025000\n",
      "2020-10-31 14:51:48,211 epoch 30 - iter 1590/2650 - loss 1.20006311 - samples/sec: 43.28 - lr: 0.025000\n",
      "2020-10-31 14:54:56,764 epoch 30 - iter 1855/2650 - loss 1.20189270 - samples/sec: 44.98 - lr: 0.025000\n",
      "2020-10-31 14:58:14,853 epoch 30 - iter 2120/2650 - loss 1.20379499 - samples/sec: 42.81 - lr: 0.025000\n",
      "2020-10-31 15:01:21,627 epoch 30 - iter 2385/2650 - loss 1.20233731 - samples/sec: 45.41 - lr: 0.025000\n",
      "2020-10-31 15:04:38,997 epoch 30 - iter 2650/2650 - loss 1.20201074 - samples/sec: 42.97 - lr: 0.025000\n",
      "2020-10-31 15:04:38,998 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 15:04:38,998 EPOCH 30 done: loss 1.2020 - lr 0.0250000\n",
      "2020-10-31 15:04:38,999 BAD EPOCHS (no improvement): 0\n",
      "2020-10-31 15:04:45,014 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 15:07:51,308 epoch 31 - iter 265/2650 - loss 1.19747521 - samples/sec: 45.52 - lr: 0.025000\n",
      "2020-10-31 15:11:07,359 epoch 31 - iter 530/2650 - loss 1.20486764 - samples/sec: 43.26 - lr: 0.025000\n",
      "2020-10-31 15:14:20,326 epoch 31 - iter 795/2650 - loss 1.21021477 - samples/sec: 43.95 - lr: 0.025000\n",
      "2020-10-31 15:17:26,733 epoch 31 - iter 1060/2650 - loss 1.20747870 - samples/sec: 45.50 - lr: 0.025000\n",
      "2020-10-31 15:20:38,497 epoch 31 - iter 1325/2650 - loss 1.20203292 - samples/sec: 44.22 - lr: 0.025000\n",
      "2020-10-31 15:23:47,590 epoch 31 - iter 1590/2650 - loss 1.19900991 - samples/sec: 44.85 - lr: 0.025000\n",
      "2020-10-31 15:27:02,860 epoch 31 - iter 1855/2650 - loss 1.20024334 - samples/sec: 43.43 - lr: 0.025000\n",
      "2020-10-31 15:30:20,418 epoch 31 - iter 2120/2650 - loss 1.20248134 - samples/sec: 42.93 - lr: 0.025000\n",
      "2020-10-31 15:33:31,799 epoch 31 - iter 2385/2650 - loss 1.20274490 - samples/sec: 44.31 - lr: 0.025000\n",
      "2020-10-31 15:36:46,948 epoch 31 - iter 2650/2650 - loss 1.20384517 - samples/sec: 43.46 - lr: 0.025000\n",
      "2020-10-31 15:36:46,949 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 15:36:46,949 EPOCH 31 done: loss 1.2038 - lr 0.0250000\n",
      "2020-10-31 15:36:46,950 BAD EPOCHS (no improvement): 1\n",
      "2020-10-31 15:36:52,914 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 15:40:07,551 epoch 32 - iter 265/2650 - loss 1.21127290 - samples/sec: 43.57 - lr: 0.025000\n",
      "2020-10-31 15:43:19,502 epoch 32 - iter 530/2650 - loss 1.19465213 - samples/sec: 44.18 - lr: 0.025000\n",
      "2020-10-31 15:46:36,324 epoch 32 - iter 795/2650 - loss 1.19915529 - samples/sec: 43.09 - lr: 0.025000\n",
      "2020-10-31 15:49:47,607 epoch 32 - iter 1060/2650 - loss 1.19544391 - samples/sec: 44.34 - lr: 0.025000\n",
      "2020-10-31 15:52:56,409 epoch 32 - iter 1325/2650 - loss 1.19238400 - samples/sec: 44.92 - lr: 0.025000\n",
      "2020-10-31 15:56:13,707 epoch 32 - iter 1590/2650 - loss 1.19449423 - samples/sec: 42.98 - lr: 0.025000\n",
      "2020-10-31 15:59:28,912 epoch 32 - iter 1855/2650 - loss 1.19503471 - samples/sec: 43.44 - lr: 0.025000\n",
      "2020-10-31 16:02:44,354 epoch 32 - iter 2120/2650 - loss 1.19338693 - samples/sec: 43.39 - lr: 0.025000\n",
      "2020-10-31 16:05:53,269 epoch 32 - iter 2385/2650 - loss 1.19585207 - samples/sec: 44.89 - lr: 0.025000\n",
      "2020-10-31 16:09:04,720 epoch 32 - iter 2650/2650 - loss 1.19619546 - samples/sec: 44.30 - lr: 0.025000\n",
      "2020-10-31 16:09:04,721 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 16:09:04,721 EPOCH 32 done: loss 1.1962 - lr 0.0250000\n",
      "2020-10-31 16:09:04,721 BAD EPOCHS (no improvement): 0\n",
      "2020-10-31 16:09:10,749 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 16:09:16,727 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 16:09:16,728 Exiting from training early.\n",
      "2020-10-31 16:09:16,728 Saving model ...\n",
      "2020-10-31 16:09:22,699 Done.\n",
      "2020-10-31 16:09:22,699 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-31 16:09:22,699 Testing using best model ...\n"
     ]
    }
   ],
   "source": [
    "# initialize sequence tagger\n",
    "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
    "                                        embeddings=embeddings,\n",
    "                                        tag_dictionary=tag_dictionary,\n",
    "                                        tag_type=tag_type)\n",
    "\n",
    "# initialize trainer\n",
    "\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "trainer.train('models/taggers/ontonotes-pos',\n",
    "              learning_rate=0.1,\n",
    "              train_with_dev=True,  \n",
    "              # it's a big dataset so maybe set embeddings_storage_mode to 'none' (embeddings are not kept in memory)\n",
    "              embeddings_storage_mode='none', \n",
    "              checkpoint=True\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-02 23:56:55,166 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-02 23:56:55,167 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings('crawl')\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.05, inplace=False)\n",
      "        (encoder): Embedding(300, 100)\n",
      "        (rnn): LSTM(100, 2048)\n",
      "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (list_embedding_2): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.05, inplace=False)\n",
      "        (encoder): Embedding(300, 100)\n",
      "        (rnn): LSTM(100, 2048)\n",
      "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=4396, out_features=4396, bias=True)\n",
      "  (rnn): LSTM(4396, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=28, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2020-11-02 23:56:55,168 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-02 23:56:55,168 Corpus: \"Corpus: 75188 train + 9604 dev + 9480 test sentences\"\n",
      "2020-11-02 23:56:55,169 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-02 23:56:55,169 Parameters:\n",
      "2020-11-02 23:56:55,170  - learning_rate: \"0.1\"\n",
      "2020-11-02 23:56:55,170  - mini_batch_size: \"32\"\n",
      "2020-11-02 23:56:55,171  - patience: \"3\"\n",
      "2020-11-02 23:56:55,171  - anneal_factor: \"0.5\"\n",
      "2020-11-02 23:56:55,172  - max_epochs: \"100\"\n",
      "2020-11-02 23:56:55,172  - shuffle: \"True\"\n",
      "2020-11-02 23:56:55,173  - train_with_dev: \"True\"\n",
      "2020-11-02 23:56:55,174  - batch_growth_annealing: \"False\"\n",
      "2020-11-02 23:56:55,174 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-02 23:56:55,175 Model training base path: \"models/taggers/ontonotes-pos\"\n",
      "2020-11-02 23:56:55,175 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-02 23:56:55,176 Device: cuda:0\n",
      "2020-11-02 23:56:55,176 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-02 23:56:55,177 Embeddings storage mode: none\n",
      "2020-11-02 23:56:55,179 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 00:00:02,271 epoch 77 - iter 265/2650 - loss 2.19626169 - samples/sec: 45.33 - lr: 0.100000\n",
      "2020-11-03 00:03:14,249 epoch 77 - iter 530/2650 - loss 2.18604647 - samples/sec: 44.17 - lr: 0.100000\n",
      "2020-11-03 00:06:23,392 epoch 77 - iter 795/2650 - loss 2.19625788 - samples/sec: 44.84 - lr: 0.100000\n",
      "2020-11-03 00:09:33,046 epoch 77 - iter 1060/2650 - loss 2.22611905 - samples/sec: 44.72 - lr: 0.100000\n",
      "2020-11-03 00:12:37,138 epoch 77 - iter 1325/2650 - loss 2.22403211 - samples/sec: 46.07 - lr: 0.100000\n",
      "2020-11-03 00:15:49,694 epoch 77 - iter 1590/2650 - loss 2.22315696 - samples/sec: 44.04 - lr: 0.100000\n",
      "2020-11-03 00:19:06,711 epoch 77 - iter 1855/2650 - loss 2.22286989 - samples/sec: 43.04 - lr: 0.100000\n",
      "2020-11-03 00:22:18,484 epoch 77 - iter 2120/2650 - loss 2.22484188 - samples/sec: 44.22 - lr: 0.100000\n",
      "2020-11-03 00:25:29,059 epoch 77 - iter 2385/2650 - loss 2.22222618 - samples/sec: 44.50 - lr: 0.100000\n",
      "2020-11-03 00:28:39,640 epoch 77 - iter 2650/2650 - loss 2.22054822 - samples/sec: 44.50 - lr: 0.100000\n",
      "2020-11-03 00:28:39,640 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 00:28:39,641 EPOCH 77 done: loss 2.2205 - lr 0.1000000\n",
      "2020-11-03 00:28:39,641 BAD EPOCHS (no improvement): 0\n",
      "2020-11-03 00:28:45,569 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 00:31:57,445 epoch 78 - iter 265/2650 - loss 2.18907132 - samples/sec: 44.20 - lr: 0.100000\n",
      "2020-11-03 00:35:05,717 epoch 78 - iter 530/2650 - loss 2.21771542 - samples/sec: 45.04 - lr: 0.100000\n",
      "2020-11-03 00:38:21,138 epoch 78 - iter 795/2650 - loss 2.20363382 - samples/sec: 43.40 - lr: 0.100000\n",
      "2020-11-03 00:41:30,517 epoch 78 - iter 1060/2650 - loss 2.21655388 - samples/sec: 44.78 - lr: 0.100000\n",
      "2020-11-03 00:44:44,215 epoch 78 - iter 1325/2650 - loss 2.22163050 - samples/sec: 43.78 - lr: 0.100000\n",
      "2020-11-03 00:47:54,534 epoch 78 - iter 1590/2650 - loss 2.21958636 - samples/sec: 44.56 - lr: 0.100000\n",
      "2020-11-03 00:51:05,098 epoch 78 - iter 1855/2650 - loss 2.22045983 - samples/sec: 44.50 - lr: 0.100000\n",
      "2020-11-03 00:54:19,825 epoch 78 - iter 2120/2650 - loss 2.22435742 - samples/sec: 43.55 - lr: 0.100000\n",
      "2020-11-03 00:57:25,150 epoch 78 - iter 2385/2650 - loss 2.23242182 - samples/sec: 45.76 - lr: 0.100000\n",
      "2020-11-03 01:00:39,009 epoch 78 - iter 2650/2650 - loss 2.23223608 - samples/sec: 43.75 - lr: 0.100000\n",
      "2020-11-03 01:00:39,010 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 01:00:39,010 EPOCH 78 done: loss 2.2322 - lr 0.1000000\n",
      "2020-11-03 01:00:39,011 BAD EPOCHS (no improvement): 1\n",
      "2020-11-03 01:00:45,002 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 01:03:55,160 epoch 79 - iter 265/2650 - loss 2.21179946 - samples/sec: 44.60 - lr: 0.100000\n",
      "2020-11-03 01:07:06,515 epoch 79 - iter 530/2650 - loss 2.17300360 - samples/sec: 44.32 - lr: 0.100000\n",
      "2020-11-03 01:10:13,641 epoch 79 - iter 795/2650 - loss 2.16212698 - samples/sec: 45.32 - lr: 0.100000\n",
      "2020-11-03 01:13:30,461 epoch 79 - iter 1060/2650 - loss 2.17327789 - samples/sec: 43.09 - lr: 0.100000\n",
      "2020-11-03 01:16:46,660 epoch 79 - iter 1325/2650 - loss 2.17664436 - samples/sec: 43.22 - lr: 0.100000\n",
      "2020-11-03 01:19:55,261 epoch 79 - iter 1590/2650 - loss 2.18783992 - samples/sec: 44.97 - lr: 0.100000\n",
      "2020-11-03 01:23:04,527 epoch 79 - iter 1855/2650 - loss 2.18726502 - samples/sec: 44.81 - lr: 0.100000\n",
      "2020-11-03 01:26:18,440 epoch 79 - iter 2120/2650 - loss 2.21063883 - samples/sec: 43.73 - lr: 0.100000\n",
      "2020-11-03 01:29:31,238 epoch 79 - iter 2385/2650 - loss 2.21536939 - samples/sec: 43.99 - lr: 0.100000\n",
      "2020-11-03 01:32:36,722 epoch 79 - iter 2650/2650 - loss 2.21266578 - samples/sec: 45.72 - lr: 0.100000\n",
      "2020-11-03 01:32:36,723 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 01:32:36,723 EPOCH 79 done: loss 2.2127 - lr 0.1000000\n",
      "2020-11-03 01:32:36,724 BAD EPOCHS (no improvement): 0\n",
      "2020-11-03 01:32:42,747 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 01:35:55,015 epoch 80 - iter 265/2650 - loss 2.13395390 - samples/sec: 44.11 - lr: 0.100000\n",
      "2020-11-03 01:39:07,232 epoch 80 - iter 530/2650 - loss 2.18779787 - samples/sec: 44.12 - lr: 0.100000\n",
      "2020-11-03 01:42:20,622 epoch 80 - iter 795/2650 - loss 2.20837346 - samples/sec: 43.85 - lr: 0.100000\n",
      "2020-11-03 01:45:34,237 epoch 80 - iter 1060/2650 - loss 2.22213746 - samples/sec: 43.80 - lr: 0.100000\n",
      "2020-11-03 01:48:43,303 epoch 80 - iter 1325/2650 - loss 2.22214263 - samples/sec: 44.85 - lr: 0.100000\n",
      "2020-11-03 01:51:51,356 epoch 80 - iter 1590/2650 - loss 2.21169898 - samples/sec: 45.10 - lr: 0.100000\n",
      "2020-11-03 01:55:01,869 epoch 80 - iter 1855/2650 - loss 2.21234725 - samples/sec: 44.51 - lr: 0.100000\n",
      "2020-11-03 01:58:19,872 epoch 80 - iter 2120/2650 - loss 2.21531164 - samples/sec: 42.83 - lr: 0.100000\n",
      "2020-11-03 02:01:32,652 epoch 80 - iter 2385/2650 - loss 2.22420495 - samples/sec: 43.99 - lr: 0.100000\n",
      "2020-11-03 02:04:41,850 epoch 80 - iter 2650/2650 - loss 2.22584427 - samples/sec: 44.82 - lr: 0.100000\n",
      "2020-11-03 02:04:41,851 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 02:04:41,851 EPOCH 80 done: loss 2.2258 - lr 0.1000000\n",
      "2020-11-03 02:04:41,852 BAD EPOCHS (no improvement): 1\n",
      "2020-11-03 02:04:47,889 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-03 02:08:09,089 epoch 81 - iter 265/2650 - loss 2.27419177 - samples/sec: 42.15 - lr: 0.100000\n",
      "2020-11-03 02:11:19,789 epoch 81 - iter 530/2650 - loss 2.25483339 - samples/sec: 44.47 - lr: 0.100000\n",
      "2020-11-03 02:14:29,717 epoch 81 - iter 795/2650 - loss 2.25330724 - samples/sec: 44.65 - lr: 0.100000\n",
      "2020-11-03 02:17:36,554 epoch 81 - iter 1060/2650 - loss 2.25417044 - samples/sec: 45.39 - lr: 0.100000\n",
      "2020-11-03 02:20:42,059 epoch 81 - iter 1325/2650 - loss 2.24131235 - samples/sec: 45.72 - lr: 0.100000\n",
      "2020-11-03 02:23:49,028 epoch 81 - iter 1590/2650 - loss 2.24311438 - samples/sec: 45.36 - lr: 0.100000\n",
      "2020-11-03 02:26:52,600 epoch 81 - iter 1855/2650 - loss 2.23395515 - samples/sec: 46.20 - lr: 0.100000\n",
      "2020-11-03 02:30:07,260 epoch 81 - iter 2120/2650 - loss 2.23587232 - samples/sec: 43.57 - lr: 0.100000\n",
      "2020-11-03 02:33:23,926 epoch 81 - iter 2385/2650 - loss 2.23530808 - samples/sec: 43.12 - lr: 0.100000\n",
      "2020-11-03 02:36:30,165 epoch 81 - iter 2650/2650 - loss 2.23188309 - samples/sec: 45.54 - lr: 0.100000\n",
      "2020-11-03 02:36:30,166 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 02:36:30,166 EPOCH 81 done: loss 2.2319 - lr 0.1000000\n",
      "2020-11-03 02:36:30,166 BAD EPOCHS (no improvement): 2\n",
      "2020-11-03 02:36:36,240 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 02:39:44,282 epoch 82 - iter 265/2650 - loss 2.22078207 - samples/sec: 45.10 - lr: 0.100000\n",
      "2020-11-03 02:42:55,691 epoch 82 - iter 530/2650 - loss 2.23142837 - samples/sec: 44.31 - lr: 0.100000\n",
      "2020-11-03 02:46:12,865 epoch 82 - iter 795/2650 - loss 2.25641554 - samples/sec: 43.01 - lr: 0.100000\n",
      "2020-11-03 02:49:19,128 epoch 82 - iter 1060/2650 - loss 2.24453905 - samples/sec: 45.53 - lr: 0.100000\n",
      "2020-11-03 02:52:34,218 epoch 82 - iter 1325/2650 - loss 2.22318018 - samples/sec: 43.47 - lr: 0.100000\n",
      "2020-11-03 02:55:44,464 epoch 82 - iter 1590/2650 - loss 2.22676500 - samples/sec: 44.58 - lr: 0.100000\n",
      "2020-11-03 02:58:56,854 epoch 82 - iter 1855/2650 - loss 2.23142836 - samples/sec: 44.08 - lr: 0.100000\n",
      "2020-11-03 03:02:07,282 epoch 82 - iter 2120/2650 - loss 2.23435495 - samples/sec: 44.53 - lr: 0.100000\n",
      "2020-11-03 03:05:20,869 epoch 82 - iter 2385/2650 - loss 2.23516088 - samples/sec: 43.81 - lr: 0.100000\n",
      "2020-11-03 03:08:27,416 epoch 82 - iter 2650/2650 - loss 2.23476080 - samples/sec: 45.46 - lr: 0.100000\n",
      "2020-11-03 03:08:27,416 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 03:08:27,417 EPOCH 82 done: loss 2.2348 - lr 0.1000000\n",
      "2020-11-03 03:08:27,418 BAD EPOCHS (no improvement): 3\n",
      "2020-11-03 03:08:33,486 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 03:11:40,775 epoch 83 - iter 265/2650 - loss 2.29480374 - samples/sec: 45.28 - lr: 0.100000\n",
      "2020-11-03 03:14:52,474 epoch 83 - iter 530/2650 - loss 2.23978714 - samples/sec: 44.24 - lr: 0.100000\n",
      "2020-11-03 03:18:00,572 epoch 83 - iter 795/2650 - loss 2.23577931 - samples/sec: 45.09 - lr: 0.100000\n",
      "2020-11-03 03:21:16,975 epoch 83 - iter 1060/2650 - loss 2.23201284 - samples/sec: 43.18 - lr: 0.100000\n",
      "2020-11-03 03:24:32,204 epoch 83 - iter 1325/2650 - loss 2.23162733 - samples/sec: 43.44 - lr: 0.100000\n",
      "2020-11-03 03:27:41,801 epoch 83 - iter 1590/2650 - loss 2.23073520 - samples/sec: 44.73 - lr: 0.100000\n",
      "2020-11-03 03:30:50,002 epoch 83 - iter 1855/2650 - loss 2.23264780 - samples/sec: 45.06 - lr: 0.100000\n",
      "2020-11-03 03:33:57,828 epoch 83 - iter 2120/2650 - loss 2.22766248 - samples/sec: 45.15 - lr: 0.100000\n",
      "2020-11-03 03:37:08,581 epoch 83 - iter 2385/2650 - loss 2.22864761 - samples/sec: 44.46 - lr: 0.100000\n",
      "2020-11-03 03:40:17,002 epoch 83 - iter 2650/2650 - loss 2.22603874 - samples/sec: 45.01 - lr: 0.100000\n",
      "2020-11-03 03:40:17,003 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 03:40:17,003 EPOCH 83 done: loss 2.2260 - lr 0.1000000\n",
      "Epoch     7: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2020-11-03 03:40:17,004 BAD EPOCHS (no improvement): 4\n",
      "2020-11-03 03:40:23,036 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 03:43:30,800 epoch 84 - iter 265/2650 - loss 1.45578244 - samples/sec: 45.17 - lr: 0.050000\n",
      "2020-11-03 03:46:44,742 epoch 84 - iter 530/2650 - loss 1.43078612 - samples/sec: 43.73 - lr: 0.050000\n",
      "2020-11-03 03:49:58,009 epoch 84 - iter 795/2650 - loss 1.43791614 - samples/sec: 43.88 - lr: 0.050000\n",
      "2020-11-03 03:53:11,630 epoch 84 - iter 1060/2650 - loss 1.45342714 - samples/sec: 43.80 - lr: 0.050000\n",
      "2020-11-03 03:56:21,377 epoch 84 - iter 1325/2650 - loss 1.45092536 - samples/sec: 44.69 - lr: 0.050000\n",
      "2020-11-03 03:59:34,287 epoch 84 - iter 1590/2650 - loss 1.45712094 - samples/sec: 43.96 - lr: 0.050000\n",
      "2020-11-03 04:02:35,259 epoch 84 - iter 1855/2650 - loss 1.45163478 - samples/sec: 46.86 - lr: 0.050000\n",
      "2020-11-03 04:05:47,841 epoch 84 - iter 2120/2650 - loss 1.45506589 - samples/sec: 44.04 - lr: 0.050000\n",
      "2020-11-03 04:08:57,274 epoch 84 - iter 2385/2650 - loss 1.45790242 - samples/sec: 44.77 - lr: 0.050000\n",
      "2020-11-03 04:12:11,696 epoch 84 - iter 2650/2650 - loss 1.45821749 - samples/sec: 43.62 - lr: 0.050000\n",
      "2020-11-03 04:12:11,696 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 04:12:11,697 EPOCH 84 done: loss 1.4582 - lr 0.0500000\n",
      "2020-11-03 04:12:11,697 BAD EPOCHS (no improvement): 0\n",
      "2020-11-03 04:12:17,796 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 04:15:27,553 epoch 85 - iter 265/2650 - loss 1.46297584 - samples/sec: 44.69 - lr: 0.050000\n",
      "2020-11-03 04:18:39,605 epoch 85 - iter 530/2650 - loss 1.47382836 - samples/sec: 44.16 - lr: 0.050000\n",
      "2020-11-03 04:21:47,207 epoch 85 - iter 795/2650 - loss 1.46625190 - samples/sec: 45.20 - lr: 0.050000\n",
      "2020-11-03 04:25:04,265 epoch 85 - iter 1060/2650 - loss 1.46382271 - samples/sec: 43.04 - lr: 0.050000\n",
      "2020-11-03 04:28:15,007 epoch 85 - iter 1325/2650 - loss 1.46979472 - samples/sec: 44.46 - lr: 0.050000\n",
      "2020-11-03 04:31:19,543 epoch 85 - iter 1590/2650 - loss 1.45853491 - samples/sec: 45.96 - lr: 0.050000\n",
      "2020-11-03 04:34:30,934 epoch 85 - iter 1855/2650 - loss 1.46252742 - samples/sec: 44.31 - lr: 0.050000\n",
      "2020-11-03 04:37:49,448 epoch 85 - iter 2120/2650 - loss 1.45994780 - samples/sec: 42.72 - lr: 0.050000\n",
      "2020-11-03 04:41:00,999 epoch 85 - iter 2385/2650 - loss 1.45859292 - samples/sec: 44.27 - lr: 0.050000\n",
      "2020-11-03 04:44:16,442 epoch 85 - iter 2650/2650 - loss 1.45717328 - samples/sec: 43.39 - lr: 0.050000\n",
      "2020-11-03 04:44:16,442 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 04:44:16,443 EPOCH 85 done: loss 1.4572 - lr 0.0500000\n",
      "2020-11-03 04:44:16,443 BAD EPOCHS (no improvement): 0\n",
      "2020-11-03 04:44:22,488 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 04:47:35,846 epoch 86 - iter 265/2650 - loss 1.46354791 - samples/sec: 43.86 - lr: 0.050000\n",
      "2020-11-03 04:50:45,851 epoch 86 - iter 530/2650 - loss 1.45984385 - samples/sec: 44.63 - lr: 0.050000\n",
      "2020-11-03 04:53:57,300 epoch 86 - iter 795/2650 - loss 1.44977639 - samples/sec: 44.30 - lr: 0.050000\n",
      "2020-11-03 04:57:10,146 epoch 86 - iter 1060/2650 - loss 1.44785670 - samples/sec: 43.98 - lr: 0.050000\n",
      "2020-11-03 05:00:18,980 epoch 86 - iter 1325/2650 - loss 1.44412039 - samples/sec: 44.91 - lr: 0.050000\n",
      "2020-11-03 05:03:29,045 epoch 86 - iter 1590/2650 - loss 1.43923142 - samples/sec: 44.62 - lr: 0.050000\n",
      "2020-11-03 05:06:41,463 epoch 86 - iter 1855/2650 - loss 1.44366041 - samples/sec: 44.07 - lr: 0.050000\n",
      "2020-11-03 05:09:52,584 epoch 86 - iter 2120/2650 - loss 1.44738950 - samples/sec: 44.37 - lr: 0.050000\n",
      "2020-11-03 05:12:54,724 epoch 86 - iter 2385/2650 - loss 1.44421182 - samples/sec: 46.56 - lr: 0.050000\n",
      "2020-11-03 05:16:15,178 epoch 86 - iter 2650/2650 - loss 1.44979368 - samples/sec: 42.31 - lr: 0.050000\n",
      "2020-11-03 05:16:15,179 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-03 05:16:15,179 EPOCH 86 done: loss 1.4498 - lr 0.0500000\n",
      "2020-11-03 05:16:15,179 BAD EPOCHS (no improvement): 0\n",
      "2020-11-03 05:16:21,208 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 05:19:33,265 epoch 87 - iter 265/2650 - loss 1.46422534 - samples/sec: 44.16 - lr: 0.050000\n",
      "2020-11-03 05:22:51,847 epoch 87 - iter 530/2650 - loss 1.46983711 - samples/sec: 42.71 - lr: 0.050000\n",
      "2020-11-03 05:26:03,974 epoch 87 - iter 795/2650 - loss 1.46093412 - samples/sec: 44.14 - lr: 0.050000\n",
      "2020-11-03 05:29:09,791 epoch 87 - iter 1060/2650 - loss 1.46080808 - samples/sec: 45.64 - lr: 0.050000\n",
      "2020-11-03 05:32:16,404 epoch 87 - iter 1325/2650 - loss 1.44980201 - samples/sec: 45.44 - lr: 0.050000\n",
      "2020-11-03 05:35:35,667 epoch 87 - iter 1590/2650 - loss 1.45737809 - samples/sec: 42.56 - lr: 0.050000\n",
      "2020-11-03 05:38:51,199 epoch 87 - iter 1855/2650 - loss 1.45427178 - samples/sec: 43.37 - lr: 0.050000\n",
      "2020-11-03 05:42:02,313 epoch 87 - iter 2120/2650 - loss 1.45437225 - samples/sec: 44.37 - lr: 0.050000\n",
      "2020-11-03 05:45:15,859 epoch 87 - iter 2385/2650 - loss 1.45691389 - samples/sec: 43.82 - lr: 0.050000\n",
      "2020-11-03 05:48:26,183 epoch 87 - iter 2650/2650 - loss 1.45024034 - samples/sec: 44.56 - lr: 0.050000\n",
      "2020-11-03 05:48:26,184 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 05:48:26,184 EPOCH 87 done: loss 1.4502 - lr 0.0500000\n",
      "2020-11-03 05:48:26,185 BAD EPOCHS (no improvement): 1\n",
      "2020-11-03 05:48:32,284 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 05:51:39,071 epoch 88 - iter 265/2650 - loss 1.40462452 - samples/sec: 45.40 - lr: 0.050000\n",
      "2020-11-03 05:54:54,356 epoch 88 - iter 530/2650 - loss 1.43483493 - samples/sec: 43.43 - lr: 0.050000\n",
      "2020-11-03 05:58:09,554 epoch 88 - iter 795/2650 - loss 1.44219293 - samples/sec: 43.45 - lr: 0.050000\n",
      "2020-11-03 06:01:18,265 epoch 88 - iter 1060/2650 - loss 1.44813465 - samples/sec: 44.94 - lr: 0.050000\n",
      "2020-11-03 06:04:32,253 epoch 88 - iter 1325/2650 - loss 1.44828969 - samples/sec: 43.72 - lr: 0.050000\n",
      "2020-11-03 06:07:41,724 epoch 88 - iter 1590/2650 - loss 1.44122716 - samples/sec: 44.76 - lr: 0.050000\n",
      "2020-11-03 06:10:54,576 epoch 88 - iter 1855/2650 - loss 1.44441516 - samples/sec: 43.97 - lr: 0.050000\n",
      "2020-11-03 06:14:07,061 epoch 88 - iter 2120/2650 - loss 1.44737823 - samples/sec: 44.06 - lr: 0.050000\n",
      "2020-11-03 06:17:21,268 epoch 88 - iter 2385/2650 - loss 1.44557220 - samples/sec: 43.67 - lr: 0.050000\n",
      "2020-11-03 06:20:32,973 epoch 88 - iter 2650/2650 - loss 1.44912600 - samples/sec: 44.24 - lr: 0.050000\n",
      "2020-11-03 06:20:32,974 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 06:20:32,974 EPOCH 88 done: loss 1.4491 - lr 0.0500000\n",
      "2020-11-03 06:20:32,975 BAD EPOCHS (no improvement): 0\n",
      "2020-11-03 06:20:38,984 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 06:23:50,175 epoch 89 - iter 265/2650 - loss 1.45464173 - samples/sec: 44.36 - lr: 0.050000\n",
      "2020-11-03 06:27:04,837 epoch 89 - iter 530/2650 - loss 1.45635318 - samples/sec: 43.57 - lr: 0.050000\n",
      "2020-11-03 06:30:17,271 epoch 89 - iter 795/2650 - loss 1.46905514 - samples/sec: 44.07 - lr: 0.050000\n",
      "2020-11-03 06:33:31,492 epoch 89 - iter 1060/2650 - loss 1.45903615 - samples/sec: 43.66 - lr: 0.050000\n",
      "2020-11-03 06:36:43,773 epoch 89 - iter 1325/2650 - loss 1.46082239 - samples/sec: 44.10 - lr: 0.050000\n",
      "2020-11-03 06:39:54,776 epoch 89 - iter 1590/2650 - loss 1.46450237 - samples/sec: 44.40 - lr: 0.050000\n",
      "2020-11-03 06:43:05,985 epoch 89 - iter 1855/2650 - loss 1.46381120 - samples/sec: 44.35 - lr: 0.050000\n",
      "2020-11-03 06:46:19,122 epoch 89 - iter 2120/2650 - loss 1.46555542 - samples/sec: 43.91 - lr: 0.050000\n",
      "2020-11-03 06:49:28,082 epoch 89 - iter 2385/2650 - loss 1.46340488 - samples/sec: 44.88 - lr: 0.050000\n",
      "2020-11-03 06:52:38,659 epoch 89 - iter 2650/2650 - loss 1.46333621 - samples/sec: 44.50 - lr: 0.050000\n",
      "2020-11-03 06:52:38,660 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 06:52:38,660 EPOCH 89 done: loss 1.4633 - lr 0.0500000\n",
      "2020-11-03 06:52:38,660 BAD EPOCHS (no improvement): 1\n",
      "2020-11-03 06:52:44,631 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 06:55:55,384 epoch 90 - iter 265/2650 - loss 1.51045979 - samples/sec: 44.46 - lr: 0.050000\n",
      "2020-11-03 06:59:06,627 epoch 90 - iter 530/2650 - loss 1.47642095 - samples/sec: 44.34 - lr: 0.050000\n",
      "2020-11-03 07:02:21,459 epoch 90 - iter 795/2650 - loss 1.46733642 - samples/sec: 43.53 - lr: 0.050000\n",
      "2020-11-03 07:05:32,244 epoch 90 - iter 1060/2650 - loss 1.47265720 - samples/sec: 44.45 - lr: 0.050000\n",
      "2020-11-03 07:08:46,967 epoch 90 - iter 1325/2650 - loss 1.47289729 - samples/sec: 43.55 - lr: 0.050000\n",
      "2020-11-03 07:12:02,167 epoch 90 - iter 1590/2650 - loss 1.46445129 - samples/sec: 43.45 - lr: 0.050000\n",
      "2020-11-03 07:15:12,374 epoch 90 - iter 1855/2650 - loss 1.46498312 - samples/sec: 44.59 - lr: 0.050000\n",
      "2020-11-03 07:18:22,200 epoch 90 - iter 2120/2650 - loss 1.46464320 - samples/sec: 44.68 - lr: 0.050000\n",
      "2020-11-03 07:21:34,586 epoch 90 - iter 2385/2650 - loss 1.46533755 - samples/sec: 44.08 - lr: 0.050000\n",
      "2020-11-03 07:24:41,626 epoch 90 - iter 2650/2650 - loss 1.46044559 - samples/sec: 45.34 - lr: 0.050000\n",
      "2020-11-03 07:24:41,627 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 07:24:41,628 EPOCH 90 done: loss 1.4604 - lr 0.0500000\n",
      "2020-11-03 07:24:41,628 BAD EPOCHS (no improvement): 2\n",
      "2020-11-03 07:24:47,632 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 07:28:00,647 epoch 91 - iter 265/2650 - loss 1.48972692 - samples/sec: 43.94 - lr: 0.050000\n",
      "2020-11-03 07:31:20,266 epoch 91 - iter 530/2650 - loss 1.46349794 - samples/sec: 42.48 - lr: 0.050000\n",
      "2020-11-03 07:34:36,766 epoch 91 - iter 795/2650 - loss 1.45620887 - samples/sec: 43.16 - lr: 0.050000\n",
      "2020-11-03 07:37:45,802 epoch 91 - iter 1060/2650 - loss 1.45003511 - samples/sec: 44.86 - lr: 0.050000\n",
      "2020-11-03 07:40:58,041 epoch 91 - iter 1325/2650 - loss 1.45509092 - samples/sec: 44.11 - lr: 0.050000\n",
      "2020-11-03 07:44:18,822 epoch 91 - iter 1590/2650 - loss 1.45393856 - samples/sec: 42.24 - lr: 0.050000\n",
      "2020-11-03 07:47:19,758 epoch 91 - iter 1855/2650 - loss 1.45374504 - samples/sec: 46.87 - lr: 0.050000\n",
      "2020-11-03 07:50:29,639 epoch 91 - iter 2120/2650 - loss 1.45069067 - samples/sec: 44.66 - lr: 0.050000\n",
      "2020-11-03 07:53:41,429 epoch 91 - iter 2385/2650 - loss 1.45175523 - samples/sec: 44.22 - lr: 0.050000\n",
      "2020-11-03 07:56:56,753 epoch 91 - iter 2650/2650 - loss 1.44822438 - samples/sec: 43.42 - lr: 0.050000\n",
      "2020-11-03 07:56:56,754 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 07:56:56,754 EPOCH 91 done: loss 1.4482 - lr 0.0500000\n",
      "2020-11-03 07:56:56,755 BAD EPOCHS (no improvement): 0\n",
      "2020-11-03 07:57:02,797 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 08:00:15,049 epoch 92 - iter 265/2650 - loss 1.43906484 - samples/sec: 44.11 - lr: 0.050000\n",
      "2020-11-03 08:03:21,836 epoch 92 - iter 530/2650 - loss 1.43947713 - samples/sec: 45.40 - lr: 0.050000\n",
      "2020-11-03 08:06:29,544 epoch 92 - iter 795/2650 - loss 1.44396527 - samples/sec: 45.18 - lr: 0.050000\n",
      "2020-11-03 08:09:43,803 epoch 92 - iter 1060/2650 - loss 1.43855504 - samples/sec: 43.66 - lr: 0.050000\n",
      "2020-11-03 08:12:53,123 epoch 92 - iter 1325/2650 - loss 1.44112022 - samples/sec: 44.79 - lr: 0.050000\n",
      "2020-11-03 08:16:03,509 epoch 92 - iter 1590/2650 - loss 1.44557201 - samples/sec: 44.54 - lr: 0.050000\n",
      "2020-11-03 08:19:24,310 epoch 92 - iter 1855/2650 - loss 1.45109401 - samples/sec: 42.23 - lr: 0.050000\n",
      "2020-11-03 08:22:38,013 epoch 92 - iter 2120/2650 - loss 1.45240422 - samples/sec: 43.78 - lr: 0.050000\n",
      "2020-11-03 08:25:48,229 epoch 92 - iter 2385/2650 - loss 1.45077497 - samples/sec: 44.58 - lr: 0.050000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-03 08:29:04,811 epoch 92 - iter 2650/2650 - loss 1.45273500 - samples/sec: 43.14 - lr: 0.050000\n",
      "2020-11-03 08:29:04,811 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 08:29:04,812 EPOCH 92 done: loss 1.4527 - lr 0.0500000\n",
      "2020-11-03 08:29:04,812 BAD EPOCHS (no improvement): 1\n",
      "2020-11-03 08:29:10,798 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 08:32:22,647 epoch 93 - iter 265/2650 - loss 1.42957536 - samples/sec: 44.20 - lr: 0.050000\n",
      "2020-11-03 08:35:29,369 epoch 93 - iter 530/2650 - loss 1.44931692 - samples/sec: 45.42 - lr: 0.050000\n",
      "2020-11-03 08:38:40,718 epoch 93 - iter 795/2650 - loss 1.45013816 - samples/sec: 44.32 - lr: 0.050000\n",
      "2020-11-03 08:41:57,609 epoch 93 - iter 1060/2650 - loss 1.44894879 - samples/sec: 43.07 - lr: 0.050000\n",
      "2020-11-03 08:45:09,085 epoch 93 - iter 1325/2650 - loss 1.44910877 - samples/sec: 44.29 - lr: 0.050000\n",
      "2020-11-03 08:48:22,797 epoch 93 - iter 1590/2650 - loss 1.45133101 - samples/sec: 43.78 - lr: 0.050000\n",
      "2020-11-03 08:51:33,665 epoch 93 - iter 1855/2650 - loss 1.45194393 - samples/sec: 44.43 - lr: 0.050000\n",
      "2020-11-03 08:54:42,341 epoch 93 - iter 2120/2650 - loss 1.45846307 - samples/sec: 44.95 - lr: 0.050000\n",
      "2020-11-03 08:57:53,643 epoch 93 - iter 2385/2650 - loss 1.45600896 - samples/sec: 44.33 - lr: 0.050000\n",
      "2020-11-03 09:01:04,492 epoch 93 - iter 2650/2650 - loss 1.45954779 - samples/sec: 44.44 - lr: 0.050000\n",
      "2020-11-03 09:01:04,492 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 09:01:04,493 EPOCH 93 done: loss 1.4595 - lr 0.0500000\n",
      "2020-11-03 09:01:04,493 BAD EPOCHS (no improvement): 2\n",
      "2020-11-03 09:01:10,477 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 09:04:18,395 epoch 94 - iter 265/2650 - loss 1.44521621 - samples/sec: 45.13 - lr: 0.050000\n",
      "2020-11-03 09:07:33,009 epoch 94 - iter 530/2650 - loss 1.43768966 - samples/sec: 43.58 - lr: 0.050000\n",
      "2020-11-03 09:10:43,158 epoch 94 - iter 795/2650 - loss 1.45615750 - samples/sec: 44.60 - lr: 0.050000\n",
      "2020-11-03 09:13:57,971 epoch 94 - iter 1060/2650 - loss 1.45886562 - samples/sec: 43.53 - lr: 0.050000\n",
      "2020-11-03 09:17:05,357 epoch 94 - iter 1325/2650 - loss 1.45383307 - samples/sec: 45.26 - lr: 0.050000\n",
      "2020-11-03 09:20:14,765 epoch 94 - iter 1590/2650 - loss 1.45167628 - samples/sec: 44.77 - lr: 0.050000\n",
      "2020-11-03 09:23:28,787 epoch 94 - iter 1855/2650 - loss 1.46177359 - samples/sec: 43.71 - lr: 0.050000\n",
      "2020-11-03 09:26:35,601 epoch 94 - iter 2120/2650 - loss 1.45345840 - samples/sec: 45.40 - lr: 0.050000\n",
      "2020-11-03 09:29:47,565 epoch 94 - iter 2385/2650 - loss 1.45348869 - samples/sec: 44.18 - lr: 0.050000\n",
      "2020-11-03 09:32:59,893 epoch 94 - iter 2650/2650 - loss 1.45262419 - samples/sec: 44.09 - lr: 0.050000\n",
      "2020-11-03 09:32:59,894 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 09:32:59,895 EPOCH 94 done: loss 1.4526 - lr 0.0500000\n",
      "2020-11-03 09:32:59,895 BAD EPOCHS (no improvement): 3\n",
      "2020-11-03 09:33:05,945 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 09:36:18,206 epoch 95 - iter 265/2650 - loss 1.41845614 - samples/sec: 44.11 - lr: 0.050000\n",
      "2020-11-03 09:39:24,844 epoch 95 - iter 530/2650 - loss 1.44100133 - samples/sec: 45.44 - lr: 0.050000\n",
      "2020-11-03 09:42:43,303 epoch 95 - iter 795/2650 - loss 1.44912822 - samples/sec: 42.73 - lr: 0.050000\n",
      "2020-11-03 09:45:59,280 epoch 95 - iter 1060/2650 - loss 1.46016029 - samples/sec: 43.27 - lr: 0.050000\n",
      "2020-11-03 09:49:06,486 epoch 95 - iter 1325/2650 - loss 1.45604203 - samples/sec: 45.30 - lr: 0.050000\n",
      "2020-11-03 09:52:14,194 epoch 95 - iter 1590/2650 - loss 1.44999860 - samples/sec: 45.18 - lr: 0.050000\n",
      "2020-11-03 09:55:19,518 epoch 95 - iter 1855/2650 - loss 1.44850155 - samples/sec: 45.76 - lr: 0.050000\n",
      "2020-11-03 09:58:34,856 epoch 95 - iter 2120/2650 - loss 1.45001458 - samples/sec: 43.41 - lr: 0.050000\n",
      "2020-11-03 10:01:53,069 epoch 95 - iter 2385/2650 - loss 1.44820326 - samples/sec: 42.78 - lr: 0.050000\n",
      "2020-11-03 10:05:23,661 epoch 95 - iter 2650/2650 - loss 1.45157503 - samples/sec: 40.27 - lr: 0.050000\n",
      "2020-11-03 10:05:23,665 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 10:05:23,666 EPOCH 95 done: loss 1.4516 - lr 0.0500000\n",
      "Epoch    19: reducing learning rate of group 0 to 2.5000e-02.\n",
      "2020-11-03 10:05:23,667 BAD EPOCHS (no improvement): 4\n",
      "2020-11-03 10:05:30,494 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 10:08:53,652 epoch 96 - iter 265/2650 - loss 1.20311689 - samples/sec: 41.74 - lr: 0.025000\n",
      "2020-11-03 10:12:16,328 epoch 96 - iter 530/2650 - loss 1.18896743 - samples/sec: 41.84 - lr: 0.025000\n",
      "2020-11-03 10:15:39,744 epoch 96 - iter 795/2650 - loss 1.18231032 - samples/sec: 41.69 - lr: 0.025000\n",
      "2020-11-03 10:18:57,752 epoch 96 - iter 1060/2650 - loss 1.17889846 - samples/sec: 42.83 - lr: 0.025000\n",
      "2020-11-03 10:22:13,092 epoch 96 - iter 1325/2650 - loss 1.17753179 - samples/sec: 43.41 - lr: 0.025000\n",
      "2020-11-03 10:25:24,295 epoch 96 - iter 1590/2650 - loss 1.17682858 - samples/sec: 44.35 - lr: 0.025000\n",
      "2020-11-03 10:28:37,357 epoch 96 - iter 1855/2650 - loss 1.17188005 - samples/sec: 43.93 - lr: 0.025000\n",
      "2020-11-03 10:31:49,212 epoch 96 - iter 2120/2650 - loss 1.16905953 - samples/sec: 44.20 - lr: 0.025000\n",
      "2020-11-03 10:34:57,691 epoch 96 - iter 2385/2650 - loss 1.16776022 - samples/sec: 44.99 - lr: 0.025000\n",
      "2020-11-03 10:38:14,753 epoch 96 - iter 2650/2650 - loss 1.16918029 - samples/sec: 43.04 - lr: 0.025000\n",
      "2020-11-03 10:38:14,754 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 10:38:14,754 EPOCH 96 done: loss 1.1692 - lr 0.0250000\n",
      "2020-11-03 10:38:14,755 BAD EPOCHS (no improvement): 0\n",
      "2020-11-03 10:38:20,960 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 10:41:38,529 epoch 97 - iter 265/2650 - loss 1.15478886 - samples/sec: 42.93 - lr: 0.025000\n",
      "2020-11-03 10:44:49,792 epoch 97 - iter 530/2650 - loss 1.15081276 - samples/sec: 44.34 - lr: 0.025000\n",
      "2020-11-03 10:48:03,963 epoch 97 - iter 795/2650 - loss 1.15912724 - samples/sec: 43.68 - lr: 0.025000\n",
      "2020-11-03 10:51:14,169 epoch 97 - iter 1060/2650 - loss 1.16321359 - samples/sec: 44.59 - lr: 0.025000\n",
      "2020-11-03 10:54:25,997 epoch 97 - iter 1325/2650 - loss 1.16171715 - samples/sec: 44.21 - lr: 0.025000\n",
      "2020-11-03 10:57:40,870 epoch 97 - iter 1590/2650 - loss 1.16220698 - samples/sec: 43.52 - lr: 0.025000\n",
      "2020-11-03 11:01:04,468 epoch 97 - iter 1855/2650 - loss 1.16598083 - samples/sec: 41.65 - lr: 0.025000\n",
      "2020-11-03 11:04:22,561 epoch 97 - iter 2120/2650 - loss 1.16709609 - samples/sec: 42.81 - lr: 0.025000\n",
      "2020-11-03 11:07:36,705 epoch 97 - iter 2385/2650 - loss 1.16618012 - samples/sec: 43.68 - lr: 0.025000\n",
      "2020-11-03 11:10:51,277 epoch 97 - iter 2650/2650 - loss 1.16581844 - samples/sec: 43.59 - lr: 0.025000\n",
      "2020-11-03 11:10:51,278 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 11:10:51,278 EPOCH 97 done: loss 1.1658 - lr 0.0250000\n",
      "2020-11-03 11:10:51,279 BAD EPOCHS (no improvement): 0\n",
      "2020-11-03 11:10:57,389 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 11:14:09,069 epoch 98 - iter 265/2650 - loss 1.16597717 - samples/sec: 44.25 - lr: 0.025000\n",
      "2020-11-03 11:17:25,604 epoch 98 - iter 530/2650 - loss 1.15744537 - samples/sec: 43.15 - lr: 0.025000\n",
      "2020-11-03 11:20:37,396 epoch 98 - iter 795/2650 - loss 1.16238232 - samples/sec: 44.22 - lr: 0.025000\n",
      "2020-11-03 11:23:56,644 epoch 98 - iter 1060/2650 - loss 1.17125316 - samples/sec: 42.56 - lr: 0.025000\n",
      "2020-11-03 11:27:15,955 epoch 98 - iter 1325/2650 - loss 1.16908818 - samples/sec: 42.55 - lr: 0.025000\n",
      "2020-11-03 11:30:30,214 epoch 98 - iter 1590/2650 - loss 1.16676454 - samples/sec: 43.66 - lr: 0.025000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-03 11:33:41,490 epoch 98 - iter 1855/2650 - loss 1.16749422 - samples/sec: 44.34 - lr: 0.025000\n",
      "2020-11-03 11:36:59,448 epoch 98 - iter 2120/2650 - loss 1.16489176 - samples/sec: 42.84 - lr: 0.025000\n",
      "2020-11-03 11:40:14,392 epoch 98 - iter 2385/2650 - loss 1.16614878 - samples/sec: 43.50 - lr: 0.025000\n",
      "2020-11-03 11:43:24,993 epoch 98 - iter 2650/2650 - loss 1.16703117 - samples/sec: 44.49 - lr: 0.025000\n",
      "2020-11-03 11:43:24,993 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 11:43:24,994 EPOCH 98 done: loss 1.1670 - lr 0.0250000\n",
      "2020-11-03 11:43:24,994 BAD EPOCHS (no improvement): 1\n",
      "2020-11-03 11:43:31,005 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 11:46:51,165 epoch 99 - iter 265/2650 - loss 1.18048681 - samples/sec: 42.37 - lr: 0.025000\n",
      "2020-11-03 11:50:02,650 epoch 99 - iter 530/2650 - loss 1.17623984 - samples/sec: 44.29 - lr: 0.025000\n",
      "2020-11-03 11:53:08,469 epoch 99 - iter 795/2650 - loss 1.16732254 - samples/sec: 45.64 - lr: 0.025000\n",
      "2020-11-03 11:56:27,435 epoch 99 - iter 1060/2650 - loss 1.16477468 - samples/sec: 42.62 - lr: 0.025000\n",
      "2020-11-03 11:59:44,089 epoch 99 - iter 1325/2650 - loss 1.16437193 - samples/sec: 43.12 - lr: 0.025000\n",
      "2020-11-03 12:02:56,795 epoch 99 - iter 1590/2650 - loss 1.16867159 - samples/sec: 44.01 - lr: 0.025000\n",
      "2020-11-03 12:06:08,846 epoch 99 - iter 1855/2650 - loss 1.17235469 - samples/sec: 44.16 - lr: 0.025000\n",
      "2020-11-03 12:09:20,957 epoch 99 - iter 2120/2650 - loss 1.17209634 - samples/sec: 44.14 - lr: 0.025000\n",
      "2020-11-03 12:12:30,312 epoch 99 - iter 2385/2650 - loss 1.16809907 - samples/sec: 44.79 - lr: 0.025000\n",
      "2020-11-03 12:15:42,932 epoch 99 - iter 2650/2650 - loss 1.16889193 - samples/sec: 44.03 - lr: 0.025000\n",
      "2020-11-03 12:15:42,932 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 12:15:42,932 EPOCH 99 done: loss 1.1689 - lr 0.0250000\n",
      "2020-11-03 12:15:42,933 BAD EPOCHS (no improvement): 2\n",
      "2020-11-03 12:15:48,939 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 12:19:03,738 epoch 100 - iter 265/2650 - loss 1.18904143 - samples/sec: 43.54 - lr: 0.025000\n",
      "2020-11-03 12:22:13,181 epoch 100 - iter 530/2650 - loss 1.17263267 - samples/sec: 44.77 - lr: 0.025000\n",
      "2020-11-03 12:25:23,068 epoch 100 - iter 795/2650 - loss 1.16534259 - samples/sec: 44.66 - lr: 0.025000\n",
      "2020-11-03 12:28:32,791 epoch 100 - iter 1060/2650 - loss 1.16343251 - samples/sec: 44.70 - lr: 0.025000\n",
      "2020-11-03 12:31:50,581 epoch 100 - iter 1325/2650 - loss 1.16741237 - samples/sec: 42.88 - lr: 0.025000\n",
      "2020-11-03 12:35:07,446 epoch 100 - iter 1590/2650 - loss 1.17175664 - samples/sec: 43.08 - lr: 0.025000\n",
      "2020-11-03 12:38:18,694 epoch 100 - iter 1855/2650 - loss 1.16892769 - samples/sec: 44.34 - lr: 0.025000\n",
      "2020-11-03 12:41:24,052 epoch 100 - iter 2120/2650 - loss 1.16966874 - samples/sec: 45.75 - lr: 0.025000\n",
      "2020-11-03 12:44:35,012 epoch 100 - iter 2385/2650 - loss 1.16875093 - samples/sec: 44.41 - lr: 0.025000\n",
      "2020-11-03 12:47:54,319 epoch 100 - iter 2650/2650 - loss 1.16676813 - samples/sec: 42.55 - lr: 0.025000\n",
      "2020-11-03 12:47:54,320 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 12:47:54,320 EPOCH 100 done: loss 1.1668 - lr 0.0250000\n",
      "2020-11-03 12:47:54,321 BAD EPOCHS (no improvement): 3\n",
      "2020-11-03 12:48:06,710 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-03 12:48:06,711 Testing using best model ...\n",
      "2020-11-03 12:50:47,590 \t0.5935\n",
      "2020-11-03 12:50:47,591 \n",
      "Results:\n",
      "- F-score (micro) 0.5935\n",
      "- F-score (macro) 0.1102\n",
      "- Accuracy 0.5935\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    document     1.0000    1.0000    1.0000       696\n",
      "           0     0.8081    0.9571    0.8763     98497\n",
      "           4     0.1156    0.9141    0.2052      6657\n",
      "           1     1.0000    0.0000    0.0000     17120\n",
      "           8     0.0397    0.0074    0.0125      1487\n",
      "           2     1.0000    0.0000    0.0000     13404\n",
      "           3     1.0000    0.0000    0.0000      7548\n",
      "           5     1.0000    0.0000    0.0000      5797\n",
      "           6     1.0000    0.0000    0.0000      5255\n",
      "           7     1.0000    0.0000    0.0000      2633\n",
      "           9     1.0000    0.0000    0.0000      1217\n",
      "          10     1.0000    0.0000    0.0000      2058\n",
      "          11     1.0000    0.0000    0.0000      2884\n",
      "          12     1.0000    0.0000    0.0000      1056\n",
      "          13     1.0000    0.0000    0.0000      1209\n",
      "          14     1.0000    0.0000    0.0000       887\n",
      "          15     1.0000    0.0000    0.0000       741\n",
      "          16     1.0000    0.0000    0.0000       595\n",
      "          17     1.0000    0.0000    0.0000       534\n",
      "\n",
      "    accuracy                         0.5935    170275\n",
      "   macro avg     0.8928    0.1515    0.1102    170275\n",
      "weighted avg     0.8460    0.5935    0.5191    170275\n",
      "\n",
      "2020-11-03 12:50:47,591 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.5935,\n",
       " 'dev_score_history': [],\n",
       " 'train_loss_history': [2.220548223684419,\n",
       "  2.2322360849380494,\n",
       "  2.212665776992744,\n",
       "  2.2258442742532156,\n",
       "  2.2318830942432837,\n",
       "  2.234760799419205,\n",
       "  2.2260387383879356,\n",
       "  1.4582174939479469,\n",
       "  1.4571732783879874,\n",
       "  1.44979367571057,\n",
       "  1.4502403410313265,\n",
       "  1.4491260002356656,\n",
       "  1.4633362090812538,\n",
       "  1.4604455889171024,\n",
       "  1.4482243834351594,\n",
       "  1.452734996822645,\n",
       "  1.4595477888044321,\n",
       "  1.4526241859062663,\n",
       "  1.4515750320452565,\n",
       "  1.1691802895743892,\n",
       "  1.165818441543939,\n",
       "  1.1670311651589735,\n",
       "  1.1688919344375719,\n",
       "  1.1667681279159943],\n",
       " 'dev_loss_history': []}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "checkpoint = 'models/taggers/ontonotes-pos/checkpoint.pt'\n",
    "trainer = ModelTrainer.load_checkpoint(checkpoint, corpus)\n",
    "trainer.train('models/taggers/ontonotes-pos',\n",
    "              learning_rate=0.1,\n",
    "              train_with_dev=True,  \n",
    "              # it's a big dataset so maybe set embeddings_storage_mode to 'none' (embeddings are not kept in memory)\n",
    "              embeddings_storage_mode='none', \n",
    "              checkpoint=True\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
